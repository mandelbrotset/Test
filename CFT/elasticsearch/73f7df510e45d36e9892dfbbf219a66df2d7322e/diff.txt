diff --git a/core/src/main/java/org/apache/lucene/queries/ExtendedCommonTermsQuery.java b/core/src/main/java/org/apache/lucene/queries/ExtendedCommonTermsQuery.java
index 1889c6e..e09c555 100644
--- a/core/src/main/java/org/apache/lucene/queries/ExtendedCommonTermsQuery.java
+++ b/core/src/main/java/org/apache/lucene/queries/ExtendedCommonTermsQuery.java
@@ -76,10 +76,6 @@ public class ExtendedCommonTermsQuery extends CommonTermsQuery {
         return lowFreqMinNumShouldMatchSpec;
     }
 
-    public float getMaxTermFrequency() {
-        return this.maxTermFrequency;
-    }
-
     @Override
     protected Query newTermQuery(Term term, TermContext context) {
         if (fieldType == null) {
diff --git a/core/src/main/java/org/apache/lucene/queryparser/classic/ExistsFieldQueryExtension.java b/core/src/main/java/org/apache/lucene/queryparser/classic/ExistsFieldQueryExtension.java
index cb4bee3..6cac629 100644
--- a/core/src/main/java/org/apache/lucene/queryparser/classic/ExistsFieldQueryExtension.java
+++ b/core/src/main/java/org/apache/lucene/queryparser/classic/ExistsFieldQueryExtension.java
@@ -21,8 +21,8 @@ package org.apache.lucene.queryparser.classic;
 
 import org.apache.lucene.search.ConstantScoreQuery;
 import org.apache.lucene.search.Query;
-import org.elasticsearch.index.query.ExistsQueryBuilder;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.ExistsQueryParser;
+import org.elasticsearch.index.query.QueryParseContext;
 
 /**
  *
@@ -32,7 +32,7 @@ public class ExistsFieldQueryExtension implements FieldQueryExtension {
     public static final String NAME = "_exists_";
 
     @Override
-    public Query query(QueryShardContext context, String queryText) {
-        return new ConstantScoreQuery(ExistsQueryBuilder.newFilter(context, queryText));
+    public Query query(QueryParseContext parseContext, String queryText) {
+        return new ConstantScoreQuery(ExistsQueryParser.newFilter(parseContext, queryText, null));
     }
 }
diff --git a/core/src/main/java/org/apache/lucene/queryparser/classic/FieldQueryExtension.java b/core/src/main/java/org/apache/lucene/queryparser/classic/FieldQueryExtension.java
index 299a37a..003ff18 100644
--- a/core/src/main/java/org/apache/lucene/queryparser/classic/FieldQueryExtension.java
+++ b/core/src/main/java/org/apache/lucene/queryparser/classic/FieldQueryExtension.java
@@ -20,12 +20,12 @@
 package org.apache.lucene.queryparser.classic;
 
 import org.apache.lucene.search.Query;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 
 /**
  *
  */
 public interface FieldQueryExtension {
 
-    Query query(QueryShardContext context, String queryText);
+    Query query(QueryParseContext parseContext, String queryText);
 }
diff --git a/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java b/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java
index 34fdcfc..1585acd 100644
--- a/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java
+++ b/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java
@@ -19,21 +19,31 @@
 
 package org.apache.lucene.queryparser.classic;
 
-import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.search.*;
+import org.apache.lucene.search.BooleanClause;
+import org.apache.lucene.search.DisjunctionMaxQuery;
+import org.apache.lucene.search.FilteredQuery;
+import org.apache.lucene.search.FuzzyQuery;
+import org.apache.lucene.search.MatchNoDocsQuery;
+import org.apache.lucene.search.MultiPhraseQuery;
+import org.apache.lucene.search.PhraseQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.WildcardQuery;
+import org.apache.lucene.util.Version;
 import org.apache.lucene.util.automaton.RegExp;
 import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.unit.Fuzziness;
 import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.mapper.core.DateFieldMapper;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.support.QueryParsers;
 
+import com.google.common.collect.ImmutableMap;
+
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Collection;
@@ -60,27 +70,53 @@ public class MapperQueryParser extends QueryParser {
                 .build();
     }
 
-    private final QueryShardContext context;
+    private final QueryParseContext parseContext;
 
     private QueryParserSettings settings;
 
+    private Analyzer quoteAnalyzer;
+
+    private boolean forcedAnalyzer;
+    private boolean forcedQuoteAnalyzer;
+
     private MappedFieldType currentFieldType;
 
-    public MapperQueryParser(QueryShardContext context) {
+    private boolean analyzeWildcard;
+
+    private String quoteFieldSuffix;
+
+    public MapperQueryParser(QueryParseContext parseContext) {
         super(null, null);
-        this.context = context;
+        this.parseContext = parseContext;
     }
 
     public void reset(QueryParserSettings settings) {
         this.settings = settings;
-        if (settings.fieldsAndWeights().isEmpty()) {
-            this.field = settings.defaultField();
-        } else if (settings.fieldsAndWeights().size() == 1) {
-            this.field = settings.fieldsAndWeights().keySet().iterator().next();
+        this.field = settings.defaultField();
+
+        if (settings.fields() != null) {
+            if (settings.fields.size() == 1) {
+                // just mark it as the default field
+                this.field = settings.fields().get(0);
+            } else {
+                // otherwise, we need to have the default field being null...
+                this.field = null;
+            }
+        }
+
+        this.forcedAnalyzer = settings.forcedAnalyzer() != null;
+        this.setAnalyzer(forcedAnalyzer ? settings.forcedAnalyzer() : settings.defaultAnalyzer());
+        if (settings.forcedQuoteAnalyzer() != null) {
+            this.forcedQuoteAnalyzer = true;
+            this.quoteAnalyzer = settings.forcedQuoteAnalyzer();
+        } else if (forcedAnalyzer) {
+            this.forcedQuoteAnalyzer = true;
+            this.quoteAnalyzer = settings.forcedAnalyzer();
         } else {
-            this.field = null;
+            this.forcedAnalyzer = false;
+            this.quoteAnalyzer = settings.defaultQuoteAnalyzer();
         }
-        setAnalyzer(settings.analyzer());
+        this.quoteFieldSuffix = settings.quoteFieldSuffix();
         setMultiTermRewriteMethod(settings.rewriteMethod());
         setEnablePositionIncrements(settings.enablePositionIncrements());
         setAutoGeneratePhraseQueries(settings.autoGeneratePhraseQueries());
@@ -89,9 +125,10 @@ public class MapperQueryParser extends QueryParser {
         setLowercaseExpandedTerms(settings.lowercaseExpandedTerms());
         setPhraseSlop(settings.phraseSlop());
         setDefaultOperator(settings.defaultOperator());
-        setFuzzyMinSim(settings.fuzziness().asFloat());
+        setFuzzyMinSim(settings.getFuzziness().asFloat());
         setFuzzyPrefixLength(settings.fuzzyPrefixLength());
         setLocale(settings.locale());
+        this.analyzeWildcard = settings.analyzeWildcard();
     }
 
     /**
@@ -125,7 +162,7 @@ public class MapperQueryParser extends QueryParser {
     public Query getFieldQuery(String field, String queryText, boolean quoted) throws ParseException {
         FieldQueryExtension fieldQueryExtension = fieldQueryExtensions.get(field);
         if (fieldQueryExtension != null) {
-            return fieldQueryExtension.query(context, queryText);
+            return fieldQueryExtension.query(parseContext, queryText);
         }
         Collection<String> fields = extractMultiFields(field);
         if (fields != null) {
@@ -187,29 +224,29 @@ public class MapperQueryParser extends QueryParser {
         Analyzer oldAnalyzer = getAnalyzer();
         try {
             if (quoted) {
-                setAnalyzer(settings.quoteAnalyzer());
-                if (settings.quoteFieldSuffix() != null) {
-                    currentFieldType = context.fieldMapper(field + settings.quoteFieldSuffix());
+                setAnalyzer(quoteAnalyzer);
+                if (quoteFieldSuffix != null) {
+                    currentFieldType = parseContext.fieldMapper(field + quoteFieldSuffix);
                 }
             }
             if (currentFieldType == null) {
-                currentFieldType = context.fieldMapper(field);
+                currentFieldType = parseContext.fieldMapper(field);
             }
             if (currentFieldType != null) {
                 if (quoted) {
-                    if (!settings.forceQuoteAnalyzer()) {
-                        setAnalyzer(context.getSearchQuoteAnalyzer(currentFieldType));
+                    if (!forcedQuoteAnalyzer) {
+                        setAnalyzer(parseContext.getSearchQuoteAnalyzer(currentFieldType));
                     }
                 } else {
-                    if (!settings.forceAnalyzer()) {
-                        setAnalyzer(context.getSearchAnalyzer(currentFieldType));
+                    if (!forcedAnalyzer) {
+                        setAnalyzer(parseContext.getSearchAnalyzer(currentFieldType));
                     }
                 }
                 if (currentFieldType != null) {
                     Query query = null;
                     if (currentFieldType.useTermQueryWithQueryString()) {
                         try {
-                            query = currentFieldType.termQuery(queryText, context);
+                            query = currentFieldType.termQuery(queryText, parseContext);
                         } catch (RuntimeException e) {
                             if (settings.lenient()) {
                                 return null;
@@ -320,7 +357,7 @@ public class MapperQueryParser extends QueryParser {
     }
 
     private Query getRangeQuerySingle(String field, String part1, String part2, boolean startInclusive, boolean endInclusive) {
-        currentFieldType = context.fieldMapper(field);
+        currentFieldType = parseContext.fieldMapper(field);
         if (currentFieldType != null) {
             if (lowercaseExpandedTerms && !currentFieldType.isNumeric()) {
                 part1 = part1 == null ? null : part1.toLowerCase(locale);
@@ -385,7 +422,7 @@ public class MapperQueryParser extends QueryParser {
     }
 
     private Query getFuzzyQuerySingle(String field, String termStr, String minSimilarity) throws ParseException {
-        currentFieldType = context.fieldMapper(field);
+        currentFieldType = parseContext.fieldMapper(field);
         if (currentFieldType != null) {
             try {
                 return currentFieldType.fuzzyQuery(termStr, Fuzziness.build(minSimilarity), fuzzyPrefixLength, settings.fuzzyMaxExpansions(), FuzzyQuery.defaultTranspositions);
@@ -455,14 +492,14 @@ public class MapperQueryParser extends QueryParser {
         currentFieldType = null;
         Analyzer oldAnalyzer = getAnalyzer();
         try {
-            currentFieldType = context.fieldMapper(field);
+            currentFieldType = parseContext.fieldMapper(field);
             if (currentFieldType != null) {
-                if (!settings.forceAnalyzer()) {
-                    setAnalyzer(context.getSearchAnalyzer(currentFieldType));
+                if (!forcedAnalyzer) {
+                    setAnalyzer(parseContext.getSearchAnalyzer(currentFieldType));
                 }
                 Query query = null;
                 if (currentFieldType.useTermQueryWithQueryString()) {
-                    query = currentFieldType.prefixQuery(termStr, multiTermRewriteMethod, context);
+                    query = currentFieldType.prefixQuery(termStr, multiTermRewriteMethod, parseContext);
                 }
                 if (query == null) {
                     query = getPossiblyAnalyzedPrefixQuery(currentFieldType.names().indexName(), termStr);
@@ -481,7 +518,7 @@ public class MapperQueryParser extends QueryParser {
     }
 
     private Query getPossiblyAnalyzedPrefixQuery(String field, String termStr) throws ParseException {
-        if (!settings.analyzeWildcard()) {
+        if (!analyzeWildcard) {
             return super.getPrefixQuery(field, termStr);
         }
         // get Analyzer from superclass and tokenize the term
@@ -519,7 +556,16 @@ public class MapperQueryParser extends QueryParser {
                 clauses.add(new BooleanClause(super.getPrefixQuery(field, token), BooleanClause.Occur.SHOULD));
             }
             return getBooleanQuery(clauses, true);
+
+            //return super.getPrefixQuery(field, termStr);
+
+            /* this means that the analyzer used either added or consumed
+* (common for a stemmer) tokens, and we can't build a PrefixQuery */
+//            throw new ParseException("Cannot build PrefixQuery with analyzer "
+//                    + getAnalyzer().getClass()
+//                    + (tlist.size() > 1 ? " - token(s) added" : " - token consumed"));
         }
+
     }
 
     @Override
@@ -538,7 +584,7 @@ public class MapperQueryParser extends QueryParser {
                     return newMatchAllDocsQuery();
                 }
                 // effectively, we check if a field exists or not
-                return fieldQueryExtensions.get(ExistsFieldQueryExtension.NAME).query(context, actualField);
+                return fieldQueryExtensions.get(ExistsFieldQueryExtension.NAME).query(parseContext, actualField);
             }
         }
         if (lowercaseExpandedTerms) {
@@ -587,10 +633,10 @@ public class MapperQueryParser extends QueryParser {
         currentFieldType = null;
         Analyzer oldAnalyzer = getAnalyzer();
         try {
-            currentFieldType = context.fieldMapper(field);
+            currentFieldType = parseContext.fieldMapper(field);
             if (currentFieldType != null) {
-                if (!settings.forceAnalyzer()) {
-                    setAnalyzer(context.getSearchAnalyzer(currentFieldType));
+                if (!forcedAnalyzer) {
+                    setAnalyzer(parseContext.getSearchAnalyzer(currentFieldType));
                 }
                 indexedNameField = currentFieldType.names().indexName();
                 return getPossiblyAnalyzedWildcardQuery(indexedNameField, termStr);
@@ -607,7 +653,7 @@ public class MapperQueryParser extends QueryParser {
     }
 
     private Query getPossiblyAnalyzedWildcardQuery(String field, String termStr) throws ParseException {
-        if (!settings.analyzeWildcard()) {
+        if (!analyzeWildcard) {
             return super.getWildcardQuery(field, termStr);
         }
         boolean isWithinToken = (!termStr.startsWith("?") && !termStr.startsWith("*"));
@@ -719,14 +765,14 @@ public class MapperQueryParser extends QueryParser {
         currentFieldType = null;
         Analyzer oldAnalyzer = getAnalyzer();
         try {
-            currentFieldType = context.fieldMapper(field);
+            currentFieldType = parseContext.fieldMapper(field);
             if (currentFieldType != null) {
-                if (!settings.forceAnalyzer()) {
-                    setAnalyzer(context.getSearchAnalyzer(currentFieldType));
+                if (!forcedAnalyzer) {
+                    setAnalyzer(parseContext.getSearchAnalyzer(currentFieldType));
                 }
                 Query query = null;
                 if (currentFieldType.useTermQueryWithQueryString()) {
-                    query = currentFieldType.regexpQuery(termStr, RegExp.ALL, maxDeterminizedStates, multiTermRewriteMethod, context);
+                    query = currentFieldType.regexpQuery(termStr, RegExp.ALL, maxDeterminizedStates, multiTermRewriteMethod, parseContext);
                 }
                 if (query == null) {
                     query = super.getRegexpQuery(field, termStr);
@@ -754,9 +800,9 @@ public class MapperQueryParser extends QueryParser {
     }
 
     private void applyBoost(String field, Query q) {
-        Float fieldBoost = settings.fieldsAndWeights().get(field);
-        if (fieldBoost != null) {
-            q.setBoost(fieldBoost);
+        if (settings.boosts() != null) {
+            float boost = settings.boosts().getOrDefault(field, 1f);
+            q.setBoost(boost);
         }
     }
 
@@ -782,11 +828,11 @@ public class MapperQueryParser extends QueryParser {
     }
 
     private Collection<String> extractMultiFields(String field) {
-        Collection<String> fields;
+        Collection<String> fields = null;
         if (field != null) {
-            fields = context.simpleMatchToIndexNames(field);
+            fields = parseContext.simpleMatchToIndexNames(field);
         } else {
-            fields = settings.fieldsAndWeights().keySet();
+            fields = settings.fields();
         }
         return fields;
     }
diff --git a/core/src/main/java/org/apache/lucene/queryparser/classic/MissingFieldQueryExtension.java b/core/src/main/java/org/apache/lucene/queryparser/classic/MissingFieldQueryExtension.java
index f9fc8c9..ed1b704 100644
--- a/core/src/main/java/org/apache/lucene/queryparser/classic/MissingFieldQueryExtension.java
+++ b/core/src/main/java/org/apache/lucene/queryparser/classic/MissingFieldQueryExtension.java
@@ -21,8 +21,8 @@ package org.apache.lucene.queryparser.classic;
 
 import org.apache.lucene.search.ConstantScoreQuery;
 import org.apache.lucene.search.Query;
-import org.elasticsearch.index.query.MissingQueryBuilder;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.MissingQueryParser;
+import org.elasticsearch.index.query.QueryParseContext;
 
 /**
  *
@@ -32,11 +32,8 @@ public class MissingFieldQueryExtension implements FieldQueryExtension {
     public static final String NAME = "_missing_";
 
     @Override
-    public Query query(QueryShardContext context, String queryText) {
-        Query query = MissingQueryBuilder.newFilter(context, queryText, MissingQueryBuilder.DEFAULT_EXISTENCE_VALUE, MissingQueryBuilder.DEFAULT_NULL_VALUE);
-        if (query != null) {
-            return new ConstantScoreQuery(query);
-        }
-        return null;
+    public Query query(QueryParseContext parseContext, String queryText) {
+        return new ConstantScoreQuery(MissingQueryParser.newFilter(parseContext, queryText,
+                MissingQueryParser.DEFAULT_EXISTENCE_VALUE, MissingQueryParser.DEFAULT_NULL_VALUE, null));
     }
 }
diff --git a/core/src/main/java/org/apache/lucene/queryparser/classic/QueryParserSettings.java b/core/src/main/java/org/apache/lucene/queryparser/classic/QueryParserSettings.java
index c1fc2ae..76e8b4f 100644
--- a/core/src/main/java/org/apache/lucene/queryparser/classic/QueryParserSettings.java
+++ b/core/src/main/java/org/apache/lucene/queryparser/classic/QueryParserSettings.java
@@ -19,74 +19,66 @@
 
 package org.apache.lucene.queryparser.classic;
 
+import com.carrotsearch.hppc.ObjectFloatHashMap;
 import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.search.FuzzyQuery;
 import org.apache.lucene.search.MultiTermQuery;
+import org.apache.lucene.util.automaton.Operations;
 import org.elasticsearch.common.unit.Fuzziness;
 import org.joda.time.DateTimeZone;
 
+import java.util.List;
 import java.util.Locale;
-import java.util.Map;
 
 /**
- * Encapsulates settings that affect query_string parsing via {@link MapperQueryParser}
+ *
  */
 public class QueryParserSettings {
 
-    private final String queryString;
+    public static final boolean DEFAULT_ALLOW_LEADING_WILDCARD = true;
+    public static final boolean DEFAULT_ANALYZE_WILDCARD = false;
+    public static final float DEFAULT_BOOST = 1.f;
 
+    private String queryString;
     private String defaultField;
-
-    private Map<String, Float> fieldsAndWeights;
-
-    private QueryParser.Operator defaultOperator;
-
-    private Analyzer analyzer;
-    private boolean forceAnalyzer;
-    private Analyzer quoteAnalyzer;
-    private boolean forceQuoteAnalyzer;
-
-    private String quoteFieldSuffix;
-
-    private boolean autoGeneratePhraseQueries;
-
-    private boolean allowLeadingWildcard;
-
-    private boolean analyzeWildcard;
-
-    private boolean lowercaseExpandedTerms;
-
-    private boolean enablePositionIncrements;
-
-    private Locale locale;
-
-    private Fuzziness fuzziness;
-    private int fuzzyPrefixLength;
-    private int fuzzyMaxExpansions;
-    private MultiTermQuery.RewriteMethod fuzzyRewriteMethod;
-
-    private int phraseSlop;
-
-    private boolean useDisMax;
-
-    private float tieBreaker;
-
-    private MultiTermQuery.RewriteMethod rewriteMethod;
-
+    private float boost = DEFAULT_BOOST;
+    private MapperQueryParser.Operator defaultOperator = QueryParser.Operator.OR;
+    private boolean autoGeneratePhraseQueries = false;
+    private boolean allowLeadingWildcard = DEFAULT_ALLOW_LEADING_WILDCARD;
+    private boolean lowercaseExpandedTerms = true;
+    private boolean enablePositionIncrements = true;
+    private int phraseSlop = 0;
+    private Fuzziness fuzziness = Fuzziness.AUTO;
+    private int fuzzyPrefixLength = FuzzyQuery.defaultPrefixLength;
+    private int fuzzyMaxExpansions = FuzzyQuery.defaultMaxExpansions;
+    private int maxDeterminizedStates = Operations.DEFAULT_MAX_DETERMINIZED_STATES;
+    private MultiTermQuery.RewriteMethod fuzzyRewriteMethod = null;
+    private boolean analyzeWildcard = DEFAULT_ANALYZE_WILDCARD;
+    private boolean escape = false;
+    private Analyzer defaultAnalyzer = null;
+    private Analyzer defaultQuoteAnalyzer = null;
+    private Analyzer forcedAnalyzer = null;
+    private Analyzer forcedQuoteAnalyzer = null;
+    private String quoteFieldSuffix = null;
+    private MultiTermQuery.RewriteMethod rewriteMethod = MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE;
+    private String minimumShouldMatch;
     private boolean lenient;
-
+    private Locale locale;
     private DateTimeZone timeZone;
 
-    /** To limit effort spent determinizing regexp queries. */
-    private int maxDeterminizedStates;
-
-    public QueryParserSettings(String queryString) {
-        this.queryString = queryString;
-    }
+    List<String> fields = null;
+    ObjectFloatHashMap<String> boosts = null;
+    float tieBreaker = 0.0f;
+    boolean useDisMax = true;
 
     public String queryString() {
         return queryString;
     }
 
+    public void queryString(String queryString) {
+        this.queryString = queryString;
+    }
+
     public String defaultField() {
         return defaultField;
     }
@@ -95,12 +87,12 @@ public class QueryParserSettings {
         this.defaultField = defaultField;
     }
 
-    public Map<String, Float> fieldsAndWeights() {
-        return fieldsAndWeights;
+    public float boost() {
+        return boost;
     }
 
-    public void fieldsAndWeights(Map<String, Float> fieldsAndWeights) {
-        this.fieldsAndWeights = fieldsAndWeights;
+    public void boost(float boost) {
+        this.boost = boost;
     }
 
     public QueryParser.Operator defaultOperator() {
@@ -183,40 +175,44 @@ public class QueryParserSettings {
         this.fuzzyRewriteMethod = fuzzyRewriteMethod;
     }
 
-    public void defaultAnalyzer(Analyzer analyzer) {
-        this.analyzer = analyzer;
-        this.forceAnalyzer = false;
+    public boolean escape() {
+        return escape;
     }
 
-    public void forceAnalyzer(Analyzer analyzer) {
-        this.analyzer = analyzer;
-        this.forceAnalyzer = true;
+    public void escape(boolean escape) {
+        this.escape = escape;
     }
 
-    public Analyzer analyzer() {
-        return analyzer;
+    public Analyzer defaultAnalyzer() {
+        return defaultAnalyzer;
     }
 
-    public boolean forceAnalyzer() {
-        return forceAnalyzer;
+    public void defaultAnalyzer(Analyzer defaultAnalyzer) {
+        this.defaultAnalyzer = defaultAnalyzer;
     }
 
-    public void defaultQuoteAnalyzer(Analyzer quoteAnalyzer) {
-        this.quoteAnalyzer = quoteAnalyzer;
-        this.forceQuoteAnalyzer = false;
+    public Analyzer defaultQuoteAnalyzer() {
+        return defaultQuoteAnalyzer;
     }
 
-    public void forceQuoteAnalyzer(Analyzer quoteAnalyzer) {
-        this.quoteAnalyzer = quoteAnalyzer;
-        this.forceQuoteAnalyzer = true;
+    public void defaultQuoteAnalyzer(Analyzer defaultAnalyzer) {
+        this.defaultQuoteAnalyzer = defaultAnalyzer;
     }
 
-    public Analyzer quoteAnalyzer() {
-        return quoteAnalyzer;
+    public Analyzer forcedAnalyzer() {
+        return forcedAnalyzer;
     }
 
-    public boolean forceQuoteAnalyzer() {
-        return forceQuoteAnalyzer;
+    public void forcedAnalyzer(Analyzer forcedAnalyzer) {
+        this.forcedAnalyzer = forcedAnalyzer;
+    }
+
+    public Analyzer forcedQuoteAnalyzer() {
+        return forcedQuoteAnalyzer;
+    }
+
+    public void forcedQuoteAnalyzer(Analyzer forcedAnalyzer) {
+        this.forcedQuoteAnalyzer = forcedAnalyzer;
     }
 
     public boolean analyzeWildcard() {
@@ -235,6 +231,14 @@ public class QueryParserSettings {
         this.rewriteMethod = rewriteMethod;
     }
 
+    public String minimumShouldMatch() {
+        return this.minimumShouldMatch;
+    }
+
+    public void minimumShouldMatch(String minimumShouldMatch) {
+        this.minimumShouldMatch = minimumShouldMatch;
+    }
+
     public void quoteFieldSuffix(String quoteFieldSuffix) {
         this.quoteFieldSuffix = quoteFieldSuffix;
     }
@@ -251,6 +255,22 @@ public class QueryParserSettings {
         return this.lenient;
     }
 
+    public List<String> fields() {
+        return fields;
+    }
+
+    public void fields(List<String> fields) {
+        this.fields = fields;
+    }
+
+    public ObjectFloatHashMap<String> boosts() {
+        return boosts;
+    }
+
+    public void boosts(ObjectFloatHashMap<String> boosts) {
+        this.boosts = boosts;
+    }
+
     public float tieBreaker() {
         return tieBreaker;
     }
@@ -283,11 +303,97 @@ public class QueryParserSettings {
         return this.timeZone;
     }
 
-    public void fuzziness(Fuzziness fuzziness) {
+    @Override
+    public boolean equals(Object o) {
+        if (this == o) return true;
+        if (o == null || getClass() != o.getClass()) return false;
+
+        QueryParserSettings that = (QueryParserSettings) o;
+
+        if (autoGeneratePhraseQueries != that.autoGeneratePhraseQueries()) return false;
+        if (maxDeterminizedStates != that.maxDeterminizedStates()) return false;
+        if (allowLeadingWildcard != that.allowLeadingWildcard) return false;
+        if (Float.compare(that.boost, boost) != 0) return false;
+        if (enablePositionIncrements != that.enablePositionIncrements) return false;
+        if (escape != that.escape) return false;
+        if (analyzeWildcard != that.analyzeWildcard) return false;
+        if (fuzziness != null ? fuzziness.equals(that.fuzziness) == false : fuzziness != null) return false;
+        if (fuzzyPrefixLength != that.fuzzyPrefixLength) return false;
+        if (fuzzyMaxExpansions != that.fuzzyMaxExpansions) return false;
+        if (fuzzyRewriteMethod != null ? !fuzzyRewriteMethod.equals(that.fuzzyRewriteMethod) : that.fuzzyRewriteMethod != null)
+            return false;
+        if (lowercaseExpandedTerms != that.lowercaseExpandedTerms) return false;
+        if (phraseSlop != that.phraseSlop) return false;
+        if (defaultAnalyzer != null ? !defaultAnalyzer.equals(that.defaultAnalyzer) : that.defaultAnalyzer != null)
+            return false;
+        if (defaultQuoteAnalyzer != null ? !defaultQuoteAnalyzer.equals(that.defaultQuoteAnalyzer) : that.defaultQuoteAnalyzer != null)
+            return false;
+        if (forcedAnalyzer != null ? !forcedAnalyzer.equals(that.forcedAnalyzer) : that.forcedAnalyzer != null)
+            return false;
+        if (forcedQuoteAnalyzer != null ? !forcedQuoteAnalyzer.equals(that.forcedQuoteAnalyzer) : that.forcedQuoteAnalyzer != null)
+            return false;
+        if (defaultField != null ? !defaultField.equals(that.defaultField) : that.defaultField != null) return false;
+        if (defaultOperator != that.defaultOperator) return false;
+        if (queryString != null ? !queryString.equals(that.queryString) : that.queryString != null) return false;
+        if (rewriteMethod != null ? !rewriteMethod.equals(that.rewriteMethod) : that.rewriteMethod != null)
+            return false;
+        if (minimumShouldMatch != null ? !minimumShouldMatch.equals(that.minimumShouldMatch) : that.minimumShouldMatch != null)
+            return false;
+        if (quoteFieldSuffix != null ? !quoteFieldSuffix.equals(that.quoteFieldSuffix) : that.quoteFieldSuffix != null)
+            return false;
+        if (lenient != that.lenient) {
+            return false;
+        }
+        if (locale != null ? !locale.equals(that.locale) : that.locale != null) {
+            return false;
+        }
+        if (timeZone != null ? !timeZone.equals(that.timeZone) : that.timeZone != null) {
+            return false;
+        }
+
+        if (Float.compare(that.tieBreaker, tieBreaker) != 0) return false;
+        if (useDisMax != that.useDisMax) return false;
+        if (boosts != null ? !boosts.equals(that.boosts) : that.boosts != null) return false;
+        if (fields != null ? !fields.equals(that.fields) : that.fields != null) return false;
+
+        return true;
+    }
+
+    @Override
+    public int hashCode() {
+        int result = queryString != null ? queryString.hashCode() : 0;
+        result = 31 * result + (defaultField != null ? defaultField.hashCode() : 0);
+        result = 31 * result + (boost != +0.0f ? Float.floatToIntBits(boost) : 0);
+        result = 31 * result + (defaultOperator != null ? defaultOperator.hashCode() : 0);
+        result = 31 * result + (autoGeneratePhraseQueries ? 1 : 0);
+        result = 31 * result + maxDeterminizedStates;
+        result = 31 * result + (allowLeadingWildcard ? 1 : 0);
+        result = 31 * result + (lowercaseExpandedTerms ? 1 : 0);
+        result = 31 * result + (enablePositionIncrements ? 1 : 0);
+        result = 31 * result + phraseSlop;
+        result = 31 * result + (fuzziness.hashCode());
+        result = 31 * result + fuzzyPrefixLength;
+        result = 31 * result + (escape ? 1 : 0);
+        result = 31 * result + (defaultAnalyzer != null ? defaultAnalyzer.hashCode() : 0);
+        result = 31 * result + (defaultQuoteAnalyzer != null ? defaultQuoteAnalyzer.hashCode() : 0);
+        result = 31 * result + (forcedAnalyzer != null ? forcedAnalyzer.hashCode() : 0);
+        result = 31 * result + (forcedQuoteAnalyzer != null ? forcedQuoteAnalyzer.hashCode() : 0);
+        result = 31 * result + (analyzeWildcard ? 1 : 0);
+
+        result = 31 * result + (fields != null ? fields.hashCode() : 0);
+        result = 31 * result + (boosts != null ? boosts.hashCode() : 0);
+        result = 31 * result + (tieBreaker != +0.0f ? Float.floatToIntBits(tieBreaker) : 0);
+        result = 31 * result + (useDisMax ? 1 : 0);
+        result = 31 * result + (locale != null ? locale.hashCode() : 0);
+        result = 31 * result + (timeZone != null ? timeZone.hashCode() : 0);
+        return result;
+    }
+
+    public void setFuzziness(Fuzziness fuzziness) {
         this.fuzziness = fuzziness;
     }
 
-    public Fuzziness fuzziness() {
+    public Fuzziness getFuzziness() {
         return fuzziness;
     }
 }
diff --git a/core/src/main/java/org/apache/lucene/search/vectorhighlight/CustomFieldQuery.java b/core/src/main/java/org/apache/lucene/search/vectorhighlight/CustomFieldQuery.java
index e1a78ac..e1a8d81 100644
--- a/core/src/main/java/org/apache/lucene/search/vectorhighlight/CustomFieldQuery.java
+++ b/core/src/main/java/org/apache/lucene/search/vectorhighlight/CustomFieldQuery.java
@@ -58,28 +58,28 @@ public class CustomFieldQuery extends FieldQuery {
     }
 
     @Override
-    void flatten(Query sourceQuery, IndexReader reader, Collection<Query> flatQueries) throws IOException {
+    void flatten(Query sourceQuery, IndexReader reader, Collection<Query> flatQueries, float boost) throws IOException {
         if (sourceQuery instanceof SpanTermQuery) {
-            super.flatten(new TermQuery(((SpanTermQuery) sourceQuery).getTerm()), reader, flatQueries);
+            super.flatten(new TermQuery(((SpanTermQuery) sourceQuery).getTerm()), reader, flatQueries, boost);
         } else if (sourceQuery instanceof ConstantScoreQuery) {
-            flatten(((ConstantScoreQuery) sourceQuery).getQuery(), reader, flatQueries);
+            flatten(((ConstantScoreQuery) sourceQuery).getQuery(), reader, flatQueries, boost);
         } else if (sourceQuery instanceof FunctionScoreQuery) {
-            flatten(((FunctionScoreQuery) sourceQuery).getSubQuery(), reader, flatQueries);
+            flatten(((FunctionScoreQuery) sourceQuery).getSubQuery(), reader, flatQueries, boost);
         } else if (sourceQuery instanceof FilteredQuery) {
-            flatten(((FilteredQuery) sourceQuery).getQuery(), reader, flatQueries);
+            flatten(((FilteredQuery) sourceQuery).getQuery(), reader, flatQueries, boost);
             flatten(((FilteredQuery) sourceQuery).getFilter(), reader, flatQueries);
         } else if (sourceQuery instanceof MultiPhrasePrefixQuery) {
-            flatten(sourceQuery.rewrite(reader), reader, flatQueries);
+            flatten(sourceQuery.rewrite(reader), reader, flatQueries, boost);
         } else if (sourceQuery instanceof FiltersFunctionScoreQuery) {
-            flatten(((FiltersFunctionScoreQuery) sourceQuery).getSubQuery(), reader, flatQueries);
+            flatten(((FiltersFunctionScoreQuery) sourceQuery).getSubQuery(), reader, flatQueries, boost);
         } else if (sourceQuery instanceof MultiPhraseQuery) {
             MultiPhraseQuery q = ((MultiPhraseQuery) sourceQuery);
             convertMultiPhraseQuery(0, new int[q.getTermArrays().size()], q, q.getTermArrays(), q.getPositions(), reader, flatQueries);
         } else if (sourceQuery instanceof BlendedTermQuery) {
             final BlendedTermQuery blendedTermQuery = (BlendedTermQuery) sourceQuery;
-            flatten(blendedTermQuery.rewrite(reader), reader, flatQueries);
+            flatten(blendedTermQuery.rewrite(reader), reader, flatQueries, boost);
         } else {
-            super.flatten(sourceQuery, reader, flatQueries);
+            super.flatten(sourceQuery, reader, flatQueries, boost);
         }
     }
     
@@ -93,7 +93,7 @@ public class CustomFieldQuery extends FieldQuery {
             if (numTerms > 16) {
                 for (Term[] currentPosTerm : terms) {
                     for (Term term : currentPosTerm) {
-                        super.flatten(new TermQuery(term), reader, flatQueries);    
+                        super.flatten(new TermQuery(term), reader, flatQueries, orig.getBoost());    
                     }
                 }
                 return;
@@ -111,7 +111,7 @@ public class CustomFieldQuery extends FieldQuery {
             }
             PhraseQuery query = queryBuilder.build();
             query.setBoost(orig.getBoost());
-            this.flatten(query, reader, flatQueries);
+            this.flatten(query, reader, flatQueries, orig.getBoost());
         } else {
             Term[] t = terms.get(currentPos);
             for (int i = 0; i < t.length; i++) {
@@ -127,7 +127,7 @@ public class CustomFieldQuery extends FieldQuery {
             return;
         }
         if (sourceFilter instanceof QueryWrapperFilter) {
-            flatten(((QueryWrapperFilter) sourceFilter).getQuery(), reader, flatQueries);
+            flatten(((QueryWrapperFilter) sourceFilter).getQuery(), reader, flatQueries, 1.0F);
         }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/ElasticsearchException.java b/core/src/main/java/org/elasticsearch/ElasticsearchException.java
index 819e520..a9b0ba5 100644
--- a/core/src/main/java/org/elasticsearch/ElasticsearchException.java
+++ b/core/src/main/java/org/elasticsearch/ElasticsearchException.java
@@ -580,7 +580,6 @@ public class ElasticsearchException extends RuntimeException implements ToXConte
                 org.elasticsearch.index.engine.RecoveryEngineException.class,
                 org.elasticsearch.common.blobstore.BlobStoreException.class,
                 org.elasticsearch.index.snapshots.IndexShardRestoreException.class,
-                org.elasticsearch.index.query.QueryShardException.class,
                 org.elasticsearch.index.query.QueryParsingException.class,
                 org.elasticsearch.action.support.replication.TransportReplicationAction.RetryOnPrimaryException.class,
                 org.elasticsearch.index.engine.DeleteByQueryFailedEngineException.class,
diff --git a/core/src/main/java/org/elasticsearch/action/ActionRequestBuilder.java b/core/src/main/java/org/elasticsearch/action/ActionRequestBuilder.java
index aaf5c9e..9ad449f 100644
--- a/core/src/main/java/org/elasticsearch/action/ActionRequestBuilder.java
+++ b/core/src/main/java/org/elasticsearch/action/ActionRequestBuilder.java
@@ -19,12 +19,13 @@
 
 package org.elasticsearch.action;
 
-import com.google.common.base.Preconditions;
 import org.elasticsearch.action.support.PlainListenableActionFuture;
 import org.elasticsearch.client.ElasticsearchClient;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.threadpool.ThreadPool;
 
+import java.util.Objects;
+
 /**
  *
  */
@@ -36,7 +37,7 @@ public abstract class ActionRequestBuilder<Request extends ActionRequest, Respon
     protected final ElasticsearchClient client;
 
     protected ActionRequestBuilder(ElasticsearchClient client, Action<Request, Response, RequestBuilder> action, Request request) {
-        Preconditions.checkNotNull(action, "action must not be null");
+        Objects.requireNonNull(action, "action must not be null");
         this.action = action;
         this.request = request;
         this.client = client;
diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/shards/TransportClusterSearchShardsAction.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/shards/TransportClusterSearchShardsAction.java
index b9a372e..58ad671 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/shards/TransportClusterSearchShardsAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/shards/TransportClusterSearchShardsAction.java
@@ -36,11 +36,10 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
+import java.util.HashSet;
 import java.util.Map;
 import java.util.Set;
 
-import static com.google.common.collect.Sets.newHashSet;
-
 /**
  */
 public class TransportClusterSearchShardsAction extends TransportMasterNodeReadAction<ClusterSearchShardsRequest, ClusterSearchShardsResponse> {
@@ -72,7 +71,7 @@ public class TransportClusterSearchShardsAction extends TransportMasterNodeReadA
         ClusterState clusterState = clusterService.state();
         String[] concreteIndices = indexNameExpressionResolver.concreteIndices(clusterState, request);
         Map<String, Set<String>> routingMap = indexNameExpressionResolver.resolveSearchRouting(state, request.routing(), request.indices());
-        Set<String> nodeIds = newHashSet();
+        Set<String> nodeIds = new HashSet<>();
         GroupShardsIterator groupShardsIterator = clusterService.operationRouting().searchShards(clusterState, concreteIndices, routingMap, request.preference());
         ShardRouting shard;
         ClusterSearchShardsGroup[] groupResponses = new ClusterSearchShardsGroup[groupShardsIterator.size()];
diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/SnapshotStatus.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/SnapshotStatus.java
index eeba6af..7e1a47c 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/SnapshotStatus.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/SnapshotStatus.java
@@ -33,12 +33,11 @@ import org.elasticsearch.common.xcontent.XContentFactory;
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Collections;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
-import static com.google.common.collect.Sets.newHashSet;
-
 /**
  * Status of a snapshot
  */
@@ -103,7 +102,7 @@ public class SnapshotStatus implements ToXContent, Streamable {
 
         ImmutableMap.Builder<String, SnapshotIndexStatus> indicesStatus = ImmutableMap.builder();
 
-        Set<String> indices = newHashSet();
+        Set<String> indices = new HashSet<>();
         for (SnapshotIndexShardStatus shard : shards) {
             indices.add(shard.getIndex());
         }
diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/TransportSnapshotsStatusAction.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/TransportSnapshotsStatusAction.java
index 57518f4..fca3f21 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/TransportSnapshotsStatusAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/TransportSnapshotsStatusAction.java
@@ -44,12 +44,11 @@ import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
-import static com.google.common.collect.Sets.newHashSet;
-
 /**
  */
 public class TransportSnapshotsStatusAction extends TransportMasterNodeAction<SnapshotsStatusRequest, SnapshotsStatusResponse> {
@@ -94,7 +93,7 @@ public class TransportSnapshotsStatusAction extends TransportMasterNodeAction<Sn
             return;
         }
 
-        Set<String> nodesIds = newHashSet();
+        Set<String> nodesIds = new HashSet<>();
         for (SnapshotsInProgress.Entry entry : currentSnapshots) {
             for (SnapshotsInProgress.ShardSnapshotStatus status : entry.shards().values()) {
                 if (status.nodeId() != null) {
@@ -140,7 +139,7 @@ public class TransportSnapshotsStatusAction extends TransportMasterNodeAction<Sn
                                                   TransportNodesSnapshotsStatus.NodesSnapshotStatus nodeSnapshotStatuses) throws IOException {
         // First process snapshot that are currently processed
         List<SnapshotStatus> builder = new ArrayList<>();
-        Set<SnapshotId> currentSnapshotIds = newHashSet();
+        Set<SnapshotId> currentSnapshotIds = new HashSet<>();
         if (!currentSnapshots.isEmpty()) {
             Map<String, TransportNodesSnapshotsStatus.NodeSnapshotStatus> nodeSnapshotStatusMap;
             if (nodeSnapshotStatuses != null) {
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/alias/TransportIndicesAliasesAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/alias/TransportIndicesAliasesAction.java
index 5cabb7f..3916d83 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/alias/TransportIndicesAliasesAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/alias/TransportIndicesAliasesAction.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.action.admin.indices.alias;
 
-import com.google.common.collect.Sets;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.admin.indices.alias.IndicesAliasesRequest.AliasActions;
 import org.elasticsearch.action.support.ActionFilters;
@@ -38,7 +37,11 @@ import org.elasticsearch.rest.action.admin.indices.alias.delete.AliasesNotFoundE
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
 
 /**
  * Add/remove aliases action
@@ -68,7 +71,7 @@ public class TransportIndicesAliasesAction extends TransportMasterNodeAction<Ind
 
     @Override
     protected ClusterBlockException checkBlock(IndicesAliasesRequest request, ClusterState state) {
-        Set<String> indices = Sets.newHashSet();
+        Set<String> indices = new HashSet<>();
         for (AliasActions aliasAction : request.aliasActions()) {
             for (String index : aliasAction.indices()) {
                 indices.add(index);
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/create/CreateIndexClusterStateUpdateRequest.java b/core/src/main/java/org/elasticsearch/action/admin/indices/create/CreateIndexClusterStateUpdateRequest.java
index dd50f68..72fe055 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/create/CreateIndexClusterStateUpdateRequest.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/create/CreateIndexClusterStateUpdateRequest.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.action.admin.indices.create;
 
-import com.google.common.collect.Sets;
 import org.elasticsearch.action.admin.indices.alias.Alias;
 import org.elasticsearch.cluster.ack.ClusterStateUpdateRequest;
 import org.elasticsearch.cluster.block.ClusterBlock;
@@ -28,6 +27,7 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.transport.TransportMessage;
 
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.Map;
 import java.util.Set;
 
@@ -47,11 +47,11 @@ public class CreateIndexClusterStateUpdateRequest extends ClusterStateUpdateRequ
 
     private final Map<String, String> mappings = new HashMap<>();
 
-    private final Set<Alias> aliases = Sets.newHashSet();
+    private final Set<Alias> aliases = new HashSet<>();
 
     private final Map<String, IndexMetaData.Custom> customs = new HashMap<>();
 
-    private final Set<ClusterBlock> blocks = Sets.newHashSet();
+    private final Set<ClusterBlock> blocks = new HashSet<>();
 
 
     CreateIndexClusterStateUpdateRequest(TransportMessage originalMessage, String cause, String index, boolean updateAllTypes) {
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/create/CreateIndexRequest.java b/core/src/main/java/org/elasticsearch/action/admin/indices/create/CreateIndexRequest.java
index c5ade4f..48342f9 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/create/CreateIndexRequest.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/create/CreateIndexRequest.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.action.admin.indices.create;
 
 import com.google.common.base.Charsets;
-import com.google.common.collect.Sets;
 import org.elasticsearch.ElasticsearchGenerationException;
 import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.action.ActionRequest;
@@ -45,6 +44,7 @@ import org.elasticsearch.common.xcontent.XContentType;
 
 import java.io.IOException;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.Map;
 import java.util.Set;
 
@@ -72,7 +72,7 @@ public class CreateIndexRequest extends AcknowledgedRequest<CreateIndexRequest>
 
     private final Map<String, String> mappings = new HashMap<>();
 
-    private final Set<Alias> aliases = Sets.newHashSet();
+    private final Set<Alias> aliases = new HashSet<>();
 
     private final Map<String, IndexMetaData.Custom> customs = new HashMap<>();
 
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/segments/IndicesSegmentResponse.java b/core/src/main/java/org/elasticsearch/action/admin/indices/segments/IndicesSegmentResponse.java
index 06a9112..979e51f 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/segments/IndicesSegmentResponse.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/segments/IndicesSegmentResponse.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.action.admin.indices.segments;
 
-import com.google.common.collect.Sets;
 import org.apache.lucene.util.Accountable;
 import org.elasticsearch.action.ShardOperationFailedException;
 import org.elasticsearch.action.support.broadcast.BroadcastResponse;
@@ -35,6 +34,7 @@ import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
@@ -60,7 +60,7 @@ public class IndicesSegmentResponse extends BroadcastResponse implements ToXCont
         }
         Map<String, IndexSegments> indicesSegments = new HashMap<>();
 
-        Set<String> indices = Sets.newHashSet();
+        Set<String> indices = new HashSet<>();
         for (ShardSegments shard : shards) {
             indices.add(shard.getShardRouting().getIndex());
         }
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/stats/IndicesStatsResponse.java b/core/src/main/java/org/elasticsearch/action/admin/indices/stats/IndicesStatsResponse.java
index 6725850..5cb94b2 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/stats/IndicesStatsResponse.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/stats/IndicesStatsResponse.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.action.admin.indices.stats;
 
 import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.Sets;
 import org.elasticsearch.action.ShardOperationFailedException;
 import org.elasticsearch.action.support.broadcast.BroadcastResponse;
 import org.elasticsearch.cluster.routing.ShardRouting;
@@ -34,6 +33,7 @@ import org.elasticsearch.common.xcontent.XContentFactory;
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
@@ -87,7 +87,7 @@ public class IndicesStatsResponse extends BroadcastResponse implements ToXConten
         }
         Map<String, IndexStats> indicesStats = new HashMap<>();
 
-        Set<String> indices = Sets.newHashSet();
+        Set<String> indices = new HashSet<>();
         for (ShardStats shard : shards) {
             indices.add(shard.getShardRouting().getIndex());
         }
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/template/put/PutIndexTemplateRequest.java b/core/src/main/java/org/elasticsearch/action/admin/indices/template/put/PutIndexTemplateRequest.java
index 9b9dbbe..fe42f7e 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/template/put/PutIndexTemplateRequest.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/template/put/PutIndexTemplateRequest.java
@@ -42,10 +42,10 @@ import org.elasticsearch.common.xcontent.support.XContentMapValues;
 
 import java.io.IOException;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.Map;
 import java.util.Set;
 
-import static com.google.common.collect.Sets.newHashSet;
 import static org.elasticsearch.action.ValidateActions.addValidationError;
 import static org.elasticsearch.common.settings.Settings.Builder.EMPTY_SETTINGS;
 import static org.elasticsearch.common.settings.Settings.readSettingsFromStream;
@@ -70,7 +70,7 @@ public class PutIndexTemplateRequest extends MasterNodeRequest<PutIndexTemplateR
 
     private Map<String, String> mappings = new HashMap<>();
 
-    private final Set<Alias> aliases = newHashSet();
+    private final Set<Alias> aliases = new HashSet<>();
     
     private Map<String, IndexMetaData.Custom> customs = new HashMap<>();
 
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/get/UpgradeStatusResponse.java b/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/get/UpgradeStatusResponse.java
index 5cb6084..5ace664 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/get/UpgradeStatusResponse.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/get/UpgradeStatusResponse.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.action.admin.indices.upgrade.get;
 
-import com.google.common.collect.Sets;
 import org.elasticsearch.action.ShardOperationFailedException;
 import org.elasticsearch.action.support.broadcast.BroadcastResponse;
 import org.elasticsearch.common.io.stream.StreamInput;
@@ -31,6 +30,7 @@ import org.elasticsearch.common.xcontent.XContentBuilderString;
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
@@ -54,7 +54,7 @@ public class UpgradeStatusResponse extends BroadcastResponse implements ToXConte
         }
         Map<String, IndexUpgradeStatus> indicesUpgradeStats = new HashMap<>();
 
-        Set<String> indices = Sets.newHashSet();
+        Set<String> indices = new HashSet<>();
         for (ShardUpgradeStatus shard : shards) {
             indices.add(shard.getIndex());
         }
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/post/TransportUpgradeAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/post/TransportUpgradeAction.java
index d1bee20..55c389d 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/post/TransportUpgradeAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/post/TransportUpgradeAction.java
@@ -46,12 +46,11 @@ import org.elasticsearch.transport.TransportService;
 
 import java.io.IOException;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
-import static com.google.common.collect.Sets.newHashSet;
-
 /**
  * Upgrade index/indices action.
  */
@@ -158,7 +157,7 @@ public class TransportUpgradeAction extends TransportBroadcastByNodeAction<Upgra
      * Finds all indices that have not all primaries available
      */
     private Set<String> indicesWithMissingPrimaries(ClusterState clusterState, String[] concreteIndices) {
-        Set<String> indices = newHashSet();
+        Set<String> indices = new HashSet<>();
         RoutingTable routingTable = clusterState.routingTable();
         for (String index : concreteIndices) {
             IndexRoutingTable indexRoutingTable = routingTable.index(index);
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/TransportValidateQueryAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/TransportValidateQueryAction.java
index d73e0d2..6fefa0d 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/TransportValidateQueryAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/TransportValidateQueryAction.java
@@ -42,7 +42,6 @@ import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.query.IndexQueryParserService;
-import org.elasticsearch.index.query.QueryShardException;
 import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.shard.IndexShard;
 import org.elasticsearch.indices.IndicesService;
@@ -189,8 +188,8 @@ public class TransportValidateQueryAction extends TransportBroadcastAction<Valid
             }
             if (request.rewrite()) {
                 explanation = getRewrittenQuery(searcher.searcher(), searchContext.query());
-            }
-        } catch (QueryShardException|QueryParsingException e) {
+            }   
+        } catch (QueryParsingException e) {
             valid = false;
             error = e.getDetailedMessage();
         } catch (AssertionError|IOException e) {
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/ValidateQueryRequestBuilder.java b/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/ValidateQueryRequestBuilder.java
index 515ecd1..4acdfdc 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/ValidateQueryRequestBuilder.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/ValidateQueryRequestBuilder.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.action.admin.indices.validate.query;
 
+import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.support.QuerySourceBuilder;
 import org.elasticsearch.action.support.broadcast.BroadcastOperationRequestBuilder;
 import org.elasticsearch.client.ElasticsearchClient;
diff --git a/core/src/main/java/org/elasticsearch/action/exists/TransportExistsAction.java b/core/src/main/java/org/elasticsearch/action/exists/TransportExistsAction.java
index 6995859..d9c89e7 100644
--- a/core/src/main/java/org/elasticsearch/action/exists/TransportExistsAction.java
+++ b/core/src/main/java/org/elasticsearch/action/exists/TransportExistsAction.java
@@ -41,7 +41,7 @@ import org.elasticsearch.common.lucene.Lucene;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.index.IndexService;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.shard.IndexShard;
 import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.script.ScriptService;
@@ -166,10 +166,10 @@ public class TransportExistsAction extends TransportBroadcastAction<ExistsReques
             BytesReference source = request.querySource();
             if (source != null && source.length() > 0) {
                 try {
-                    QueryShardContext.setTypes(request.types());
+                    QueryParseContext.setTypes(request.types());
                     context.parsedQuery(indexService.queryParserService().parseQuery(source));
                 } finally {
-                    QueryShardContext.removeTypes();
+                    QueryParseContext.removeTypes();
                 }
             }
             context.preProcess();
diff --git a/core/src/main/java/org/elasticsearch/action/search/SearchRequestBuilder.java b/core/src/main/java/org/elasticsearch/action/search/SearchRequestBuilder.java
index ccdfb23..f636534 100644
--- a/core/src/main/java/org/elasticsearch/action/search/SearchRequestBuilder.java
+++ b/core/src/main/java/org/elasticsearch/action/search/SearchRequestBuilder.java
@@ -715,13 +715,8 @@ public class SearchRequestBuilder extends ActionRequestBuilder<SearchRequest, Se
         return this;
     }
 
-    public SearchRequestBuilder addParentChildInnerHits(String name, String type,  InnerHitsBuilder.InnerHit innerHit) {
-        innerHitsBuilder().addParentChildInnerHits(name, type, innerHit);
-        return this;
-    }
-
-    public SearchRequestBuilder addNestedInnerHits(String name, String path,  InnerHitsBuilder.InnerHit innerHit) {
-        innerHitsBuilder().addNestedInnerHits(name, path, innerHit);
+    public SearchRequestBuilder addInnerHit(String name, InnerHitsBuilder.InnerHit innerHit) {
+        innerHitsBuilder().addInnerHit(name, innerHit);
         return this;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/action/termvectors/TermVectorsRequest.java b/core/src/main/java/org/elasticsearch/action/termvectors/TermVectorsRequest.java
index a3033c5..fdc9a41 100644
--- a/core/src/main/java/org/elasticsearch/action/termvectors/TermVectorsRequest.java
+++ b/core/src/main/java/org/elasticsearch/action/termvectors/TermVectorsRequest.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.action.termvectors;
 
-import com.google.common.collect.Sets;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.action.ActionRequestValidationException;
@@ -33,6 +32,7 @@ import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.lucene.uid.Versions;
+import org.elasticsearch.common.util.set.Sets;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.VersionType;
diff --git a/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java b/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java
index 9062140..a5c71e3 100644
--- a/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java
+++ b/core/src/main/java/org/elasticsearch/bootstrap/JarHell.java
@@ -26,6 +26,7 @@ import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.logging.Loggers;
 
 import java.io.IOException;
+import java.net.MalformedURLException;
 import java.net.URL;
 import java.net.URLClassLoader;
 import java.nio.file.FileVisitResult;
@@ -70,21 +71,43 @@ public class JarHell {
     }
 
     /**
-     * Checks the current classloader for duplicate classes
+     * Checks the current classpath for duplicate classes
      * @throws IllegalStateException if jar hell was found
      */
     public static void checkJarHell() throws Exception {
         ClassLoader loader = JarHell.class.getClassLoader();
-        if (loader instanceof URLClassLoader == false) {
-           return;
-        }
         ESLogger logger = Loggers.getLogger(JarHell.class);
         if (logger.isDebugEnabled()) {
             logger.debug("java.class.path: {}", System.getProperty("java.class.path"));
             logger.debug("sun.boot.class.path: {}", System.getProperty("sun.boot.class.path"));
-            logger.debug("classloader urls: {}", Arrays.toString(((URLClassLoader)loader).getURLs()));
+            if (loader instanceof URLClassLoader ) {
+                logger.debug("classloader urls: {}", Arrays.toString(((URLClassLoader)loader).getURLs()));
+             }
+        }
+        checkJarHell(parseClassPath());
+    }
+    
+    /**
+     * Parses the classpath into a set of URLs
+     */
+    @SuppressForbidden(reason = "resolves against CWD because that is how classpaths work")
+    public static URL[] parseClassPath()  {
+        String elements[] = System.getProperty("java.class.path").split(System.getProperty("path.separator"));
+        URL urlElements[] = new URL[elements.length];
+        for (int i = 0; i < elements.length; i++) {
+            String element = elements[i];
+            // empty classpath element behaves like CWD.
+            if (element.isEmpty()) {
+                element = System.getProperty("user.dir");
+            }
+            try {
+                urlElements[i] = PathUtils.get(element).toUri().toURL();
+            } catch (MalformedURLException e) {
+                // should not happen, as we use the filesystem API
+                throw new RuntimeException(e);
+            }
         }
-        checkJarHell(((URLClassLoader) loader).getURLs());
+        return urlElements;
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/bootstrap/Security.java b/core/src/main/java/org/elasticsearch/bootstrap/Security.java
index 4b32baa..a6bcb2f 100644
--- a/core/src/main/java/org/elasticsearch/bootstrap/Security.java
+++ b/core/src/main/java/org/elasticsearch/bootstrap/Security.java
@@ -24,7 +24,6 @@ import org.elasticsearch.env.Environment;
 
 import java.io.*;
 import java.net.URL;
-import java.net.URLClassLoader;
 import java.nio.file.AccessMode;
 import java.nio.file.FileAlreadyExistsException;
 import java.nio.file.Files;
@@ -121,8 +120,8 @@ final class Security {
     private static final Map<Pattern,String> SPECIAL_JARS;
     static {
         Map<Pattern,String> m = new IdentityHashMap<>();
-        m.put(Pattern.compile(".*lucene-core-.*\\.jar$"),    "es.security.jar.lucene.core");
-        m.put(Pattern.compile(".*securemock-.*\\.jar$"),     "es.security.jar.elasticsearch.securemock");
+        m.put(Pattern.compile(".*lucene-core-.*\\.jar$"),              "es.security.jar.lucene.core");
+        m.put(Pattern.compile(".*securemock-.*\\.jar$"),               "es.security.jar.elasticsearch.securemock");
         SPECIAL_JARS = Collections.unmodifiableMap(m);
     }
 
@@ -133,27 +132,21 @@ final class Security {
      */
     @SuppressForbidden(reason = "proper use of URL")
     static void setCodebaseProperties() {
-        ClassLoader loader = Security.class.getClassLoader();
-        if (loader instanceof URLClassLoader) {
-            for (URL url : ((URLClassLoader)loader).getURLs()) {
-                for (Map.Entry<Pattern,String> e : SPECIAL_JARS.entrySet()) {
-                    if (e.getKey().matcher(url.getPath()).matches()) {
-                        String prop = e.getValue();
-                        if (System.getProperty(prop) != null) {
-                            throw new IllegalStateException("property: " + prop + " is unexpectedly set: " + System.getProperty(prop));
-                        }
-                        System.setProperty(prop, url.toString());
+        for (URL url : JarHell.parseClassPath()) {
+            for (Map.Entry<Pattern,String> e : SPECIAL_JARS.entrySet()) {
+                if (e.getKey().matcher(url.getPath()).matches()) {
+                    String prop = e.getValue();
+                    if (System.getProperty(prop) != null) {
+                        throw new IllegalStateException("property: " + prop + " is unexpectedly set: " + System.getProperty(prop));
                     }
+                    System.setProperty(prop, url.toString());
                 }
             }
-            for (String prop : SPECIAL_JARS.values()) {
-                if (System.getProperty(prop) == null) {
-                    System.setProperty(prop, "file:/dev/null"); // no chance to be interpreted as "all"
-                }
+        }
+        for (String prop : SPECIAL_JARS.values()) {
+            if (System.getProperty(prop) == null) {
+                System.setProperty(prop, "file:/dev/null"); // no chance to be interpreted as "all"
             }
-        } else {
-            // we could try to parse the classpath or something, but screw it for now.
-            throw new UnsupportedOperationException("Unsupported system classloader type: " + loader.getClass());
         }
     }
 
diff --git a/core/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java b/core/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java
index c60d689..64e2655 100644
--- a/core/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java
+++ b/core/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.client.transport;
 
 import com.carrotsearch.hppc.cursors.ObjectCursor;
-import com.google.common.collect.Sets;
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.Version;
 import org.elasticsearch.action.ActionListener;
@@ -396,7 +395,7 @@ public class TransportClientNodesService extends AbstractComponent {
         protected void doSample() {
             // the nodes we are going to ping include the core listed nodes that were added
             // and the last round of discovered nodes
-            Set<DiscoveryNode> nodesToPing = Sets.newHashSet();
+            Set<DiscoveryNode> nodesToPing = new HashSet<>();
             for (DiscoveryNode node : listedNodes) {
                 nodesToPing.add(node);
             }
diff --git a/core/src/main/java/org/elasticsearch/cluster/ClusterModule.java b/core/src/main/java/org/elasticsearch/cluster/ClusterModule.java
index 4720bb0..0cb46cb 100644
--- a/core/src/main/java/org/elasticsearch/cluster/ClusterModule.java
+++ b/core/src/main/java/org/elasticsearch/cluster/ClusterModule.java
@@ -90,6 +90,7 @@ import org.elasticsearch.indices.recovery.RecoverySettings;
 import org.elasticsearch.indices.store.IndicesStore;
 import org.elasticsearch.indices.ttl.IndicesTTLService;
 import org.elasticsearch.search.SearchService;
+import org.elasticsearch.search.internal.DefaultSearchContext;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
@@ -275,6 +276,7 @@ public class ClusterModule extends AbstractModule {
         registerIndexDynamicSetting(IndicesRequestCache.INDEX_CACHE_REQUEST_ENABLED, Validator.BOOLEAN);
         registerIndexDynamicSetting(IndicesRequestCache.DEPRECATED_INDEX_CACHE_REQUEST_ENABLED, Validator.BOOLEAN);
         registerIndexDynamicSetting(UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING, Validator.TIME);
+        registerIndexDynamicSetting(DefaultSearchContext.MAX_RESULT_WINDOW, Validator.POSITIVE_INTEGER);
     }
 
     public void registerIndexDynamicSetting(String setting, Validator validator) {
diff --git a/core/src/main/java/org/elasticsearch/cluster/block/ClusterBlocks.java b/core/src/main/java/org/elasticsearch/cluster/block/ClusterBlocks.java
index 1724c41..8d902f6 100644
--- a/core/src/main/java/org/elasticsearch/cluster/block/ClusterBlocks.java
+++ b/core/src/main/java/org/elasticsearch/cluster/block/ClusterBlocks.java
@@ -21,7 +21,6 @@ package org.elasticsearch.cluster.block;
 
 import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Sets;
 import org.elasticsearch.cluster.AbstractDiffable;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaDataIndexStateService;
@@ -31,6 +30,7 @@ import org.elasticsearch.rest.RestStatus;
 
 import java.io.IOException;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.Map;
 import java.util.Set;
 
@@ -270,7 +270,7 @@ public class ClusterBlocks extends AbstractDiffable<ClusterBlocks> {
 
     public static class Builder {
 
-        private Set<ClusterBlock> global = Sets.newHashSet();
+        private Set<ClusterBlock> global = new HashSet<>();
 
         private Map<String, Set<ClusterBlock>> indices = new HashMap<>();
 
@@ -281,7 +281,7 @@ public class ClusterBlocks extends AbstractDiffable<ClusterBlocks> {
             global.addAll(blocks.global());
             for (Map.Entry<String, ImmutableSet<ClusterBlock>> entry : blocks.indices().entrySet()) {
                 if (!indices.containsKey(entry.getKey())) {
-                    indices.put(entry.getKey(), Sets.<ClusterBlock>newHashSet());
+                    indices.put(entry.getKey(), new HashSet<>());
                 }
                 indices.get(entry.getKey()).addAll(entry.getValue());
             }
@@ -319,7 +319,7 @@ public class ClusterBlocks extends AbstractDiffable<ClusterBlocks> {
 
         public Builder addIndexBlock(String index, ClusterBlock block) {
             if (!indices.containsKey(index)) {
-                indices.put(index, Sets.<ClusterBlock>newHashSet());
+                indices.put(index, new HashSet<>());
             }
             indices.get(index).add(block);
             return this;
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/AliasValidator.java b/core/src/main/java/org/elasticsearch/cluster/metadata/AliasValidator.java
index d5b398c..f12824d 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/AliasValidator.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/AliasValidator.java
@@ -28,7 +28,7 @@ import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.Index;
 import org.elasticsearch.index.query.IndexQueryParserService;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.indices.InvalidAliasNameException;
 
 import java.io.IOException;
@@ -142,10 +142,10 @@ public class AliasValidator extends AbstractComponent {
     }
 
     private void validateAliasFilter(XContentParser parser, IndexQueryParserService indexQueryParserService) throws IOException {
-        QueryShardContext context = indexQueryParserService.getShardContext();
+        QueryParseContext context = indexQueryParserService.getParseContext();
         try {
             context.reset(parser);
-            context.parseContext().parseInnerFilter();
+            context.parseInnerFilter();
         } finally {
             context.reset(null);
             parser.close();
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/IndexTemplateMetaData.java b/core/src/main/java/org/elasticsearch/cluster/metadata/IndexTemplateMetaData.java
index 4f0539e..5b70f68 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/IndexTemplateMetaData.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/IndexTemplateMetaData.java
@@ -20,7 +20,6 @@ package org.elasticsearch.cluster.metadata;
 
 import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-import com.google.common.collect.Sets;
 import org.elasticsearch.cluster.AbstractDiffable;
 import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.collect.MapBuilder;
@@ -29,6 +28,7 @@ import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.settings.loader.SettingsLoader;
+import org.elasticsearch.common.util.set.Sets;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexTemplateService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexTemplateService.java
index 975ebbb..f5b163c 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexTemplateService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexTemplateService.java
@@ -19,7 +19,6 @@
 package org.elasticsearch.cluster.metadata;
 
 import com.carrotsearch.hppc.cursors.ObjectCursor;
-import com.google.common.collect.Sets;
 import org.elasticsearch.action.admin.indices.alias.Alias;
 import org.elasticsearch.action.support.master.MasterNodeRequest;
 import org.elasticsearch.cluster.ClusterService;
@@ -39,6 +38,7 @@ import org.elasticsearch.indices.InvalidIndexTemplateException;
 
 import java.util.ArrayList;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Locale;
 import java.util.Map;
@@ -76,7 +76,7 @@ public class MetaDataIndexTemplateService extends AbstractComponent {
 
             @Override
             public ClusterState execute(ClusterState currentState) {
-                Set<String> templateNames = Sets.newHashSet();
+                Set<String> templateNames = new HashSet<>();
                 for (ObjectCursor<String> cursor : currentState.metaData().templates().keys()) {
                     String templateName = cursor.value;
                     if (Regex.simpleMatch(request.name, templateName)) {
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java
index a791361..c8b78b0 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java
@@ -20,8 +20,6 @@
 package org.elasticsearch.cluster.metadata;
 
 import com.carrotsearch.hppc.cursors.ObjectCursor;
-import com.google.common.collect.Sets;
-import org.elasticsearch.Version;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.admin.indices.mapping.put.PutMappingClusterStateUpdateRequest;
 import org.elasticsearch.cluster.AckedClusterStateUpdateTask;
@@ -49,6 +47,7 @@ import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
@@ -182,7 +181,7 @@ public class MetaDataMappingService extends AbstractComponent {
                 // we need to create the index here, and add the current mapping to it, so we can merge
                 indexService = indicesService.createIndex(indexMetaData.index(), indexMetaData.settings(), currentState.nodes().localNode().id());
                 removeIndex = true;
-                Set<String> typesToIntroduce = Sets.newHashSet();
+                Set<String> typesToIntroduce = new HashSet<>();
                 for (MappingTask task : tasks) {
                     if (task instanceof UpdateTask) {
                         typesToIntroduce.add(((UpdateTask) task).type);
@@ -223,7 +222,7 @@ public class MetaDataMappingService extends AbstractComponent {
         boolean dirty = false;
         String index = indexService.index().name();
         // keep track of what we already refreshed, no need to refresh it again...
-        Set<String> processedRefreshes = Sets.newHashSet();
+        Set<String> processedRefreshes = new HashSet<>();
         for (MappingTask task : tasks) {
             if (task instanceof RefreshTask) {
                 RefreshTask refreshTask = (RefreshTask) task;
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataUpdateSettingsService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataUpdateSettingsService.java
index 4665633..65d862c 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataUpdateSettingsService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataUpdateSettingsService.java
@@ -19,13 +19,16 @@
 
 package org.elasticsearch.cluster.metadata;
 
-import com.google.common.collect.Sets;
 import org.elasticsearch.Version;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.admin.indices.settings.put.UpdateSettingsClusterStateUpdateRequest;
 import org.elasticsearch.action.admin.indices.upgrade.post.UpgradeSettingsClusterStateUpdateRequest;
 import org.elasticsearch.action.support.IndicesOptions;
-import org.elasticsearch.cluster.*;
+import org.elasticsearch.cluster.AckedClusterStateUpdateTask;
+import org.elasticsearch.cluster.ClusterChangedEvent;
+import org.elasticsearch.cluster.ClusterService;
+import org.elasticsearch.cluster.ClusterState;
+import org.elasticsearch.cluster.ClusterStateListener;
 import org.elasticsearch.cluster.ack.ClusterStateUpdateResponse;
 import org.elasticsearch.cluster.block.ClusterBlocks;
 import org.elasticsearch.cluster.routing.RoutingTable;
@@ -41,7 +44,13 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.index.settings.IndexDynamicSettings;
 
-import java.util.*;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Locale;
+import java.util.Map;
+import java.util.Set;
 
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 
@@ -185,8 +194,8 @@ public class MetaDataUpdateSettingsService extends AbstractComponent implements
 
         final Settings closeSettings = updatedSettingsBuilder.build();
 
-        final Set<String> removedSettings = Sets.newHashSet();
-        final Set<String> errors = Sets.newHashSet();
+        final Set<String> removedSettings = new HashSet<>();
+        final Set<String> errors = new HashSet<>();
         for (Map.Entry<String, String> setting : updatedSettingsBuilder.internalMap().entrySet()) {
             if (!dynamicSettings.hasDynamicSetting(setting.getKey())) {
                 removedSettings.add(setting.getKey());
@@ -225,8 +234,8 @@ public class MetaDataUpdateSettingsService extends AbstractComponent implements
 
                 // allow to change any settings to a close index, and only allow dynamic settings to be changed
                 // on an open index
-                Set<String> openIndices = Sets.newHashSet();
-                Set<String> closeIndices = Sets.newHashSet();
+                Set<String> openIndices = new HashSet<>();
+                Set<String> closeIndices = new HashSet<>();
                 for (String index : actualIndices) {
                     if (currentState.metaData().index(index).state() == IndexMetaData.State.OPEN) {
                         openIndices.add(index);
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/IndexRoutingTable.java b/core/src/main/java/org/elasticsearch/cluster/routing/IndexRoutingTable.java
index 2987cdf..a909b55 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/IndexRoutingTable.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/IndexRoutingTable.java
@@ -22,7 +22,6 @@ package org.elasticsearch.cluster.routing;
 import com.carrotsearch.hppc.IntSet;
 import com.carrotsearch.hppc.cursors.IntCursor;
 import com.carrotsearch.hppc.cursors.IntObjectCursor;
-import com.google.common.collect.Sets;
 import com.google.common.collect.UnmodifiableIterator;
 import org.apache.lucene.util.CollectionUtil;
 import org.elasticsearch.cluster.AbstractDiffable;
@@ -37,6 +36,7 @@ import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Comparator;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
 import java.util.concurrent.ThreadLocalRandom;
@@ -137,7 +137,7 @@ public class IndexRoutingTable extends AbstractDiffable<IndexRoutingTable> imple
 
         // check the number of shards
         if (indexMetaData.numberOfShards() != shards().size()) {
-            Set<Integer> expected = Sets.newHashSet();
+            Set<Integer> expected = new HashSet<>();
             for (int i = 0; i < indexMetaData.numberOfShards(); i++) {
                 expected.add(i);
             }
@@ -176,7 +176,7 @@ public class IndexRoutingTable extends AbstractDiffable<IndexRoutingTable> imple
      * @return number of distinct nodes this index has at least one shard allocated on
      */
     public int numberOfNodesShardsAreAllocatedOn(String... excludedNodes) {
-        Set<String> nodes = Sets.newHashSet();
+        Set<String> nodes = new HashSet<>();
         for (IndexShardRoutingTable shardRoutingTable : this) {
             for (ShardRouting shardRouting : shardRoutingTable) {
                 if (shardRouting.assignedToNode()) {
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/IndexShardRoutingTable.java b/core/src/main/java/org/elasticsearch/cluster/routing/IndexShardRoutingTable.java
index 1f9a346..55301b4 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/IndexShardRoutingTable.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/IndexShardRoutingTable.java
@@ -20,12 +20,12 @@
 package org.elasticsearch.cluster.routing;
 
 import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.Sets;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
 import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
+import org.elasticsearch.common.util.set.Sets;
 import org.elasticsearch.index.shard.ShardId;
 
 import java.io.IOException;
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java
index 41459c9..0a2a5c9 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java
@@ -35,14 +35,13 @@ import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Comparator;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.function.Predicate;
 
-import static com.google.common.collect.Sets.newHashSet;
-
 /**
  * {@link RoutingNodes} represents a copy the routing information contained in
  * the {@link ClusterState cluster state}.
@@ -704,7 +703,7 @@ public class RoutingNodes implements Iterable<RoutingNode> {
         int inactivePrimaryCount = 0;
         int inactiveShardCount = 0;
         int relocating = 0;
-        final Set<ShardId> seenShards = newHashSet();
+        final Set<ShardId> seenShards = new HashSet<>();
         Map<String, Integer> indicesAndShards = new HashMap<>();
         for (RoutingNode node : routingNodes) {
             for (ShardRouting shard : node) {
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/AwarenessAllocationDecider.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/AwarenessAllocationDecider.java
index f87f07d..c0004c9 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/AwarenessAllocationDecider.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/AwarenessAllocationDecider.java
@@ -188,7 +188,7 @@ public class AwarenessAllocationDecider extends AllocationDecider {
                 if (assignedShard.relocating()) {
                     RoutingNode relocationNode = allocation.routingNodes().node(assignedShard.relocatingNodeId());
                     shardPerAttribute.addTo(relocationNode.node().attributes().get(awarenessAttribute), 1);
-                } else if (assignedShard.started()) {
+                } else if (assignedShard.started() || assignedShard.initializing()) {
                     RoutingNode routingNode = allocation.routingNodes().node(assignedShard.currentNodeId());
                     shardPerAttribute.addTo(routingNode.node().attributes().get(awarenessAttribute), 1);
                 }
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java
index b7ee93e..9a6353a 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.cluster.routing.allocation.decider;
 
-import com.google.common.collect.Sets;
 import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.client.Client;
 import org.elasticsearch.cluster.ClusterInfo;
@@ -36,6 +35,7 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.ByteSizeValue;
 import org.elasticsearch.common.unit.RatioValue;
 import org.elasticsearch.common.unit.TimeValue;
+import org.elasticsearch.common.util.set.Sets;
 import org.elasticsearch.node.settings.NodeSettingsService;
 
 import java.util.Map;
diff --git a/core/src/main/java/org/elasticsearch/common/geo/ShapeRelation.java b/core/src/main/java/org/elasticsearch/common/geo/ShapeRelation.java
index 67287b6..6ee1693 100644
--- a/core/src/main/java/org/elasticsearch/common/geo/ShapeRelation.java
+++ b/core/src/main/java/org/elasticsearch/common/geo/ShapeRelation.java
@@ -19,18 +19,13 @@
 
 package org.elasticsearch.common.geo;
 
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.io.stream.Writeable;
-
-import java.io.IOException;
 import java.util.Locale;
 
 /**
  * Enum representing the relationship between a Query / Filter Shape and indexed Shapes
  * that will be used to determine if a Document should be matched or not
  */
-public enum ShapeRelation implements Writeable<ShapeRelation>{
+public enum ShapeRelation {
 
     INTERSECTS("intersects"),
     DISJOINT("disjoint"),
@@ -42,20 +37,6 @@ public enum ShapeRelation implements Writeable<ShapeRelation>{
         this.relationName = relationName;
     }
 
-    @Override
-    public ShapeRelation readFrom(StreamInput in) throws IOException {
-        int ordinal = in.readVInt();
-        if (ordinal < 0 || ordinal >= values().length) {
-            throw new IOException("Unknown ShapeRelation ordinal [" + ordinal + "]");
-        }
-        return values()[ordinal];
-    }
-
-    @Override
-    public void writeTo(StreamOutput out) throws IOException {
-        out.writeVInt(ordinal());
-    }
-
     public static ShapeRelation getRelationByName(String name) {
         name = name.toLowerCase(Locale.ENGLISH);
         for (ShapeRelation relation : ShapeRelation.values()) {
diff --git a/core/src/main/java/org/elasticsearch/common/geo/SpatialStrategy.java b/core/src/main/java/org/elasticsearch/common/geo/SpatialStrategy.java
index 23c1dbb..a83f291 100644
--- a/core/src/main/java/org/elasticsearch/common/geo/SpatialStrategy.java
+++ b/core/src/main/java/org/elasticsearch/common/geo/SpatialStrategy.java
@@ -18,16 +18,11 @@
  */
 package org.elasticsearch.common.geo;
 
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.io.stream.Writeable;
-
-import java.io.IOException;
 
 /**
  *
  */
-public enum SpatialStrategy implements Writeable<SpatialStrategy> {
+public enum SpatialStrategy {
 
     TERM("term"),
     RECURSIVE("recursive");
@@ -41,27 +36,4 @@ public enum SpatialStrategy implements Writeable<SpatialStrategy> {
     public String getStrategyName() {
         return strategyName;
     }
-
-    @Override
-    public SpatialStrategy readFrom(StreamInput in) throws IOException {
-        int ordinal = in.readVInt();
-        if (ordinal < 0 || ordinal >= values().length) {
-            throw new IOException("Unknown SpatialStrategy ordinal [" + ordinal + "]");
-        }
-        return values()[ordinal];
-    }
-
-    @Override
-    public void writeTo(StreamOutput out) throws IOException {
-        out.writeVInt(ordinal());
-    }
-
-    public static SpatialStrategy fromString(String strategyName) {
-        for (SpatialStrategy strategy : values()) {
-            if (strategy.strategyName.equals(strategyName)) {
-                return strategy;
-            }
-        }
-        return null;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/common/geo/builders/BasePolygonBuilder.java b/core/src/main/java/org/elasticsearch/common/geo/builders/BasePolygonBuilder.java
index c37c8a6..aabba08 100644
--- a/core/src/main/java/org/elasticsearch/common/geo/builders/BasePolygonBuilder.java
+++ b/core/src/main/java/org/elasticsearch/common/geo/builders/BasePolygonBuilder.java
@@ -19,11 +19,16 @@
 
 package org.elasticsearch.common.geo.builders;
 
-import com.google.common.collect.Sets;
 import com.spatial4j.core.exception.InvalidShapeException;
 import com.spatial4j.core.shape.Shape;
-import com.vividsolutions.jts.geom.*;
+import com.vividsolutions.jts.geom.Coordinate;
+import com.vividsolutions.jts.geom.Geometry;
+import com.vividsolutions.jts.geom.GeometryFactory;
+import com.vividsolutions.jts.geom.LinearRing;
+import com.vividsolutions.jts.geom.MultiPolygon;
+import com.vividsolutions.jts.geom.Polygon;
 import org.elasticsearch.common.collect.Tuple;
+import org.elasticsearch.common.util.set.Sets;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
diff --git a/core/src/main/java/org/elasticsearch/common/inject/AbstractModule.java b/core/src/main/java/org/elasticsearch/common/inject/AbstractModule.java
index bfebed7..af90884 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/AbstractModule.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/AbstractModule.java
@@ -25,8 +25,8 @@ import org.elasticsearch.common.inject.spi.TypeConverter;
 import org.elasticsearch.common.inject.spi.TypeListener;
 
 import java.lang.annotation.Annotation;
+import java.util.Objects;
 
-import static com.google.common.base.Preconditions.checkNotNull;
 import static com.google.common.base.Preconditions.checkState;
 
 /**
@@ -56,7 +56,7 @@ public abstract class AbstractModule implements Module {
     public final synchronized void configure(Binder builder) {
         checkState(this.binder == null, "Re-entry is not allowed.");
 
-        this.binder = checkNotNull(builder, "builder");
+        this.binder = Objects.requireNonNull(builder, "builder");
         try {
             configure();
         } finally {
diff --git a/core/src/main/java/org/elasticsearch/common/inject/InheritingState.java b/core/src/main/java/org/elasticsearch/common/inject/InheritingState.java
index d51638d..d70f47a 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/InheritingState.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/InheritingState.java
@@ -33,8 +33,7 @@ import java.util.HashMap;
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
-
-import static com.google.common.base.Preconditions.checkNotNull;
+import java.util.Objects;
 
 /**
  * @author jessewilson@google.com (Jesse Wilson)
@@ -54,7 +53,7 @@ class InheritingState implements State {
     private final Object lock;
 
     InheritingState(State parent) {
-        this.parent = checkNotNull(parent, "parent");
+        this.parent = Objects.requireNonNull(parent, "parent");
         this.lock = (parent == State.NONE) ? this : parent.lock();
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/inject/Initializer.java b/core/src/main/java/org/elasticsearch/common/inject/Initializer.java
index 1cb91f4..f1288c5 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/Initializer.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/Initializer.java
@@ -23,11 +23,10 @@ import org.elasticsearch.common.inject.spi.InjectionPoint;
 import java.util.ArrayList;
 import java.util.IdentityHashMap;
 import java.util.Map;
+import java.util.Objects;
 import java.util.Set;
 import java.util.concurrent.CountDownLatch;
 
-import static com.google.common.base.Preconditions.checkNotNull;
-
 /**
  * Manages and injects instances at injector-creation time. This is made more complicated by
  * instances that request other instances while they're being injected. We overcome this by using
@@ -60,7 +59,7 @@ class Initializer {
      */
     public <T> Initializable<T> requestInjection(InjectorImpl injector, T instance, Object source,
                                                  Set<InjectionPoint> injectionPoints) {
-        checkNotNull(source);
+        Objects.requireNonNull(source);
 
         // short circuit if the object has no injections
         if (instance == null
@@ -118,8 +117,8 @@ class Initializer {
 
         public InjectableReference(InjectorImpl injector, T instance, Object source) {
             this.injector = injector;
-            this.instance = checkNotNull(instance, "instance");
-            this.source = checkNotNull(source, "source");
+            this.instance = Objects.requireNonNull(instance, "instance");
+            this.source = Objects.requireNonNull(source, "source");
         }
 
         public void validate(Errors errors) throws ErrorsException {
diff --git a/core/src/main/java/org/elasticsearch/common/inject/InjectorShell.java b/core/src/main/java/org/elasticsearch/common/inject/InjectorShell.java
index 5ac7934..510d9b5 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/InjectorShell.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/InjectorShell.java
@@ -35,9 +35,9 @@ import org.elasticsearch.common.inject.spi.TypeListenerBinding;
 
 import java.util.ArrayList;
 import java.util.List;
+import java.util.Objects;
 import java.util.logging.Logger;
 
-import static com.google.common.base.Preconditions.checkNotNull;
 import static com.google.common.base.Preconditions.checkState;
 import static org.elasticsearch.common.inject.Scopes.SINGLETON;
 
@@ -257,7 +257,7 @@ class InjectorShell {
         final Stage stage;
 
         private RootModule(Stage stage) {
-            this.stage = checkNotNull(stage, "stage");
+            this.stage = Objects.requireNonNull(stage, "stage");
         }
 
         @Override
diff --git a/core/src/main/java/org/elasticsearch/common/inject/Injectors.java b/core/src/main/java/org/elasticsearch/common/inject/Injectors.java
index a51487e..40a0ae1 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/Injectors.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/Injectors.java
@@ -19,12 +19,12 @@
 
 package org.elasticsearch.common.inject;
 
-import com.google.common.collect.Sets;
 import org.elasticsearch.common.inject.matcher.Matcher;
 import org.elasticsearch.common.inject.name.Names;
 import org.elasticsearch.common.inject.spi.Message;
 
 import java.lang.reflect.Type;
+import java.util.HashSet;
 import java.util.Map;
 import java.util.Map.Entry;
 import java.util.Set;
@@ -69,7 +69,7 @@ public class Injectors {
      * @return a set of objects returned from this injector
      */
     public static <T> Set<T> getInstancesOf(Injector injector, Class<T> baseClass) {
-        Set<T> answer = Sets.newHashSet();
+        Set<T> answer = new HashSet<>();
         Set<Entry<Key<?>, Binding<?>>> entries = injector.getBindings().entrySet();
         for (Entry<Key<?>, Binding<?>> entry : entries) {
             Key<?> key = entry.getKey();
@@ -93,7 +93,7 @@ public class Injectors {
      * @return a set of objects returned from this injector
      */
     public static <T> Set<T> getInstancesOf(Injector injector, Matcher<Class> matcher) {
-        Set<T> answer = Sets.newHashSet();
+        Set<T> answer = new HashSet<>();
         Set<Entry<Key<?>, Binding<?>>> entries = injector.getBindings().entrySet();
         for (Entry<Key<?>, Binding<?>> entry : entries) {
             Key<?> key = entry.getKey();
@@ -114,7 +114,7 @@ public class Injectors {
      * @return a set of objects returned from this injector
      */
     public static <T> Set<Provider<T>> getProvidersOf(Injector injector, Matcher<Class> matcher) {
-        Set<Provider<T>> answer = Sets.newHashSet();
+        Set<Provider<T>> answer = new HashSet<>();
         Set<Entry<Key<?>, Binding<?>>> entries = injector.getBindings().entrySet();
         for (Entry<Key<?>, Binding<?>> entry : entries) {
             Key<?> key = entry.getKey();
@@ -135,7 +135,7 @@ public class Injectors {
      * @return a set of objects returned from this injector
      */
     public static <T> Set<Provider<T>> getProvidersOf(Injector injector, Class<T> baseClass) {
-        Set<Provider<T>> answer = Sets.newHashSet();
+        Set<Provider<T>> answer = new HashSet<>();
         Set<Entry<Key<?>, Binding<?>>> entries = injector.getBindings().entrySet();
         for (Entry<Key<?>, Binding<?>> entry : entries) {
             Key<?> key = entry.getKey();
@@ -186,7 +186,7 @@ public class Injectors {
      * @return a set of objects returned from this injector
      */
     public static Set<Binding<?>> getBindingsOf(Injector injector, Matcher<Class> matcher) {
-        Set<Binding<?>> answer = Sets.newHashSet();
+        Set<Binding<?>> answer = new HashSet<>();
         Set<Entry<Key<?>, Binding<?>>> entries = injector.getBindings().entrySet();
         for (Entry<Key<?>, Binding<?>> entry : entries) {
             Key<?> key = entry.getKey();
@@ -205,7 +205,7 @@ public class Injectors {
      * @return a set of objects returned from this injector
      */
     public static Set<Binding<?>> getBindingsOf(Injector injector, Class<?> baseClass) {
-        Set<Binding<?>> answer = Sets.newHashSet();
+        Set<Binding<?>> answer = new HashSet<>();
         Set<Entry<Key<?>, Binding<?>>> entries = injector.getBindings().entrySet();
         for (Entry<Key<?>, Binding<?>> entry : entries) {
             Key<?> key = entry.getKey();
diff --git a/core/src/main/java/org/elasticsearch/common/inject/InternalFactoryToProviderAdapter.java b/core/src/main/java/org/elasticsearch/common/inject/InternalFactoryToProviderAdapter.java
index 9cdc4e4..d748cec 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/InternalFactoryToProviderAdapter.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/InternalFactoryToProviderAdapter.java
@@ -19,7 +19,7 @@ package org.elasticsearch.common.inject;
 import org.elasticsearch.common.inject.internal.*;
 import org.elasticsearch.common.inject.spi.Dependency;
 
-import static com.google.common.base.Preconditions.checkNotNull;
+import java.util.Objects;
 
 /**
  * @author crazybob@google.com (Bob Lee)
@@ -35,8 +35,8 @@ class InternalFactoryToProviderAdapter<T> implements InternalFactory<T> {
 
     public InternalFactoryToProviderAdapter(
             Initializable<Provider<? extends T>> initializable, Object source) {
-        this.initializable = checkNotNull(initializable, "provider");
-        this.source = checkNotNull(source, "source");
+        this.initializable = Objects.requireNonNull(initializable, "provider");
+        this.source = Objects.requireNonNull(source, "source");
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/common/inject/Key.java b/core/src/main/java/org/elasticsearch/common/inject/Key.java
index 7de5735..e2bbcf8 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/Key.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/Key.java
@@ -22,9 +22,9 @@ import org.elasticsearch.common.inject.internal.ToStringBuilder;
 
 import java.lang.annotation.Annotation;
 import java.lang.reflect.Type;
+import java.util.Objects;
 
 import static com.google.common.base.Preconditions.checkArgument;
-import static com.google.common.base.Preconditions.checkNotNull;
 
 /**
  * Binding key consisting of an injection type and an optional annotation.
@@ -343,7 +343,7 @@ public class Key<T> {
      * Gets the strategy for an annotation.
      */
     static AnnotationStrategy strategyFor(Annotation annotation) {
-        checkNotNull(annotation, "annotation");
+        Objects.requireNonNull(annotation, "annotation");
         Class<? extends Annotation> annotationType = annotation.annotationType();
         ensureRetainedAtRuntime(annotationType);
         ensureIsBindingAnnotation(annotationType);
@@ -359,7 +359,7 @@ public class Key<T> {
      * Gets the strategy for an annotation type.
      */
     static AnnotationStrategy strategyFor(Class<? extends Annotation> annotationType) {
-        checkNotNull(annotationType, "annotation type");
+        Objects.requireNonNull(annotationType, "annotation type");
         ensureRetainedAtRuntime(annotationType);
         ensureIsBindingAnnotation(annotationType);
         return new AnnotationTypeStrategy(annotationType, null);
@@ -414,7 +414,7 @@ public class Key<T> {
         final Annotation annotation;
 
         AnnotationInstanceStrategy(Annotation annotation) {
-            this.annotation = checkNotNull(annotation, "annotation");
+            this.annotation = Objects.requireNonNull(annotation, "annotation");
         }
 
         @Override
@@ -467,7 +467,7 @@ public class Key<T> {
 
         AnnotationTypeStrategy(Class<? extends Annotation> annotationType,
                                Annotation annotation) {
-            this.annotationType = checkNotNull(annotationType, "annotation type");
+            this.annotationType = Objects.requireNonNull(annotationType, "annotation type");
             this.annotation = annotation;
         }
 
diff --git a/core/src/main/java/org/elasticsearch/common/inject/ScopeBindingProcessor.java b/core/src/main/java/org/elasticsearch/common/inject/ScopeBindingProcessor.java
index 019d04c..187db3b 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/ScopeBindingProcessor.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/ScopeBindingProcessor.java
@@ -21,8 +21,7 @@ import org.elasticsearch.common.inject.internal.Errors;
 import org.elasticsearch.common.inject.spi.ScopeBinding;
 
 import java.lang.annotation.Annotation;
-
-import static com.google.common.base.Preconditions.checkNotNull;
+import java.util.Objects;
 
 /**
  * Handles {@link Binder#bindScope} commands.
@@ -52,11 +51,11 @@ class ScopeBindingProcessor extends AbstractProcessor {
             // Go ahead and bind anyway so we don't get collateral errors.
         }
 
-        Scope existing = injector.state.getScope(checkNotNull(annotationType, "annotation type"));
+        Scope existing = injector.state.getScope(Objects.requireNonNull(annotationType, "annotation type"));
         if (existing != null) {
             errors.duplicateScopes(existing, annotationType, scope);
         } else {
-            injector.state.putAnnotation(annotationType, checkNotNull(scope, "scope"));
+            injector.state.putAnnotation(annotationType, Objects.requireNonNull(scope, "scope"));
         }
 
         return true;
diff --git a/core/src/main/java/org/elasticsearch/common/inject/TypeLiteral.java b/core/src/main/java/org/elasticsearch/common/inject/TypeLiteral.java
index b83df09..de9101d 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/TypeLiteral.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/TypeLiteral.java
@@ -21,11 +21,10 @@ import org.elasticsearch.common.inject.util.Types;
 
 import java.lang.reflect.*;
 import java.util.Arrays;
-import java.util.Collections;
 import java.util.List;
+import java.util.Objects;
 
 import static com.google.common.base.Preconditions.checkArgument;
-import static com.google.common.base.Preconditions.checkNotNull;
 import static org.elasticsearch.common.inject.internal.MoreTypes.canonicalize;
 
 /**
@@ -85,7 +84,7 @@ public class TypeLiteral<T> {
      */
     @SuppressWarnings("unchecked")
     TypeLiteral(Type type) {
-        this.type = canonicalize(checkNotNull(type, "type"));
+        this.type = canonicalize(Objects.requireNonNull(type, "type"));
         this.rawType = (Class<? super T>) MoreTypes.getRawType(this.type);
         this.hashCode = MoreTypes.hashCode(this.type);
     }
diff --git a/core/src/main/java/org/elasticsearch/common/inject/WeakKeySet.java b/core/src/main/java/org/elasticsearch/common/inject/WeakKeySet.java
index bff939d..f13ff34 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/WeakKeySet.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/WeakKeySet.java
@@ -16,8 +16,7 @@
 
 package org.elasticsearch.common.inject;
 
-import com.google.common.collect.Sets;
-
+import java.util.HashSet;
 import java.util.Set;
 
 /**
@@ -34,7 +33,7 @@ final class WeakKeySet {
      * keys whose class names are equal but class loaders are different. This shouldn't be an issue
      * in practice.
      */
-    private Set<String> backingSet = Sets.newHashSet();
+    private Set<String> backingSet = new HashSet<>();
 
     public boolean add(Key<?> key) {
         return backingSet.add(key.toString());
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/AbstractBindingBuilder.java b/core/src/main/java/org/elasticsearch/common/inject/internal/AbstractBindingBuilder.java
index 65b7a17..e6c3b1c 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/AbstractBindingBuilder.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/AbstractBindingBuilder.java
@@ -24,8 +24,7 @@ import org.elasticsearch.common.inject.spi.InstanceBinding;
 
 import java.lang.annotation.Annotation;
 import java.util.List;
-
-import static com.google.common.base.Preconditions.checkNotNull;
+import java.util.Objects;
 
 /**
  * Bind a value or constant.
@@ -73,7 +72,7 @@ public abstract class AbstractBindingBuilder<T> {
      * Sets the binding to a copy with the specified annotation on the bound key
      */
     protected BindingImpl<T> annotatedWithInternal(Class<? extends Annotation> annotationType) {
-        checkNotNull(annotationType, "annotationType");
+        Objects.requireNonNull(annotationType, "annotationType");
         checkNotAnnotated();
         return setBinding(binding.withKey(
                 Key.get(this.binding.getKey().getTypeLiteral(), annotationType)));
@@ -83,20 +82,20 @@ public abstract class AbstractBindingBuilder<T> {
      * Sets the binding to a copy with the specified annotation on the bound key
      */
     protected BindingImpl<T> annotatedWithInternal(Annotation annotation) {
-        checkNotNull(annotation, "annotation");
+        Objects.requireNonNull(annotation, "annotation");
         checkNotAnnotated();
         return setBinding(binding.withKey(
                 Key.get(this.binding.getKey().getTypeLiteral(), annotation)));
     }
 
     public void in(final Class<? extends Annotation> scopeAnnotation) {
-        checkNotNull(scopeAnnotation, "scopeAnnotation");
+        Objects.requireNonNull(scopeAnnotation, "scopeAnnotation");
         checkNotScoped();
         setBinding(getBinding().withScoping(Scoping.forAnnotation(scopeAnnotation)));
     }
 
     public void in(final Scope scope) {
-        checkNotNull(scope, "scope");
+        Objects.requireNonNull(scope, "scope");
         checkNotScoped();
         setBinding(getBinding().withScoping(Scoping.forInstance(scope)));
     }
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/BindingBuilder.java b/core/src/main/java/org/elasticsearch/common/inject/internal/BindingBuilder.java
index bbec011..45a1259 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/BindingBuilder.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/BindingBuilder.java
@@ -25,10 +25,9 @@ import org.elasticsearch.common.inject.spi.Message;
 
 import java.lang.annotation.Annotation;
 import java.util.List;
+import java.util.Objects;
 import java.util.Set;
 
-import static com.google.common.base.Preconditions.checkNotNull;
-
 /**
  * Bind a non-constant key.
  *
@@ -65,7 +64,7 @@ public class BindingBuilder<T> extends AbstractBindingBuilder<T>
 
     @Override
     public BindingBuilder<T> to(Key<? extends T> linkedKey) {
-        checkNotNull(linkedKey, "linkedKey");
+        Objects.requireNonNull(linkedKey, "linkedKey");
         checkNotTargetted();
         BindingImpl<T> base = getBinding();
         setBinding(new LinkedBindingImpl<>(
@@ -100,7 +99,7 @@ public class BindingBuilder<T> extends AbstractBindingBuilder<T>
 
     @Override
     public BindingBuilder<T> toProvider(Provider<? extends T> provider) {
-        checkNotNull(provider, "provider");
+        Objects.requireNonNull(provider, "provider");
         checkNotTargetted();
 
         // lookup the injection points, adding any errors to the binder's errors list
@@ -127,7 +126,7 @@ public class BindingBuilder<T> extends AbstractBindingBuilder<T>
 
     @Override
     public BindingBuilder<T> toProvider(Key<? extends Provider<? extends T>> providerKey) {
-        checkNotNull(providerKey, "providerKey");
+        Objects.requireNonNull(providerKey, "providerKey");
         checkNotTargetted();
 
         BindingImpl<T> base = getBinding();
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/ExposureBuilder.java b/core/src/main/java/org/elasticsearch/common/inject/internal/ExposureBuilder.java
index 354b27d..6b5f5f9 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/ExposureBuilder.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/ExposureBuilder.java
@@ -21,6 +21,7 @@ import org.elasticsearch.common.inject.Key;
 import org.elasticsearch.common.inject.binder.AnnotatedElementBuilder;
 
 import java.lang.annotation.Annotation;
+import java.util.Objects;
 
 /**
  * For private binder's expose() method.
@@ -44,14 +45,14 @@ public class ExposureBuilder<T> implements AnnotatedElementBuilder {
 
     @Override
     public void annotatedWith(Class<? extends Annotation> annotationType) {
-        com.google.common.base.Preconditions.checkNotNull(annotationType, "annotationType");
+        Objects.requireNonNull(annotationType, "annotationType");
         checkNotAnnotated();
         key = Key.get(key.getTypeLiteral(), annotationType);
     }
 
     @Override
     public void annotatedWith(Annotation annotation) {
-        com.google.common.base.Preconditions.checkNotNull(annotation, "annotation");
+        Objects.requireNonNull(annotation, "annotation");
         checkNotAnnotated();
         key = Key.get(key.getTypeLiteral(), annotation);
     }
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/Join.java b/core/src/main/java/org/elasticsearch/common/inject/internal/Join.java
index 6500599..db0afe9 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/Join.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/Join.java
@@ -22,8 +22,7 @@ import java.io.IOException;
 import java.util.Arrays;
 import java.util.Iterator;
 import java.util.Map;
-
-import static com.google.common.base.Preconditions.checkNotNull;
+import java.util.Objects;
 
 /**
  * Utility for joining pieces of text separated by a delimiter. It can handle
@@ -97,7 +96,7 @@ public final class Join {
      */
     public static String join(
             String delimiter, @Nullable Object firstToken, Object... otherTokens) {
-        checkNotNull(otherTokens);
+        Objects.requireNonNull(otherTokens);
         return join(delimiter, CollectionUtils.asArrayList(firstToken, otherTokens));
     }
 
@@ -207,7 +206,7 @@ public final class Join {
      */
     public static <T extends Appendable> T join(T appendable, String delimiter,
                                                 @Nullable Object firstToken, Object... otherTokens) {
-        checkNotNull(otherTokens);
+        Objects.requireNonNull(otherTokens);
         return join(appendable, delimiter, CollectionUtils.asArrayList(firstToken, otherTokens));
     }
 
@@ -232,8 +231,8 @@ public final class Join {
 
         /* This method is the workhorse of the class */
 
-        checkNotNull(appendable);
-        checkNotNull(delimiter);
+        Objects.requireNonNull(appendable);
+        Objects.requireNonNull(delimiter);
         if (tokens.hasNext()) {
             try {
                 appendOneToken(appendable, tokens.next());
@@ -268,9 +267,9 @@ public final class Join {
      */
     public static <T extends Appendable> T join(T appendable,
                                                 String keyValueSeparator, String entryDelimiter, Map<?, ?> map) {
-        checkNotNull(appendable);
-        checkNotNull(keyValueSeparator);
-        checkNotNull(entryDelimiter);
+        Objects.requireNonNull(appendable);
+        Objects.requireNonNull(keyValueSeparator);
+        Objects.requireNonNull(entryDelimiter);
         Iterator<? extends Map.Entry<?, ?>> entries = map.entrySet().iterator();
         if (entries.hasNext()) {
             try {
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/MatcherAndConverter.java b/core/src/main/java/org/elasticsearch/common/inject/internal/MatcherAndConverter.java
index 7ee9313..fbafd4c 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/MatcherAndConverter.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/MatcherAndConverter.java
@@ -20,7 +20,7 @@ import org.elasticsearch.common.inject.TypeLiteral;
 import org.elasticsearch.common.inject.matcher.Matcher;
 import org.elasticsearch.common.inject.spi.TypeConverter;
 
-import static com.google.common.base.Preconditions.checkNotNull;
+import java.util.Objects;
 
 /**
  * @author crazybob@google.com (Bob Lee)
@@ -33,8 +33,8 @@ public final class MatcherAndConverter {
 
     public MatcherAndConverter(Matcher<? super TypeLiteral<?>> typeMatcher,
                                TypeConverter typeConverter, Object source) {
-        this.typeMatcher = checkNotNull(typeMatcher, "type matcher");
-        this.typeConverter = checkNotNull(typeConverter, "converter");
+        this.typeMatcher = Objects.requireNonNull(typeMatcher, "type matcher");
+        this.typeConverter = Objects.requireNonNull(typeConverter, "converter");
         this.source = source;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/MoreTypes.java b/core/src/main/java/org/elasticsearch/common/inject/internal/MoreTypes.java
index 8587a54..6eb6f40 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/MoreTypes.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/MoreTypes.java
@@ -31,7 +31,6 @@ import java.util.NoSuchElementException;
 import java.util.Objects;
 
 import static com.google.common.base.Preconditions.checkArgument;
-import static com.google.common.base.Preconditions.checkNotNull;
 
 /**
  * Static methods for working with types that we aren't publishing in the
@@ -316,7 +315,7 @@ public class MoreTypes {
      * Returns {@code Field.class}, {@code Method.class} or {@code Constructor.class}.
      */
     public static Class<? extends Member> memberType(Member member) {
-        checkNotNull(member, "member");
+        Objects.requireNonNull(member, "member");
 
         if (member instanceof MemberImpl) {
             return ((MemberImpl) member).memberType;
@@ -355,7 +354,7 @@ public class MoreTypes {
     }
 
     public static String memberKey(Member member) {
-        checkNotNull(member, "member");
+        Objects.requireNonNull(member, "member");
 
         return "<NO_MEMBER_KEY>";
     }
@@ -456,7 +455,7 @@ public class MoreTypes {
             this.rawType = canonicalize(rawType);
             this.typeArguments = typeArguments.clone();
             for (int t = 0; t < this.typeArguments.length; t++) {
-                checkNotNull(this.typeArguments[t], "type parameter");
+                Objects.requireNonNull(this.typeArguments[t], "type parameter");
                 checkNotPrimitive(this.typeArguments[t], "type parameters");
                 this.typeArguments[t] = canonicalize(this.typeArguments[t]);
             }
@@ -566,14 +565,14 @@ public class MoreTypes {
             checkArgument(upperBounds.length == 1, "Must have exactly one upper bound.");
 
             if (lowerBounds.length == 1) {
-                checkNotNull(lowerBounds[0], "lowerBound");
+                Objects.requireNonNull(lowerBounds[0], "lowerBound");
                 checkNotPrimitive(lowerBounds[0], "wildcard bounds");
                 checkArgument(upperBounds[0] == Object.class, "bounded both ways");
                 this.lowerBound = canonicalize(lowerBounds[0]);
                 this.upperBound = Object.class;
 
             } else {
-                checkNotNull(upperBounds[0], "upperBound");
+                Objects.requireNonNull(upperBounds[0], "upperBound");
                 checkNotPrimitive(upperBounds[0], "wildcard bounds");
                 this.lowerBound = null;
                 this.upperBound = canonicalize(upperBounds[0]);
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/PrivateElementsImpl.java b/core/src/main/java/org/elasticsearch/common/inject/internal/PrivateElementsImpl.java
index 47b1f53..5d2bbad 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/PrivateElementsImpl.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/PrivateElementsImpl.java
@@ -30,10 +30,10 @@ import java.util.Collections;
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
+import java.util.Objects;
 import java.util.Set;
 
 import static com.google.common.base.Preconditions.checkArgument;
-import static com.google.common.base.Preconditions.checkNotNull;
 import static com.google.common.base.Preconditions.checkState;
 
 /**
@@ -64,7 +64,7 @@ public final class PrivateElementsImpl implements PrivateElements {
     private Injector injector;
 
     public PrivateElementsImpl(Object source) {
-        this.source = checkNotNull(source, "source");
+        this.source = Objects.requireNonNull(source, "source");
     }
 
     @Override
@@ -89,7 +89,7 @@ public final class PrivateElementsImpl implements PrivateElements {
 
     public void initInjector(Injector injector) {
         checkState(this.injector == null, "injector already initialized");
-        this.injector = checkNotNull(injector, "injector");
+        this.injector = Objects.requireNonNull(injector, "injector");
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/ProviderMethodsModule.java b/core/src/main/java/org/elasticsearch/common/inject/internal/ProviderMethodsModule.java
index 9884b88..aa556ed 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/ProviderMethodsModule.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/ProviderMethodsModule.java
@@ -32,8 +32,7 @@ import java.lang.reflect.Member;
 import java.lang.reflect.Method;
 import java.util.ArrayList;
 import java.util.List;
-
-import static com.google.common.base.Preconditions.checkNotNull;
+import java.util.Objects;
 
 /**
  * Creates bindings to methods annotated with {@literal @}{@link Provides}. Use the scope and
@@ -47,7 +46,7 @@ public final class ProviderMethodsModule implements Module {
     private final TypeLiteral<?> typeLiteral;
 
     private ProviderMethodsModule(Object delegate) {
-        this.delegate = checkNotNull(delegate, "delegate");
+        this.delegate = Objects.requireNonNull(delegate, "delegate");
         this.typeLiteral = TypeLiteral.get(this.delegate.getClass());
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/inject/matcher/Matchers.java b/core/src/main/java/org/elasticsearch/common/inject/matcher/Matchers.java
index 2c31bfc..7e663db 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/matcher/Matchers.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/matcher/Matchers.java
@@ -22,9 +22,9 @@ import java.lang.annotation.Retention;
 import java.lang.annotation.RetentionPolicy;
 import java.lang.reflect.AnnotatedElement;
 import java.lang.reflect.Method;
+import java.util.Objects;
 
 import static com.google.common.base.Preconditions.checkArgument;
-import static com.google.common.base.Preconditions.checkNotNull;
 
 /**
  * Matcher implementations. Supports matching classes and methods.
@@ -73,7 +73,7 @@ public class Matchers {
         final Matcher<? super T> delegate;
 
         private Not(Matcher<? super T> delegate) {
-            this.delegate = checkNotNull(delegate, "delegate");
+            this.delegate = Objects.requireNonNull(delegate, "delegate");
         }
 
         @Override
@@ -121,7 +121,7 @@ public class Matchers {
         private final Class<? extends Annotation> annotationType;
 
         public AnnotatedWithType(Class<? extends Annotation> annotationType) {
-            this.annotationType = checkNotNull(annotationType, "annotation type");
+            this.annotationType = Objects.requireNonNull(annotationType, "annotation type");
             checkForRuntimeRetention(annotationType);
         }
 
@@ -163,7 +163,7 @@ public class Matchers {
         private final Annotation annotation;
 
         public AnnotatedWith(Annotation annotation) {
-            this.annotation = checkNotNull(annotation, "annotation");
+            this.annotation = Objects.requireNonNull(annotation, "annotation");
             checkForRuntimeRetention(annotation.annotationType());
         }
 
@@ -205,7 +205,7 @@ public class Matchers {
         private final Class<?> superclass;
 
         public SubclassesOf(Class<?> superclass) {
-            this.superclass = checkNotNull(superclass, "superclass");
+            this.superclass = Objects.requireNonNull(superclass, "superclass");
         }
 
         @Override
@@ -244,7 +244,7 @@ public class Matchers {
         private final Object value;
 
         public Only(Object value) {
-            this.value = checkNotNull(value, "value");
+            this.value = Objects.requireNonNull(value, "value");
         }
 
         @Override
@@ -283,7 +283,7 @@ public class Matchers {
         private final Object value;
 
         public IdenticalTo(Object value) {
-            this.value = checkNotNull(value, "value");
+            this.value = Objects.requireNonNull(value, "value");
         }
 
         @Override
@@ -323,7 +323,7 @@ public class Matchers {
         private final String packageName;
 
         public InPackage(Package targetPackage) {
-            this.targetPackage = checkNotNull(targetPackage, "package");
+            this.targetPackage = Objects.requireNonNull(targetPackage, "package");
             this.packageName = targetPackage.getName();
         }
 
@@ -410,7 +410,7 @@ public class Matchers {
         private final Matcher<? super Class<?>> returnType;
 
         public Returns(Matcher<? super Class<?>> returnType) {
-            this.returnType = checkNotNull(returnType, "return type matcher");
+            this.returnType = Objects.requireNonNull(returnType, "return type matcher");
         }
 
         @Override
diff --git a/core/src/main/java/org/elasticsearch/common/inject/multibindings/Multibinder.java b/core/src/main/java/org/elasticsearch/common/inject/multibindings/Multibinder.java
index a564631..50c87d7 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/multibindings/Multibinder.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/multibindings/Multibinder.java
@@ -39,6 +39,7 @@ import java.util.ArrayList;
 import java.util.Collections;
 import java.util.LinkedHashSet;
 import java.util.List;
+import java.util.Objects;
 import java.util.Set;
 
 /**
@@ -208,10 +209,10 @@ public abstract class Multibinder<T> {
 
         private RealMultibinder(Binder binder, TypeLiteral<T> elementType,
                                 String setName, Key<Set<T>> setKey) {
-            this.binder = checkNotNull(binder, "binder");
-            this.elementType = checkNotNull(elementType, "elementType");
-            this.setName = checkNotNull(setName, "setName");
-            this.setKey = checkNotNull(setKey, "setKey");
+            this.binder = Objects.requireNonNull(binder, "binder");
+            this.elementType = Objects.requireNonNull(elementType, "elementType");
+            this.setName = Objects.requireNonNull(setName, "setName");
+            this.setKey = Objects.requireNonNull(setKey, "setKey");
         }
 
         @Override
diff --git a/core/src/main/java/org/elasticsearch/common/inject/name/NamedImpl.java b/core/src/main/java/org/elasticsearch/common/inject/name/NamedImpl.java
index 5f6a5c2..8cf7af1 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/name/NamedImpl.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/name/NamedImpl.java
@@ -18,15 +18,14 @@ package org.elasticsearch.common.inject.name;
 
 import java.io.Serializable;
 import java.lang.annotation.Annotation;
-
-import static com.google.common.base.Preconditions.checkNotNull;
+import java.util.Objects;
 
 class NamedImpl implements Named, Serializable {
 
     private final String value;
 
     public NamedImpl(String value) {
-        this.value = checkNotNull(value, "name");
+        this.value = Objects.requireNonNull(value, "name");
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/common/inject/spi/Elements.java b/core/src/main/java/org/elasticsearch/common/inject/spi/Elements.java
index b4d548d..9c50a1a 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/spi/Elements.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/spi/Elements.java
@@ -16,7 +16,6 @@
 
 package org.elasticsearch.common.inject.spi;
 
-import com.google.common.collect.Sets;
 import org.elasticsearch.common.inject.AbstractModule;
 import org.elasticsearch.common.inject.Binder;
 import org.elasticsearch.common.inject.Binding;
@@ -49,6 +48,7 @@ import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.Collections;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
 
@@ -141,7 +141,7 @@ public final class Elements {
 
         private RecordingBinder(Stage stage) {
             this.stage = stage;
-            this.modules = Sets.newHashSet();
+            this.modules = new HashSet<>();
             this.elements = new ArrayList<>();
             this.source = null;
             this.sourceProvider = new SourceProvider().plusSkippedClasses(
@@ -172,7 +172,7 @@ public final class Elements {
          */
         private RecordingBinder(RecordingBinder parent, PrivateElementsImpl privateElements) {
             this.stage = parent.stage;
-            this.modules = Sets.newHashSet();
+            this.modules = new HashSet<>();
             this.elements = privateElements.getElementsMutable();
             this.source = parent.source;
             this.sourceProvider = parent.sourceProvider;
diff --git a/core/src/main/java/org/elasticsearch/common/inject/spi/InjectionRequest.java b/core/src/main/java/org/elasticsearch/common/inject/spi/InjectionRequest.java
index 0db580e..f52e6c3 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/spi/InjectionRequest.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/spi/InjectionRequest.java
@@ -20,10 +20,9 @@ import org.elasticsearch.common.inject.Binder;
 import org.elasticsearch.common.inject.ConfigurationException;
 import org.elasticsearch.common.inject.TypeLiteral;
 
+import java.util.Objects;
 import java.util.Set;
 
-import static com.google.common.base.Preconditions.checkNotNull;
-
 /**
  * A request to inject the instance fields and methods of an instance. Requests are created
  * explicitly in a module using {@link org.elasticsearch.common.inject.Binder#requestInjection(Object)
@@ -41,9 +40,9 @@ public final class InjectionRequest<T> implements Element {
     private final T instance;
 
     public InjectionRequest(Object source, TypeLiteral<T> type, T instance) {
-        this.source = checkNotNull(source, "source");
-        this.type = checkNotNull(type, "type");
-        this.instance = checkNotNull(instance, "instance");
+        this.source = Objects.requireNonNull(source, "source");
+        this.type = Objects.requireNonNull(type, "type");
+        this.instance = Objects.requireNonNull(instance, "instance");
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/common/inject/spi/MembersInjectorLookup.java b/core/src/main/java/org/elasticsearch/common/inject/spi/MembersInjectorLookup.java
index f5b8f98..f53d662 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/spi/MembersInjectorLookup.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/spi/MembersInjectorLookup.java
@@ -20,7 +20,8 @@ import org.elasticsearch.common.inject.Binder;
 import org.elasticsearch.common.inject.MembersInjector;
 import org.elasticsearch.common.inject.TypeLiteral;
 
-import static com.google.common.base.Preconditions.checkNotNull;
+import java.util.Objects;
+
 import static com.google.common.base.Preconditions.checkState;
 
 /**
@@ -40,8 +41,8 @@ public final class MembersInjectorLookup<T> implements Element {
     private MembersInjector<T> delegate;
 
     public MembersInjectorLookup(Object source, TypeLiteral<T> type) {
-        this.source = checkNotNull(source, "source");
-        this.type = checkNotNull(type, "type");
+        this.source = Objects.requireNonNull(source, "source");
+        this.type = Objects.requireNonNull(type, "type");
     }
 
     @Override
@@ -68,7 +69,7 @@ public final class MembersInjectorLookup<T> implements Element {
      */
     public void initializeDelegate(MembersInjector<T> delegate) {
         checkState(this.delegate == null, "delegate already initialized");
-        this.delegate = checkNotNull(delegate, "delegate");
+        this.delegate = Objects.requireNonNull(delegate, "delegate");
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/common/inject/spi/Message.java b/core/src/main/java/org/elasticsearch/common/inject/spi/Message.java
index 796aa80..37aa3b9 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/spi/Message.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/spi/Message.java
@@ -27,8 +27,6 @@ import java.util.Collections;
 import java.util.List;
 import java.util.Objects;
 
-import static com.google.common.base.Preconditions.checkNotNull;
-
 /**
  * An error message and the context in which it occurred. Messages are usually created internally by
  * Guice and its extensions. Messages can be created explicitly in a module using {@link
@@ -52,7 +50,7 @@ public final class Message implements Serializable, Element {
      */
     public Message(List<Object> sources, String message, Throwable cause) {
         this.sources = Collections.unmodifiableList(sources);
-        this.message = checkNotNull(message, "message");
+        this.message = Objects.requireNonNull(message, "message");
         this.cause = cause;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/inject/spi/ProviderLookup.java b/core/src/main/java/org/elasticsearch/common/inject/spi/ProviderLookup.java
index 06a732b..61ae67a 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/spi/ProviderLookup.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/spi/ProviderLookup.java
@@ -20,7 +20,8 @@ import org.elasticsearch.common.inject.Binder;
 import org.elasticsearch.common.inject.Key;
 import org.elasticsearch.common.inject.Provider;
 
-import static com.google.common.base.Preconditions.checkNotNull;
+import java.util.Objects;
+
 import static com.google.common.base.Preconditions.checkState;
 
 /**
@@ -64,8 +65,8 @@ public final class ProviderLookup<T> implements Element {
     private Provider<T> delegate;
 
     public ProviderLookup(Object source, Key<T> key) {
-        this.source = checkNotNull(source, "source");
-        this.key = checkNotNull(key, "key");
+        this.source = Objects.requireNonNull(source, "source");
+        this.key = Objects.requireNonNull(key, "key");
     }
 
     @Override
@@ -89,7 +90,7 @@ public final class ProviderLookup<T> implements Element {
      */
     public void initializeDelegate(Provider<T> delegate) {
         checkState(this.delegate == null, "delegate already initialized");
-        this.delegate = checkNotNull(delegate, "delegate");
+        this.delegate = Objects.requireNonNull(delegate, "delegate");
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/common/inject/spi/ScopeBinding.java b/core/src/main/java/org/elasticsearch/common/inject/spi/ScopeBinding.java
index 74d3d6c..9db84af 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/spi/ScopeBinding.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/spi/ScopeBinding.java
@@ -20,8 +20,7 @@ import org.elasticsearch.common.inject.Binder;
 import org.elasticsearch.common.inject.Scope;
 
 import java.lang.annotation.Annotation;
-
-import static com.google.common.base.Preconditions.checkNotNull;
+import java.util.Objects;
 
 /**
  * Registration of a scope annotation with the scope that implements it. Instances are created
@@ -40,9 +39,9 @@ public final class ScopeBinding implements Element {
     private final Scope scope;
 
     ScopeBinding(Object source, Class<? extends Annotation> annotationType, Scope scope) {
-        this.source = checkNotNull(source, "source");
-        this.annotationType = checkNotNull(annotationType, "annotationType");
-        this.scope = checkNotNull(scope, "scope");
+        this.source = Objects.requireNonNull(source, "source");
+        this.annotationType = Objects.requireNonNull(annotationType, "annotationType");
+        this.scope = Objects.requireNonNull(scope, "scope");
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/common/inject/spi/StaticInjectionRequest.java b/core/src/main/java/org/elasticsearch/common/inject/spi/StaticInjectionRequest.java
index 1d11f32..b7a0525 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/spi/StaticInjectionRequest.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/spi/StaticInjectionRequest.java
@@ -19,10 +19,9 @@ package org.elasticsearch.common.inject.spi;
 import org.elasticsearch.common.inject.Binder;
 import org.elasticsearch.common.inject.ConfigurationException;
 
+import java.util.Objects;
 import java.util.Set;
 
-import static com.google.common.base.Preconditions.checkNotNull;
-
 /**
  * A request to inject the static fields and methods of a type. Requests are created
  * explicitly in a module using {@link org.elasticsearch.common.inject.Binder#requestStaticInjection(Class[])
@@ -38,8 +37,8 @@ public final class StaticInjectionRequest implements Element {
     private final Class<?> type;
 
     StaticInjectionRequest(Object source, Class<?> type) {
-        this.source = checkNotNull(source, "source");
-        this.type = checkNotNull(type, "type");
+        this.source = Objects.requireNonNull(source, "source");
+        this.type = Objects.requireNonNull(type, "type");
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/common/inject/spi/TypeConverterBinding.java b/core/src/main/java/org/elasticsearch/common/inject/spi/TypeConverterBinding.java
index 484a11b..84215c7 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/spi/TypeConverterBinding.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/spi/TypeConverterBinding.java
@@ -20,7 +20,7 @@ import org.elasticsearch.common.inject.Binder;
 import org.elasticsearch.common.inject.TypeLiteral;
 import org.elasticsearch.common.inject.matcher.Matcher;
 
-import static com.google.common.base.Preconditions.checkNotNull;
+import java.util.Objects;
 
 /**
  * Registration of type converters for matching target types. Instances are created
@@ -39,9 +39,9 @@ public final class TypeConverterBinding implements Element {
 
     TypeConverterBinding(Object source, Matcher<? super TypeLiteral<?>> typeMatcher,
                          TypeConverter typeConverter) {
-        this.source = checkNotNull(source, "source");
-        this.typeMatcher = checkNotNull(typeMatcher, "typeMatcher");
-        this.typeConverter = checkNotNull(typeConverter, "typeConverter");
+        this.source = Objects.requireNonNull(source, "source");
+        this.typeMatcher = Objects.requireNonNull(typeMatcher, "typeMatcher");
+        this.typeConverter = Objects.requireNonNull(typeConverter, "typeConverter");
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/common/inject/util/Modules.java b/core/src/main/java/org/elasticsearch/common/inject/util/Modules.java
index e950dc2..6e0fdca 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/util/Modules.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/util/Modules.java
@@ -17,7 +17,6 @@
 package org.elasticsearch.common.inject.util;
 
 import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Sets;
 import org.elasticsearch.common.inject.AbstractModule;
 import org.elasticsearch.common.inject.Binder;
 import org.elasticsearch.common.inject.Binding;
@@ -36,6 +35,7 @@ import java.lang.annotation.Annotation;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
@@ -151,8 +151,8 @@ public final class Modules {
                     final List<Element> elements = Elements.getElements(baseModules);
                     final List<Element> overrideElements = Elements.getElements(overrides);
 
-                    final Set<Key> overriddenKeys = Sets.newHashSet();
-                    final Set<Class<? extends Annotation>> overridesScopeAnnotations = Sets.newHashSet();
+                    final Set<Key> overriddenKeys = new HashSet<>();
+                    final Set<Class<? extends Annotation>> overridesScopeAnnotations = new HashSet<>();
 
                     // execute the overrides module, keeping track of which keys and scopes are bound
                     new ModuleWriter(binder()) {
@@ -201,7 +201,7 @@ public final class Modules {
                             PrivateBinder privateBinder = binder.withSource(privateElements.getSource())
                                     .newPrivateBinder();
 
-                            Set<Key<?>> skippedExposes = Sets.newHashSet();
+                            Set<Key<?>> skippedExposes = new HashSet<>();
 
                             for (Key<?> key : privateElements.getExposedKeys()) {
                                 if (overriddenKeys.remove(key)) {
diff --git a/core/src/main/java/org/elasticsearch/common/io/Streams.java b/core/src/main/java/org/elasticsearch/common/io/Streams.java
index e6265ab..5d79863 100644
--- a/core/src/main/java/org/elasticsearch/common/io/Streams.java
+++ b/core/src/main/java/org/elasticsearch/common/io/Streams.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.common.io;
 
 import com.google.common.base.Charsets;
-import com.google.common.base.Preconditions;
 import org.elasticsearch.common.util.Callback;
 
 import java.io.BufferedReader;
@@ -33,6 +32,7 @@ import java.io.StringWriter;
 import java.io.Writer;
 import java.util.ArrayList;
 import java.util.List;
+import java.util.Objects;
 
 /**
  * Simple utility methods for file and stream copying.
@@ -66,8 +66,8 @@ public abstract class Streams {
      * @throws IOException in case of I/O errors
      */
     public static long copy(InputStream in, OutputStream out, byte[] buffer) throws IOException {
-        Preconditions.checkNotNull(in, "No InputStream specified");
-        Preconditions.checkNotNull(out, "No OutputStream specified");
+        Objects.requireNonNull(in, "No InputStream specified");
+        Objects.requireNonNull(out, "No OutputStream specified");
         try {
             long byteCount = 0;
             int bytesRead;
@@ -100,8 +100,8 @@ public abstract class Streams {
      * @throws IOException in case of I/O errors
      */
     public static void copy(byte[] in, OutputStream out) throws IOException {
-        Preconditions.checkNotNull(in, "No input byte array specified");
-        Preconditions.checkNotNull(out, "No OutputStream specified");
+        Objects.requireNonNull(in, "No input byte array specified");
+        Objects.requireNonNull(out, "No OutputStream specified");
         try {
             out.write(in);
         } finally {
@@ -128,8 +128,8 @@ public abstract class Streams {
      * @throws IOException in case of I/O errors
      */
     public static int copy(Reader in, Writer out) throws IOException {
-        Preconditions.checkNotNull(in, "No Reader specified");
-        Preconditions.checkNotNull(out, "No Writer specified");
+        Objects.requireNonNull(in, "No Reader specified");
+        Objects.requireNonNull(out, "No Writer specified");
         try {
             int byteCount = 0;
             char[] buffer = new char[BUFFER_SIZE];
@@ -163,8 +163,8 @@ public abstract class Streams {
      * @throws IOException in case of I/O errors
      */
     public static void copy(String in, Writer out) throws IOException {
-        Preconditions.checkNotNull(in, "No input String specified");
-        Preconditions.checkNotNull(out, "No Writer specified");
+        Objects.requireNonNull(in, "No input String specified");
+        Objects.requireNonNull(out, "No Writer specified");
         try {
             out.write(in);
         } finally {
diff --git a/core/src/main/java/org/elasticsearch/common/io/stream/FilterStreamInput.java b/core/src/main/java/org/elasticsearch/common/io/stream/FilterStreamInput.java
index 5f3bd01..0dac786 100644
--- a/core/src/main/java/org/elasticsearch/common/io/stream/FilterStreamInput.java
+++ b/core/src/main/java/org/elasticsearch/common/io/stream/FilterStreamInput.java
@@ -68,4 +68,4 @@ public abstract class FilterStreamInput extends StreamInput {
     public void setVersion(Version version) {
         delegate.setVersion(version);
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java b/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java
index c2bbaa3..1b22a69 100644
--- a/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java
+++ b/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java
@@ -33,7 +33,6 @@ import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.text.StringAndBytesText;
 import org.elasticsearch.common.text.Text;
-import org.elasticsearch.index.query.QueryBuilder;
 import org.joda.time.DateTime;
 import org.joda.time.DateTimeZone;
 
@@ -46,18 +45,8 @@ import static org.elasticsearch.ElasticsearchException.readStackTrace;
 
 public abstract class StreamInput extends InputStream {
 
-    private final NamedWriteableRegistry namedWriteableRegistry;
-
     private Version version = Version.CURRENT;
 
-    protected StreamInput() {
-        this.namedWriteableRegistry = new NamedWriteableRegistry();
-    }
-
-    protected StreamInput(NamedWriteableRegistry namedWriteableRegistry) {
-        this.namedWriteableRegistry = namedWriteableRegistry;
-    }
-
     public Version getVersion() {
         return this.version;
     }
@@ -572,13 +561,6 @@ public abstract class StreamInput extends InputStream {
         throw new UnsupportedOperationException();
     }
 
-    /**
-     * Reads a {@link QueryBuilder} from the current stream
-     */
-    public QueryBuilder readQuery() throws IOException {
-        return readNamedWriteable(QueryBuilder.class);
-    }
-
     public static StreamInput wrap(BytesReference reference) {
         if (reference.hasArray() == false) {
             reference = reference.toBytesArray();
diff --git a/core/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java b/core/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java
index a808919..536af8b 100644
--- a/core/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java
+++ b/core/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java
@@ -31,7 +31,6 @@ import org.elasticsearch.Version;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.text.Text;
-import org.elasticsearch.index.query.QueryBuilder;
 import org.joda.time.ReadableInstant;
 
 import java.io.EOFException;
@@ -570,11 +569,4 @@ public abstract class StreamOutput extends OutputStream {
         writeString(namedWriteable.getWriteableName());
         namedWriteable.writeTo(this);
     }
-
-    /**
-     * Writes a {@link QueryBuilder} to the current stream
-     */
-    public void writeQuery(QueryBuilder queryBuilder) throws IOException {
-        writeNamedWriteable(queryBuilder);
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/common/joda/DateMathParser.java b/core/src/main/java/org/elasticsearch/common/joda/DateMathParser.java
index 7246db2..65ec7e7 100644
--- a/core/src/main/java/org/elasticsearch/common/joda/DateMathParser.java
+++ b/core/src/main/java/org/elasticsearch/common/joda/DateMathParser.java
@@ -24,10 +24,9 @@ import org.joda.time.DateTimeZone;
 import org.joda.time.MutableDateTime;
 import org.joda.time.format.DateTimeFormatter;
 
+import java.util.Objects;
 import java.util.concurrent.Callable;
 
-import static com.google.common.base.Preconditions.checkNotNull;
-
 /**
  * A parser for date/time formatted text with optional date math.
  * 
@@ -40,7 +39,7 @@ public class DateMathParser {
     private final FormatDateTimeFormatter dateTimeFormatter;
 
     public DateMathParser(FormatDateTimeFormatter dateTimeFormatter) {
-        checkNotNull(dateTimeFormatter);
+        Objects.requireNonNull(dateTimeFormatter);
         this.dateTimeFormatter = dateTimeFormatter;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/all/AllEntries.java b/core/src/main/java/org/elasticsearch/common/lucene/all/AllEntries.java
index 5106cda..d7892c9 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/all/AllEntries.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/all/AllEntries.java
@@ -25,12 +25,11 @@ import org.elasticsearch.common.io.FastStringReader;
 import java.io.IOException;
 import java.io.Reader;
 import java.util.ArrayList;
+import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Set;
 
-import static com.google.common.collect.Sets.newHashSet;
-
 /**
  *
  */
@@ -136,7 +135,7 @@ public class AllEntries extends Reader {
     }
 
     public Set<String> fields() {
-        Set<String> fields = newHashSet();
+        Set<String> fields = new HashSet<>();
         for (Entry entry : entries) {
             fields.add(entry.name());
         }
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/all/AllTermQuery.java b/core/src/main/java/org/elasticsearch/common/lucene/all/AllTermQuery.java
index 9853659..a59af2c 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/all/AllTermQuery.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/all/AllTermQuery.java
@@ -64,6 +64,9 @@ public final class AllTermQuery extends Query {
 
     @Override
     public Query rewrite(IndexReader reader) throws IOException {
+        if (getBoost() != 1f) {
+            return super.rewrite(reader);
+        }
         boolean fieldExists = false;
         boolean hasPayloads = false;
         for (LeafReaderContext context : reader.leaves()) {
@@ -98,7 +101,7 @@ public final class AllTermQuery extends Query {
         final CollectionStatistics collectionStats = searcher.collectionStatistics(term.field());
         final TermStatistics termStats = searcher.termStatistics(term, termStates);
         final Similarity similarity = searcher.getSimilarity(needsScores);
-        final SimWeight stats = similarity.computeWeight(getBoost(), collectionStats, termStats);
+        final SimWeight stats = similarity.computeWeight(collectionStats, termStats);
         return new Weight(this) {
 
             @Override
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/search/MultiPhrasePrefixQuery.java b/core/src/main/java/org/elasticsearch/common/lucene/search/MultiPhrasePrefixQuery.java
index 3990cca..3d870bc 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/search/MultiPhrasePrefixQuery.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/search/MultiPhrasePrefixQuery.java
@@ -120,6 +120,9 @@ public class MultiPhrasePrefixQuery extends Query {
 
     @Override
     public Query rewrite(IndexReader reader) throws IOException {
+        if (getBoost() != 1.0F) {
+            return super.rewrite(reader);
+        }
         if (termArrays.isEmpty()) {
             return new MatchNoDocsQuery();
         }
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/search/function/BoostScoreFunction.java b/core/src/main/java/org/elasticsearch/common/lucene/search/function/BoostScoreFunction.java
deleted file mode 100644
index 13b4526..0000000
--- a/core/src/main/java/org/elasticsearch/common/lucene/search/function/BoostScoreFunction.java
+++ /dev/null
@@ -1,70 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.common.lucene.search.function;
-
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.search.Explanation;
-
-/**
- *
- */
-@Deprecated
-public class BoostScoreFunction extends ScoreFunction {
-
-    public static final String BOOST_WEIGHT_ERROR_MESSAGE = "'boost_factor' and 'weight' cannot be used together. Use 'weight'.";
-
-    private final float boost;
-
-    public BoostScoreFunction(float boost) {
-        super(CombineFunction.MULT);
-        this.boost = boost;
-    }
-
-    public float getBoost() {
-        return boost;
-    }
-
-    @Override
-    public LeafScoreFunction getLeafScoreFunction(LeafReaderContext ctx) {
-        return new LeafScoreFunction() {
-
-            @Override
-            public double score(int docId, float subQueryScore) {
-                return boost;
-            }
-
-            @Override
-            public Explanation explainScore(int docId, Explanation subQueryScore) {
-                return Explanation.match(boost, "static boost factor", Explanation.match(boost, "boostFactor"));
-            }
-        };
-    }
-
-    @Override
-    public boolean needsScores() {
-        return false;
-    }
-
-    @Override
-    public String toString() {
-        return "boost[" + boost + "]";
-    }
-
-}
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/search/function/CombineFunction.java b/core/src/main/java/org/elasticsearch/common/lucene/search/function/CombineFunction.java
index 30c8f01..41a5b85 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/search/function/CombineFunction.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/search/function/CombineFunction.java
@@ -24,8 +24,8 @@ import org.apache.lucene.search.Explanation;
 public enum CombineFunction {
     MULT {
         @Override
-        public float combine(double queryBoost, double queryScore, double funcScore, double maxBoost) {
-            return toFloat(queryBoost * queryScore * Math.min(funcScore, maxBoost));
+        public float combine(double queryScore, double funcScore, double maxBoost) {
+            return toFloat(queryScore * Math.min(funcScore, maxBoost));
         }
 
         @Override
@@ -34,21 +34,20 @@ public enum CombineFunction {
         }
 
         @Override
-        public Explanation explain(float queryBoost, Explanation queryExpl, Explanation funcExpl, float maxBoost) {
-            float score = queryBoost * Math.min(funcExpl.getValue(), maxBoost) * queryExpl.getValue();
+        public Explanation explain(Explanation queryExpl, Explanation funcExpl, float maxBoost) {
             Explanation boostExpl = Explanation.match(maxBoost, "maxBoost");
             Explanation minExpl = Explanation.match(
                     Math.min(funcExpl.getValue(), maxBoost),
                     "min of:",
                     funcExpl, boostExpl);
-            return Explanation.match(score, "function score, product of:",
-                    queryExpl, minExpl, Explanation.match(queryBoost, "queryBoost"));
+            return Explanation.match(queryExpl.getValue() * minExpl.getValue(),
+                    "function score, product of:", queryExpl, minExpl);
         }
     },
     REPLACE {
         @Override
-        public float combine(double queryBoost, double queryScore, double funcScore, double maxBoost) {
-            return toFloat(queryBoost * Math.min(funcScore, maxBoost));
+        public float combine(double queryScore, double funcScore, double maxBoost) {
+            return toFloat(Math.min(funcScore, maxBoost));
         }
 
         @Override
@@ -57,22 +56,19 @@ public enum CombineFunction {
         }
 
         @Override
-        public Explanation explain(float queryBoost, Explanation queryExpl, Explanation funcExpl, float maxBoost) {
-            float score = queryBoost * Math.min(funcExpl.getValue(), maxBoost);
+        public Explanation explain(Explanation queryExpl, Explanation funcExpl, float maxBoost) {
             Explanation boostExpl = Explanation.match(maxBoost, "maxBoost");
-            Explanation minExpl = Explanation.match(
+            return Explanation.match(
                     Math.min(funcExpl.getValue(), maxBoost),
                     "min of:",
                     funcExpl, boostExpl);
-            return Explanation.match(score, "function score, product of:",
-                    minExpl, Explanation.match(queryBoost, "queryBoost"));
         }
 
     },
     SUM {
         @Override
-        public float combine(double queryBoost, double queryScore, double funcScore, double maxBoost) {
-            return toFloat(queryBoost * (queryScore + Math.min(funcScore, maxBoost)));
+        public float combine(double queryScore, double funcScore, double maxBoost) {
+            return toFloat(queryScore + Math.min(funcScore, maxBoost));
         }
 
         @Override
@@ -81,21 +77,18 @@ public enum CombineFunction {
         }
 
         @Override
-        public Explanation explain(float queryBoost, Explanation queryExpl, Explanation funcExpl, float maxBoost) {
-            float score = queryBoost * (Math.min(funcExpl.getValue(), maxBoost) + queryExpl.getValue());
+        public Explanation explain(Explanation queryExpl, Explanation funcExpl, float maxBoost) {
             Explanation minExpl = Explanation.match(Math.min(funcExpl.getValue(), maxBoost), "min of:",
                     funcExpl, Explanation.match(maxBoost, "maxBoost"));
-            Explanation sumExpl = Explanation.match(Math.min(funcExpl.getValue(), maxBoost) + queryExpl.getValue(), "sum of",
+            return Explanation.match(Math.min(funcExpl.getValue(), maxBoost) + queryExpl.getValue(), "sum of",
                     queryExpl, minExpl);
-            return Explanation.match(score, "function score, product of:",
-                    sumExpl, Explanation.match(queryBoost, "queryBoost"));
         }
 
     },
     AVG {
         @Override
-        public float combine(double queryBoost, double queryScore, double funcScore, double maxBoost) {
-            return toFloat((queryBoost * (Math.min(funcScore, maxBoost) + queryScore) / 2.0));
+        public float combine(double queryScore, double funcScore, double maxBoost) {
+            return toFloat((Math.min(funcScore, maxBoost) + queryScore) / 2.0);
         }
 
         @Override
@@ -104,22 +97,19 @@ public enum CombineFunction {
         }
 
         @Override
-        public Explanation explain(float queryBoost, Explanation queryExpl, Explanation funcExpl, float maxBoost) {
-            float score = toFloat(queryBoost * (queryExpl.getValue() + Math.min(funcExpl.getValue(), maxBoost)) / 2.0);
+        public Explanation explain(Explanation queryExpl, Explanation funcExpl, float maxBoost) {
             Explanation minExpl = Explanation.match(Math.min(funcExpl.getValue(), maxBoost), "min of:",
                     funcExpl, Explanation.match(maxBoost, "maxBoost"));
-            Explanation avgExpl = Explanation.match(
+            return Explanation.match(
                     toFloat((Math.min(funcExpl.getValue(), maxBoost) + queryExpl.getValue()) / 2.0), "avg of",
                     queryExpl, minExpl);
-            return Explanation.match(score, "function score, product of:",
-                    avgExpl, Explanation.match(queryBoost, "queryBoost"));
         }
 
     },
     MIN {
         @Override
-        public float combine(double queryBoost, double queryScore, double funcScore, double maxBoost) {
-            return toFloat(queryBoost * Math.min(queryScore, Math.min(funcScore, maxBoost)));
+        public float combine(double queryScore, double funcScore, double maxBoost) {
+            return toFloat(Math.min(queryScore, Math.min(funcScore, maxBoost)));
         }
 
         @Override
@@ -128,23 +118,20 @@ public enum CombineFunction {
         }
 
         @Override
-        public Explanation explain(float queryBoost, Explanation queryExpl, Explanation funcExpl, float maxBoost) {
-            float score = toFloat(queryBoost * Math.min(queryExpl.getValue(), Math.min(funcExpl.getValue(), maxBoost)));
+        public Explanation explain(Explanation queryExpl, Explanation funcExpl, float maxBoost) {
             Explanation innerMinExpl = Explanation.match(
                     Math.min(funcExpl.getValue(), maxBoost), "min of:",
                     funcExpl, Explanation.match(maxBoost, "maxBoost"));
-            Explanation outerMinExpl = Explanation.match(
+            return Explanation.match(
                     Math.min(Math.min(funcExpl.getValue(), maxBoost), queryExpl.getValue()), "min of",
                     queryExpl, innerMinExpl);
-            return Explanation.match(score, "function score, product of:",
-                    outerMinExpl, Explanation.match(queryBoost, "queryBoost"));
         }
 
     },
     MAX {
         @Override
-        public float combine(double queryBoost, double queryScore, double funcScore, double maxBoost) {
-            return toFloat(queryBoost * (Math.max(queryScore, Math.min(funcScore, maxBoost))));
+        public float combine(double queryScore, double funcScore, double maxBoost) {
+            return toFloat(Math.max(queryScore, Math.min(funcScore, maxBoost)));
         }
 
         @Override
@@ -153,21 +140,18 @@ public enum CombineFunction {
         }
 
         @Override
-        public Explanation explain(float queryBoost, Explanation queryExpl, Explanation funcExpl, float maxBoost) {
-            float score = toFloat(queryBoost * Math.max(queryExpl.getValue(), Math.min(funcExpl.getValue(), maxBoost)));
+        public Explanation explain(Explanation queryExpl, Explanation funcExpl, float maxBoost) {
             Explanation innerMinExpl = Explanation.match(
                     Math.min(funcExpl.getValue(), maxBoost), "min of:",
                     funcExpl, Explanation.match(maxBoost, "maxBoost"));
-            Explanation outerMaxExpl = Explanation.match(
+            return Explanation.match(
                     Math.max(Math.min(funcExpl.getValue(), maxBoost), queryExpl.getValue()), "max of:",
                     queryExpl, innerMinExpl);
-            return Explanation.match(score, "function score, product of:",
-                    outerMaxExpl, Explanation.match(queryBoost, "queryBoost"));
         }
 
     };
 
-    public abstract float combine(double queryBoost, double queryScore, double funcScore, double maxBoost);
+    public abstract float combine(double queryScore, double funcScore, double maxBoost);
 
     public abstract String getName();
 
@@ -181,5 +165,5 @@ public enum CombineFunction {
         return Double.compare(floatVersion, input) == 0 || input == 0.0d ? 0 : 1.d - (floatVersion) / input;
     }
 
-    public abstract Explanation explain(float queryBoost, Explanation queryExpl, Explanation funcExpl, float maxBoost);
+    public abstract Explanation explain(Explanation queryExpl, Explanation funcExpl, float maxBoost);
 }
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/search/function/CustomBoostFactorScorer.java b/core/src/main/java/org/elasticsearch/common/lucene/search/function/CustomBoostFactorScorer.java
index b4ddaf2..709c7df 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/search/function/CustomBoostFactorScorer.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/search/function/CustomBoostFactorScorer.java
@@ -21,13 +21,11 @@ package org.elasticsearch.common.lucene.search.function;
 
 import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.Weight;
-import org.apache.lucene.util.BytesRef;
 
 import java.io.IOException;
 
 abstract class CustomBoostFactorScorer extends Scorer {
 
-    final float subQueryBoost;
     final Scorer scorer;
     final float maxBoost;
     final CombineFunction scoreCombiner;
@@ -43,7 +41,6 @@ abstract class CustomBoostFactorScorer extends Scorer {
         } else {
             nextDoc = new MinScoreNextDoc();
         }
-        this.subQueryBoost = w.getQuery().getBoost();
         this.scorer = scorer;
         this.maxBoost = maxBoost;
         this.scoreCombiner = scoreCombiner;
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/search/function/FiltersFunctionScoreQuery.java b/core/src/main/java/org/elasticsearch/common/lucene/search/function/FiltersFunctionScoreQuery.java
index e95da1d..ebe25b8 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/search/function/FiltersFunctionScoreQuery.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/search/function/FiltersFunctionScoreQuery.java
@@ -114,6 +114,9 @@ public class FiltersFunctionScoreQuery extends Query {
 
     @Override
     public Query rewrite(IndexReader reader) throws IOException {
+        if (getBoost() != 1.0F) {
+            return super.rewrite(reader);
+        }
         Query newQ = subQuery.rewrite(reader);
         if (newQ == subQuery)
             return this;
@@ -158,14 +161,12 @@ public class FiltersFunctionScoreQuery extends Query {
 
         @Override
         public float getValueForNormalization() throws IOException {
-            float sum = subQueryWeight.getValueForNormalization();
-            sum *= getBoost() * getBoost();
-            return sum;
+            return subQueryWeight.getValueForNormalization();
         }
 
         @Override
-        public void normalize(float norm, float topLevelBoost) {
-            subQueryWeight.normalize(norm, topLevelBoost * getBoost());
+        public void normalize(float norm, float boost) {
+            subQueryWeight.normalize(norm, boost);
         }
 
         @Override
@@ -219,10 +220,7 @@ public class FiltersFunctionScoreQuery extends Query {
                 }
             }
             if (filterExplanations.size() == 0) {
-                float sc = getBoost() * subQueryExpl.getValue();
-                return Explanation.match(sc, "function score, no filter match, product of:",
-                        subQueryExpl,
-                        Explanation.match(getBoost(), "queryBoost"));
+                return subQueryExpl;
             }
 
             // Second: Compute the factor that would have been computed by the
@@ -266,7 +264,7 @@ public class FiltersFunctionScoreQuery extends Query {
                     CombineFunction.toFloat(factor),
                     "function score, score mode [" + scoreMode.toString().toLowerCase(Locale.ROOT) + "]",
                     filterExplanations);
-            return combineFunction.explain(getBoost(), subQueryExpl, factorExplanation, maxBoost);
+            return combineFunction.explain(subQueryExpl, factorExplanation, maxBoost);
         }
     }
 
@@ -348,7 +346,7 @@ public class FiltersFunctionScoreQuery extends Query {
                     }
                 }
             }
-            return scoreCombiner.combine(subQueryBoost, subQueryScore, factor, maxBoost);
+            return scoreCombiner.combine(subQueryScore, factor, maxBoost);
         }
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/search/function/FunctionScoreQuery.java b/core/src/main/java/org/elasticsearch/common/lucene/search/function/FunctionScoreQuery.java
index 448eda8..2a88296 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/search/function/FunctionScoreQuery.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/search/function/FunctionScoreQuery.java
@@ -76,6 +76,9 @@ public class FunctionScoreQuery extends Query {
 
     @Override
     public Query rewrite(IndexReader reader) throws IOException {
+        if (getBoost() != 1.0F) {
+            return super.rewrite(reader);
+        }
         Query newQ = subQuery.rewrite(reader);
         if (newQ == subQuery) {
             return this;
@@ -117,14 +120,12 @@ public class FunctionScoreQuery extends Query {
 
         @Override
         public float getValueForNormalization() throws IOException {
-            float sum = subQueryWeight.getValueForNormalization();
-            sum *= getBoost() * getBoost();
-            return sum;
+            return subQueryWeight.getValueForNormalization();
         }
 
         @Override
-        public void normalize(float norm, float topLevelBoost) {
-            subQueryWeight.normalize(norm, topLevelBoost * getBoost());
+        public void normalize(float norm, float boost) {
+            subQueryWeight.normalize(norm, boost);
         }
 
         @Override
@@ -148,7 +149,7 @@ public class FunctionScoreQuery extends Query {
             }
             if (function != null) {
                 Explanation functionExplanation = function.getLeafScoreFunction(context).explainScore(doc, subQueryExpl);
-                return combineFunction.explain(getBoost(), subQueryExpl, functionExplanation, maxBoost);
+                return combineFunction.explain(subQueryExpl, functionExplanation, maxBoost);
             } else {
                 return subQueryExpl;
             }
@@ -174,9 +175,9 @@ public class FunctionScoreQuery extends Query {
             // are needed
             float score = needsScores ? scorer.score() : 0f;
             if (function == null) {
-                return subQueryBoost * score;
+                return score;
             } else {
-                return scoreCombiner.combine(subQueryBoost, score,
+                return scoreCombiner.combine(score,
                         function.score(scorer.docID(), score), maxBoost);
             }
         }
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/search/function/WeightFactorFunction.java b/core/src/main/java/org/elasticsearch/common/lucene/search/function/WeightFactorFunction.java
index 2def071..c585da42 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/search/function/WeightFactorFunction.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/search/function/WeightFactorFunction.java
@@ -35,9 +35,6 @@ public class WeightFactorFunction extends ScoreFunction {
 
     public WeightFactorFunction(float weight, ScoreFunction scoreFunction) {
         super(CombineFunction.MULT);
-        if (scoreFunction instanceof BoostScoreFunction) {
-            throw new IllegalArgumentException(BoostScoreFunction.BOOST_WEIGHT_ERROR_MESSAGE);
-        }
         if (scoreFunction == null) {
             this.scoreFunction = SCORE_ONE;
         } else {
diff --git a/core/src/main/java/org/elasticsearch/common/property/PropertyPlaceholder.java b/core/src/main/java/org/elasticsearch/common/property/PropertyPlaceholder.java
index a4b067e..11f7d8b 100644
--- a/core/src/main/java/org/elasticsearch/common/property/PropertyPlaceholder.java
+++ b/core/src/main/java/org/elasticsearch/common/property/PropertyPlaceholder.java
@@ -19,10 +19,10 @@
 
 package org.elasticsearch.common.property;
 
-import com.google.common.base.Preconditions;
 import org.elasticsearch.common.Strings;
 
 import java.util.HashSet;
+import java.util.Objects;
 import java.util.Properties;
 import java.util.Set;
 
@@ -61,8 +61,8 @@ public class PropertyPlaceholder {
      */
     public PropertyPlaceholder(String placeholderPrefix, String placeholderSuffix,
                                boolean ignoreUnresolvablePlaceholders) {
-        Preconditions.checkNotNull(placeholderPrefix, "Argument 'placeholderPrefix' must not be null.");
-        Preconditions.checkNotNull(placeholderSuffix, "Argument 'placeholderSuffix' must not be null.");
+        Objects.requireNonNull(placeholderPrefix, "Argument 'placeholderPrefix' must not be null.");
+        Objects.requireNonNull(placeholderSuffix, "Argument 'placeholderSuffix' must not be null.");
         this.placeholderPrefix = placeholderPrefix;
         this.placeholderSuffix = placeholderSuffix;
         this.ignoreUnresolvablePlaceholders = ignoreUnresolvablePlaceholders;
@@ -77,7 +77,7 @@ public class PropertyPlaceholder {
      * @return the supplied value with placeholders replaced inline.
      */
     public String replacePlaceholders(String value, PlaceholderResolver placeholderResolver) {
-        Preconditions.checkNotNull(value, "Argument 'value' must not be null.");
+        Objects.requireNonNull(value, "Argument 'value' must not be null.");
         return parseStringValue(value, placeholderResolver, new HashSet<String>());
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/recycler/Recyclers.java b/core/src/main/java/org/elasticsearch/common/recycler/Recyclers.java
index daff885..5bac8f7 100644
--- a/core/src/main/java/org/elasticsearch/common/recycler/Recyclers.java
+++ b/core/src/main/java/org/elasticsearch/common/recycler/Recyclers.java
@@ -20,8 +20,8 @@
 package org.elasticsearch.common.recycler;
 
 import com.carrotsearch.hppc.BitMixer;
-import com.google.common.collect.Queues;
-import org.elasticsearch.ElasticsearchException;
+
+import java.util.ArrayDeque;
 
 public enum Recyclers {
     ;
@@ -44,7 +44,7 @@ public enum Recyclers {
      * Return a recycler based on a deque.
      */
     public static <T> Recycler<T> deque(Recycler.C<T> c, int limit) {
-        return new DequeRecycler<>(c, Queues.<T>newArrayDeque(), limit);
+        return new DequeRecycler<>(c, new ArrayDeque<>(), limit);
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/common/unit/Fuzziness.java b/core/src/main/java/org/elasticsearch/common/unit/Fuzziness.java
index bc48042..cfcd209 100644
--- a/core/src/main/java/org/elasticsearch/common/unit/Fuzziness.java
+++ b/core/src/main/java/org/elasticsearch/common/unit/Fuzziness.java
@@ -19,26 +19,22 @@
 package org.elasticsearch.common.unit;
 
 import com.google.common.base.Preconditions;
-
+import org.apache.lucene.search.FuzzyQuery;
+import org.apache.lucene.util.automaton.LevenshteinAutomata;
 import org.elasticsearch.common.ParseField;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.io.stream.Writeable;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentBuilderString;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
-import java.util.Locale;
-import java.util.Objects;
 
 /**
  * A unit class that encapsulates all in-exact search
  * parsing and conversion from similarities to edit distances
  * etc.
  */
-public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
+public final class Fuzziness implements ToXContent {
 
     public static final XContentBuilderString X_FIELD_NAME = new XContentBuilderString("fuzziness");
     public static final Fuzziness ZERO = new Fuzziness(0);
@@ -49,20 +45,13 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
 
     private final String fuzziness;
 
-    /** the prototype constant is intended for deserialization when used with
-     * {@link org.elasticsearch.common.io.stream.StreamableReader#readFrom(StreamInput)} */
-    static final Fuzziness PROTOTYPE = AUTO;
-
     private Fuzziness(int fuzziness) {
         Preconditions.checkArgument(fuzziness >= 0 && fuzziness <= 2, "Valid edit distances are [0, 1, 2] but was [" + fuzziness + "]");
         this.fuzziness = Integer.toString(fuzziness);
     }
 
     private Fuzziness(String fuzziness) {
-        if (fuzziness == null) {
-            throw new IllegalArgumentException("fuzziness can't be null!");
-        }
-        this.fuzziness = fuzziness.toUpperCase(Locale.ROOT);
+        this.fuzziness = fuzziness;
     }
 
     /**
@@ -132,7 +121,7 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     }
 
     public int asDistance(String text) {
-        if (this.equals(AUTO)) { //AUTO
+        if (this == AUTO) { //AUTO
             final int len = termLen(text);
             if (len <= 2) {
                 return 0;
@@ -146,7 +135,7 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     }
 
     public TimeValue asTimeValue() {
-        if (this.equals(AUTO)) {
+        if (this == AUTO) {
             return TimeValue.timeValueMillis(1);
         } else {
             return TimeValue.parseTimeValue(fuzziness.toString(), null, "fuzziness");
@@ -154,7 +143,7 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     }
 
     public long asLong() {
-        if (this.equals(AUTO)) {
+        if (this == AUTO) {
             return 1;
         }
         try {
@@ -165,7 +154,7 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     }
 
     public int asInt() {
-        if (this.equals(AUTO)) {
+        if (this == AUTO) {
             return 1;
         }
         try {
@@ -176,7 +165,7 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     }
 
     public short asShort() {
-        if (this.equals(AUTO)) {
+        if (this == AUTO) {
             return 1;
         }
         try {
@@ -187,7 +176,7 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     }
 
     public byte asByte() {
-        if (this.equals(AUTO)) {
+        if (this == AUTO) {
             return 1;
         }
         try {
@@ -198,14 +187,14 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     }
 
     public double asDouble() {
-        if (this.equals(AUTO)) {
+        if (this == AUTO) {
             return 1d;
         }
         return Double.parseDouble(fuzziness.toString());
     }
 
     public float asFloat() {
-        if (this.equals(AUTO)) {
+        if (this == AUTO) {
             return 1f;
         }
         return Float.parseFloat(fuzziness.toString());
@@ -218,35 +207,4 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     public String asString() {
         return fuzziness.toString();
     }
-
-    @Override
-    public boolean equals(Object obj) {
-        if (this == obj) {
-            return true;
-        }
-        if (obj == null || getClass() != obj.getClass()) {
-            return false;
-        }
-        Fuzziness other = (Fuzziness) obj;
-        return Objects.equals(fuzziness, other.fuzziness);
-    }
-
-    @Override
-    public int hashCode() {
-        return fuzziness.hashCode();
-    }
-
-    @Override
-    public void writeTo(StreamOutput out) throws IOException {
-        out.writeString(fuzziness);
-    }
-
-    @Override
-    public Fuzziness readFrom(StreamInput in) throws IOException {
-        return new Fuzziness(in.readString());
-    }
-
-    public static Fuzziness readFuzzinessFrom(StreamInput in) throws IOException {
-        return PROTOTYPE.readFrom(in);
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/common/util/MultiDataPathUpgrader.java b/core/src/main/java/org/elasticsearch/common/util/MultiDataPathUpgrader.java
index b260391..e840722 100644
--- a/core/src/main/java/org/elasticsearch/common/util/MultiDataPathUpgrader.java
+++ b/core/src/main/java/org/elasticsearch/common/util/MultiDataPathUpgrader.java
@@ -19,7 +19,6 @@
 package org.elasticsearch.common.util;
 
 import com.google.common.base.Charsets;
-import com.google.common.collect.Sets;
 import com.google.common.primitives.Ints;
 import org.apache.lucene.index.CheckIndex;
 import org.apache.lucene.index.IndexWriter;
@@ -38,13 +37,25 @@ import org.elasticsearch.env.NodeEnvironment;
 import org.elasticsearch.env.ShardLock;
 import org.elasticsearch.gateway.MetaDataStateFormat;
 import org.elasticsearch.index.Index;
-import org.elasticsearch.index.shard.*;
+import org.elasticsearch.index.shard.ShardId;
+import org.elasticsearch.index.shard.ShardPath;
+import org.elasticsearch.index.shard.ShardStateMetaData;
 
 import java.io.IOException;
 import java.io.PrintStream;
-import java.nio.file.*;
+import java.nio.file.DirectoryStream;
+import java.nio.file.FileStore;
+import java.nio.file.FileVisitResult;
+import java.nio.file.FileVisitor;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.StandardCopyOption;
 import java.nio.file.attribute.BasicFileAttributes;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
 
 /**
  */
@@ -343,7 +354,7 @@ public class MultiDataPathUpgrader {
     }
 
     private static Set<ShardId> findAllShardIds(Path... locations) throws IOException {
-        final Set<ShardId> shardIds = Sets.newHashSet();
+        final Set<ShardId> shardIds = new HashSet<>();
         for (final Path location : locations) {
             if (Files.isDirectory(location)) {
                 shardIds.addAll(findAllShardsForIndex(location));
diff --git a/core/src/main/java/org/elasticsearch/common/util/concurrent/BaseFuture.java b/core/src/main/java/org/elasticsearch/common/util/concurrent/BaseFuture.java
index a48eb60..ae80671 100644
--- a/core/src/main/java/org/elasticsearch/common/util/concurrent/BaseFuture.java
+++ b/core/src/main/java/org/elasticsearch/common/util/concurrent/BaseFuture.java
@@ -22,11 +22,10 @@ package org.elasticsearch.common.util.concurrent;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.transport.Transports;
 
+import java.util.Objects;
 import java.util.concurrent.*;
 import java.util.concurrent.locks.AbstractQueuedSynchronizer;
 
-import static com.google.common.base.Preconditions.checkNotNull;
-
 /**
  * An abstract implementation of the {@link com.google.common.util.concurrent.ListenableFuture} interface. This
  * class is preferable to {@link java.util.concurrent.FutureTask} for two
@@ -178,7 +177,7 @@ public abstract class BaseFuture<V> implements Future<V> {
      * @throws Error if the throwable was an {@link Error}.
      */
     protected boolean setException(Throwable throwable) {
-        boolean result = sync.setException(checkNotNull(throwable));
+        boolean result = sync.setException(Objects.requireNonNull(throwable));
         if (result) {
             done();
         }
diff --git a/core/src/main/java/org/elasticsearch/common/util/concurrent/ConcurrentCollections.java b/core/src/main/java/org/elasticsearch/common/util/concurrent/ConcurrentCollections.java
index 791afa3..74a1c13 100644
--- a/core/src/main/java/org/elasticsearch/common/util/concurrent/ConcurrentCollections.java
+++ b/core/src/main/java/org/elasticsearch/common/util/concurrent/ConcurrentCollections.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.common.util.concurrent;
 
+import java.util.Collections;
 import java.util.Deque;
 import java.util.Queue;
 import java.util.Set;
@@ -29,7 +30,6 @@ import java.util.concurrent.ConcurrentLinkedQueue;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.LinkedTransferQueue;
 
-import com.google.common.collect.Sets;
 
 /**
  *
@@ -67,7 +67,7 @@ public abstract class ConcurrentCollections {
     }
 
     public static <V> Set<V> newConcurrentSet() {
-        return Sets.newSetFromMap(ConcurrentCollections.<V, Boolean>newConcurrentMap());
+        return Collections.newSetFromMap(ConcurrentCollections.<V, Boolean>newConcurrentMap());
     }
 
     public static <T> Queue<T> newQueue() {
diff --git a/core/src/main/java/org/elasticsearch/common/util/set/Sets.java b/core/src/main/java/org/elasticsearch/common/util/set/Sets.java
new file mode 100644
index 0000000..4b323c4
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/common/util/set/Sets.java
@@ -0,0 +1,79 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.common.util.set;
+
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.Objects;
+import java.util.Set;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.stream.Collectors;
+
+public final class Sets {
+    private Sets() {
+    }
+
+    public static <T> HashSet<T> newHashSet(Iterator<T> iterator) {
+        Objects.requireNonNull(iterator);
+        HashSet<T> set = new HashSet<>();
+        while (iterator.hasNext()) {
+            set.add(iterator.next());
+        }
+        return set;
+    }
+
+    public static <T> HashSet<T> newHashSet(Iterable<T> iterable) {
+        Objects.requireNonNull(iterable);
+        return iterable instanceof Collection ? new HashSet<>((Collection)iterable) : newHashSet(iterable.iterator());
+    }
+
+    public static <T> HashSet<T> newHashSet(T... elements) {
+        Objects.requireNonNull(elements);
+        HashSet<T> set = new HashSet<>(elements.length);
+        Collections.addAll(set, elements);
+        return set;
+    }
+
+    public static <T> Set<T> newConcurrentHashSet() {
+        return Collections.newSetFromMap(new ConcurrentHashMap<>());
+    }
+
+    public static <T> boolean haveEmptyIntersection(Set<T> left, Set<T> right) {
+        Objects.requireNonNull(left);
+        Objects.requireNonNull(right);
+        return !left.stream().anyMatch(k -> right.contains(k));
+    }
+
+    public static <T> Set<T> difference(Set<T> left, Set<T> right) {
+        Objects.requireNonNull(left);
+        Objects.requireNonNull(right);
+        return left.stream().filter(k -> !right.contains(k)).collect(Collectors.toSet());
+    }
+
+    public static <T> Set<T> union(Set<T> left, Set<T> right) {
+        Objects.requireNonNull(left);
+        Objects.requireNonNull(right);
+        Set<T> union = new HashSet<>(left);
+        union.addAll(right);
+        return union;
+    }
+}
diff --git a/core/src/main/java/org/elasticsearch/discovery/local/LocalDiscovery.java b/core/src/main/java/org/elasticsearch/discovery/local/LocalDiscovery.java
index f1f69a6..03cdd4b 100644
--- a/core/src/main/java/org/elasticsearch/discovery/local/LocalDiscovery.java
+++ b/core/src/main/java/org/elasticsearch/discovery/local/LocalDiscovery.java
@@ -20,13 +20,19 @@
 package org.elasticsearch.discovery.local;
 
 import org.elasticsearch.Version;
-import org.elasticsearch.cluster.*;
+import org.elasticsearch.cluster.ClusterChangedEvent;
+import org.elasticsearch.cluster.ClusterName;
+import org.elasticsearch.cluster.ClusterService;
+import org.elasticsearch.cluster.ClusterState;
+import org.elasticsearch.cluster.ClusterStateNonMasterUpdateTask;
+import org.elasticsearch.cluster.Diff;
+import org.elasticsearch.cluster.IncompatibleClusterStateVersionException;
+import org.elasticsearch.cluster.ProcessedClusterStateNonMasterUpdateTask;
 import org.elasticsearch.cluster.block.ClusterBlocks;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.node.DiscoveryNodeService;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
 import org.elasticsearch.cluster.routing.RoutingService;
-import org.elasticsearch.cluster.routing.allocation.AllocationService;
 import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;
 import org.elasticsearch.common.component.AbstractLifecycleComponent;
 import org.elasticsearch.common.inject.Inject;
@@ -36,7 +42,12 @@ import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.common.util.concurrent.ConcurrentCollections;
-import org.elasticsearch.discovery.*;
+import org.elasticsearch.discovery.AckClusterStatePublishResponseHandler;
+import org.elasticsearch.discovery.BlockingClusterStatePublishResponseHandler;
+import org.elasticsearch.discovery.Discovery;
+import org.elasticsearch.discovery.DiscoveryService;
+import org.elasticsearch.discovery.DiscoverySettings;
+import org.elasticsearch.discovery.InitialStateDiscoveryListener;
 import org.elasticsearch.node.service.NodeService;
 import org.elasticsearch.transport.TransportService;
 
@@ -48,7 +59,6 @@ import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.CopyOnWriteArrayList;
 import java.util.concurrent.atomic.AtomicBoolean;
 
-import static com.google.common.collect.Sets.newHashSet;
 import static org.elasticsearch.cluster.ClusterState.Builder;
 
 /**
@@ -227,7 +237,7 @@ public class LocalDiscovery extends AbstractLifecycleComponent<Discovery> implem
                     firstMaster.master = true;
                 }
 
-                final Set<String> newMembers = newHashSet();
+                final Set<String> newMembers = new HashSet<>();
                 for (LocalDiscovery discovery : clusterGroup.members()) {
                     newMembers.add(discovery.localNode.id());
                 }
diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java b/core/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java
index 6b52531..878e5bd 100644
--- a/core/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java
+++ b/core/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.discovery.zen;
 
-import com.google.common.collect.Sets;
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.ClusterChangedEvent;
@@ -73,6 +72,7 @@ import org.elasticsearch.transport.TransportService;
 
 import java.io.IOException;
 import java.util.ArrayList;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Objects;
 import java.util.Queue;
@@ -948,9 +948,9 @@ public class ZenDiscovery extends AbstractLifecycleComponent<Discovery> implemen
         }
 
         // nodes discovered during pinging
-        Set<DiscoveryNode> activeNodes = Sets.newHashSet();
+        Set<DiscoveryNode> activeNodes = new HashSet<>();
         // nodes discovered who has previously been part of the cluster and do not ping for the very first time
-        Set<DiscoveryNode> joinedOnceActiveNodes = Sets.newHashSet();
+        Set<DiscoveryNode> joinedOnceActiveNodes = new HashSet<>();
         if (localNode.masterNode()) {
             activeNodes.add(localNode);
             long joinsCounter = clusterJoinsCounter.get();
diff --git a/core/src/main/java/org/elasticsearch/env/NodeEnvironment.java b/core/src/main/java/org/elasticsearch/env/NodeEnvironment.java
index 725ec82..06562f8 100644
--- a/core/src/main/java/org/elasticsearch/env/NodeEnvironment.java
+++ b/core/src/main/java/org/elasticsearch/env/NodeEnvironment.java
@@ -20,12 +20,15 @@
 package org.elasticsearch.env;
 
 import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Sets;
-
 import com.google.common.primitives.Ints;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.SegmentInfos;
-import org.apache.lucene.store.*;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.FSDirectory;
+import org.apache.lucene.store.Lock;
+import org.apache.lucene.store.LockObtainFailedException;
+import org.apache.lucene.store.NativeFSLockFactory;
+import org.apache.lucene.store.SimpleFSDirectory;
 import org.apache.lucene.util.IOUtils;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
@@ -34,7 +37,6 @@ import org.elasticsearch.common.SuppressForbidden;
 import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.io.FileSystemUtils;
-import org.elasticsearch.common.io.PathUtils;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.index.Index;
@@ -46,8 +48,21 @@ import org.elasticsearch.monitor.fs.FsProbe;
 
 import java.io.Closeable;
 import java.io.IOException;
-import java.nio.file.*;
-import java.util.*;
+import java.nio.file.AtomicMoveNotSupportedException;
+import java.nio.file.DirectoryStream;
+import java.nio.file.FileStore;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.StandardCopyOption;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Locale;
+import java.util.Map;
+import java.util.Set;
 import java.util.concurrent.Semaphore;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicBoolean;
@@ -643,7 +658,7 @@ public class NodeEnvironment extends AbstractComponent implements Closeable {
             throw new IllegalStateException("node is not configured to store local location");
         }
         assert assertEnvIsLocked();
-        Set<String> indices = Sets.newHashSet();
+        Set<String> indices = new HashSet<>();
         for (NodePath nodePath : nodePaths) {
             Path indicesLocation = nodePath.indicesPath;
             if (Files.isDirectory(indicesLocation)) {
@@ -673,7 +688,7 @@ public class NodeEnvironment extends AbstractComponent implements Closeable {
             throw new IllegalStateException("node is not configured to store local location");
         }
         assert assertEnvIsLocked();
-        final Set<ShardId> shardIds = Sets.newHashSet();
+        final Set<ShardId> shardIds = new HashSet<>();
         String indexName = index.name();
         for (final NodePath nodePath : nodePaths) {
             Path location = nodePath.indicesPath;
diff --git a/core/src/main/java/org/elasticsearch/http/HttpServerModule.java b/core/src/main/java/org/elasticsearch/http/HttpServerModule.java
index 6030ac0..49d6736 100644
--- a/core/src/main/java/org/elasticsearch/http/HttpServerModule.java
+++ b/core/src/main/java/org/elasticsearch/http/HttpServerModule.java
@@ -19,13 +19,14 @@
 
 package org.elasticsearch.http;
 
-import com.google.common.base.Preconditions;
 import org.elasticsearch.common.inject.AbstractModule;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.logging.Loggers;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.http.netty.NettyHttpServerTransport;
 
+import java.util.Objects;
+
 /**
  *
  */
@@ -50,8 +51,8 @@ public class HttpServerModule extends AbstractModule {
     }
 
     public void setHttpServerTransport(Class<? extends HttpServerTransport> httpServerTransport, String source) {
-        Preconditions.checkNotNull(httpServerTransport, "Configured http server transport may not be null");
-        Preconditions.checkNotNull(source, "Plugin, that changes transport may not be null");
+        Objects.requireNonNull(httpServerTransport, "Configured http server transport may not be null");
+        Objects.requireNonNull(source, "Plugin, that changes transport may not be null");
         logger.info("Using [{}] as http transport, overridden by [{}]", httpServerTransportClass.getName(), source);
         this.httpServerTransportClass = httpServerTransport;
     }
diff --git a/core/src/main/java/org/elasticsearch/index/engine/Engine.java b/core/src/main/java/org/elasticsearch/index/engine/Engine.java
index 54cbcca..92434d3 100644
--- a/core/src/main/java/org/elasticsearch/index/engine/Engine.java
+++ b/core/src/main/java/org/elasticsearch/index/engine/Engine.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.index.engine;
 
-import com.google.common.base.Preconditions;
-
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.FilterLeafReader;
 import org.apache.lucene.index.IndexCommit;
@@ -71,6 +69,7 @@ import java.util.Comparator;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
+import java.util.Objects;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.locks.Condition;
@@ -100,8 +99,8 @@ public abstract class Engine implements Closeable {
     protected volatile Throwable failedEngine = null;
 
     protected Engine(EngineConfig engineConfig) {
-        Preconditions.checkNotNull(engineConfig.getStore(), "Store must be provided to the engine");
-        Preconditions.checkNotNull(engineConfig.getDeletionPolicy(), "Snapshot deletion policy must be provided to the engine");
+        Objects.requireNonNull(engineConfig.getStore(), "Store must be provided to the engine");
+        Objects.requireNonNull(engineConfig.getDeletionPolicy(), "Snapshot deletion policy must be provided to the engine");
 
         this.engineConfig = engineConfig;
         this.shardId = engineConfig.getShardId();
diff --git a/core/src/main/java/org/elasticsearch/index/fielddata/plain/PackedArrayIndexFieldData.java b/core/src/main/java/org/elasticsearch/index/fielddata/plain/PackedArrayIndexFieldData.java
index e809a2e..8996209 100644
--- a/core/src/main/java/org/elasticsearch/index/fielddata/plain/PackedArrayIndexFieldData.java
+++ b/core/src/main/java/org/elasticsearch/index/fielddata/plain/PackedArrayIndexFieldData.java
@@ -72,7 +72,7 @@ public class PackedArrayIndexFieldData extends AbstractIndexFieldData<AtomicNume
                                      FieldDataType fieldDataType, IndexFieldDataCache cache, NumericType numericType,
                                      CircuitBreakerService breakerService) {
         super(index, indexSettings, fieldNames, fieldDataType, cache);
-        Preconditions.checkNotNull(numericType);
+        Objects.requireNonNull(numericType);
         Preconditions.checkArgument(EnumSet.of(NumericType.BOOLEAN, NumericType.BYTE, NumericType.SHORT, NumericType.INT, NumericType.LONG).contains(numericType), getClass().getSimpleName() + " only supports integer types, not " + numericType);
         this.numericType = numericType;
         this.breakerService = breakerService;
diff --git a/core/src/main/java/org/elasticsearch/index/fielddata/plain/ParentChildIndexFieldData.java b/core/src/main/java/org/elasticsearch/index/fielddata/plain/ParentChildIndexFieldData.java
index eebcf4a..cc88210 100644
--- a/core/src/main/java/org/elasticsearch/index/fielddata/plain/ParentChildIndexFieldData.java
+++ b/core/src/main/java/org/elasticsearch/index/fielddata/plain/ParentChildIndexFieldData.java
@@ -19,25 +19,15 @@
 
 package org.elasticsearch.index.fielddata.plain;
 
-import com.carrotsearch.hppc.ObjectObjectHashMap;
-import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.ImmutableSortedSet;
-
 import org.apache.lucene.index.*;
 import org.apache.lucene.index.MultiDocValues.OrdinalMap;
-import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LongValues;
-import org.apache.lucene.util.PagedBytes;
 import org.apache.lucene.util.packed.PackedInts;
-import org.apache.lucene.util.packed.PackedLongValues;
 import org.elasticsearch.ElasticsearchException;
-import org.elasticsearch.Version;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.breaker.CircuitBreaker;
-import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.lease.Releasable;
 import org.elasticsearch.common.lease.Releasables;
 import org.elasticsearch.common.settings.Settings;
@@ -46,15 +36,11 @@ import org.elasticsearch.index.Index;
 import org.elasticsearch.index.fielddata.*;
 import org.elasticsearch.index.fielddata.IndexFieldData.XFieldComparatorSource.Nested;
 import org.elasticsearch.index.fielddata.fieldcomparator.BytesRefFieldComparatorSource;
-import org.elasticsearch.index.fielddata.ordinals.Ordinals;
-import org.elasticsearch.index.fielddata.ordinals.OrdinalsBuilder;
 import org.elasticsearch.index.mapper.DocumentMapper;
-import org.elasticsearch.index.mapper.DocumentTypeListener;
 import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.MappedFieldType.Names;
 import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.mapper.internal.ParentFieldMapper;
-import org.elasticsearch.index.mapper.internal.UidFieldMapper;
 import org.elasticsearch.index.settings.IndexSettings;
 import org.elasticsearch.indices.breaker.CircuitBreakerService;
 import org.elasticsearch.search.MultiValueMode;
diff --git a/core/src/main/java/org/elasticsearch/index/get/ShardGetService.java b/core/src/main/java/org/elasticsearch/index/get/ShardGetService.java
index 20bca78..212362c 100644
--- a/core/src/main/java/org/elasticsearch/index/get/ShardGetService.java
+++ b/core/src/main/java/org/elasticsearch/index/get/ShardGetService.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.index.get;
 
-import com.google.common.collect.Sets;
 import org.apache.lucene.index.Term;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.common.Nullable;
@@ -28,6 +27,7 @@ import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.lucene.uid.Versions;
 import org.elasticsearch.common.metrics.CounterMetric;
 import org.elasticsearch.common.metrics.MeanMetric;
+import org.elasticsearch.common.util.set.Sets;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentHelper;
 import org.elasticsearch.common.xcontent.XContentType;
diff --git a/core/src/main/java/org/elasticsearch/index/indexing/IndexingStats.java b/core/src/main/java/org/elasticsearch/index/indexing/IndexingStats.java
index 07aca1e..5bda1de 100644
--- a/core/src/main/java/org/elasticsearch/index/indexing/IndexingStats.java
+++ b/core/src/main/java/org/elasticsearch/index/indexing/IndexingStats.java
@@ -42,6 +42,7 @@ public class IndexingStats implements Streamable, ToXContent {
         private long indexCount;
         private long indexTimeInMillis;
         private long indexCurrent;
+        private long indexFailedCount;
 
         private long deleteCount;
         private long deleteTimeInMillis;
@@ -56,10 +57,11 @@ public class IndexingStats implements Streamable, ToXContent {
 
         }
 
-        public Stats(long indexCount, long indexTimeInMillis, long indexCurrent, long deleteCount, long deleteTimeInMillis, long deleteCurrent, long noopUpdateCount, boolean isThrottled, long throttleTimeInMillis) {
+        public Stats(long indexCount, long indexTimeInMillis, long indexCurrent, long indexFailedCount, long deleteCount, long deleteTimeInMillis, long deleteCurrent, long noopUpdateCount, boolean isThrottled, long throttleTimeInMillis) {
             this.indexCount = indexCount;
             this.indexTimeInMillis = indexTimeInMillis;
             this.indexCurrent = indexCurrent;
+            this.indexFailedCount = indexFailedCount;
             this.deleteCount = deleteCount;
             this.deleteTimeInMillis = deleteTimeInMillis;
             this.deleteCurrent = deleteCurrent;
@@ -72,6 +74,7 @@ public class IndexingStats implements Streamable, ToXContent {
             indexCount += stats.indexCount;
             indexTimeInMillis += stats.indexTimeInMillis;
             indexCurrent += stats.indexCurrent;
+            indexFailedCount += stats.indexFailedCount;
 
             deleteCount += stats.deleteCount;
             deleteTimeInMillis += stats.deleteTimeInMillis;
@@ -88,6 +91,10 @@ public class IndexingStats implements Streamable, ToXContent {
             return indexCount;
         }
 
+        public long getIndexFailedCount() {
+            return indexFailedCount;
+        }
+
         public TimeValue getIndexTime() {
             return new TimeValue(indexTimeInMillis);
         }
@@ -156,6 +163,10 @@ public class IndexingStats implements Streamable, ToXContent {
             indexTimeInMillis = in.readVLong();
             indexCurrent = in.readVLong();
 
+            if(in.getVersion().onOrAfter(Version.V_2_1_0)){
+                indexFailedCount = in.readVLong();
+            }
+
             deleteCount = in.readVLong();
             deleteTimeInMillis = in.readVLong();
             deleteCurrent = in.readVLong();
@@ -170,6 +181,10 @@ public class IndexingStats implements Streamable, ToXContent {
             out.writeVLong(indexTimeInMillis);
             out.writeVLong(indexCurrent);
 
+            if(out.getVersion().onOrAfter(Version.V_2_1_0)) {
+                out.writeVLong(indexFailedCount);
+            }
+
             out.writeVLong(deleteCount);
             out.writeVLong(deleteTimeInMillis);
             out.writeVLong(deleteCurrent);
@@ -184,6 +199,7 @@ public class IndexingStats implements Streamable, ToXContent {
             builder.field(Fields.INDEX_TOTAL, indexCount);
             builder.timeValueField(Fields.INDEX_TIME_IN_MILLIS, Fields.INDEX_TIME, indexTimeInMillis);
             builder.field(Fields.INDEX_CURRENT, indexCurrent);
+            builder.field(Fields.INDEX_FAILED, indexFailedCount);
 
             builder.field(Fields.DELETE_TOTAL, deleteCount);
             builder.timeValueField(Fields.DELETE_TIME_IN_MILLIS, Fields.DELETE_TIME, deleteTimeInMillis);
@@ -268,6 +284,7 @@ public class IndexingStats implements Streamable, ToXContent {
         static final XContentBuilderString INDEX_TIME = new XContentBuilderString("index_time");
         static final XContentBuilderString INDEX_TIME_IN_MILLIS = new XContentBuilderString("index_time_in_millis");
         static final XContentBuilderString INDEX_CURRENT = new XContentBuilderString("index_current");
+        static final XContentBuilderString INDEX_FAILED = new XContentBuilderString("index_failed");
         static final XContentBuilderString DELETE_TOTAL = new XContentBuilderString("delete_total");
         static final XContentBuilderString DELETE_TIME = new XContentBuilderString("delete_time");
         static final XContentBuilderString DELETE_TIME_IN_MILLIS = new XContentBuilderString("delete_time_in_millis");
diff --git a/core/src/main/java/org/elasticsearch/index/indexing/ShardIndexingService.java b/core/src/main/java/org/elasticsearch/index/indexing/ShardIndexingService.java
index 7766a31..4f0ea77 100644
--- a/core/src/main/java/org/elasticsearch/index/indexing/ShardIndexingService.java
+++ b/core/src/main/java/org/elasticsearch/index/indexing/ShardIndexingService.java
@@ -178,6 +178,8 @@ public class ShardIndexingService extends AbstractIndexShardComponent {
     public void postIndex(Engine.Index index, Throwable ex) {
         totalStats.indexCurrent.dec();
         typeStats(index.type()).indexCurrent.dec();
+        totalStats.indexFailed.inc();
+        typeStats(index.type()).indexFailed.inc();
         for (IndexingOperationListener listener : listeners) {
             try {
                 listener.postIndex(index, ex);
@@ -277,6 +279,7 @@ public class ShardIndexingService extends AbstractIndexShardComponent {
         public final MeanMetric indexMetric = new MeanMetric();
         public final MeanMetric deleteMetric = new MeanMetric();
         public final CounterMetric indexCurrent = new CounterMetric();
+        public final CounterMetric indexFailed = new CounterMetric();
         public final CounterMetric deleteCurrent = new CounterMetric();
         public final CounterMetric noopUpdates = new CounterMetric();
         public final CounterMetric throttleTimeMillisMetric = new CounterMetric();
@@ -293,7 +296,7 @@ public class ShardIndexingService extends AbstractIndexShardComponent {
                 }
             }
             return new IndexingStats.Stats(
-                    indexMetric.count(), TimeUnit.NANOSECONDS.toMillis(indexMetric.sum()), indexCurrent.count(),
+                    indexMetric.count(), TimeUnit.NANOSECONDS.toMillis(indexMetric.sum()), indexCurrent.count(), indexFailed.count(),
                     deleteMetric.count(), TimeUnit.NANOSECONDS.toMillis(deleteMetric.sum()), deleteCurrent.count(),
                     noopUpdates.count(), isThrottled, TimeUnit.MILLISECONDS.toMillis(throttleTimeMillisMetric.count() + TimeValue.nsecToMSec(currentThrottleNS)));
         }
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/DocumentFieldMappers.java b/core/src/main/java/org/elasticsearch/index/mapper/DocumentFieldMappers.java
index fa3b1d6..683543e 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/DocumentFieldMappers.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/DocumentFieldMappers.java
@@ -21,7 +21,6 @@ package org.elasticsearch.index.mapper;
 
 import com.google.common.base.Function;
 import com.google.common.collect.Collections2;
-import com.google.common.collect.Sets;
 import org.apache.lucene.analysis.Analyzer;
 import org.elasticsearch.common.collect.CopyOnWriteHashMap;
 import org.elasticsearch.common.regex.Regex;
@@ -30,6 +29,7 @@ import org.elasticsearch.index.analysis.FieldNameAnalyzer;
 
 import java.util.AbstractMap;
 import java.util.Collection;
+import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Set;
@@ -92,7 +92,7 @@ public final class DocumentFieldMappers implements Iterable<FieldMapper> {
     }
 
     public Collection<String> simpleMatchToFullName(String pattern) {
-        Set<String> fields = Sets.newHashSet();
+        Set<String> fields = new HashSet<>();
         for (FieldMapper fieldMapper : this) {
             if (Regex.simpleMatch(pattern, fieldMapper.fieldType().names().fullName())) {
                 fields.add(fieldMapper.fieldType().names().fullName());
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapper.java
index 1dfca8b..54b2c98 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapper.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.index.mapper;
 
-import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.search.DocIdSet;
@@ -68,6 +67,7 @@ import java.util.HashMap;
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
+import java.util.Objects;
 import java.util.concurrent.locks.ReentrantReadWriteLock;
 
 /**
@@ -142,7 +142,7 @@ public class DocumentMapper implements ToXContent {
         }
 
         public DocumentMapper build(MapperService mapperService, DocumentMapperParser docMapperParser) {
-            Preconditions.checkNotNull(rootObjectMapper, "Mapper builder must have the root object mapper set");
+            Objects.requireNonNull(rootObjectMapper, "Mapper builder must have the root object mapper set");
             return new DocumentMapper(mapperService, indexSettings, docMapperParser, rootObjectMapper, meta, rootMappers, sourceTransforms, mapperService.mappingLock);
         }
     }
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/DocumentParser.java b/core/src/main/java/org/elasticsearch/index/mapper/DocumentParser.java
index 8f51271..db2919e 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/DocumentParser.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/DocumentParser.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.index.mapper;
 
-import com.google.common.collect.Sets;
-
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexOptions;
 import org.apache.lucene.index.IndexableField;
@@ -34,20 +32,20 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentHelper;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.core.DateFieldMapper.DateFieldType;
 import org.elasticsearch.index.mapper.core.NumberFieldMapper;
 import org.elasticsearch.index.mapper.core.StringFieldMapper;
-import org.elasticsearch.index.mapper.core.DateFieldMapper.DateFieldType;
 import org.elasticsearch.index.mapper.core.StringFieldMapper.StringFieldType;
 import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
 import org.elasticsearch.index.mapper.internal.UidFieldMapper;
 import org.elasticsearch.index.mapper.object.ArrayValueMapperParser;
 import org.elasticsearch.index.mapper.object.ObjectMapper;
 import org.elasticsearch.index.mapper.object.RootObjectMapper;
-import org.elasticsearch.percolator.PercolatorService;
 
 import java.io.Closeable;
 import java.io.IOException;
 import java.util.Collections;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
@@ -169,7 +167,7 @@ class DocumentParser implements Closeable {
         }
         // apply doc boost
         if (context.docBoost() != 1.0f) {
-            Set<String> encounteredFields = Sets.newHashSet();
+            Set<String> encounteredFields = new HashSet<>();
             for (ParseContext.Document doc : context.docs()) {
                 encounteredFields.clear();
                 for (IndexableField field : doc) {
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/FieldTypeLookup.java b/core/src/main/java/org/elasticsearch/index/mapper/FieldTypeLookup.java
index 4dfba26..7a416db 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/FieldTypeLookup.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/FieldTypeLookup.java
@@ -21,12 +21,12 @@ package org.elasticsearch.index.mapper;
 
 import com.google.common.base.Function;
 import com.google.common.collect.Iterators;
-import com.google.common.collect.Sets;
 import org.elasticsearch.common.collect.CopyOnWriteHashMap;
 import org.elasticsearch.common.regex.Regex;
 
 import java.util.ArrayList;
 import java.util.Collection;
+import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Set;
@@ -152,7 +152,7 @@ class FieldTypeLookup implements Iterable<MappedFieldType> {
      * Returns a list of the index names of a simple match regex like pattern against full name and index name.
      */
     public Collection<String> simpleMatchToIndexNames(String pattern) {
-        Set<String> fields = Sets.newHashSet();
+        Set<String> fields = new HashSet<>();
         for (MappedFieldType fieldType : this) {
             if (Regex.simpleMatch(pattern, fieldType.names().fullName())) {
                 fields.add(fieldType.names().indexName());
@@ -167,7 +167,7 @@ class FieldTypeLookup implements Iterable<MappedFieldType> {
      * Returns a list of the full names of a simple match regex like pattern against full name and index name.
      */
     public Collection<String> simpleMatchToFullName(String pattern) {
-        Set<String> fields = Sets.newHashSet();
+        Set<String> fields = new HashSet<>();
         for (MappedFieldType fieldType : this) {
             if (Regex.simpleMatch(pattern, fieldType.names().fullName())) {
                 fields.add(fieldType.names().fullName());
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/MappedFieldType.java b/core/src/main/java/org/elasticsearch/index/mapper/MappedFieldType.java
index 2e1f9df..1d34e4e 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/MappedFieldType.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/MappedFieldType.java
@@ -33,7 +33,7 @@ import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.unit.Fuzziness;
 import org.elasticsearch.index.analysis.NamedAnalyzer;
 import org.elasticsearch.index.fielddata.FieldDataType;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.similarity.SimilarityProvider;
 
 import java.io.IOException;
@@ -437,7 +437,7 @@ public abstract class MappedFieldType extends FieldType {
     }
 
     /**
-     * Should the field query {@link #termQuery(Object, org.elasticsearch.index.query.QueryShardContext)}  be used when detecting this
+     * Should the field query {@link #termQuery(Object, org.elasticsearch.index.query.QueryParseContext)}  be used when detecting this
      * field in query string.
      */
     public boolean useTermQueryWithQueryString() {
@@ -449,11 +449,11 @@ public abstract class MappedFieldType extends FieldType {
         return new Term(names().indexName(), indexedValueForSearch(value));
     }
 
-    public Query termQuery(Object value, @Nullable QueryShardContext context) {
+    public Query termQuery(Object value, @Nullable QueryParseContext context) {
         return new TermQuery(createTerm(value));
     }
 
-    public Query termsQuery(List values, @Nullable QueryShardContext context) {
+    public Query termsQuery(List values, @Nullable QueryParseContext context) {
         BytesRef[] bytesRefs = new BytesRef[values.size()];
         for (int i = 0; i < bytesRefs.length; i++) {
             bytesRefs[i] = indexedValueForSearch(values.get(i));
@@ -472,7 +472,7 @@ public abstract class MappedFieldType extends FieldType {
         return new FuzzyQuery(createTerm(value), fuzziness.asDistance(BytesRefs.toString(value)), prefixLength, maxExpansions, transpositions);
     }
 
-    public Query prefixQuery(String value, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryShardContext context) {
+    public Query prefixQuery(String value, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryParseContext context) {
         PrefixQuery query = new PrefixQuery(createTerm(value));
         if (method != null) {
             query.setRewriteMethod(method);
@@ -480,7 +480,7 @@ public abstract class MappedFieldType extends FieldType {
         return query;
     }
 
-    public Query regexpQuery(String value, int flags, int maxDeterminizedStates, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryShardContext context) {
+    public Query regexpQuery(String value, int flags, int maxDeterminizedStates, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryParseContext context) {
         RegexpQuery query = new RegexpQuery(createTerm(value), flags, maxDeterminizedStates);
         if (method != null) {
             query.setRewriteMethod(method);
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/core/CompletionFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/core/CompletionFieldMapper.java
index 3027c53..3a3a854 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/core/CompletionFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/core/CompletionFieldMapper.java
@@ -18,7 +18,6 @@
  */
 package org.elasticsearch.index.mapper.core;
 
-import com.google.common.collect.Sets;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.codecs.PostingsFormat;
@@ -29,6 +28,7 @@ import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.Version;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.util.set.Sets;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentParser;
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/core/DateFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/core/DateFieldMapper.java
index 9e24b50..686cfcf 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/core/DateFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/core/DateFieldMapper.java
@@ -219,6 +219,9 @@ public class DateFieldMapper extends NumberFieldMapper {
 
             @Override
             public Query rewrite(IndexReader reader) throws IOException {
+                if (getBoost() != 1.0F) {
+                    return super.rewrite(reader);
+                }
                 return innerRangeQuery(lowerTerm, upperTerm, includeLower, includeUpper, timeZone, forcedDateParser);
             }
 
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/geo/GeoShapeFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/geo/GeoShapeFieldMapper.java
index b99d200..4179508 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/geo/GeoShapeFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/geo/GeoShapeFieldMapper.java
@@ -125,7 +125,6 @@ public class GeoShapeFieldMapper extends FieldMapper {
             super(name, Defaults.FIELD_TYPE);
         }
 
-        @Override
         public GeoShapeFieldType fieldType() {
             return (GeoShapeFieldType)fieldType;
         }
@@ -401,10 +400,6 @@ public class GeoShapeFieldMapper extends FieldMapper {
             return this.defaultStrategy;
         }
 
-        public PrefixTreeStrategy resolveStrategy(SpatialStrategy strategy) {
-            return resolveStrategy(strategy.getStrategyName());
-        }
-
         public PrefixTreeStrategy resolveStrategy(String strategyName) {
             if (SpatialStrategy.RECURSIVE.getStrategyName().equals(strategyName)) {
                 recursiveStrategy.setPointsOnly(pointsOnly());
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/internal/AllFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/internal/AllFieldMapper.java
index e538a00..f872207 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/internal/AllFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/internal/AllFieldMapper.java
@@ -40,7 +40,7 @@ import org.elasticsearch.index.mapper.MergeMappingException;
 import org.elasticsearch.index.mapper.MergeResult;
 import org.elasticsearch.index.mapper.MetadataFieldMapper;
 import org.elasticsearch.index.mapper.ParseContext;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.similarity.SimilarityLookupService;
 
 import java.io.IOException;
@@ -186,7 +186,7 @@ public class AllFieldMapper extends MetadataFieldMapper {
         }
 
         @Override
-        public Query termQuery(Object value, QueryShardContext context) {
+        public Query termQuery(Object value, QueryParseContext context) {
             return queryStringTermQuery(createTerm(value));
         }
     }
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java
index b012a45..96810ec 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java
@@ -49,7 +49,7 @@ import org.elasticsearch.index.mapper.MergeResult;
 import org.elasticsearch.index.mapper.MetadataFieldMapper;
 import org.elasticsearch.index.mapper.ParseContext;
 import org.elasticsearch.index.mapper.Uid;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 
 import java.io.IOException;
 import java.util.Collection;
@@ -167,7 +167,7 @@ public class IdFieldMapper extends MetadataFieldMapper {
         }
 
         @Override
-        public Query termQuery(Object value, @Nullable QueryShardContext context) {
+        public Query termQuery(Object value, @Nullable QueryParseContext context) {
             if (indexOptions() != IndexOptions.NONE || context == null) {
                 return super.termQuery(value, context);
             }
@@ -176,7 +176,7 @@ public class IdFieldMapper extends MetadataFieldMapper {
         }
 
         @Override
-        public Query termsQuery(List values, @Nullable QueryShardContext context) {
+        public Query termsQuery(List values, @Nullable QueryParseContext context) {
             if (indexOptions() != IndexOptions.NONE || context == null) {
                 return super.termsQuery(values, context);
             }
@@ -184,7 +184,7 @@ public class IdFieldMapper extends MetadataFieldMapper {
         }
 
         @Override
-        public Query prefixQuery(String value, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryShardContext context) {
+        public Query prefixQuery(String value, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryParseContext context) {
             if (indexOptions() != IndexOptions.NONE || context == null) {
                 return super.prefixQuery(value, method, context);
             }
@@ -201,7 +201,7 @@ public class IdFieldMapper extends MetadataFieldMapper {
         }
 
         @Override
-        public Query regexpQuery(String value, int flags, int maxDeterminizedStates, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryShardContext context) {
+        public Query regexpQuery(String value, int flags, int maxDeterminizedStates, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryParseContext context) {
             if (indexOptions() != IndexOptions.NONE || context == null) {
                 return super.regexpQuery(value, flags, maxDeterminizedStates, method, context);
             }
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/internal/IndexFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/internal/IndexFieldMapper.java
index 1b7168a..3f395a8 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/internal/IndexFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/internal/IndexFieldMapper.java
@@ -38,7 +38,7 @@ import org.elasticsearch.index.mapper.MergeMappingException;
 import org.elasticsearch.index.mapper.MergeResult;
 import org.elasticsearch.index.mapper.MetadataFieldMapper;
 import org.elasticsearch.index.mapper.ParseContext;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 
 import java.io.IOException;
 import java.util.Iterator;
@@ -157,7 +157,7 @@ public class IndexFieldMapper extends MetadataFieldMapper {
          * indices
          */
         @Override
-        public Query termQuery(Object value, @Nullable QueryShardContext context) {
+        public Query termQuery(Object value, @Nullable QueryParseContext context) {
             if (context == null) {
                 return super.termQuery(value, context);
             }
@@ -171,7 +171,7 @@ public class IndexFieldMapper extends MetadataFieldMapper {
         
 
         @Override
-        public Query termsQuery(List values, QueryShardContext context) {
+        public Query termsQuery(List values, QueryParseContext context) {
             if (context == null) {
                 return super.termsQuery(values, context);
             }
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/internal/ParentFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/internal/ParentFieldMapper.java
index ca792b8..70c1de6 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/internal/ParentFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/internal/ParentFieldMapper.java
@@ -34,16 +34,8 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.settings.loader.SettingsLoader;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.index.fielddata.FieldDataType;
-import org.elasticsearch.index.mapper.DocumentMapper;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.mapper.Mapper;
-import org.elasticsearch.index.mapper.MapperParsingException;
-import org.elasticsearch.index.mapper.MergeMappingException;
-import org.elasticsearch.index.mapper.MergeResult;
-import org.elasticsearch.index.mapper.MetadataFieldMapper;
-import org.elasticsearch.index.mapper.ParseContext;
-import org.elasticsearch.index.mapper.Uid;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.mapper.*;
+import org.elasticsearch.index.query.QueryParseContext;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -210,12 +202,12 @@ public class ParentFieldMapper extends MetadataFieldMapper {
         }
 
         @Override
-        public Query termQuery(Object value, @Nullable QueryShardContext context) {
+        public Query termQuery(Object value, @Nullable QueryParseContext context) {
             return termsQuery(Collections.singletonList(value), context);
         }
 
         @Override
-        public Query termsQuery(List values, @Nullable QueryShardContext context) {
+        public Query termsQuery(List values, @Nullable QueryParseContext context) {
             if (context == null) {
                 return super.termsQuery(values, context);
             }
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/internal/TypeFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/internal/TypeFieldMapper.java
index 12e40de..480d2a4 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/internal/TypeFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/internal/TypeFieldMapper.java
@@ -43,7 +43,7 @@ import org.elasticsearch.index.mapper.MergeResult;
 import org.elasticsearch.index.mapper.MetadataFieldMapper;
 import org.elasticsearch.index.mapper.ParseContext;
 import org.elasticsearch.index.mapper.Uid;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 
 import java.io.IOException;
 import java.util.List;
@@ -137,7 +137,7 @@ public class TypeFieldMapper extends MetadataFieldMapper {
         }
 
         @Override
-        public Query termQuery(Object value, @Nullable QueryShardContext context) {
+        public Query termQuery(Object value, @Nullable QueryParseContext context) {
             if (indexOptions() == IndexOptions.NONE) {
                 return new ConstantScoreQuery(new PrefixQuery(new Term(UidFieldMapper.NAME, Uid.typePrefixAsBytes(BytesRefs.toBytesRef(value)))));
             }
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/object/RootObjectMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/object/RootObjectMapper.java
index 160c8ed..b2e572f 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/object/RootObjectMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/object/RootObjectMapper.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.index.mapper.object;
 
-import com.google.common.collect.Sets;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.joda.FormatDateTimeFormatter;
@@ -38,6 +37,7 @@ import org.elasticsearch.index.settings.IndexSettings;
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
@@ -66,7 +66,7 @@ public class RootObjectMapper extends ObjectMapper {
         protected final List<DynamicTemplate> dynamicTemplates = new ArrayList<>();
 
         // we use this to filter out seen date formats, because we might get duplicates during merging
-        protected Set<String> seenDateFormats = Sets.newHashSet();
+        protected Set<String> seenDateFormats = new HashSet<>();
         protected List<FormatDateTimeFormatter> dynamicDateTimeFormatters = new ArrayList<>();
 
         protected boolean dateDetection = Defaults.DATE_DETECTION;
diff --git a/core/src/main/java/org/elasticsearch/index/percolator/PercolatorQueriesRegistry.java b/core/src/main/java/org/elasticsearch/index/percolator/PercolatorQueriesRegistry.java
index 19c466a..7add3d3 100644
--- a/core/src/main/java/org/elasticsearch/index/percolator/PercolatorQueriesRegistry.java
+++ b/core/src/main/java/org/elasticsearch/index/percolator/PercolatorQueriesRegistry.java
@@ -43,7 +43,7 @@ import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
 import org.elasticsearch.index.percolator.stats.ShardPercolateService;
 import org.elasticsearch.index.query.IndexQueryParserService;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.settings.IndexSettings;
 import org.elasticsearch.index.shard.AbstractIndexShardComponent;
@@ -185,13 +185,12 @@ public class PercolatorQueriesRegistry extends AbstractIndexShardComponent imple
         }
     }
 
-    //norelease this method parses from xcontent to lucene query, need to re-investigate how to split context here
     private Query parseQuery(String type, XContentParser parser) {
         String[] previousTypes = null;
         if (type != null) {
-            QueryShardContext.setTypesWithPrevious(new String[]{type});
+            QueryParseContext.setTypesWithPrevious(new String[]{type});
         }
-        QueryShardContext context = queryParserService.getShardContext();
+        QueryParseContext context = queryParserService.getParseContext();
         try {
             context.reset(parser);
             // This means that fields in the query need to exist in the mapping prior to registering this query
@@ -210,10 +209,10 @@ public class PercolatorQueriesRegistry extends AbstractIndexShardComponent imple
             context.setMapUnmappedFieldAsString(mapUnmappedFieldsAsString ? true : false);
             return queryParserService.parseInnerQuery(context);
         } catch (IOException e) {
-            throw new QueryParsingException(context.parseContext(), "Failed to parse", e);
+            throw new QueryParsingException(context, "Failed to parse", e);
         } finally {
             if (type != null) {
-                QueryShardContext.setTypes(previousTypes);
+                QueryParseContext.setTypes(previousTypes);
             }
             context.reset(null);
         }
diff --git a/core/src/main/java/org/elasticsearch/index/query/AbstractQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/AbstractQueryBuilder.java
deleted file mode 100644
index a38c067..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/AbstractQueryBuilder.java
+++ /dev/null
@@ -1,328 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.action.support.ToXContentToBytes;
-import org.elasticsearch.common.ParseField;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.BytesRefs;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentType;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.List;
-import java.util.Objects;
-
-/**
- * Base class for all classes producing lucene queries.
- * Supports conversion to BytesReference and creation of lucene Query objects.
- */
-public abstract class AbstractQueryBuilder<QB extends AbstractQueryBuilder> extends ToXContentToBytes implements QueryBuilder<QB> {
-
-    /** Default for boost to apply to resulting Lucene query. Defaults to 1.0*/
-    public static final float DEFAULT_BOOST = 1.0f;
-    public static final ParseField NAME_FIELD = new ParseField("_name");
-    public static final ParseField BOOST_FIELD = new ParseField("boost");
-
-    protected String queryName;
-    protected float boost = DEFAULT_BOOST;
-
-    protected AbstractQueryBuilder() {
-        super(XContentType.JSON);
-    }
-
-    @Override
-    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject();
-        doXContent(builder, params);
-        builder.endObject();
-        return builder;
-    }
-
-    protected abstract void doXContent(XContentBuilder builder, Params params) throws IOException;
-
-    protected void printBoostAndQueryName(XContentBuilder builder) throws IOException {
-        builder.field("boost", boost);
-        if (queryName != null) {
-            builder.field("_name", queryName);
-        }
-    }
-
-    @Override
-    public final Query toQuery(QueryShardContext context) throws IOException {
-        Query query = doToQuery(context);
-        if (query != null) {
-            setFinalBoost(query);
-            if (queryName != null) {
-                context.addNamedQuery(queryName, query);
-            }
-        }
-        return query;
-    }
-
-    /**
-     * Sets the main boost to the query obtained by converting the current query into a lucene query.
-     * The default behaviour is to set the main boost, after verifying that we are not overriding any non default boost
-     * value that was previously set to the lucene query. That case would require some manual decision on how to combine
-     * the main boost with the boost coming from lucene by overriding this method.
-     * @throws IllegalStateException if the lucene query boost has already been set
-     */
-    protected void setFinalBoost(Query query) {
-        if (query.getBoost() != AbstractQueryBuilder.DEFAULT_BOOST) {
-            throw new IllegalStateException("lucene query boost is already set, override setFinalBoost to define how to combine lucene boost with main boost");
-        }
-        query.setBoost(boost);
-    }
-
-    @Override
-    public final Query toFilter(QueryShardContext context) throws IOException {
-        Query result = null;
-            final boolean originalIsFilter = context.isFilter;
-            try {
-                context.isFilter = true;
-                result = toQuery(context);
-            } finally {
-                context.isFilter = originalIsFilter;
-            }
-        return result;
-    }
-
-    //norelease to be made abstract once all query builders override doToQuery providing their own specific implementation.
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        return context.indexQueryParserService().indicesQueriesRegistry().queryParsers().get(getName()).parse(context);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        // default impl does not validate, subclasses should override.
-        //norelease to be possibly made abstract once all queries support validation
-        return null;
-    }
-
-    /**
-     * Returns the query name for the query.
-     */
-    @SuppressWarnings("unchecked")
-    @Override
-    public final QB queryName(String queryName) {
-        this.queryName = queryName;
-        return (QB) this;
-    }
-
-    /**
-     * Sets the query name for the query.
-     */
-    @Override
-    public final String queryName() {
-        return queryName;
-    }
-
-    /**
-     * Returns the boost for this query.
-     */
-    @Override
-    public final float boost() {
-        return this.boost;
-    }
-
-    /**
-     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
-     * weightings) have their score multiplied by the boost provided.
-     */
-    @SuppressWarnings("unchecked")
-    @Override
-    public final QB boost(float boost) {
-        this.boost = boost;
-        return (QB) this;
-    }
-
-    @Override
-    public final QB readFrom(StreamInput in) throws IOException {
-        QB queryBuilder = doReadFrom(in);
-        queryBuilder.boost = in.readFloat();
-        queryBuilder.queryName = in.readOptionalString();
-        return queryBuilder;
-    }
-
-    //norelease make this abstract once all builders implement doReadFrom themselves
-    protected QB doReadFrom(StreamInput in) throws IOException {
-        throw new UnsupportedOperationException();
-    }
-
-    @Override
-    public final void writeTo(StreamOutput out) throws IOException {
-        doWriteTo(out);
-        out.writeFloat(boost);
-        out.writeOptionalString(queryName);
-    }
-
-    //norelease make this abstract once all builders implement doWriteTo themselves
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        throw new UnsupportedOperationException();
-    }
-
-    protected final QueryValidationException addValidationError(String validationError, QueryValidationException validationException) {
-        return QueryValidationException.addValidationError(getName(), validationError, validationException);
-    }
-
-    @Override
-    public final boolean equals(Object obj) {
-        if (this == obj) {
-            return true;
-        }
-        if (obj == null || getClass() != obj.getClass()) {
-            return false;
-        }
-        @SuppressWarnings("unchecked")
-        QB other = (QB) obj;
-        return Objects.equals(queryName, other.queryName) &&
-                Objects.equals(boost, other.boost) &&
-                doEquals(other);
-    }
-
-    /**
-     * Indicates whether some other {@link QueryBuilder} object of the same type is "equal to" this one.
-     */
-    //norelease to be made abstract once all queries are refactored
-    protected boolean doEquals(QB other) {
-        return super.equals(other);
-    }
-
-    @Override
-    public final int hashCode() {
-        return Objects.hash(getClass(), queryName, boost, doHashCode());
-    }
-
-    //norelease to be made abstract once all queries are refactored
-    protected int doHashCode() {
-        return super.hashCode();
-    }
-
-    /**
-     * This helper method checks if the object passed in is a string, if so it
-     * converts it to a {@link BytesRef}.
-     * @param obj the input object
-     * @return the same input object or a {@link BytesRef} representation if input was of type string
-     */
-    protected static Object convertToBytesRefIfString(Object obj) {
-        if (obj instanceof String) {
-            return BytesRefs.toBytesRef(obj);
-        }
-        return obj;
-    }
-
-    /**
-     * This helper method checks if the object passed in is a {@link BytesRef}, if so it
-     * converts it to a utf8 string.
-     * @param obj the input object
-     * @return the same input object or a utf8 string if input was of type {@link BytesRef}
-     */
-    protected static Object convertToStringIfBytesRef(Object obj) {
-        if (obj instanceof BytesRef) {
-            return ((BytesRef) obj).utf8ToString();
-        }
-        return obj;
-    }
-
-    /**
-     * Helper method to convert collection of {@link QueryBuilder} instances to lucene
-     * {@link Query} instances. {@link QueryBuilder} that return <tt>null</tt> calling
-     * their {@link QueryBuilder#toQuery(QueryShardContext)} method are not added to the
-     * resulting collection.
-     *
-     * @throws IOException
-     * @throws QueryShardException
-     */
-    protected static Collection<Query> toQueries(Collection<QueryBuilder> queryBuilders, QueryShardContext context) throws QueryShardException,
-            IOException {
-        List<Query> queries = new ArrayList<>(queryBuilders.size());
-        for (QueryBuilder queryBuilder : queryBuilders) {
-            Query query = queryBuilder.toQuery(context);
-            if (query != null) {
-                queries.add(query);
-            }
-        }
-        return queries;
-    }
-
-    protected QueryValidationException validateInnerQueries(List<QueryBuilder> queryBuilders, QueryValidationException initialValidationException) {
-        QueryValidationException validationException = initialValidationException;
-        for (QueryBuilder queryBuilder : queryBuilders) {
-            validationException = validateInnerQuery(queryBuilder, validationException);
-        }
-        return validationException;
-    }
-
-    protected QueryValidationException validateInnerQuery(QueryBuilder queryBuilder, QueryValidationException initialValidationException) {
-        QueryValidationException validationException = initialValidationException;
-        if (queryBuilder != null) {
-            QueryValidationException queryValidationException = queryBuilder.validate();
-            if (queryValidationException != null) {
-                validationException = QueryValidationException.addValidationErrors(queryValidationException.validationErrors(), validationException);
-            }
-        } else {
-            validationException = addValidationError("inner query cannot be null", validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    public String getName() {
-        //default impl returns the same as writeable name, but we keep the distinction between the two just to make sure
-        return getWriteableName();
-    }
-
-    protected final void writeQueries(StreamOutput out, List<? extends QueryBuilder> queries) throws IOException {
-        out.writeVInt(queries.size());
-        for (QueryBuilder query : queries) {
-            out.writeQuery(query);
-        }
-    }
-
-    protected final List<QueryBuilder> readQueries(StreamInput in) throws IOException {
-        List<QueryBuilder> queries = new ArrayList<>();
-        int size = in.readVInt();
-        for (int i = 0; i < size; i++) {
-            queries.add(in.readQuery());
-        }
-        return queries;
-    }
-
-    protected final void writeOptionalQuery(StreamOutput out, QueryBuilder query) throws IOException {
-        if (query == null) {
-            out.writeBoolean(false);
-        } else {
-            out.writeBoolean(true);
-            out.writeQuery(query);
-        }
-    }
-
-    protected final QueryBuilder readOptionalQuery(StreamInput in) throws IOException {
-        if (in.readBoolean()) {
-            return in.readQuery();
-        }
-        return null;
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/BaseQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/BaseQueryParser.java
deleted file mode 100644
index 4ff02df..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/BaseQueryParser.java
+++ /dev/null
@@ -1,39 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-
-import java.io.IOException;
-
-/**
- * Class used during the query parsers refactoring. Will be removed once we can parse search requests on the coordinating node.
- * All query parsers that have a refactored "fromXContent" method can be changed to extend this instead of {@link BaseQueryParserTemp}.
- * Keeps old {@link QueryParser#parse(QueryShardContext)} method as a stub delegating to
- * {@link QueryParser#fromXContent(QueryParseContext)} and {@link QueryBuilder#toQuery(QueryShardContext)}}
- */
-//norelease needs to be removed once we parse search requests on the coordinating node, as the parse method is not needed anymore at that point.
-public abstract class BaseQueryParser<QB extends QueryBuilder<QB>> implements QueryParser<QB> {
-
-    @Override
-    public final Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        return fromXContent(context.parseContext()).toQuery(context);
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/BaseQueryParserTemp.java b/core/src/main/java/org/elasticsearch/index/query/BaseQueryParserTemp.java
deleted file mode 100644
index 4dc3eae..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/BaseQueryParserTemp.java
+++ /dev/null
@@ -1,39 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-
-import java.io.IOException;
-
-/**
- * This class with method impl is an intermediate step in the query parsers refactoring.
- * Provides a fromXContent default implementation for query parsers that don't have yet a
- * specific fromXContent implementation that returns a QueryBuilder.
- */
-//norelease to be removed once all queries are moved over to extend BaseQueryParser
-public abstract class BaseQueryParserTemp implements QueryParser {
-
-    @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
-        Query query = parse(parseContext.shardContext());
-        return new QueryWrappingQueryBuilder(query);
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/BaseTermQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/BaseTermQueryBuilder.java
deleted file mode 100644
index 6444184..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/BaseTermQueryBuilder.java
+++ /dev/null
@@ -1,171 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-
-import java.io.IOException;
-import java.util.Objects;
-
-public abstract class BaseTermQueryBuilder<QB extends BaseTermQueryBuilder<QB>> extends AbstractQueryBuilder<QB> {
-
-    /** Name of field to match against. */
-    protected final String fieldName;
-
-    /** Value to find matches for. */
-    protected final Object value;
-
-    /**
-     * Constructs a new base term query.
-     *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
-     */
-    public BaseTermQueryBuilder(String fieldName, String value) {
-        this(fieldName, (Object) value);
-    }
-
-    /**
-     * Constructs a new base term query.
-     *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
-     */
-    public BaseTermQueryBuilder(String fieldName, int value) {
-        this(fieldName, (Object) value);
-    }
-
-    /**
-     * Constructs a new base term query.
-     *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
-     */
-    public BaseTermQueryBuilder(String fieldName, long value) {
-        this(fieldName, (Object) value);
-    }
-
-    /**
-     * Constructs a new base term query.
-     *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
-     */
-    public BaseTermQueryBuilder(String fieldName, float value) {
-        this(fieldName, (Object) value);
-    }
-
-    /**
-     * Constructs a new base term query.
-     *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
-     */
-    public BaseTermQueryBuilder(String fieldName, double value) {
-        this(fieldName, (Object) value);
-    }
-
-    /**
-     * Constructs a new base term query.
-     *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
-     */
-    public BaseTermQueryBuilder(String fieldName, boolean value) {
-        this(fieldName, (Object) value);
-    }
-
-    /**
-     * Constructs a new base term query.
-     * In case value is assigned to a string, we internally convert it to a {@link BytesRef}
-     * because in {@link TermQueryParser} and {@link SpanTermQueryParser} string values are parsed to {@link BytesRef}
-     * and we want internal representation of query to be equal regardless of whether it was created from XContent or via Java API.
-     *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
-     */
-    public BaseTermQueryBuilder(String fieldName, Object value) {
-        this.fieldName = fieldName;
-        this.value = convertToBytesRefIfString(value);
-    }
-
-    /** Returns the field name used in this query. */
-    public String fieldName() {
-        return this.fieldName;
-    }
-
-    /**
-     *  Returns the value used in this query.
-     *  If necessary, converts internal {@link BytesRef} representation back to string.
-     */
-    public Object value() {
-        return convertToStringIfBytesRef(this.value);
-    }
-
-    @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(getName());
-        builder.startObject(fieldName);
-        builder.field("value", convertToStringIfBytesRef(this.value));
-        printBoostAndQueryName(builder);
-        builder.endObject();
-        builder.endObject();
-    }
-
-    /** Returns a {@link QueryValidationException} if fieldName is null or empty, or if value is null. */
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (fieldName == null || fieldName.isEmpty()) {
-            validationException = addValidationError("field name cannot be null or empty.", validationException);
-        }
-        if (value == null) {
-            validationException = addValidationError("value cannot be null.", validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    protected final int doHashCode() {
-        return Objects.hash(fieldName, value);
-    }
-
-    @Override
-    protected final boolean doEquals(BaseTermQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-               Objects.equals(value, other.value);
-    }
-
-    @Override
-    protected final QB doReadFrom(StreamInput in) throws IOException {
-        return createBuilder(in.readString(), in.readGenericValue());
-    }
-
-    protected abstract QB createBuilder(String fieldName, Object value);
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-        out.writeGenericValue(value);
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/BoolQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/BoolQueryBuilder.java
index 9b4e06d..c377667 100644
--- a/core/src/main/java/org/elasticsearch/index/query/BoolQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/BoolQueryBuilder.java
@@ -19,35 +19,17 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Objects;
-
-import static org.elasticsearch.common.lucene.search.Queries.fixNegativeQueryIfNeeded;
 
 /**
  * A Query that matches documents matching boolean combinations of other queries.
  */
-public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
-
-    public static final String NAME = "bool";
-
-    public static final boolean ADJUST_PURE_NEGATIVE_DEFAULT = true;
-
-    public static final boolean DISABLE_COORD_DEFAULT = false;
-
-    static final BoolQueryBuilder PROTOTYPE = new BoolQueryBuilder();
+public class BoolQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<BoolQueryBuilder> {
 
     private final List<QueryBuilder> mustClauses = new ArrayList<>();
 
@@ -57,15 +39,19 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
 
     private final List<QueryBuilder> shouldClauses = new ArrayList<>();
 
-    private boolean disableCoord = DISABLE_COORD_DEFAULT;
+    private float boost = -1;
 
-    private boolean adjustPureNegative = ADJUST_PURE_NEGATIVE_DEFAULT;
+    private Boolean disableCoord;
 
     private String minimumShouldMatch;
+    
+    private Boolean adjustPureNegative;
+
+    private String queryName;
 
     /**
      * Adds a query that <b>must</b> appear in the matching documents and will
-     * contribute to scoring. No <tt>null</tt> value allowed.
+     * contribute to scoring.
      */
     public BoolQueryBuilder must(QueryBuilder queryBuilder) {
         mustClauses.add(queryBuilder);
@@ -73,15 +59,8 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
     }
 
     /**
-     * Gets the queries that <b>must</b> appear in the matching documents.
-     */
-    public List<QueryBuilder> must() {
-        return this.mustClauses;
-    }
-
-    /**
      * Adds a query that <b>must</b> appear in the matching documents but will
-     * not contribute to scoring. No <tt>null</tt> value allowed.
+     * not contribute to scoring.
      */
     public BoolQueryBuilder filter(QueryBuilder queryBuilder) {
         filterClauses.add(queryBuilder);
@@ -89,15 +68,8 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
     }
 
     /**
-     * Gets the queries that <b>must</b> appear in the matching documents but don't conntribute to scoring
-     */
-    public List<QueryBuilder> filter() {
-        return this.filterClauses;
-    }
-
-    /**
-     * Adds a query that <b>must not</b> appear in the matching documents.
-     * No <tt>null</tt> value allowed.
+     * Adds a query that <b>must not</b> appear in the matching documents and
+     * will not contribute to scoring.
      */
     public BoolQueryBuilder mustNot(QueryBuilder queryBuilder) {
         mustNotClauses.add(queryBuilder);
@@ -105,16 +77,9 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
     }
 
     /**
-     * Gets the queries that <b>must not</b> appear in the matching documents.
-     */
-    public List<QueryBuilder> mustNot() {
-        return this.mustNotClauses;
-    }
-
-    /**
-     * Adds a clause that <i>should</i> be matched by the returned documents. For a boolean query with no
+     * Adds a query that <i>should</i> appear in the matching documents. For a boolean query with no
      * <tt>MUST</tt> clauses one or more <code>SHOULD</code> clauses must match a document
-     * for the BooleanQuery to match. No <tt>null</tt> value allowed.
+     * for the BooleanQuery to match.
      *
      * @see #minimumNumberShouldMatch(int)
      */
@@ -124,13 +89,13 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
     }
 
     /**
-     * Gets the list of clauses that <b>should</b> be matched by the returned documents.
-     *
-     * @see #should(QueryBuilder)
-     *  @see #minimumNumberShouldMatch(int)
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
      */
-    public List<QueryBuilder> should() {
-        return this.shouldClauses;
+    @Override
+    public BoolQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
@@ -142,13 +107,6 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
     }
 
     /**
-     * @return whether the <tt>Similarity#coord(int,int)</tt> in scoring are disabled. Defaults to <tt>false</tt>.
-     */
-    public boolean disableCoord() {
-        return this.disableCoord;
-    }
-
-    /**
      * Specifies a minimum number of the optional (should) boolean clauses which must be satisfied.
      * <p/>
      * <p>By default no optional clauses are necessary for a match
@@ -166,23 +124,6 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
         return this;
     }
 
-
-    /**
-     * Specifies a minimum number of the optional (should) boolean clauses which must be satisfied.
-     * @see BoolQueryBuilder#minimumNumberShouldMatch(int)
-     */
-    public BoolQueryBuilder minimumNumberShouldMatch(String minimumNumberShouldMatch) {
-        this.minimumShouldMatch = minimumNumberShouldMatch;
-        return this;
-    }
-
-    /**
-     * @return the string representation of the minimumShouldMatch settings for this query
-     */
-    public String minimumNumberShouldMatch() {
-        return this.minimumShouldMatch;
-    }
-
     /**
      * Sets the minimum should match using the special syntax (for example, supporting percentage).
      */
@@ -198,7 +139,7 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
     public boolean hasClauses() {
         return !(mustClauses.isEmpty() && shouldClauses.isEmpty() && mustNotClauses.isEmpty() && filterClauses.isEmpty());
     }
-
+    
     /**
      * If a boolean query contains only negative ("must not") clauses should the
      * BooleanQuery be enhanced with a {@link MatchAllDocsQuery} in order to act
@@ -210,136 +151,52 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
     }
 
     /**
-     * @return the setting for the adjust_pure_negative setting in this query
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public boolean adjustPureNegative() {
-        return this.adjustPureNegative;
+    public BoolQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject("bool");
         doXArrayContent("must", mustClauses, builder, params);
         doXArrayContent("filter", filterClauses, builder, params);
         doXArrayContent("must_not", mustNotClauses, builder, params);
         doXArrayContent("should", shouldClauses, builder, params);
-        builder.field("disable_coord", disableCoord);
-        builder.field("adjust_pure_negative", adjustPureNegative);
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
+        if (disableCoord != null) {
+            builder.field("disable_coord", disableCoord);
+        }
         if (minimumShouldMatch != null) {
             builder.field("minimum_should_match", minimumShouldMatch);
         }
-        printBoostAndQueryName(builder);
+        if (adjustPureNegative != null) {
+            builder.field("adjust_pure_negative", adjustPureNegative);
+        }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         builder.endObject();
     }
 
-    private static void doXArrayContent(String field, List<QueryBuilder> clauses, XContentBuilder builder, Params params) throws IOException {
+    private void doXArrayContent(String field, List<QueryBuilder> clauses, XContentBuilder builder, Params params) throws IOException {
         if (clauses.isEmpty()) {
             return;
         }
-        builder.startArray(field);
-        for (QueryBuilder clause : clauses) {
-            clause.toXContent(builder, params);
-        }
-        builder.endArray();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        BooleanQuery.Builder booleanQueryBuilder = new BooleanQuery.Builder();
-        booleanQueryBuilder.setDisableCoord(disableCoord);
-        addBooleanClauses(context, booleanQueryBuilder, mustClauses, BooleanClause.Occur.MUST);
-        addBooleanClauses(context, booleanQueryBuilder, mustNotClauses, BooleanClause.Occur.MUST_NOT);
-        addBooleanClauses(context, booleanQueryBuilder, shouldClauses, BooleanClause.Occur.SHOULD);
-        addBooleanClauses(context, booleanQueryBuilder, filterClauses, BooleanClause.Occur.FILTER);
-        BooleanQuery booleanQuery = booleanQueryBuilder.build();
-        if (booleanQuery.clauses().isEmpty()) {
-            return new MatchAllDocsQuery();
-        }
-        booleanQuery = Queries.applyMinimumShouldMatch(booleanQuery, minimumShouldMatch);
-        return adjustPureNegative ? fixNegativeQueryIfNeeded(booleanQuery) : booleanQuery;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        validationException = validateInnerQueries(mustClauses, validationException);
-        validationException = validateInnerQueries(shouldClauses, validationException);
-        validationException = validateInnerQueries(mustNotClauses, validationException);
-        validationException = validateInnerQueries(filterClauses, validationException);
-        return validationException;
-    }
-
-    private void addBooleanClauses(QueryShardContext context, BooleanQuery.Builder booleanQueryBuilder, List<QueryBuilder> clauses, Occur occurs) throws IOException {
-        for (QueryBuilder query : clauses) {
-            Query luceneQuery = null;
-            switch (occurs) {
-            case SHOULD:
-                if (context.isFilter() && minimumShouldMatch == null) {
-                    minimumShouldMatch = "1";
-                }
-                luceneQuery = query.toQuery(context);
-                break;
-            case FILTER:
-            case MUST_NOT:
-                luceneQuery = query.toFilter(context);
-                break;
-            case MUST:
-                luceneQuery = query.toQuery(context);
-            }
-            if (luceneQuery != null) {
-                booleanQueryBuilder.add(new BooleanClause(luceneQuery, occurs));
+        if (clauses.size() == 1) {
+            builder.field(field);
+            clauses.get(0).toXContent(builder, params);
+        } else {
+            builder.startArray(field);
+            for (QueryBuilder clause : clauses) {
+                clause.toXContent(builder, params);
             }
+            builder.endArray();
         }
     }
 
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(adjustPureNegative, disableCoord,
-                minimumShouldMatch, mustClauses, shouldClauses, mustNotClauses, filterClauses);
-    }
-
-    @Override
-    protected boolean doEquals(BoolQueryBuilder other) {
-        return Objects.equals(adjustPureNegative, other.adjustPureNegative) &&
-                Objects.equals(disableCoord, other.disableCoord) &&
-                Objects.equals(minimumShouldMatch, other.minimumShouldMatch) &&
-                Objects.equals(mustClauses, other.mustClauses) &&
-                Objects.equals(shouldClauses, other.shouldClauses) &&
-                Objects.equals(mustNotClauses, other.mustNotClauses) &&
-                Objects.equals(filterClauses, other.filterClauses);
-    }
-
-    @Override
-    protected BoolQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        BoolQueryBuilder boolQueryBuilder = new BoolQueryBuilder();
-        List<QueryBuilder> queryBuilders = readQueries(in);
-        boolQueryBuilder.mustClauses.addAll(queryBuilders);
-        queryBuilders = readQueries(in);
-        boolQueryBuilder.mustNotClauses.addAll(queryBuilders);
-        queryBuilders = readQueries(in);
-        boolQueryBuilder.shouldClauses.addAll(queryBuilders);
-        queryBuilders = readQueries(in);
-        boolQueryBuilder.filterClauses.addAll(queryBuilders);
-        boolQueryBuilder.adjustPureNegative = in.readBoolean();
-        boolQueryBuilder.disableCoord = in.readBoolean();
-        boolQueryBuilder.minimumShouldMatch = in.readOptionalString();
-        return boolQueryBuilder;
-
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        writeQueries(out, mustClauses);
-        writeQueries(out, mustNotClauses);
-        writeQueries(out, shouldClauses);
-        writeQueries(out, filterClauses);
-        out.writeBoolean(adjustPureNegative);
-        out.writeBoolean(disableCoord);
-        out.writeOptionalString(minimumShouldMatch);
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/BoolQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/BoolQueryParser.java
index a1ff2fa..542a085 100644
--- a/core/src/main/java/org/elasticsearch/index/query/BoolQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/BoolQueryParser.java
@@ -19,7 +19,10 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.MatchAllDocsQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.settings.Settings;
@@ -32,9 +35,11 @@ import java.util.List;
 import static org.elasticsearch.common.lucene.search.Queries.fixNegativeQueryIfNeeded;
 
 /**
- * Parser for bool query
+ *
  */
-public class BoolQueryParser extends BaseQueryParser<BoolQueryBuilder> {
+public class BoolQueryParser implements QueryParser {
+
+    public static final String NAME = "bool";
 
     @Inject
     public BoolQueryParser(Settings settings) {
@@ -43,27 +48,23 @@ public class BoolQueryParser extends BaseQueryParser<BoolQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{BoolQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public BoolQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        boolean disableCoord = BoolQueryBuilder.DISABLE_COORD_DEFAULT;
-        boolean adjustPureNegative = BoolQueryBuilder.ADJUST_PURE_NEGATIVE_DEFAULT;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        boolean disableCoord = false;
+        float boost = 1.0f;
         String minimumShouldMatch = null;
 
-        final List<QueryBuilder> mustClauses = new ArrayList<>();
-        final List<QueryBuilder> mustNotClauses = new ArrayList<>();
-        final List<QueryBuilder> shouldClauses = new ArrayList<>();
-        final List<QueryBuilder> filterClauses = new ArrayList<>();
+        List<BooleanClause> clauses = new ArrayList<>();
+        boolean adjustPureNegative = true;
         String queryName = null;
-
+        
         String currentFieldName = null;
         XContentParser.Token token;
-        QueryBuilder query;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
@@ -72,21 +73,32 @@ public class BoolQueryParser extends BaseQueryParser<BoolQueryBuilder> {
             } else if (token == XContentParser.Token.START_OBJECT) {
                 switch (currentFieldName) {
                 case "must":
-                    query = parseContext.parseInnerQueryBuilder();
-                    mustClauses.add(query);
+                    Query query = parseContext.parseInnerQuery();
+                    if (query != null) {
+                        clauses.add(new BooleanClause(query, BooleanClause.Occur.MUST));
+                    }
                     break;
                 case "should":
-                    query = parseContext.parseInnerQueryBuilder();
-                    shouldClauses.add(query);
+                    query = parseContext.parseInnerQuery();
+                    if (query != null) {
+                        clauses.add(new BooleanClause(query, BooleanClause.Occur.SHOULD));
+                        if (parseContext.isFilter() && minimumShouldMatch == null) {
+                            minimumShouldMatch = "1";
+                        }
+                    }
                     break;
                 case "filter":
-                    query = parseContext.parseInnerFilterToQueryBuilder();
-                    filterClauses.add(query);
+                    query = parseContext.parseInnerFilter();
+                    if (query != null) {
+                        clauses.add(new BooleanClause(query, BooleanClause.Occur.FILTER));
+                    }
                     break;
                 case "must_not":
                 case "mustNot":
-                    query = parseContext.parseInnerFilterToQueryBuilder();
-                    mustNotClauses.add(query);
+                    query = parseContext.parseInnerFilter();
+                    if (query != null) {
+                        clauses.add(new BooleanClause(query, BooleanClause.Occur.MUST_NOT));
+                    }
                     break;
                 default:
                     throw new QueryParsingException(parseContext, "[bool] query does not support [" + currentFieldName + "]");
@@ -95,21 +107,32 @@ public class BoolQueryParser extends BaseQueryParser<BoolQueryBuilder> {
                 while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                     switch (currentFieldName) {
                     case "must":
-                        query = parseContext.parseInnerQueryBuilder();
-                        mustClauses.add(query);
+                        Query query = parseContext.parseInnerQuery();
+                        if (query != null) {
+                            clauses.add(new BooleanClause(query, BooleanClause.Occur.MUST));
+                        }
                         break;
                     case "should":
-                        query = parseContext.parseInnerQueryBuilder();
-                        shouldClauses.add(query);
+                        query = parseContext.parseInnerQuery();
+                        if (query != null) {
+                            clauses.add(new BooleanClause(query, BooleanClause.Occur.SHOULD));
+                            if (parseContext.isFilter() && minimumShouldMatch == null) {
+                                minimumShouldMatch = "1";
+                            }
+                        }
                         break;
                     case "filter":
-                        query = parseContext.parseInnerFilterToQueryBuilder();
-                        filterClauses.add(query);
+                        query = parseContext.parseInnerFilter();
+                        if (query != null) {
+                            clauses.add(new BooleanClause(query, BooleanClause.Occur.FILTER));
+                        }
                         break;
                     case "must_not":
                     case "mustNot":
-                        query = parseContext.parseInnerFilterToQueryBuilder();
-                        mustNotClauses.add(query);
+                        query = parseContext.parseInnerFilter();
+                        if (query != null) {
+                            clauses.add(new BooleanClause(query, BooleanClause.Occur.MUST_NOT));
+                        }
                         break;
                     default:
                         throw new QueryParsingException(parseContext, "bool query does not support [" + currentFieldName + "]");
@@ -133,29 +156,23 @@ public class BoolQueryParser extends BaseQueryParser<BoolQueryBuilder> {
                 }
             }
         }
-        BoolQueryBuilder boolQuery = new BoolQueryBuilder();
-        for (QueryBuilder queryBuilder : mustClauses) {
-            boolQuery.must(queryBuilder);
-        }
-        for (QueryBuilder queryBuilder : mustNotClauses) {
-            boolQuery.mustNot(queryBuilder);
+
+        if (clauses.isEmpty()) {
+            return new MatchAllDocsQuery();
         }
-        for (QueryBuilder queryBuilder : shouldClauses) {
-            boolQuery.should(queryBuilder);
+
+        BooleanQuery.Builder booleanQueryBuilder = new BooleanQuery.Builder();
+        booleanQueryBuilder.setDisableCoord(disableCoord);
+        for (BooleanClause clause : clauses) {
+            booleanQueryBuilder.add(clause);
         }
-        for (QueryBuilder queryBuilder : filterClauses) {
-            boolQuery.filter(queryBuilder);
+        BooleanQuery booleanQuery = booleanQueryBuilder.build();
+        booleanQuery.setBoost(boost);
+        booleanQuery = Queries.applyMinimumShouldMatch(booleanQuery, minimumShouldMatch);
+        Query query = adjustPureNegative ? fixNegativeQueryIfNeeded(booleanQuery) : booleanQuery;
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
         }
-        boolQuery.boost(boost);
-        boolQuery.disableCoord(disableCoord);
-        boolQuery.adjustPureNegative(adjustPureNegative);
-        boolQuery.minimumNumberShouldMatch(minimumShouldMatch);
-        boolQuery.queryName(queryName);
-        return boolQuery;
-    }
-
-    @Override
-    public BoolQueryBuilder getBuilderPrototype() {
-        return BoolQueryBuilder.PROTOTYPE;
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/BoostableQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/BoostableQueryBuilder.java
new file mode 100644
index 0000000..31572ce
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/index/query/BoostableQueryBuilder.java
@@ -0,0 +1,33 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.query;
+
+/**
+ * Query builder which allow setting some boost
+ */
+public interface BoostableQueryBuilder<B extends BoostableQueryBuilder<B>> {
+
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
+    B boost(float boost);
+
+}
diff --git a/core/src/main/java/org/elasticsearch/index/query/BoostingQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/BoostingQueryBuilder.java
index 69ab70a..9d67469 100644
--- a/core/src/main/java/org/elasticsearch/index/query/BoostingQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/BoostingQueryBuilder.java
@@ -19,14 +19,9 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.queries.BoostingQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * The BoostingQuery class can be used to effectively demote results that match a given query.
@@ -40,132 +35,63 @@ import java.util.Objects;
  * multiplied by the supplied "boost" parameter, so this should be less than 1 to achieve a
  * demoting effect
  */
-public class BoostingQueryBuilder extends AbstractQueryBuilder<BoostingQueryBuilder> {
+public class BoostingQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<BoostingQueryBuilder> {
 
-    public static final String NAME = "boosting";
+    private QueryBuilder positiveQuery;
 
-    private final QueryBuilder positiveQuery;
-
-    private final QueryBuilder negativeQuery;
+    private QueryBuilder negativeQuery;
 
     private float negativeBoost = -1;
 
-    static final BoostingQueryBuilder PROTOTYPE = new BoostingQueryBuilder(null, null);
+    private float boost = -1;
+
+    public BoostingQueryBuilder() {
 
-    /**
-     * Create a new {@link BoostingQueryBuilder}
-     *
-     * @param positiveQuery the positive query for this boosting query.
-     * @param negativeQuery the negative query for this boosting query.
-     */
-    public BoostingQueryBuilder(QueryBuilder positiveQuery, QueryBuilder negativeQuery) {
-        this.positiveQuery = positiveQuery;
-        this.negativeQuery = negativeQuery;
     }
 
-    /**
-     * Get the positive query for this boosting query.
-     */
-    public QueryBuilder positiveQuery() {
-        return this.positiveQuery;
+    public BoostingQueryBuilder positive(QueryBuilder positiveQuery) {
+        this.positiveQuery = positiveQuery;
+        return this;
     }
 
-    /**
-     * Get the negative query for this boosting query.
-     */
-    public QueryBuilder negativeQuery() {
-        return this.negativeQuery;
+    public BoostingQueryBuilder negative(QueryBuilder negativeQuery) {
+        this.negativeQuery = negativeQuery;
+        return this;
     }
 
-    /**
-     * Set the negative boost factor.
-     */
     public BoostingQueryBuilder negativeBoost(float negativeBoost) {
         this.negativeBoost = negativeBoost;
         return this;
     }
 
-    /**
-     * Get the negative boost factor.
-     */
-    public float negativeBoost() {
-        return this.negativeBoost;
-    }
-
     @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("positive");
-        positiveQuery.toXContent(builder, params);
-        builder.field("negative");
-        negativeQuery.toXContent(builder, params);
-        builder.field("negative_boost", negativeBoost);
-        printBoostAndQueryName(builder);
-        builder.endObject();
+    public BoostingQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (negativeBoost < 0) {
-            validationException = addValidationError("query requires negativeBoost to be set to positive value", validationException);
+    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
+        if (positiveQuery == null) {
+            throw new IllegalArgumentException("boosting query requires positive query to be set");
         }
         if (negativeQuery == null) {
-            validationException = addValidationError("inner clause [negative] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(negativeQuery, validationException);
+            throw new IllegalArgumentException("boosting query requires negative query to be set");
         }
-        if (positiveQuery == null) {
-            validationException = addValidationError("inner clause [positive] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(positiveQuery, validationException);
+        if (negativeBoost == -1) {
+            throw new IllegalArgumentException("boosting query requires negativeBoost to be set");
         }
-        return validationException;
-    }
+        builder.startObject(BoostingQueryParser.NAME);
+        builder.field("positive");
+        positiveQuery.toXContent(builder, params);
+        builder.field("negative");
+        negativeQuery.toXContent(builder, params);
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
+        builder.field("negative_boost", negativeBoost);
 
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query positive = positiveQuery.toQuery(context);
-        Query negative = negativeQuery.toQuery(context);
-        // make upstream queries ignore this query by returning `null`
-        // if either inner query builder returns null
-        if (positive == null || negative == null) {
-            return null;
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-
-        return new BoostingQuery(positive, negative, negativeBoost);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(negativeBoost, positiveQuery, negativeQuery);
-    }
-
-    @Override
-    protected boolean doEquals(BoostingQueryBuilder other) {
-        return Objects.equals(negativeBoost, other.negativeBoost) &&
-                Objects.equals(positiveQuery, other.positiveQuery) &&
-                Objects.equals(negativeQuery, other.negativeQuery);
-    }
-
-    @Override
-    protected BoostingQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        QueryBuilder positiveQuery = in.readQuery();
-        QueryBuilder negativeQuery = in.readQuery();
-        BoostingQueryBuilder boostingQuery = new BoostingQueryBuilder(positiveQuery, negativeQuery);
-        boostingQuery.negativeBoost = in.readFloat();
-        return boostingQuery;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(positiveQuery);
-        out.writeQuery(negativeQuery);
-        out.writeFloat(negativeBoost);
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/BoostingQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/BoostingQueryParser.java
index 699d23d..c160b2f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/BoostingQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/BoostingQueryParser.java
@@ -19,15 +19,19 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.queries.BoostingQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
 
 /**
- * Parser for boosting query
+ *
  */
-public class BoostingQueryParser extends BaseQueryParser<BoostingQueryBuilder> {
+public class BoostingQueryParser implements QueryParser {
+
+    public static final String NAME = "boosting";
 
     @Inject
     public BoostingQueryParser() {
@@ -35,20 +39,19 @@ public class BoostingQueryParser extends BaseQueryParser<BoostingQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{BoostingQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public BoostingQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        QueryBuilder positiveQuery = null;
+        Query positiveQuery = null;
         boolean positiveQueryFound = false;
-        QueryBuilder negativeQuery = null;
+        Query negativeQuery = null;
         boolean negativeQueryFound = false;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = -1;
         float negativeBoost = -1;
-        String queryName = null;
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -57,10 +60,10 @@ public class BoostingQueryParser extends BaseQueryParser<BoostingQueryBuilder> {
                 currentFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("positive".equals(currentFieldName)) {
-                    positiveQuery = parseContext.parseInnerQueryBuilder();
+                    positiveQuery = parseContext.parseInnerQuery();
                     positiveQueryFound = true;
                 } else if ("negative".equals(currentFieldName)) {
-                    negativeQuery = parseContext.parseInnerQueryBuilder();
+                    negativeQuery = parseContext.parseInnerQuery();
                     negativeQueryFound = true;
                 } else {
                     throw new QueryParsingException(parseContext, "[boosting] query does not support [" + currentFieldName + "]");
@@ -68,8 +71,6 @@ public class BoostingQueryParser extends BaseQueryParser<BoostingQueryBuilder> {
             } else if (token.isValue()) {
                 if ("negative_boost".equals(currentFieldName) || "negativeBoost".equals(currentFieldName)) {
                     negativeBoost = parser.floatValue();
-                } else if ("_name".equals(currentFieldName)) {
-                    queryName = parser.text();
                 } else if ("boost".equals(currentFieldName)) {
                     boost = parser.floatValue();
                 } else {
@@ -78,25 +79,25 @@ public class BoostingQueryParser extends BaseQueryParser<BoostingQueryBuilder> {
             }
         }
 
-        if (!positiveQueryFound) {
+        if (positiveQuery == null && !positiveQueryFound) {
             throw new QueryParsingException(parseContext, "[boosting] query requires 'positive' query to be set'");
         }
-        if (!negativeQueryFound) {
+        if (negativeQuery == null && !negativeQueryFound) {
             throw new QueryParsingException(parseContext, "[boosting] query requires 'negative' query to be set'");
         }
-        if (negativeBoost < 0) {
-            throw new QueryParsingException(parseContext, "[boosting] query requires 'negative_boost' to be set to be a positive value'");
+        if (negativeBoost == -1) {
+            throw new QueryParsingException(parseContext, "[boosting] query requires 'negative_boost' to be set'");
         }
 
-        BoostingQueryBuilder boostingQuery = new BoostingQueryBuilder(positiveQuery, negativeQuery);
-        boostingQuery.negativeBoost(negativeBoost);
-        boostingQuery.boost(boost);
-        boostingQuery.queryName(queryName);
-        return boostingQuery;
-    }
+        // parsers returned null
+        if (positiveQuery == null || negativeQuery == null) {
+            return null;
+        }
 
-    @Override
-    public BoostingQueryBuilder getBuilderPrototype() {
-        return BoostingQueryBuilder.PROTOTYPE;
+        BoostingQuery boostingQuery = new BoostingQuery(positiveQuery, negativeQuery, negativeBoost);
+        if (boost != -1) {
+            boostingQuery.setBoost(boost);
+        }
+        return boostingQuery;
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryBuilder.java
index 853c583..ae9c10d 100644
--- a/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryBuilder.java
@@ -19,31 +19,18 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.queries.ExtendedCommonTermsQuery;
-import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
 import org.apache.lucene.search.similarities.Similarity;
-import org.apache.lucene.util.BytesRefBuilder;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * CommonTermsQuery query is a query that executes high-frequency terms in a
  * optional sub-query to prevent slow queries due to "common" terms like
- * stopwords. This query basically builds 2 queries off the
- * {@link org.apache.lucene.queries.CommonTermsQuery#add(Term) added} terms
- * where low-frequency terms are added to a required boolean clause
+ * stopwords. This query basically builds 2 queries off the {@link #add(Term)
+ * added} terms where low-frequency terms are added to a required boolean clause
  * and high-frequency terms are added to an optional boolean clause. The
  * optional clause is only executed if the required "low-frequency' clause
  * matches. Scores produced by this query will be slightly different to plain
@@ -55,52 +42,46 @@ import java.util.Objects;
  * execution times significantly if applicable.
  * <p>
  */
-public class CommonTermsQueryBuilder extends AbstractQueryBuilder<CommonTermsQueryBuilder> {
+public class CommonTermsQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<CommonTermsQueryBuilder> {
 
-    public static final String NAME = "common";
-
-    public static final float DEFAULT_CUTOFF_FREQ = 0.01f;
-
-    public static final Operator DEFAULT_HIGH_FREQ_OCCUR = Operator.OR;
-
-    public static final Operator DEFAULT_LOW_FREQ_OCCUR = Operator.OR;
-
-    public static final boolean DEFAULT_DISABLE_COORD = true;
+    public static enum Operator {
+        OR, AND
+    }
 
-    private final String fieldName;
+    private final String name;
 
     private final Object text;
 
-    private Operator highFreqOperator = DEFAULT_HIGH_FREQ_OCCUR;
+    private Operator highFreqOperator = null;
 
-    private Operator lowFreqOperator = DEFAULT_LOW_FREQ_OCCUR;
+    private Operator lowFreqOperator = null;
 
     private String analyzer = null;
 
+    private Float boost = null;
+
     private String lowFreqMinimumShouldMatch = null;
 
     private String highFreqMinimumShouldMatch = null;
 
-    private boolean disableCoord = DEFAULT_DISABLE_COORD;
+    private Boolean disableCoord = null;
 
-    private float cutoffFrequency = DEFAULT_CUTOFF_FREQ;
+    private Float cutoffFrequency = null;
 
-    static final CommonTermsQueryBuilder PROTOTYPE = new CommonTermsQueryBuilder(null, null);
+    private String queryName;
 
     /**
      * Constructs a new common terms query.
      */
-    public CommonTermsQueryBuilder(String fieldName, Object text) {
-        this.fieldName = fieldName;
+    public CommonTermsQueryBuilder(String name, Object text) {
+        if (name == null) {
+            throw new IllegalArgumentException("Field name must not be null");
+        }
+        if (text == null) {
+            throw new IllegalArgumentException("Query must not be null");
+        }
         this.text = text;
-    }
-
-    public String fieldName() {
-        return this.fieldName;
-    }
-
-    public Object value() {
-        return this.text;
+        this.name = name;
     }
 
     /**
@@ -109,27 +90,19 @@ public class CommonTermsQueryBuilder extends AbstractQueryBuilder<CommonTermsQue
      * <tt>AND</tt>.
      */
     public CommonTermsQueryBuilder highFreqOperator(Operator operator) {
-        this.highFreqOperator = (operator == null) ? DEFAULT_HIGH_FREQ_OCCUR : operator;
+        this.highFreqOperator = operator;
         return this;
     }
 
-    public Operator highFreqOperator() {
-        return highFreqOperator;
-    }
-
     /**
      * Sets the operator to use for terms with a low document frequency (less
      * than {@link #cutoffFrequency(float)}. Defaults to <tt>AND</tt>.
      */
     public CommonTermsQueryBuilder lowFreqOperator(Operator operator) {
-        this.lowFreqOperator = (operator == null) ? DEFAULT_LOW_FREQ_OCCUR : operator;
+        this.lowFreqOperator = operator;
         return this;
     }
 
-    public Operator lowFreqOperator() {
-        return lowFreqOperator;
-    }
-
     /**
      * Explicitly set the analyzer to use. Defaults to use explicit mapping
      * config for the field, or, if not set, the default search analyzer.
@@ -139,8 +112,13 @@ public class CommonTermsQueryBuilder extends AbstractQueryBuilder<CommonTermsQue
         return this;
     }
 
-    public String analyzer() {
-        return this.analyzer;
+    /**
+     * Set the boost to apply to the query.
+     */
+    @Override
+    public CommonTermsQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
@@ -148,17 +126,13 @@ public class CommonTermsQueryBuilder extends AbstractQueryBuilder<CommonTermsQue
      * in [0..1] (or absolute number >=1) representing the maximum threshold of
      * a terms document frequency to be considered a low frequency term.
      * Defaults to
-     * <tt>{@value #DEFAULT_CUTOFF_FREQ}</tt>
+     * <tt>{@value CommonTermsQueryParser#DEFAULT_MAX_TERM_DOC_FREQ}</tt>
      */
     public CommonTermsQueryBuilder cutoffFrequency(float cutoffFrequency) {
         this.cutoffFrequency = cutoffFrequency;
         return this;
     }
 
-    public float cutoffFrequency() {
-        return this.cutoffFrequency;
-    }
-
     /**
      * Sets the minimum number of high frequent query terms that need to match in order to
      * produce a hit when there are no low frequen terms.
@@ -168,10 +142,6 @@ public class CommonTermsQueryBuilder extends AbstractQueryBuilder<CommonTermsQue
         return this;
     }
 
-    public String highFreqMinimumShouldMatch() {
-        return this.highFreqMinimumShouldMatch;
-    }
-
     /**
      * Sets the minimum number of low frequent query terms that need to match in order to
      * produce a hit.
@@ -180,32 +150,44 @@ public class CommonTermsQueryBuilder extends AbstractQueryBuilder<CommonTermsQue
         this.lowFreqMinimumShouldMatch = lowFreqMinimumShouldMatch;
         return this;
     }
-
-    public String lowFreqMinimumShouldMatch() {
-        return this.lowFreqMinimumShouldMatch;
-    }
-
+    
     public CommonTermsQueryBuilder disableCoord(boolean disableCoord) {
         this.disableCoord = disableCoord;
         return this;
     }
 
-    public boolean disableCoord() {
-        return this.disableCoord;
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public CommonTermsQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.startObject(fieldName);
+    public void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(CommonTermsQueryParser.NAME);
+        builder.startObject(name);
+
         builder.field("query", text);
-        builder.field("disable_coord", disableCoord);
-        builder.field("high_freq_operator", highFreqOperator.toString());
-        builder.field("low_freq_operator", lowFreqOperator.toString());
+        if (disableCoord != null) {
+            builder.field("disable_coord", disableCoord);
+        }
+        if (highFreqOperator != null) {
+            builder.field("high_freq_operator", highFreqOperator.toString());
+        }
+        if (lowFreqOperator != null) {
+            builder.field("low_freq_operator", lowFreqOperator.toString());
+        }
         if (analyzer != null) {
             builder.field("analyzer", analyzer);
         }
-        builder.field("cutoff_frequency", cutoffFrequency);
+        if (boost != null) {
+            builder.field("boost", boost);
+        }
+        if (cutoffFrequency != null) {
+            builder.field("cutoff_frequency", cutoffFrequency);
+        }
         if (lowFreqMinimumShouldMatch != null || highFreqMinimumShouldMatch != null) {
             builder.startObject("minimum_should_match");
             if (lowFreqMinimumShouldMatch != null) {
@@ -216,125 +198,11 @@ public class CommonTermsQueryBuilder extends AbstractQueryBuilder<CommonTermsQue
             }
             builder.endObject();
         }
-        printBoostAndQueryName(builder);
-        builder.endObject();
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        String field;
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType != null) {
-            field = fieldType.names().indexName();
-        } else {
-            field = fieldName;
-        }
-
-        Analyzer analyzerObj;
-        if (analyzer == null) {
-            if (fieldType != null) {
-                analyzerObj = context.getSearchAnalyzer(fieldType);
-            } else {
-                analyzerObj = context.mapperService().searchAnalyzer();
-            }
-        } else {
-            analyzerObj = context.mapperService().analysisService().analyzer(analyzer);
-            if (analyzerObj == null) {
-                throw new QueryShardException(context, "[common] analyzer [" + analyzer + "] not found");
-            }
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
 
-        Occur highFreqOccur = highFreqOperator.toBooleanClauseOccur();
-        Occur lowFreqOccur = lowFreqOperator.toBooleanClauseOccur();
-
-        ExtendedCommonTermsQuery commonsQuery = new ExtendedCommonTermsQuery(highFreqOccur, lowFreqOccur, cutoffFrequency, disableCoord, fieldType);
-        return parseQueryString(commonsQuery, text, field, analyzerObj, lowFreqMinimumShouldMatch, highFreqMinimumShouldMatch);
-    }
-
-    static Query parseQueryString(ExtendedCommonTermsQuery query, Object queryString, String field, Analyzer analyzer,
-                                         String lowFreqMinimumShouldMatch, String highFreqMinimumShouldMatch) throws IOException {
-        // Logic similar to QueryParser#getFieldQuery
-        int count = 0;
-        try (TokenStream source = analyzer.tokenStream(field, queryString.toString())) {
-            source.reset();
-            CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);
-            BytesRefBuilder builder = new BytesRefBuilder();
-            while (source.incrementToken()) {
-                // UTF-8
-                builder.copyChars(termAtt);
-                query.add(new Term(field, builder.toBytesRef()));
-                count++;
-            }
-        }
-
-        if (count == 0) {
-            return null;
-        }
-        query.setLowFreqMinimumNumberShouldMatch(lowFreqMinimumShouldMatch);
-        query.setHighFreqMinimumNumberShouldMatch(highFreqMinimumShouldMatch);
-        return query;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (Strings.isEmpty(this.fieldName)) {
-            validationException = addValidationError("field name cannot be null or empty.", validationException);
-        }
-        if (this.text == null) {
-            validationException = addValidationError("query text cannot be null", validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    protected CommonTermsQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        CommonTermsQueryBuilder commonTermsQueryBuilder = new CommonTermsQueryBuilder(in.readString(), in.readGenericValue());
-        commonTermsQueryBuilder.highFreqOperator = Operator.readOperatorFrom(in);
-        commonTermsQueryBuilder.lowFreqOperator = Operator.readOperatorFrom(in);
-        commonTermsQueryBuilder.analyzer = in.readOptionalString();
-        commonTermsQueryBuilder.lowFreqMinimumShouldMatch = in.readOptionalString();
-        commonTermsQueryBuilder.highFreqMinimumShouldMatch = in.readOptionalString();
-        commonTermsQueryBuilder.disableCoord = in.readBoolean();
-        commonTermsQueryBuilder.cutoffFrequency = in.readFloat();
-        return commonTermsQueryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(this.fieldName);
-        out.writeGenericValue(this.text);
-        highFreqOperator.writeTo(out);
-        lowFreqOperator.writeTo(out);
-        out.writeOptionalString(analyzer);
-        out.writeOptionalString(lowFreqMinimumShouldMatch);
-        out.writeOptionalString(highFreqMinimumShouldMatch);
-        out.writeBoolean(disableCoord);
-        out.writeFloat(cutoffFrequency);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldName, text, highFreqOperator, lowFreqOperator, analyzer,
-                lowFreqMinimumShouldMatch, highFreqMinimumShouldMatch, disableCoord, cutoffFrequency);
-    }
-
-    @Override
-    protected boolean doEquals(CommonTermsQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-                Objects.equals(text, other.text) &&
-                Objects.equals(highFreqOperator, other.highFreqOperator) &&
-                Objects.equals(lowFreqOperator, other.lowFreqOperator) &&
-                Objects.equals(analyzer, other.analyzer) &&
-                Objects.equals(lowFreqMinimumShouldMatch, other.lowFreqMinimumShouldMatch) &&
-                Objects.equals(highFreqMinimumShouldMatch, other.highFreqMinimumShouldMatch) &&
-                Objects.equals(disableCoord, other.disableCoord) &&
-                Objects.equals(cutoffFrequency, other.cutoffFrequency);
+        builder.endObject();
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryParser.java
index 65f4fa3..c18229e 100644
--- a/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryParser.java
@@ -19,15 +19,36 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.queries.ExtendedCommonTermsQuery;
+import org.apache.lucene.search.BooleanClause;
+import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.util.BytesRefBuilder;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
 
 import java.io.IOException;
 
 /**
- * Parser for common terms query
+ *
  */
-public class CommonTermsQueryParser extends BaseQueryParser<CommonTermsQueryBuilder> {
+public class CommonTermsQueryParser implements QueryParser {
+
+    public static final String NAME = "common";
+
+    static final float DEFAULT_MAX_TERM_DOC_FREQ = 0.01f;
+
+    static final Occur DEFAULT_HIGH_FREQ_OCCUR = Occur.SHOULD;
+
+    static final Occur DEFAULT_LOW_FREQ_OCCUR = Occur.SHOULD;
+
+    static final boolean DEFAULT_DISABLE_COORD = true;
+
 
     @Inject
     public CommonTermsQueryParser() {
@@ -35,26 +56,26 @@ public class CommonTermsQueryParser extends BaseQueryParser<CommonTermsQueryBuil
 
     @Override
     public String[] names() {
-        return new String[] { CommonTermsQueryBuilder.NAME };
+        return new String[] { NAME };
     }
 
     @Override
-    public CommonTermsQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
         XContentParser.Token token = parser.nextToken();
         if (token != XContentParser.Token.FIELD_NAME) {
             throw new QueryParsingException(parseContext, "[common] query malformed, no field");
         }
         String fieldName = parser.currentName();
-        Object text = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        String analyzer = null;
+        Object value = null;
+        float boost = 1.0f;
+        String queryAnalyzer = null;
         String lowFreqMinimumShouldMatch = null;
         String highFreqMinimumShouldMatch = null;
-        boolean disableCoord = CommonTermsQueryBuilder.DEFAULT_DISABLE_COORD;
-        Operator highFreqOperator = CommonTermsQueryBuilder.DEFAULT_HIGH_FREQ_OCCUR;
-        Operator lowFreqOperator = CommonTermsQueryBuilder.DEFAULT_LOW_FREQ_OCCUR;
-        float cutoffFrequency = CommonTermsQueryBuilder.DEFAULT_CUTOFF_FREQ;
+        boolean disableCoord = DEFAULT_DISABLE_COORD;
+        Occur highFreqOccur = DEFAULT_HIGH_FREQ_OCCUR;
+        Occur lowFreqOccur = DEFAULT_LOW_FREQ_OCCUR;
+        float maxTermFrequency = DEFAULT_MAX_TERM_DOC_FREQ;
         String queryName = null;
         token = parser.nextToken();
         if (token == XContentParser.Token.START_OBJECT) {
@@ -84,21 +105,41 @@ public class CommonTermsQueryParser extends BaseQueryParser<CommonTermsQueryBuil
                     }
                 } else if (token.isValue()) {
                     if ("query".equals(currentFieldName)) {
-                        text = parser.objectText();
+                        value = parser.objectText();
                     } else if ("analyzer".equals(currentFieldName)) {
-                        analyzer = parser.text();
+                        String analyzer = parser.text();
+                        if (parseContext.analysisService().analyzer(analyzer) == null) {
+                            throw new QueryParsingException(parseContext, "[common] analyzer [" + parser.text() + "] not found");
+                        }
+                        queryAnalyzer = analyzer;
                     } else if ("disable_coord".equals(currentFieldName) || "disableCoord".equals(currentFieldName)) {
                         disableCoord = parser.booleanValue();
                     } else if ("boost".equals(currentFieldName)) {
                         boost = parser.floatValue();
                     } else if ("high_freq_operator".equals(currentFieldName) || "highFreqOperator".equals(currentFieldName)) {
-                        highFreqOperator = Operator.fromString(parser.text());
+                        String op = parser.text();
+                        if ("or".equalsIgnoreCase(op)) {
+                            highFreqOccur = BooleanClause.Occur.SHOULD;
+                        } else if ("and".equalsIgnoreCase(op)) {
+                            highFreqOccur = BooleanClause.Occur.MUST;
+                        } else {
+                            throw new QueryParsingException(parseContext,
+                                    "[common] query requires operator to be either 'and' or 'or', not [" + op + "]");
+                        }
                     } else if ("low_freq_operator".equals(currentFieldName) || "lowFreqOperator".equals(currentFieldName)) {
-                        lowFreqOperator = Operator.fromString(parser.text());
+                        String op = parser.text();
+                        if ("or".equalsIgnoreCase(op)) {
+                            lowFreqOccur = BooleanClause.Occur.SHOULD;
+                        } else if ("and".equalsIgnoreCase(op)) {
+                            lowFreqOccur = BooleanClause.Occur.MUST;
+                        } else {
+                            throw new QueryParsingException(parseContext,
+                                    "[common] query requires operator to be either 'and' or 'or', not [" + op + "]");
+                        }
                     } else if ("minimum_should_match".equals(currentFieldName) || "minimumShouldMatch".equals(currentFieldName)) {
                         lowFreqMinimumShouldMatch = parser.text();
                     } else if ("cutoff_frequency".equals(currentFieldName)) {
-                        cutoffFrequency = parser.floatValue();
+                        maxTermFrequency = parser.floatValue();
                     } else if ("_name".equals(currentFieldName)) {
                         queryName = parser.text();
                     } else {
@@ -108,7 +149,7 @@ public class CommonTermsQueryParser extends BaseQueryParser<CommonTermsQueryBuil
             }
             parser.nextToken();
         } else {
-            text = parser.objectText();
+            value = parser.objectText();
             // move to the next token
             token = parser.nextToken();
             if (token != XContentParser.Token.END_OBJECT) {
@@ -118,23 +159,66 @@ public class CommonTermsQueryParser extends BaseQueryParser<CommonTermsQueryBuil
             }
         }
 
-        if (text == null) {
+        if (value == null) {
             throw new QueryParsingException(parseContext, "No text specified for text query");
         }
-        return new CommonTermsQueryBuilder(fieldName, text)
-                .lowFreqMinimumShouldMatch(lowFreqMinimumShouldMatch)
-                .highFreqMinimumShouldMatch(highFreqMinimumShouldMatch)
-                .analyzer(analyzer)
-                .highFreqOperator(highFreqOperator)
-                .lowFreqOperator(lowFreqOperator)
-                .disableCoord(disableCoord)
-                .cutoffFrequency(cutoffFrequency)
-                .boost(boost)
-                .queryName(queryName);
+        String field;
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            field = fieldType.names().indexName();
+        } else {
+            field = fieldName;
+        }
+
+        Analyzer analyzer = null;
+        if (queryAnalyzer == null) {
+            if (fieldType != null) {
+                analyzer = fieldType.searchAnalyzer();
+            }
+            if (analyzer == null && fieldType != null) {
+                analyzer = parseContext.getSearchAnalyzer(fieldType);
+            }
+            if (analyzer == null) {
+                analyzer = parseContext.mapperService().searchAnalyzer();
+            }
+        } else {
+            analyzer = parseContext.mapperService().analysisService().analyzer(queryAnalyzer);
+            if (analyzer == null) {
+                throw new IllegalArgumentException("No analyzer found for [" + queryAnalyzer + "]");
+            }
+        }
+
+        ExtendedCommonTermsQuery commonsQuery = new ExtendedCommonTermsQuery(highFreqOccur, lowFreqOccur, maxTermFrequency, disableCoord, fieldType);
+        commonsQuery.setBoost(boost);
+        Query query = parseQueryString(commonsQuery, value.toString(), field, parseContext, analyzer, lowFreqMinimumShouldMatch, highFreqMinimumShouldMatch);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 
-    @Override
-    public CommonTermsQueryBuilder getBuilderPrototype() {
-        return CommonTermsQueryBuilder.PROTOTYPE;
+
+    private final Query parseQueryString(ExtendedCommonTermsQuery query, String queryString, String field, QueryParseContext parseContext,
+            Analyzer analyzer, String lowFreqMinimumShouldMatch, String highFreqMinimumShouldMatch) throws IOException {
+        // Logic similar to QueryParser#getFieldQuery
+        int count = 0;
+        try (TokenStream source = analyzer.tokenStream(field, queryString.toString())) {
+            source.reset();
+            CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);
+            BytesRefBuilder builder = new BytesRefBuilder();
+            while (source.incrementToken()) {
+                // UTF-8
+                builder.copyChars(termAtt);
+                query.add(new Term(field, builder.toBytesRef()));
+                count++;
+            }
+        }
+
+        if (count == 0) {
+            return null;
+        }
+        query.setLowFreqMinimumNumberShouldMatch(lowFreqMinimumShouldMatch);
+        query.setHighFreqMinimumNumberShouldMatch(highFreqMinimumShouldMatch);
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryBuilder.java
index 10b14e0..bdcbe9c 100644
--- a/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryBuilder.java
@@ -19,10 +19,6 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
@@ -32,84 +28,41 @@ import java.util.Objects;
  * A query that wraps a filter and simply returns a constant score equal to the
  * query boost for every document in the filter.
  */
-public class ConstantScoreQueryBuilder extends AbstractQueryBuilder<ConstantScoreQueryBuilder> {
-
-    public static final String NAME = "constant_score";
+public class ConstantScoreQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<ConstantScoreQueryBuilder> {
 
     private final QueryBuilder filterBuilder;
 
-    static final ConstantScoreQueryBuilder PROTOTYPE = new ConstantScoreQueryBuilder(null);
+    private float boost = -1;
 
     /**
-     * A query that wraps another query and simply returns a constant score equal to the
+     * A query that wraps a query and simply returns a constant score equal to the
      * query boost for every document in the query.
      *
      * @param filterBuilder The query to wrap in a constant score query
      */
     public ConstantScoreQueryBuilder(QueryBuilder filterBuilder) {
-        this.filterBuilder = filterBuilder;
+        this.filterBuilder = Objects.requireNonNull(filterBuilder);
     }
 
     /**
-     * @return the query that was wrapped in this constant score query
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
      */
-    public QueryBuilder innerQuery() {
-        return this.filterBuilder;
+    @Override
+    public ConstantScoreQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(ConstantScoreQueryParser.NAME);
         builder.field("filter");
         filterBuilder.toXContent(builder, params);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
 
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query innerFilter = filterBuilder.toFilter(context);
-        if (innerFilter == null ) {
-            // return null so that parent queries (e.g. bool) also ignore this
-            return null;
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        return new ConstantScoreQuery(innerFilter);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (filterBuilder == null) {
-            validationException = addValidationError("inner clause [filter] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(filterBuilder, validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(filterBuilder);
-    }
-
-    @Override
-    protected boolean doEquals(ConstantScoreQueryBuilder other) {
-        return Objects.equals(filterBuilder, other.filterBuilder);
-    }
-
-    @Override
-    protected ConstantScoreQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        QueryBuilder innerFilterBuilder = in.readQuery();
-        return new ConstantScoreQueryBuilder(innerFilterBuilder);
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(filterBuilder);
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryParser.java
index ba261e8..d8a34b9 100644
--- a/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryParser.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.ConstantScoreQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
@@ -27,10 +29,11 @@ import org.elasticsearch.common.xcontent.XContentParser;
 import java.io.IOException;
 
 /**
- * Parser for constant_score query
+ *
  */
-public class ConstantScoreQueryParser extends BaseQueryParser<ConstantScoreQueryBuilder> {
+public class ConstantScoreQueryParser implements QueryParser {
 
+    public static final String NAME = "constant_score";
     private static final ParseField INNER_QUERY_FIELD = new ParseField("filter", "query");
 
     @Inject
@@ -39,17 +42,16 @@ public class ConstantScoreQueryParser extends BaseQueryParser<ConstantScoreQuery
 
     @Override
     public String[] names() {
-        return new String[]{ConstantScoreQueryBuilder.NAME, Strings.toCamelCase(ConstantScoreQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public ConstantScoreQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        QueryBuilder query = null;
+        Query filter = null;
         boolean queryFound = false;
-        String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -60,15 +62,13 @@ public class ConstantScoreQueryParser extends BaseQueryParser<ConstantScoreQuery
                 // skip
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if (parseContext.parseFieldMatcher().match(currentFieldName, INNER_QUERY_FIELD)) {
-                    query = parseContext.parseInnerFilterToQueryBuilder();
+                    filter = parseContext.parseInnerFilter();
                     queryFound = true;
                 } else {
                     throw new QueryParsingException(parseContext, "[constant_score] query does not support [" + currentFieldName + "]");
                 }
             } else if (token.isValue()) {
-                if ("_name".equals(currentFieldName)) {
-                    queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
+                if ("boost".equals(currentFieldName)) {
                     boost = parser.floatValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[constant_score] query does not support [" + currentFieldName + "]");
@@ -79,14 +79,12 @@ public class ConstantScoreQueryParser extends BaseQueryParser<ConstantScoreQuery
             throw new QueryParsingException(parseContext, "[constant_score] requires a 'filter' element");
         }
 
-        ConstantScoreQueryBuilder constantScoreBuilder = new ConstantScoreQueryBuilder(query);
-        constantScoreBuilder.boost(boost);
-        constantScoreBuilder.queryName(queryName);
-        return constantScoreBuilder;
-    }
+        if (filter == null) {
+            return null;
+        }
 
-    @Override
-    public ConstantScoreQueryBuilder getBuilderPrototype() {
-        return ConstantScoreQueryBuilder.PROTOTYPE;
+        filter = new ConstantScoreQuery(filter);
+        filter.setBoost(boost);
+        return filter;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryBuilder.java
index 9b43de6..3724a05 100644
--- a/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryBuilder.java
@@ -19,34 +19,25 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.DisjunctionMaxQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.Collection;
-import java.util.List;
-import java.util.Objects;
 
 /**
  * A query that generates the union of documents produced by its sub-queries, and that scores each document
  * with the maximum score for that document as produced by any sub-query, plus a tie breaking increment for any
  * additional matching sub-queries.
  */
-public class DisMaxQueryBuilder extends AbstractQueryBuilder<DisMaxQueryBuilder> {
+public class DisMaxQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<DisMaxQueryBuilder> {
 
-    public static final String NAME = "dis_max";
+    private ArrayList<QueryBuilder> queries = new ArrayList<>();
 
-    private final ArrayList<QueryBuilder> queries = new ArrayList<>();
+    private float boost = -1;
 
-    /** Default multiplication factor for breaking ties in document scores.*/
-    public static float DEFAULT_TIE_BREAKER = 0.0f;
-    private float tieBreaker = DEFAULT_TIE_BREAKER;
+    private float tieBreaker = -1;
 
-    static final DisMaxQueryBuilder PROTOTYPE = new DisMaxQueryBuilder();
+    private String queryName;
 
     /**
      * Add a sub-query to this disjunction.
@@ -57,10 +48,13 @@ public class DisMaxQueryBuilder extends AbstractQueryBuilder<DisMaxQueryBuilder>
     }
 
     /**
-     * @return an immutable list copy of the current sub-queries of this disjunction
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
      */
-    public List<QueryBuilder> innerQueries() {
-        return this.queries;
+    @Override
+    public DisMaxQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
@@ -75,70 +69,30 @@ public class DisMaxQueryBuilder extends AbstractQueryBuilder<DisMaxQueryBuilder>
     }
 
     /**
-     * @return the tie breaker score
-     * @see DisMaxQueryBuilder#tieBreaker(float)
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public float tieBreaker() {
-        return this.tieBreaker;
+    public DisMaxQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("tie_breaker", tieBreaker);
+        builder.startObject(DisMaxQueryParser.NAME);
+        if (tieBreaker != -1) {
+            builder.field("tie_breaker", tieBreaker);
+        }
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         builder.startArray("queries");
         for (QueryBuilder queryBuilder : queries) {
             queryBuilder.toXContent(builder, params);
         }
         builder.endArray();
-        printBoostAndQueryName(builder);
         builder.endObject();
     }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        // return null if there are no queries at all
-        Collection<Query> luceneQueries = toQueries(queries, context);
-        if (luceneQueries.isEmpty()) {
-            return null;
-        }
-
-        return new DisjunctionMaxQuery(luceneQueries, tieBreaker);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        return validateInnerQueries(queries, null);
-    }
-
-    @Override
-    protected DisMaxQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        DisMaxQueryBuilder disMax = new DisMaxQueryBuilder();
-        List<QueryBuilder> queryBuilders = readQueries(in);
-        disMax.queries.addAll(queryBuilders);
-        disMax.tieBreaker = in.readFloat();
-        return disMax;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        writeQueries(out, queries);
-        out.writeFloat(tieBreaker);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(queries, tieBreaker);
-    }
-
-    @Override
-    protected boolean doEquals(DisMaxQueryBuilder other) {
-        return Objects.equals(queries, other.queries) &&
-               Objects.equals(tieBreaker, other.tieBreaker);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryParser.java
index 39bad2d..dc901d6 100644
--- a/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryParser.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.DisjunctionMaxQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
@@ -28,9 +30,11 @@ import java.util.ArrayList;
 import java.util.List;
 
 /**
- * Parser for dis_max query
+ *
  */
-public class DisMaxQueryParser extends BaseQueryParser<DisMaxQueryBuilder> {
+public class DisMaxQueryParser implements QueryParser {
+
+    public static final String NAME = "dis_max";
 
     @Inject
     public DisMaxQueryParser() {
@@ -38,17 +42,17 @@ public class DisMaxQueryParser extends BaseQueryParser<DisMaxQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{DisMaxQueryBuilder.NAME, Strings.toCamelCase(DisMaxQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public DisMaxQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        float tieBreaker = DisMaxQueryBuilder.DEFAULT_TIE_BREAKER;
+        float boost = 1.0f;
+        float tieBreaker = 0.0f;
 
-        final List<QueryBuilder> queries = new ArrayList<>();
+        List<Query> queries = new ArrayList<>();
         boolean queriesFound = false;
         String queryName = null;
 
@@ -60,8 +64,10 @@ public class DisMaxQueryParser extends BaseQueryParser<DisMaxQueryBuilder> {
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("queries".equals(currentFieldName)) {
                     queriesFound = true;
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    queries.add(query);
+                    Query query = parseContext.parseInnerQuery();
+                    if (query != null) {
+                        queries.add(query);
+                    }
                 } else {
                     throw new QueryParsingException(parseContext, "[dis_max] query does not support [" + currentFieldName + "]");
                 }
@@ -69,8 +75,10 @@ public class DisMaxQueryParser extends BaseQueryParser<DisMaxQueryBuilder> {
                 if ("queries".equals(currentFieldName)) {
                     queriesFound = true;
                     while (token != XContentParser.Token.END_ARRAY) {
-                        QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                        queries.add(query);
+                        Query query = parseContext.parseInnerQuery();
+                        if (query != null) {
+                            queries.add(query);
+                        }
                         token = parser.nextToken();
                     }
                 } else {
@@ -93,18 +101,15 @@ public class DisMaxQueryParser extends BaseQueryParser<DisMaxQueryBuilder> {
             throw new QueryParsingException(parseContext, "[dis_max] requires 'queries' field");
         }
 
-        DisMaxQueryBuilder disMaxQuery = new DisMaxQueryBuilder();
-        disMaxQuery.tieBreaker(tieBreaker);
-        disMaxQuery.queryName(queryName);
-        disMaxQuery.boost(boost);
-        for (QueryBuilder query : queries) {
-            disMaxQuery.add(query);
+        if (queries.isEmpty()) {
+            return null;
         }
-        return disMaxQuery;
-    }
 
-    @Override
-    public DisMaxQueryBuilder getBuilderPrototype() {
-        return DisMaxQueryBuilder.PROTOTYPE;
+        DisjunctionMaxQuery query = new DisjunctionMaxQuery(queries, tieBreaker);
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/EmptyQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/EmptyQueryBuilder.java
deleted file mode 100644
index c59d8d3..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/EmptyQueryBuilder.java
+++ /dev/null
@@ -1,118 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.elasticsearch.action.support.ToXContentToBytes;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentType;
-
-import java.io.IOException;
-
-/**
- * A {@link QueryBuilder} that is a stand in replacement for an empty query clause in the DSL.
- * The current DSL allows parsing inner queries / filters like "{ }", in order to have a
- * valid non-null representation of these clauses that actually do nothing we can use this class.
- *
- * This builder has no corresponding parser and it is not registered under the query name. It is
- * intended to be used internally as a stand-in for nested queries that are left empty and should
- * be ignored upstream.
- */
-public class EmptyQueryBuilder extends ToXContentToBytes implements QueryBuilder<EmptyQueryBuilder> {
-
-    public static final String NAME = "empty_query";
-
-    /** the one and only empty query builder */
-    public static final EmptyQueryBuilder PROTOTYPE = new EmptyQueryBuilder();
-
-    // prevent instances other than prototype
-    private EmptyQueryBuilder() {
-        super(XContentType.JSON);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    public String getName() {
-        return getWriteableName();
-    }
-
-    @Override
-    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject();
-        builder.endObject();
-        return builder;
-    }
-
-    @Override
-    public Query toQuery(QueryShardContext context) throws IOException {
-        // empty
-        return null;
-    }
-
-    @Override
-    public Query toFilter(QueryShardContext context) throws IOException {
-        // empty
-        return null;
-    }
-
-
-    @Override
-    public QueryValidationException validate() {
-        // nothing to validate
-        return null;
-    }
-
-    @Override
-    public void writeTo(StreamOutput out) throws IOException {
-    }
-
-    @Override
-    public EmptyQueryBuilder readFrom(StreamInput in) throws IOException {
-        return EmptyQueryBuilder.PROTOTYPE;
-    }
-
-    @Override
-    public EmptyQueryBuilder queryName(String queryName) {
-        //no-op
-        return this;
-    }
-
-    @Override
-    public String queryName() {
-        return null;
-    }
-
-    @Override
-    public float boost() {
-        return -1;
-    }
-
-    @Override
-    public EmptyQueryBuilder boost(float boost) {
-        //no-op
-        return this;
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/ExistsQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/ExistsQueryBuilder.java
index 67ea4c5..9980d81 100644
--- a/core/src/main/java/org/elasticsearch/index/query/ExistsQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/ExistsQueryBuilder.java
@@ -19,126 +19,38 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.*;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.mapper.internal.FieldNamesFieldMapper;
-import org.elasticsearch.index.mapper.object.ObjectMapper;
 
 import java.io.IOException;
-import java.util.Collection;
-import java.util.Objects;
 
 /**
  * Constructs a query that only match on documents that the field has a value in them.
  */
-public class ExistsQueryBuilder extends AbstractQueryBuilder<ExistsQueryBuilder> {
+public class ExistsQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "exists";
+    private String name;
 
-    private final String fieldName;
+    private String queryName;
 
-    static final ExistsQueryBuilder PROTOTYPE = new ExistsQueryBuilder(null);
-
-    public ExistsQueryBuilder(String fieldName) {
-        this.fieldName = fieldName;
+    public ExistsQueryBuilder(String name) {
+        this.name = name;
     }
 
     /**
-     * @return the field name that has to exist for this query to match
+     * Sets the query name for the query that can be used when searching for matched_queries per hit.
      */
-    public String fieldName() {
-        return this.fieldName;
+    public ExistsQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("field", fieldName);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        return newFilter(context, fieldName);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        // nothing to validate
-        return null;
-    }
-
-    public static Query newFilter(QueryShardContext context, String fieldPattern) {
-        final FieldNamesFieldMapper.FieldNamesFieldType fieldNamesFieldType = (FieldNamesFieldMapper.FieldNamesFieldType)context.mapperService().fullName(FieldNamesFieldMapper.NAME);
-        if (fieldNamesFieldType == null) {
-            // can only happen when no types exist, so no docs exist either
-            return Queries.newMatchNoDocsQuery();
-        }
-
-        ObjectMapper objectMapper = context.getObjectMapper(fieldPattern);
-        if (objectMapper != null) {
-            // automatic make the object mapper pattern
-            fieldPattern = fieldPattern + ".*";
-        }
-
-        Collection<String> fields = context.simpleMatchToIndexNames(fieldPattern);
-        if (fields.isEmpty()) {
-            // no fields exists, so we should not match anything
-            return Queries.newMatchNoDocsQuery();
-        }
-
-        BooleanQuery.Builder boolFilterBuilder = new BooleanQuery.Builder();
-        for (String field : fields) {
-            MappedFieldType fieldType = context.fieldMapper(field);
-            Query filter = null;
-            if (fieldNamesFieldType.isEnabled()) {
-                final String f;
-                if (fieldType != null) {
-                    f = fieldType.names().indexName();
-                } else {
-                    f = field;
-                }
-                filter = fieldNamesFieldType.termQuery(f, context);
-            }
-            // if _field_names are not indexed, we need to go the slow way
-            if (filter == null && fieldType != null) {
-                filter = fieldType.rangeQuery(null, null, true, true);
-            }
-            if (filter == null) {
-                filter = new TermRangeQuery(field, null, null, true, true);
-            }
-            boolFilterBuilder.add(filter, BooleanClause.Occur.SHOULD);
+        builder.startObject(ExistsQueryParser.NAME);
+        builder.field("field", name);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return new ConstantScoreQuery(boolFilterBuilder.build());
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldName);
-    }
-
-    @Override
-    protected boolean doEquals(ExistsQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName);
-    }
-
-    @Override
-    protected ExistsQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new ExistsQueryBuilder(in.readString());
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/ExistsQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/ExistsQueryParser.java
index bd584bc..9519667 100644
--- a/core/src/main/java/org/elasticsearch/index/query/ExistsQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/ExistsQueryParser.java
@@ -19,15 +19,23 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.*;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.mapper.internal.FieldNamesFieldMapper;
+import org.elasticsearch.index.mapper.object.ObjectMapper;
 
 import java.io.IOException;
+import java.util.Collection;
 
 /**
- * Parser for exists query
+ *
  */
-public class ExistsQueryParser extends BaseQueryParser<ExistsQueryBuilder> {
+public class ExistsQueryParser implements QueryParser {
+
+    public static final String NAME = "exists";
 
     @Inject
     public ExistsQueryParser() {
@@ -35,16 +43,15 @@ public class ExistsQueryParser extends BaseQueryParser<ExistsQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{ExistsQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public ExistsQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldPattern = null;
         String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
 
         XContentParser.Token token;
         String currentFieldName = null;
@@ -56,8 +63,6 @@ public class ExistsQueryParser extends BaseQueryParser<ExistsQueryBuilder> {
                     fieldPattern = parser.text();
                 } else if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[exists] query does not support [" + currentFieldName + "]");
                 }
@@ -68,14 +73,56 @@ public class ExistsQueryParser extends BaseQueryParser<ExistsQueryBuilder> {
             throw new QueryParsingException(parseContext, "exists must be provided with a [field]");
         }
 
-        ExistsQueryBuilder builder = new ExistsQueryBuilder(fieldPattern);
-        builder.queryName(queryName);
-        builder.boost(boost);
-        return builder;
+        return newFilter(parseContext, fieldPattern, queryName);
     }
 
-    @Override
-    public ExistsQueryBuilder getBuilderPrototype() {
-        return ExistsQueryBuilder.PROTOTYPE;
+    public static Query newFilter(QueryParseContext parseContext, String fieldPattern, String queryName) {
+        final FieldNamesFieldMapper.FieldNamesFieldType fieldNamesFieldType = (FieldNamesFieldMapper.FieldNamesFieldType)parseContext.mapperService().fullName(FieldNamesFieldMapper.NAME);
+        if (fieldNamesFieldType == null) {
+            // can only happen when no types exist, so no docs exist either
+            return Queries.newMatchNoDocsQuery();
+        }
+
+        ObjectMapper objectMapper = parseContext.getObjectMapper(fieldPattern);
+        if (objectMapper != null) {
+            // automatic make the object mapper pattern
+            fieldPattern = fieldPattern + ".*";
+        }
+
+        Collection<String> fields = parseContext.simpleMatchToIndexNames(fieldPattern);
+        if (fields.isEmpty()) {
+            // no fields exists, so we should not match anything
+            return Queries.newMatchNoDocsQuery();
+        }
+
+        BooleanQuery.Builder boolFilterBuilder = new BooleanQuery.Builder();
+        for (String field : fields) {
+            MappedFieldType fieldType = parseContext.fieldMapper(field);
+            Query filter = null;
+            if (fieldNamesFieldType.isEnabled()) {
+                final String f;
+                if (fieldType != null) {
+                    f = fieldType.names().indexName();
+                } else {
+                    f = field;
+                }
+                filter = fieldNamesFieldType.termQuery(f, parseContext);
+            }
+            // if _field_names are not indexed, we need to go the slow way
+            if (filter == null && fieldType != null) {
+                filter = fieldType.rangeQuery(null, null, true, true);
+            }
+            if (filter == null) {
+                filter = new TermRangeQuery(field, null, null, true, true);
+            }
+            boolFilterBuilder.add(filter, BooleanClause.Occur.SHOULD);
+        }
+
+        BooleanQuery boolFilter = boolFilterBuilder.build();
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, boolFilter);
+        }
+        return new ConstantScoreQuery(boolFilter);
     }
+
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryBuilder.java
index a577225..c118416 100644
--- a/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryBuilder.java
@@ -19,113 +19,52 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.FieldMaskingSpanQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
 
 import java.io.IOException;
-import java.util.Objects;
 
-public class FieldMaskingSpanQueryBuilder extends AbstractQueryBuilder<FieldMaskingSpanQueryBuilder> implements SpanQueryBuilder<FieldMaskingSpanQueryBuilder>{
-
-    public static final String NAME = "field_masking_span";
+public class FieldMaskingSpanQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<FieldMaskingSpanQueryBuilder> {
 
     private final SpanQueryBuilder queryBuilder;
 
-    private final String fieldName;
+    private final String field;
 
-    static final FieldMaskingSpanQueryBuilder PROTOTYPE = new FieldMaskingSpanQueryBuilder(null, null);
+    private float boost = -1;
 
-    /**
-     * Constructs a new {@link FieldMaskingSpanQueryBuilder} given an inner {@link SpanQueryBuilder} for
-     * a given field
-     * @param queryBuilder inner {@link SpanQueryBuilder}
-     * @param fieldName the field name
-     */
-    public FieldMaskingSpanQueryBuilder(SpanQueryBuilder queryBuilder, String fieldName) {
+    private String queryName;
+
+
+    public FieldMaskingSpanQueryBuilder(SpanQueryBuilder queryBuilder, String field) {
         this.queryBuilder = queryBuilder;
-        this.fieldName = fieldName;
+        this.field = field;
     }
 
-    /**
-     * @return the field name for this query
-     */
-    public String fieldName() {
-        return this.fieldName;
+    @Override
+    public FieldMaskingSpanQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
-     * @return the inner {@link QueryBuilder}
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public SpanQueryBuilder innerQuery() {
-        return this.queryBuilder;
+    public FieldMaskingSpanQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(FieldMaskingSpanQueryParser.NAME);
         builder.field("query");
         queryBuilder.toXContent(builder, params);
-        builder.field("field", fieldName);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected SpanQuery doToQuery(QueryShardContext context) throws IOException {
-        String fieldInQuery = fieldName;
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType != null) {
-            fieldInQuery = fieldType.names().indexName();
-        }
-        Query innerQuery = queryBuilder.toQuery(context);
-        assert innerQuery instanceof SpanQuery;
-        return new FieldMaskingSpanQuery((SpanQuery)innerQuery, fieldInQuery);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (queryBuilder == null) {
-            validationException = addValidationError("inner clause [query] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(queryBuilder, validationException);
+        builder.field("field", field);
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        if (fieldName == null || fieldName.isEmpty()) {
-            validationException = addValidationError("field name is null or empty", validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return validationException;
-    }
-
-    @Override
-    protected FieldMaskingSpanQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        QueryBuilder innerQueryBuilder = in.readQuery();
-        return new FieldMaskingSpanQueryBuilder((SpanQueryBuilder) innerQueryBuilder, in.readString());
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(queryBuilder);
-        out.writeString(fieldName);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(queryBuilder, fieldName);
-    }
-
-    @Override
-    protected boolean doEquals(FieldMaskingSpanQueryBuilder other) {
-        return Objects.equals(queryBuilder, other.queryBuilder) &&
-               Objects.equals(fieldName, other.fieldName);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryParser.java
index ad77039..2980be1 100644
--- a/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryParser.java
@@ -19,15 +19,23 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.FieldMaskingSpanQuery;
+import org.apache.lucene.search.spans.SpanQuery;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.FieldMapper;
+import org.elasticsearch.index.mapper.MappedFieldType;
+
 import java.io.IOException;
 
 /**
- * Parser for field_masking_span query
+ *
  */
-public class FieldMaskingSpanQueryParser extends BaseQueryParser<FieldMaskingSpanQueryBuilder> {
+public class FieldMaskingSpanQueryParser implements QueryParser {
+
+    public static final String NAME = "field_masking_span";
 
     @Inject
     public FieldMaskingSpanQueryParser() {
@@ -35,16 +43,16 @@ public class FieldMaskingSpanQueryParser extends BaseQueryParser<FieldMaskingSpa
 
     @Override
     public String[] names() {
-        return new String[]{FieldMaskingSpanQueryBuilder.NAME, Strings.toCamelCase(FieldMaskingSpanQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public FieldMaskingSpanQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
 
-        SpanQueryBuilder inner = null;
+        SpanQuery inner = null;
         String field = null;
         String queryName = null;
 
@@ -55,11 +63,11 @@ public class FieldMaskingSpanQueryParser extends BaseQueryParser<FieldMaskingSpa
                 currentFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("query".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (!(query instanceof SpanQueryBuilder)) {
-                        throw new QueryParsingException(parseContext, "[field_masking_span] query must be of type span query");
+                    Query query = parseContext.parseInnerQuery();
+                    if (!(query instanceof SpanQuery)) {
+                        throw new QueryParsingException(parseContext, "[field_masking_span] query] must be of type span query");
                     }
-                    inner = (SpanQueryBuilder) query;
+                    inner = (SpanQuery) query;
                 } else {
                     throw new QueryParsingException(parseContext, "[field_masking_span] query does not support ["
                             + currentFieldName + "]");
@@ -83,14 +91,16 @@ public class FieldMaskingSpanQueryParser extends BaseQueryParser<FieldMaskingSpa
             throw new QueryParsingException(parseContext, "field_masking_span must have [field] set for it");
         }
 
-        FieldMaskingSpanQueryBuilder queryBuilder = new FieldMaskingSpanQueryBuilder(inner, field);
-        queryBuilder.boost(boost);
-        queryBuilder.queryName(queryName);
-        return queryBuilder;
-    }
+        MappedFieldType fieldType = parseContext.fieldMapper(field);
+        if (fieldType != null) {
+            field = fieldType.names().indexName();
+        }
 
-    @Override
-    public FieldMaskingSpanQueryBuilder getBuilderPrototype() {
-        return FieldMaskingSpanQueryBuilder.PROTOTYPE;
+        FieldMaskingSpanQuery query = new FieldMaskingSpanQuery(inner, field);
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryBuilder.java
index 237b415..23557b1 100644
--- a/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryBuilder.java
@@ -19,273 +19,177 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.FuzzyQuery;
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.unit.Fuzziness;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * A Query that does fuzzy matching for a specific value.
  */
-public class FuzzyQueryBuilder extends AbstractQueryBuilder<FuzzyQueryBuilder> implements MultiTermQueryBuilder<FuzzyQueryBuilder> {
+public class FuzzyQueryBuilder extends MultiTermQueryBuilder implements BoostableQueryBuilder<FuzzyQueryBuilder> {
 
-    public static final String NAME = "fuzzy";
-
-    /** Default maximum edit distance. Defaults to AUTO. */
-    public static final Fuzziness DEFAULT_FUZZINESS = Fuzziness.AUTO;
-
-    /** Default number of initial characters which will not be fuzzified. Defaults to 0. */
-    public static final int DEFAULT_PREFIX_LENGTH = FuzzyQuery.defaultPrefixLength;
-
-    /** Default maximum number of terms that the fuzzy query will expand to. Defaults to 50. */
-    public static final int DEFAULT_MAX_EXPANSIONS = FuzzyQuery.defaultMaxExpansions;
-
-    /** Default as to whether transpositions should be treated as a primitive edit operation, 
-     * instead of classic Levenshtein algorithm. Defaults to false. */
-    public static final boolean DEFAULT_TRANSPOSITIONS = false;
-
-    private final String fieldName;
+    private final String name;
 
     private final Object value;
 
-    private Fuzziness fuzziness = DEFAULT_FUZZINESS;
+    private float boost = -1;
 
-    private int prefixLength = DEFAULT_PREFIX_LENGTH;
+    private Fuzziness fuzziness;
 
-    private int maxExpansions = DEFAULT_MAX_EXPANSIONS;
+    private Integer prefixLength;
 
+    private Integer maxExpansions;
+    
     //LUCENE 4 UPGRADE  we need a testcase for this + documentation
-    private boolean transpositions = DEFAULT_TRANSPOSITIONS;
+    private Boolean transpositions;
 
     private String rewrite;
 
-    static final FuzzyQueryBuilder PROTOTYPE = new FuzzyQueryBuilder(null, null);
+    private String queryName;
 
     /**
      * Constructs a new fuzzy query.
      *
-     * @param fieldName  The name of the field
+     * @param name  The name of the field
      * @param value The value of the text
      */
-    public FuzzyQueryBuilder(String fieldName, String value) {
-        this(fieldName, (Object) value);
+    public FuzzyQueryBuilder(String name, Object value) {
+        this.name = name;
+        this.value = value;
     }
 
     /**
      * Constructs a new fuzzy query.
      *
-     * @param fieldName  The name of the field
+     * @param name  The name of the field
      * @param value The value of the text
      */
-    public FuzzyQueryBuilder(String fieldName, int value) {
-        this(fieldName, (Object) value);
+    public FuzzyQueryBuilder(String name, String value) {
+        this(name, (Object) value);
     }
 
     /**
      * Constructs a new fuzzy query.
      *
-     * @param fieldName  The name of the field
+     * @param name  The name of the field
      * @param value The value of the text
      */
-    public FuzzyQueryBuilder(String fieldName, long value) {
-        this(fieldName, (Object) value);
+    public FuzzyQueryBuilder(String name, int value) {
+        this(name, (Object) value);
     }
 
     /**
      * Constructs a new fuzzy query.
      *
-     * @param fieldName  The name of the field
+     * @param name  The name of the field
      * @param value The value of the text
      */
-    public FuzzyQueryBuilder(String fieldName, float value) {
-        this(fieldName, (Object) value);
+    public FuzzyQueryBuilder(String name, long value) {
+        this(name, (Object) value);
     }
 
     /**
      * Constructs a new fuzzy query.
      *
-     * @param fieldName  The name of the field
+     * @param name  The name of the field
      * @param value The value of the text
      */
-    public FuzzyQueryBuilder(String fieldName, double value) {
-        this(fieldName, (Object) value);
+    public FuzzyQueryBuilder(String name, float value) {
+        this(name, (Object) value);
     }
 
     /**
      * Constructs a new fuzzy query.
      *
-     * @param fieldName  The name of the field
+     * @param name  The name of the field
      * @param value The value of the text
      */
-    public FuzzyQueryBuilder(String fieldName, boolean value) {
-        this(fieldName, (Object) value);
+    public FuzzyQueryBuilder(String name, double value) {
+        this(name, (Object) value);
     }
 
+    // NO COMMIT: not sure we should also allow boolean?
     /**
      * Constructs a new fuzzy query.
      *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
+     * @param name  The name of the field
+     * @param value The value of the text
      */
-    public FuzzyQueryBuilder(String fieldName, Object value) {
-        this.fieldName = fieldName;
-        this.value = convertToBytesRefIfString(value);
+    public FuzzyQueryBuilder(String name, boolean value) {
+        this(name, (Object) value);
     }
 
-    public String fieldName() {
-        return this.fieldName;
-    }
-
-    public Object value() {
-        return convertToStringIfBytesRef(this.value);
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
+    @Override
+    public FuzzyQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     public FuzzyQueryBuilder fuzziness(Fuzziness fuzziness) {
-        this.fuzziness = (fuzziness == null) ? DEFAULT_FUZZINESS : fuzziness;
+        this.fuzziness = fuzziness;
         return this;
     }
-    
-    public Fuzziness fuzziness() {
-        return this.fuzziness;
-    }
 
     public FuzzyQueryBuilder prefixLength(int prefixLength) {
         this.prefixLength = prefixLength;
         return this;
     }
-    
-    public int prefixLength() {
-        return this.prefixLength;
-    }
 
     public FuzzyQueryBuilder maxExpansions(int maxExpansions) {
         this.maxExpansions = maxExpansions;
         return this;
     }
-
-    public int maxExpansions() {
-        return this.maxExpansions;
-    }
-
+    
     public FuzzyQueryBuilder transpositions(boolean transpositions) {
       this.transpositions = transpositions;
       return this;
     }
 
-    public boolean transpositions() {
-        return this.transpositions;
-    }
-
     public FuzzyQueryBuilder rewrite(String rewrite) {
         this.rewrite = rewrite;
         return this;
     }
 
-    public String rewrite() {
-        return this.rewrite;
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public FuzzyQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     public void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.startObject(fieldName);
-        builder.field("value", convertToStringIfBytesRef(this.value));
-        fuzziness.toXContent(builder, params);
-        builder.field("prefix_length", prefixLength);
-        builder.field("max_expansions", maxExpansions);
-        builder.field("transpositions", transpositions);
-        if (rewrite != null) {
-            builder.field("rewrite", rewrite);
+        builder.startObject(FuzzyQueryParser.NAME);
+        builder.startObject(name);
+        builder.field("value", value);
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        printBoostAndQueryName(builder);
-        builder.endObject();
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    public Query doToQuery(QueryShardContext context) throws QueryParsingException, IOException {
-        Query query = null;
-        if (rewrite == null && context.isFilter()) {
-            rewrite = QueryParsers.CONSTANT_SCORE.getPreferredName();
+        if (transpositions != null) {
+            builder.field("transpositions", transpositions);
         }
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType != null) {
-            query = fieldType.fuzzyQuery(value, fuzziness, prefixLength, maxExpansions, transpositions);
+        if (fuzziness != null) {
+            fuzziness.toXContent(builder, params);
         }
-        if (query == null) {
-            int maxEdits = fuzziness.asDistance(BytesRefs.toString(value));
-            query = new FuzzyQuery(new Term(fieldName, BytesRefs.toBytesRef(value)), maxEdits, prefixLength, maxExpansions, transpositions);
+        if (prefixLength != null) {
+            builder.field("prefix_length", prefixLength);
         }
-        if (query instanceof MultiTermQuery) {
-            MultiTermQuery.RewriteMethod rewriteMethod = QueryParsers.parseRewriteMethod(context.parseFieldMatcher(), rewrite, null);
-            QueryParsers.setRewriteMethod((MultiTermQuery) query, rewriteMethod);
+        if (maxExpansions != null) {
+            builder.field("max_expansions", maxExpansions);
         }
-        return query;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (Strings.isEmpty(this.fieldName)) {
-            validationException = addValidationError("field name cannot be null or empty.", validationException);
+        if (rewrite != null) {
+            builder.field("rewrite", rewrite);
         }
-        if (this.value == null) {
-            validationException = addValidationError("query text cannot be null", validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return validationException;
-    }
-
-    @Override
-    public FuzzyQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        FuzzyQueryBuilder fuzzyQueryBuilder = new FuzzyQueryBuilder(in.readString(), in.readGenericValue());
-        fuzzyQueryBuilder.fuzziness = Fuzziness.readFuzzinessFrom(in);
-        fuzzyQueryBuilder.prefixLength = in.readVInt();
-        fuzzyQueryBuilder.maxExpansions = in.readVInt();
-        fuzzyQueryBuilder.transpositions = in.readBoolean();
-        fuzzyQueryBuilder.rewrite = in.readOptionalString();
-        return fuzzyQueryBuilder;
-    }
-
-    @Override
-    public void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(this.fieldName);
-        out.writeGenericValue(this.value);
-        this.fuzziness.writeTo(out);
-        out.writeVInt(this.prefixLength);
-        out.writeVInt(this.maxExpansions);
-        out.writeBoolean(this.transpositions);
-        out.writeOptionalString(this.rewrite);
-    }
-
-    @Override
-    public int doHashCode() {
-        return Objects.hash(fieldName, value, fuzziness, prefixLength, maxExpansions, transpositions, rewrite);
-    }
-
-    @Override
-    public boolean doEquals(FuzzyQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-                Objects.equals(value, other.value) &&
-                Objects.equals(fuzziness, other.fuzziness) &&
-                Objects.equals(prefixLength, other.prefixLength) &&
-                Objects.equals(maxExpansions, other.maxExpansions) &&
-                Objects.equals(transpositions, other.transpositions) &&
-                Objects.equals(rewrite, other.rewrite);
+        builder.endObject();
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryParser.java
index 694a303..aefdb4c 100644
--- a/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryParser.java
@@ -19,48 +19,60 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.FuzzyQuery;
+import org.apache.lucene.search.MultiTermQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.unit.Fuzziness;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
 
-public class FuzzyQueryParser extends BaseQueryParser {
+/**
+ *
+ */
+public class FuzzyQueryParser implements QueryParser {
 
+    public static final String NAME = "fuzzy";
+    private static final Fuzziness DEFAULT_FUZZINESS = Fuzziness.AUTO;
     private static final ParseField FUZZINESS = Fuzziness.FIELD.withDeprecation("min_similarity");
 
+
     @Inject
     public FuzzyQueryParser() {
     }
 
     @Override
     public String[] names() {
-        return new String[]{ FuzzyQueryBuilder.NAME };
+        return new String[]{NAME};
     }
 
     @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         XContentParser.Token token = parser.nextToken();
         if (token != XContentParser.Token.FIELD_NAME) {
             throw new QueryParsingException(parseContext, "[fuzzy] query malformed, no field");
         }
-        
         String fieldName = parser.currentName();
-        Object value = null;
-
-        Fuzziness fuzziness = FuzzyQueryBuilder.DEFAULT_FUZZINESS;
-        int prefixLength = FuzzyQueryBuilder.DEFAULT_PREFIX_LENGTH;
-        int maxExpansions = FuzzyQueryBuilder.DEFAULT_MAX_EXPANSIONS;
-        boolean transpositions = FuzzyQueryBuilder.DEFAULT_TRANSPOSITIONS;
-        String rewrite = null;
 
+        Object value = null;
+        float boost = 1.0f;
+        Fuzziness fuzziness = DEFAULT_FUZZINESS;
+        int prefixLength = FuzzyQuery.defaultPrefixLength;
+        int maxExpansions = FuzzyQuery.defaultMaxExpansions;
+        boolean transpositions = FuzzyQuery.defaultTranspositions;
         String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-
+        MultiTermQuery.RewriteMethod rewriteMethod = null;
+        if (parseContext.isFilter()) {
+            rewriteMethod = MultiTermQuery.CONSTANT_SCORE_REWRITE;
+        }
         token = parser.nextToken();
         if (token == XContentParser.Token.START_OBJECT) {
             String currentFieldName = null;
@@ -81,9 +93,9 @@ public class FuzzyQueryParser extends BaseQueryParser {
                     } else if ("max_expansions".equals(currentFieldName) || "maxExpansions".equals(currentFieldName)) {
                         maxExpansions = parser.intValue();
                     } else if ("transpositions".equals(currentFieldName)) {
-                        transpositions = parser.booleanValue();
+                      transpositions = parser.booleanValue();
                     } else if ("rewrite".equals(currentFieldName)) {
-                        rewrite = parser.textOrNull();
+                        rewriteMethod = QueryParsers.parseRewriteMethod(parseContext.parseFieldMatcher(), parser.textOrNull(), null);
                     } else if ("_name".equals(currentFieldName)) {
                         queryName = parser.text();
                     } else {
@@ -99,20 +111,26 @@ public class FuzzyQueryParser extends BaseQueryParser {
         }
 
         if (value == null) {
-            throw new QueryParsingException(parseContext, "no value specified for fuzzy query");
+            throw new QueryParsingException(parseContext, "No value specified for fuzzy query");
         }
-        return new FuzzyQueryBuilder(fieldName, value)
-                .fuzziness(fuzziness)
-                .prefixLength(prefixLength)
-                .maxExpansions(maxExpansions)
-                .transpositions(transpositions)
-                .rewrite(rewrite)
-                .boost(boost)
-                .queryName(queryName);
-    }
+        
+        Query query = null;
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            query = fieldType.fuzzyQuery(value, fuzziness, prefixLength, maxExpansions, transpositions);
+        }
+        if (query == null) {
+            int maxEdits = fuzziness.asDistance(BytesRefs.toString(value));
+            query = new FuzzyQuery(new Term(fieldName, BytesRefs.toBytesRef(value)), maxEdits, prefixLength, maxExpansions, transpositions);
+        }
+        if (query instanceof MultiTermQuery) {
+            QueryParsers.setRewriteMethod((MultiTermQuery) query, rewriteMethod);
+        }
+        query.setBoost(boost);
 
-    @Override
-    public FuzzyQueryBuilder getBuilderPrototype() {
-        return FuzzyQueryBuilder.PROTOTYPE;
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryBuilder.java
index 594cc6e..99b348e 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryBuilder.java
@@ -25,9 +25,7 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 
-public class GeoBoundingBoxQueryBuilder extends AbstractQueryBuilder<GeoBoundingBoxQueryBuilder> {
-
-    public static final String NAME = "geo_bbox";
+public class GeoBoundingBoxQueryBuilder extends QueryBuilder {
 
     public static final String TOP_LEFT = GeoBoundingBoxQueryParser.TOP_LEFT;
     public static final String BOTTOM_RIGHT = GeoBoundingBoxQueryParser.BOTTOM_RIGHT;
@@ -36,17 +34,16 @@ public class GeoBoundingBoxQueryBuilder extends AbstractQueryBuilder<GeoBounding
     private static final int LEFT = 1;
     private static final int BOTTOM = 2;
     private static final int RIGHT = 3;
-
+    
     private final String name;
 
     private double[] box = {Double.NaN, Double.NaN, Double.NaN, Double.NaN};
 
+    private String queryName;
     private String type;
     private Boolean coerce;
     private Boolean ignoreMalformed;
 
-    static final GeoBoundingBoxQueryBuilder PROTOTYPE = new GeoBoundingBoxQueryBuilder(null);
-
     public GeoBoundingBoxQueryBuilder(String name) {
         this.name = name;
     }
@@ -110,7 +107,7 @@ public class GeoBoundingBoxQueryBuilder extends AbstractQueryBuilder<GeoBounding
     public GeoBoundingBoxQueryBuilder bottomLeft(String geohash) {
         return bottomLeft(GeoHashUtils.decode(geohash));
     }
-
+    
     /**
      * Adds top right point.
      *
@@ -131,6 +128,14 @@ public class GeoBoundingBoxQueryBuilder extends AbstractQueryBuilder<GeoBounding
         return topRight(GeoHashUtils.decode(geohash));
     }
 
+    /**
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public GeoBoundingBoxQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
     public GeoBoundingBoxQueryBuilder coerce(boolean coerce) {
         this.coerce = coerce;
         return this;
@@ -162,14 +167,17 @@ public class GeoBoundingBoxQueryBuilder extends AbstractQueryBuilder<GeoBounding
         } else if(Double.isNaN(box[LEFT])) {
             throw new IllegalArgumentException("geo_bounding_box requires left longitude to be set");
         }
-
-        builder.startObject(NAME);
+                
+        builder.startObject(GeoBoundingBoxQueryParser.NAME);
 
         builder.startObject(name);
         builder.array(TOP_LEFT, box[LEFT], box[TOP]);
         builder.array(BOTTOM_RIGHT, box[RIGHT], box[BOTTOM]);
         builder.endObject();
 
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         if (type != null) {
             builder.field("type", type);
         }
@@ -180,13 +188,6 @@ public class GeoBoundingBoxQueryBuilder extends AbstractQueryBuilder<GeoBounding
             builder.field("ignore_malformed", ignoreMalformed);
         }
 
-        printBoostAndQueryName(builder);
-
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryParser.java
index 1476c2e..6dead6e 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryParser.java
@@ -37,7 +37,7 @@ import java.io.IOException;
 /**
  *
  */
-public class GeoBoundingBoxQueryParser extends BaseQueryParserTemp {
+public class GeoBoundingBoxQueryParser implements QueryParser {
 
     public static final String NAME = "geo_bbox";
 
@@ -64,12 +64,11 @@ public class GeoBoundingBoxQueryParser extends BaseQueryParserTemp {
 
     @Override
     public String[] names() {
-        return new String[]{GeoBoundingBoxQueryBuilder.NAME, "geoBbox", "geo_bounding_box", "geoBoundingBox"};
+        return new String[]{NAME, "geoBbox", "geo_bounding_box", "geoBoundingBox"};
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldName = null;
@@ -78,17 +77,16 @@ public class GeoBoundingBoxQueryParser extends BaseQueryParserTemp {
         double bottom = Double.NaN;
         double left = Double.NaN;
         double right = Double.NaN;
-
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        
         String queryName = null;
         String currentFieldName = null;
         XContentParser.Token token;
-        final boolean indexCreatedBeforeV2_0 = parseContext.shardContext().indexVersionCreated().before(Version.V_2_0_0);
+        final boolean indexCreatedBeforeV2_0 = parseContext.indexVersionCreated().before(Version.V_2_0_0);
         boolean coerce = false;
         boolean ignoreMalformed = false;
 
         GeoPoint sparse = new GeoPoint();
-
+        
         String type = "memory";
 
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -141,11 +139,9 @@ public class GeoBoundingBoxQueryParser extends BaseQueryParserTemp {
             } else if (token.isValue()) {
                 if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else if ("coerce".equals(currentFieldName) || (indexCreatedBeforeV2_0 && "normalize".equals(currentFieldName))) {
                     coerce = parser.booleanValue();
-                    if (coerce) {
+                    if (coerce == true) {
                         ignoreMalformed = true;
                     }
                 } else if ("type".equals(currentFieldName)) {
@@ -189,7 +185,7 @@ public class GeoBoundingBoxQueryParser extends BaseQueryParserTemp {
             }
         }
 
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
         if (fieldType == null) {
             throw new QueryParsingException(parseContext, "failed to parse [{}] query. could not find [{}] field [{}]", NAME, GeoPointFieldMapper.CONTENT_TYPE, fieldName);
         }
@@ -202,22 +198,15 @@ public class GeoBoundingBoxQueryParser extends BaseQueryParserTemp {
         if ("indexed".equals(type)) {
             filter = IndexedGeoBoundingBoxQuery.create(topLeft, bottomRight, geoFieldType);
         } else if ("memory".equals(type)) {
-            IndexGeoPointFieldData indexFieldData = context.getForField(fieldType);
+            IndexGeoPointFieldData indexFieldData = parseContext.getForField(fieldType);
             filter = new InMemoryGeoBoundingBoxQuery(topLeft, bottomRight, indexFieldData);
         } else {
             throw new QueryParsingException(parseContext, "failed to parse [{}] query. geo bounding box type [{}] is not supported. either [indexed] or [memory] are allowed", NAME, type);
         }
-        if (filter != null) {
-            filter.setBoost(boost);
-        }
+
         if (queryName != null) {
-            context.addNamedQuery(queryName, filter);
+            parseContext.addNamedQuery(queryName, filter);
         }
         return filter;
-    }
-
-    @Override
-    public GeoBoundingBoxQueryBuilder getBuilderPrototype() {
-        return GeoBoundingBoxQueryBuilder.PROTOTYPE;
-    }
+    }    
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryBuilder.java
index 6f883bd..77c8f94 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryBuilder.java
@@ -26,9 +26,7 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 import java.io.IOException;
 import java.util.Locale;
 
-public class GeoDistanceQueryBuilder extends AbstractQueryBuilder<GeoDistanceQueryBuilder> {
-
-    public static final String NAME = "geo_distance";
+public class GeoDistanceQueryBuilder extends QueryBuilder {
 
     private final String name;
 
@@ -44,7 +42,7 @@ public class GeoDistanceQueryBuilder extends AbstractQueryBuilder<GeoDistanceQue
 
     private String optimizeBbox;
 
-    static final GeoDistanceQueryBuilder PROTOTYPE = new GeoDistanceQueryBuilder(null);
+    private String queryName;
 
     private Boolean coerce;
 
@@ -95,6 +93,14 @@ public class GeoDistanceQueryBuilder extends AbstractQueryBuilder<GeoDistanceQue
         return this;
     }
 
+    /**
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public GeoDistanceQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
     public GeoDistanceQueryBuilder coerce(boolean coerce) {
         this.coerce = coerce;
         return this;
@@ -107,7 +113,7 @@ public class GeoDistanceQueryBuilder extends AbstractQueryBuilder<GeoDistanceQue
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(GeoDistanceQueryParser.NAME);
         if (geohash != null) {
             builder.field(name, geohash);
         } else {
@@ -120,18 +126,15 @@ public class GeoDistanceQueryBuilder extends AbstractQueryBuilder<GeoDistanceQue
         if (optimizeBbox != null) {
             builder.field("optimize_bbox", optimizeBbox);
         }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         if (coerce != null) {
             builder.field("coerce", coerce);
         }
         if (ignoreMalformed != null) {
             builder.field("ignore_malformed", ignoreMalformed);
         }
-        printBoostAndQueryName(builder);
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryParser.java
index 647e1d0..8201381 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryParser.java
@@ -43,7 +43,9 @@ import java.io.IOException;
  * }
  * </pre>
  */
-public class GeoDistanceQueryParser extends BaseQueryParserTemp {
+public class GeoDistanceQueryParser implements QueryParser {
+
+    public static final String NAME = "geo_distance";
 
     @Inject
     public GeoDistanceQueryParser() {
@@ -51,17 +53,15 @@ public class GeoDistanceQueryParser extends BaseQueryParserTemp {
 
     @Override
     public String[] names() {
-        return new String[]{GeoDistanceQueryBuilder.NAME, "geoDistance"};
+        return new String[]{NAME, "geoDistance"};
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         XContentParser.Token token;
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
         String queryName = null;
         String currentFieldName = null;
         GeoPoint point = new GeoPoint();
@@ -71,7 +71,7 @@ public class GeoDistanceQueryParser extends BaseQueryParserTemp {
         DistanceUnit unit = DistanceUnit.DEFAULT;
         GeoDistance geoDistance = GeoDistance.DEFAULT;
         String optimizeBbox = "memory";
-        final boolean indexCreatedBeforeV2_0 = parseContext.shardContext().indexVersionCreated().before(Version.V_2_0_0);
+        final boolean indexCreatedBeforeV2_0 = parseContext.indexVersionCreated().before(Version.V_2_0_0);
         boolean coerce = false;
         boolean ignoreMalformed = false;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -124,8 +124,6 @@ public class GeoDistanceQueryParser extends BaseQueryParserTemp {
                     fieldName = currentFieldName.substring(0, currentFieldName.length() - GeoPointFieldMapper.Names.GEOHASH_SUFFIX.length());
                 } else if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else if ("optimize_bbox".equals(currentFieldName) || "optimizeBbox".equals(currentFieldName)) {
                     optimizeBbox = parser.textOrNull();
                 } else if ("coerce".equals(currentFieldName) || (indexCreatedBeforeV2_0 && "normalize".equals(currentFieldName))) {
@@ -145,10 +143,10 @@ public class GeoDistanceQueryParser extends BaseQueryParserTemp {
         // validation was not available prior to 2.x, so to support bwc percolation queries we only ignore_malformed on 2.x created indexes
         if (!indexCreatedBeforeV2_0 && !ignoreMalformed) {
             if (point.lat() > 90.0 || point.lat() < -90.0) {
-                throw new QueryParsingException(parseContext, "illegal latitude value [{}] for [{}]", point.lat(), GeoDistanceQueryBuilder.NAME);
+                throw new QueryParsingException(parseContext, "illegal latitude value [{}] for [{}]", point.lat(), NAME);
             }
             if (point.lon() > 180.0 || point.lon() < -180) {
-                throw new QueryParsingException(parseContext, "illegal longitude value [{}] for [{}]", point.lon(), GeoDistanceQueryBuilder.NAME);
+                throw new QueryParsingException(parseContext, "illegal longitude value [{}] for [{}]", point.lon(), NAME);
             }
         }
 
@@ -165,7 +163,7 @@ public class GeoDistanceQueryParser extends BaseQueryParserTemp {
         }
         distance = geoDistance.normalize(distance, DistanceUnit.DEFAULT);
 
-        MappedFieldType fieldType = parseContext.shardContext().fieldMapper(fieldName);
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
         if (fieldType == null) {
             throw new QueryParsingException(parseContext, "failed to find geo_point field [" + fieldName + "]");
         }
@@ -175,17 +173,11 @@ public class GeoDistanceQueryParser extends BaseQueryParserTemp {
         GeoPointFieldMapper.GeoPointFieldType geoFieldType = ((GeoPointFieldMapper.GeoPointFieldType) fieldType);
 
 
-        IndexGeoPointFieldData indexFieldData = context.getForField(fieldType);
+        IndexGeoPointFieldData indexFieldData = parseContext.getForField(fieldType);
         Query query = new GeoDistanceRangeQuery(point, null, distance, true, false, geoDistance, geoFieldType, indexFieldData, optimizeBbox);
         if (queryName != null) {
-            context.addNamedQuery(queryName, query);
+            parseContext.addNamedQuery(queryName, query);
         }
-        query.setBoost(boost);
         return query;
     }
-
-    @Override
-    public GeoDistanceQueryBuilder getBuilderPrototype() {
-        return GeoDistanceQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryBuilder.java
index 2f69dfa..6aa6f0f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryBuilder.java
@@ -19,76 +19,55 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.elasticsearch.Version;
 import org.elasticsearch.common.geo.GeoDistance;
-import org.elasticsearch.common.geo.GeoPoint;
-import org.elasticsearch.common.geo.GeoUtils;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.unit.DistanceUnit;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.fielddata.IndexGeoPointFieldData;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.mapper.geo.GeoPointFieldMapper;
-import org.elasticsearch.index.search.geo.GeoDistanceRangeQuery;
 
 import java.io.IOException;
 import java.util.Locale;
-import java.util.Objects;
 
-public class GeoDistanceRangeQueryBuilder extends AbstractQueryBuilder<GeoDistanceRangeQueryBuilder> {
+public class GeoDistanceRangeQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "geo_distance_range";
-    public static final boolean DEFAULT_INCLUDE_LOWER = true;
-    public static final boolean DEFAULT_INCLUDE_UPPER = true;
-    public static final GeoDistance DEFAULT_GEO_DISTANCE = GeoDistance.DEFAULT;
-    public static final DistanceUnit DEFAULT_UNIT = DistanceUnit.DEFAULT;
-    public static final String DEFAULT_OPTIMIZE_BBOX = "memory";
-    public static final boolean DEFAULT_COERCE = false;
-    public static final boolean DEFAULT_IGNORE_MALFORMED = false;
-
-    private final String fieldName;
+    private final String name;
 
     private Object from;
     private Object to;
-    private boolean includeLower = DEFAULT_INCLUDE_LOWER;
-    private boolean includeUpper = DEFAULT_INCLUDE_UPPER;
+    private boolean includeLower = true;
+    private boolean includeUpper = true;
 
-    private GeoPoint point;
+    private double lat;
 
-    private GeoDistance geoDistance = DEFAULT_GEO_DISTANCE;
+    private double lon;
 
-    private DistanceUnit unit = DEFAULT_UNIT;
+    private String geohash;
 
-    private String optimizeBbox = DEFAULT_OPTIMIZE_BBOX;
+    private GeoDistance geoDistance;
 
-    private boolean coerce = DEFAULT_COERCE;
+    private String queryName;
 
-    private boolean ignoreMalformed = DEFAULT_IGNORE_MALFORMED;
+    private String optimizeBbox;
 
-    static final GeoDistanceRangeQueryBuilder PROTOTYPE = new GeoDistanceRangeQueryBuilder(null);
+    private Boolean coerce;
 
-    public GeoDistanceRangeQueryBuilder(String fieldName) {
-        this.fieldName = fieldName;
-    }
+    private Boolean ignoreMalformed;
 
-    public String fieldName() {
-        return fieldName;
+    public GeoDistanceRangeQueryBuilder(String name) {
+        this.name = name;
     }
 
     public GeoDistanceRangeQueryBuilder point(double lat, double lon) {
-        this.point = new GeoPoint(lat, lon);
+        this.lat = lat;
+        this.lon = lon;
         return this;
     }
 
-    public GeoDistanceRangeQueryBuilder point(GeoPoint point) {
-        this.point = point;
+    public GeoDistanceRangeQueryBuilder lat(double lat) {
+        this.lat = lat;
         return this;
     }
 
-    public GeoPoint point() {
-        return point;
+    public GeoDistanceRangeQueryBuilder lon(double lon) {
+        this.lon = lon;
+        return this;
     }
 
     public GeoDistanceRangeQueryBuilder from(Object from) {
@@ -96,19 +75,11 @@ public class GeoDistanceRangeQueryBuilder extends AbstractQueryBuilder<GeoDistan
         return this;
     }
 
-    public Object from() {
-        return from;
-    }
-
     public GeoDistanceRangeQueryBuilder to(Object to) {
         this.to = to;
         return this;
     }
 
-    public Object to() {
-        return to;
-    }
-
     public GeoDistanceRangeQueryBuilder gt(Object from) {
         this.from = from;
         this.includeLower = false;
@@ -138,21 +109,13 @@ public class GeoDistanceRangeQueryBuilder extends AbstractQueryBuilder<GeoDistan
         return this;
     }
 
-    public boolean includeLower() {
-        return includeLower;
-    }
-
     public GeoDistanceRangeQueryBuilder includeUpper(boolean includeUpper) {
         this.includeUpper = includeUpper;
         return this;
     }
 
-    public boolean includeUpper() {
-        return includeUpper;
-    }
-
     public GeoDistanceRangeQueryBuilder geohash(String geohash) {
-        this.point = new GeoPoint().resetFromGeoHash(geohash);
+        this.geohash = geohash;
         return this;
     }
 
@@ -161,235 +124,56 @@ public class GeoDistanceRangeQueryBuilder extends AbstractQueryBuilder<GeoDistan
         return this;
     }
 
-    public GeoDistance geoDistance() {
-        return geoDistance;
-    }
-
-    public GeoDistanceRangeQueryBuilder unit(DistanceUnit unit) {
-        this.unit = unit;
-        return this;
-    }
-
-    public DistanceUnit unit() {
-        return unit;
-    }
-
     public GeoDistanceRangeQueryBuilder optimizeBbox(String optimizeBbox) {
         this.optimizeBbox = optimizeBbox;
         return this;
     }
 
-    public String optimizeBbox() {
-        return optimizeBbox;
-    }
-
     public GeoDistanceRangeQueryBuilder coerce(boolean coerce) {
-        if (coerce) {
-            this.ignoreMalformed = true;
-        }
         this.coerce = coerce;
         return this;
     }
 
-    public boolean coerce() {
-        return this.coerce;
-    }
-
     public GeoDistanceRangeQueryBuilder ignoreMalformed(boolean ignoreMalformed) {
-        if (coerce == false) {
-            this.ignoreMalformed = ignoreMalformed;
-        }
+        this.ignoreMalformed = ignoreMalformed;
         return this;
     }
 
-    public boolean ignoreMalformed() {
-        return ignoreMalformed;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException errors = null;
-        if (fieldName == null) {
-            errors = QueryValidationException.addValidationError(NAME, "fieldName must not be null", errors);
-        }
-        if (point == null) {
-            errors = QueryValidationException.addValidationError(NAME, "point must not be null", errors);
-        }
-        if (from == null && to == null) {
-            errors = QueryValidationException.addValidationError(NAME, "Must define at least one parameter from [from, to]", errors);
-        }
-        if (from != null && !(from instanceof Number || from instanceof String)) {
-            errors = QueryValidationException.addValidationError(NAME, "from must either be a number or a string. Found ["
-                    + from.getClass().getName() + "]", errors);
-        }
-        if (to != null && !(to instanceof Number || to instanceof String)) {
-            errors = QueryValidationException.addValidationError(NAME, "to must either be a number or a string. Found ["
-                    + to.getClass().getName() + "]", errors);
-        }
-        if (optimizeBbox != null && !(optimizeBbox.equals("none") || optimizeBbox.equals("memory") || optimizeBbox.equals("indexed"))) {
-            errors = QueryValidationException.addValidationError(NAME, "optimizeBbox must be one of [none, memory, indexed]", errors);
-        }
-        return errors;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-
-        final boolean indexCreatedBeforeV2_0 = context.indexVersionCreated().before(Version.V_2_0_0);
-        // validation was not available prior to 2.x, so to support bwc
-        // percolation queries we only ignore_malformed on 2.x created indexes
-        if (!indexCreatedBeforeV2_0 && !ignoreMalformed) {
-            if (point.lat() > 90.0 || point.lat() < -90.0) {
-                throw new QueryShardException(context, "illegal latitude value [{}] for [{}]", point.lat(), NAME);
-            }
-            if (point.lon() > 180.0 || point.lon() < -180) {
-                throw new QueryShardException(context, "illegal longitude value [{}] for [{}]", point.lon(), NAME);
-            }
-        }
-
-        if (coerce) {
-            GeoUtils.normalizePoint(point, coerce, coerce);
-        }
-
-        Double fromValue = null;
-        Double toValue = null;
-        if (from != null) {
-            if (from instanceof Number) {
-                fromValue = unit.toMeters(((Number) from).doubleValue());
-            } else {
-                fromValue = DistanceUnit.parse((String) from, unit, DistanceUnit.DEFAULT);
-            }
-            fromValue = geoDistance.normalize(fromValue, DistanceUnit.DEFAULT);
-        }
-        if (to != null) {
-            if (to instanceof Number) {
-                toValue = unit.toMeters(((Number) to).doubleValue());
-            } else {
-                toValue = DistanceUnit.parse((String) to, unit, DistanceUnit.DEFAULT);
-            }
-            toValue = geoDistance.normalize(toValue, DistanceUnit.DEFAULT);
-        }
-
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType == null) {
-            throw new QueryShardException(context, "failed to find geo_point field [" + fieldName + "]");
-        }
-        if (!(fieldType instanceof GeoPointFieldMapper.GeoPointFieldType)) {
-            throw new QueryShardException(context, "field [" + fieldName + "] is not a geo_point field");
-        }
-        GeoPointFieldMapper.GeoPointFieldType geoFieldType = ((GeoPointFieldMapper.GeoPointFieldType) fieldType);
-
-        IndexGeoPointFieldData indexFieldData = context.getForField(fieldType);
-        return new GeoDistanceRangeQuery(point, fromValue, toValue, includeLower, includeUpper, geoDistance, geoFieldType,
-                indexFieldData, optimizeBbox);
+    /**
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public GeoDistanceRangeQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.startArray(fieldName).value(point.lon()).value(point.lat()).endArray();
-        builder.field(GeoDistanceRangeQueryParser.FROM_FIELD.getPreferredName(), from);
-        builder.field(GeoDistanceRangeQueryParser.TO_FIELD.getPreferredName(), to);
-        builder.field(GeoDistanceRangeQueryParser.INCLUDE_LOWER_FIELD.getPreferredName(), includeLower);
-        builder.field(GeoDistanceRangeQueryParser.INCLUDE_UPPER_FIELD.getPreferredName(), includeUpper);
-        if (unit != null) {
-            builder.field(GeoDistanceRangeQueryParser.UNIT_FIELD.getPreferredName(), unit);
-        }
+        builder.startObject(GeoDistanceRangeQueryParser.NAME);
+        if (geohash != null) {
+            builder.field(name, geohash);
+        } else {
+            builder.startArray(name).value(lon).value(lat).endArray();
+        }
+        builder.field("from", from);
+        builder.field("to", to);
+        builder.field("include_lower", includeLower);
+        builder.field("include_upper", includeUpper);
         if (geoDistance != null) {
-            builder.field(GeoDistanceRangeQueryParser.DISTANCE_TYPE_FIELD.getPreferredName(), geoDistance.name().toLowerCase(Locale.ROOT));
+            builder.field("distance_type", geoDistance.name().toLowerCase(Locale.ROOT));
         }
         if (optimizeBbox != null) {
-            builder.field(GeoDistanceRangeQueryParser.OPTIMIZE_BBOX_FIELD.getPreferredName(), optimizeBbox);
+            builder.field("optimize_bbox", optimizeBbox);
         }
-        builder.field(GeoDistanceRangeQueryParser.COERCE_FIELD.getPreferredName(), coerce);
-        builder.field(GeoDistanceRangeQueryParser.IGNORE_MALFORMED_FIELD.getPreferredName(), ignoreMalformed);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected GeoDistanceRangeQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        GeoDistanceRangeQueryBuilder queryBuilder = new GeoDistanceRangeQueryBuilder(in.readString());
-        double lat = in.readDouble();
-        double lon = in.readDouble();
-        queryBuilder.point = new GeoPoint(lat, lon);
-        queryBuilder.from = in.readGenericValue();
-        queryBuilder.to = in.readGenericValue();
-        queryBuilder.includeLower = in.readBoolean();
-        queryBuilder.includeUpper = in.readBoolean();
-        String unit = in.readOptionalString();
-        if (unit != null) {
-            queryBuilder.unit = DistanceUnit.valueOf(unit);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        String geoDistance = in.readOptionalString();
-        if (geoDistance != null) {
-            queryBuilder.geoDistance = GeoDistance.fromString(geoDistance);
+        if (coerce != null) {
+            builder.field("coerce", coerce);
         }
-        queryBuilder.optimizeBbox = in.readOptionalString();
-        queryBuilder.coerce = in.readBoolean();
-        queryBuilder.ignoreMalformed = in.readBoolean();
-        return queryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-        out.writeDouble(point.lat());
-        out.writeDouble(point.lon());
-        out.writeGenericValue(from);
-        out.writeGenericValue(to);
-        out.writeBoolean(includeLower);
-        out.writeBoolean(includeUpper);
-        out.writeOptionalString(unit.name());
-        out.writeOptionalString(geoDistance.name());
-        out.writeOptionalString(optimizeBbox);
-        out.writeBoolean(coerce);
-        out.writeBoolean(ignoreMalformed);
-    }
-
-    @Override
-    protected boolean doEquals(GeoDistanceRangeQueryBuilder other) {
-        if (!Objects.equals(fieldName, other.fieldName)) {
-            return false;
-        }
-        if (!Objects.equals(point, other.point)) {
-            return false;
-        }
-        if (!Objects.equals(from, other.from)) {
-            return false;
-        }
-        if (!Objects.equals(to, other.to)) {
-            return false;
-        }
-        if (!Objects.equals(includeUpper, other.includeUpper)) {
-            return false;
-        }
-        if (!Objects.equals(includeLower, other.includeLower)) {
-            return false;
-        }
-        if (!Objects.equals(geoDistance, other.geoDistance)) {
-            return false;
-        }
-        if (!Objects.equals(optimizeBbox, other.optimizeBbox)) {
-            return false;
+        if (ignoreMalformed != null) {
+            builder.field("ignore_malformed", ignoreMalformed);
         }
-        if (!Objects.equals(coerce, other.coerce)) {
-            return false;
-        }
-        if (!Objects.equals(ignoreMalformed, other.ignoreMalformed)) {
-            return false;
-        }
-        return true;
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldName, point, from, to, includeUpper, includeLower, geoDistance, optimizeBbox, coerce,
-                ignoreMalformed);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryParser.java
index 7f16aea..f60d944 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryParser.java
@@ -19,14 +19,19 @@
 
 package org.elasticsearch.index.query;
 
-import org.elasticsearch.common.ParseField;
+import org.apache.lucene.search.Query;
+import org.elasticsearch.Version;
 import org.elasticsearch.common.geo.GeoDistance;
+import org.elasticsearch.common.geo.GeoHashUtils;
 import org.elasticsearch.common.geo.GeoPoint;
 import org.elasticsearch.common.geo.GeoUtils;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.unit.DistanceUnit;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.fielddata.IndexGeoPointFieldData;
+import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.geo.GeoPointFieldMapper;
+import org.elasticsearch.index.search.geo.GeoDistanceRangeQuery;
 
 import java.io.IOException;
 
@@ -38,23 +43,9 @@ import java.io.IOException;
  * }
  * </pre>
  */
-public class GeoDistanceRangeQueryParser extends BaseQueryParser<GeoDistanceRangeQueryBuilder> {
+public class GeoDistanceRangeQueryParser implements QueryParser {
 
-    public static final ParseField FROM_FIELD = new ParseField("from");
-    public static final ParseField TO_FIELD = new ParseField("to");
-    public static final ParseField INCLUDE_LOWER_FIELD = new ParseField("include_lower");
-    public static final ParseField INCLUDE_UPPER_FIELD = new ParseField("include_upper");
-    public static final ParseField GT_FIELD = new ParseField("gt");
-    public static final ParseField GTE_FIELD = new ParseField("gte", "ge");
-    public static final ParseField LT_FIELD = new ParseField("lt");
-    public static final ParseField LTE_FIELD = new ParseField("lte", "le");
-    public static final ParseField UNIT_FIELD = new ParseField("unit");
-    public static final ParseField DISTANCE_TYPE_FIELD = new ParseField("distance_type");
-    public static final ParseField NAME_FIELD = new ParseField("_name");
-    public static final ParseField BOOST_FIELD = new ParseField("boost");
-    public static final ParseField OPTIMIZE_BBOX_FIELD = new ParseField("optimize_bbox");
-    public static final ParseField COERCE_FIELD = new ParseField("coerce", "normalize");
-    public static final ParseField IGNORE_MALFORMED_FIELD = new ParseField("ignore_malformed");
+    public static final String NAME = "geo_distance_range";
 
     @Inject
     public GeoDistanceRangeQueryParser() {
@@ -62,73 +53,61 @@ public class GeoDistanceRangeQueryParser extends BaseQueryParser<GeoDistanceRang
 
     @Override
     public String[] names() {
-        return new String[]{GeoDistanceRangeQueryBuilder.NAME, "geoDistanceRange"};
+        return new String[]{NAME, "geoDistanceRange"};
     }
 
     @Override
-    public GeoDistanceRangeQueryBuilder getBuilderPrototype() {
-        return GeoDistanceRangeQueryBuilder.PROTOTYPE;
-    }
-
-    @Override
-    public GeoDistanceRangeQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         XContentParser.Token token;
 
-        Float boost = null;
         String queryName = null;
         String currentFieldName = null;
-        GeoPoint point = null;
-        String geohash = null;
+        GeoPoint point = new GeoPoint();
         String fieldName = null;
         Object vFrom = null;
         Object vTo = null;
-        Boolean includeLower = null;
-        Boolean includeUpper = null;
-        DistanceUnit unit = null;
-        GeoDistance geoDistance = null;
-        String optimizeBbox = null;
-        Boolean coerce = null;
-        Boolean ignoreMalformed = null;
+        boolean includeLower = true;
+        boolean includeUpper = true;
+        DistanceUnit unit = DistanceUnit.DEFAULT;
+        GeoDistance geoDistance = GeoDistance.DEFAULT;
+        String optimizeBbox = "memory";
+        final boolean indexCreatedBeforeV2_0 = parseContext.indexVersionCreated().before(Version.V_2_0_0);
+        boolean coerce = false;
+        boolean ignoreMalformed = false;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
             } else if (parseContext.isDeprecatedSetting(currentFieldName)) {
                 // skip
             } else if (token == XContentParser.Token.START_ARRAY) {
-                if (point == null) {
-                    point = new GeoPoint();
-                }
                 GeoUtils.parseGeoPoint(parser, point);
                 fieldName = currentFieldName;
             } else if (token == XContentParser.Token.START_OBJECT) {
                 // the json in the format of -> field : { lat : 30, lon : 12 }
                 fieldName = currentFieldName;
-                if (point == null) {
-                    point = new GeoPoint();
-                }
                 GeoUtils.parseGeoPoint(parser, point);
             } else if (token.isValue()) {
-                if (parseContext.parseFieldMatcher().match(currentFieldName, FROM_FIELD)) {
+                if (currentFieldName.equals("from")) {
                     if (token == XContentParser.Token.VALUE_NULL) {
                     } else if (token == XContentParser.Token.VALUE_STRING) {
                         vFrom = parser.text(); // a String
                     } else {
                         vFrom = parser.numberValue(); // a Number
                     }
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, TO_FIELD)) {
+                } else if (currentFieldName.equals("to")) {
                     if (token == XContentParser.Token.VALUE_NULL) {
                     } else if (token == XContentParser.Token.VALUE_STRING) {
                         vTo = parser.text(); // a String
                     } else {
                         vTo = parser.numberValue(); // a Number
                     }
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, INCLUDE_LOWER_FIELD)) {
+                } else if ("include_lower".equals(currentFieldName) || "includeLower".equals(currentFieldName)) {
                     includeLower = parser.booleanValue();
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, INCLUDE_UPPER_FIELD)) {
+                } else if ("include_upper".equals(currentFieldName) || "includeUpper".equals(currentFieldName)) {
                     includeUpper = parser.booleanValue();
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, GT_FIELD)) {
+                } else if ("gt".equals(currentFieldName)) {
                     if (token == XContentParser.Token.VALUE_NULL) {
                     } else if (token == XContentParser.Token.VALUE_STRING) {
                         vFrom = parser.text(); // a String
@@ -136,7 +115,7 @@ public class GeoDistanceRangeQueryParser extends BaseQueryParser<GeoDistanceRang
                         vFrom = parser.numberValue(); // a Number
                     }
                     includeLower = false;
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, GTE_FIELD)) {
+                } else if ("gte".equals(currentFieldName) || "ge".equals(currentFieldName)) {
                     if (token == XContentParser.Token.VALUE_NULL) {
                     } else if (token == XContentParser.Token.VALUE_STRING) {
                         vFrom = parser.text(); // a String
@@ -144,7 +123,7 @@ public class GeoDistanceRangeQueryParser extends BaseQueryParser<GeoDistanceRang
                         vFrom = parser.numberValue(); // a Number
                     }
                     includeLower = true;
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, LT_FIELD)) {
+                } else if ("lt".equals(currentFieldName)) {
                     if (token == XContentParser.Token.VALUE_NULL) {
                     } else if (token == XContentParser.Token.VALUE_STRING) {
                         vTo = parser.text(); // a String
@@ -152,7 +131,7 @@ public class GeoDistanceRangeQueryParser extends BaseQueryParser<GeoDistanceRang
                         vTo = parser.numberValue(); // a Number
                     }
                     includeUpper = false;
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, LTE_FIELD)) {
+                } else if ("lte".equals(currentFieldName) || "le".equals(currentFieldName)) {
                     if (token == XContentParser.Token.VALUE_NULL) {
                     } else if (token == XContentParser.Token.VALUE_STRING) {
                         vTo = parser.text(); // a String
@@ -160,98 +139,84 @@ public class GeoDistanceRangeQueryParser extends BaseQueryParser<GeoDistanceRang
                         vTo = parser.numberValue(); // a Number
                     }
                     includeUpper = true;
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, UNIT_FIELD)) {
+                } else if (currentFieldName.equals("unit")) {
                     unit = DistanceUnit.fromString(parser.text());
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, DISTANCE_TYPE_FIELD)) {
+                } else if (currentFieldName.equals("distance_type") || currentFieldName.equals("distanceType")) {
                     geoDistance = GeoDistance.fromString(parser.text());
                 } else if (currentFieldName.endsWith(GeoPointFieldMapper.Names.LAT_SUFFIX)) {
-                    if (point == null) {
-                        point = new GeoPoint();
-                    }
                     point.resetLat(parser.doubleValue());
                     fieldName = currentFieldName.substring(0, currentFieldName.length() - GeoPointFieldMapper.Names.LAT_SUFFIX.length());
                 } else if (currentFieldName.endsWith(GeoPointFieldMapper.Names.LON_SUFFIX)) {
-                    if (point == null) {
-                        point = new GeoPoint();
-                    }
                     point.resetLon(parser.doubleValue());
                     fieldName = currentFieldName.substring(0, currentFieldName.length() - GeoPointFieldMapper.Names.LON_SUFFIX.length());
                 } else if (currentFieldName.endsWith(GeoPointFieldMapper.Names.GEOHASH_SUFFIX)) {
-                    geohash = parser.text();
+                    GeoHashUtils.decode(parser.text(), point);
                     fieldName = currentFieldName.substring(0, currentFieldName.length() - GeoPointFieldMapper.Names.GEOHASH_SUFFIX.length());
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, NAME_FIELD)) {
+                } else if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, BOOST_FIELD)) {
-                    boost = parser.floatValue();
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, OPTIMIZE_BBOX_FIELD)) {
+                } else if ("optimize_bbox".equals(currentFieldName) || "optimizeBbox".equals(currentFieldName)) {
                     optimizeBbox = parser.textOrNull();
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, COERCE_FIELD)) {
+                } else if ("coerce".equals(currentFieldName) || (indexCreatedBeforeV2_0 && "normalize".equals(currentFieldName))) {
                     coerce = parser.booleanValue();
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, IGNORE_MALFORMED_FIELD)) {
+                    if (coerce == true) {
+                        ignoreMalformed = true;
+                    }
+                } else if ("ignore_malformed".equals(currentFieldName) && coerce == false) {
                     ignoreMalformed = parser.booleanValue();
                 } else {
-                    if (point == null) {
-                        point = new GeoPoint();
-                    }
                     point.resetFromString(parser.text());
                     fieldName = currentFieldName;
                 }
             }
         }
 
-        GeoDistanceRangeQueryBuilder queryBuilder = new GeoDistanceRangeQueryBuilder(fieldName);
-
-        if (boost != null) {
-            queryBuilder.boost(boost);
-        }
-
-        if (queryName != null) {
-            queryBuilder.queryName(queryName);
-        }
-
-        if (point != null) {
-            queryBuilder.point(point.lat(), point.lon());
+        // validation was not available prior to 2.x, so to support bwc percolation queries we only ignore_malformed on 2.x created indexes
+        if (!indexCreatedBeforeV2_0 && !ignoreMalformed) {
+            if (point.lat() > 90.0 || point.lat() < -90.0) {
+                throw new QueryParsingException(parseContext, "illegal latitude value [{}] for [{}]", point.lat(), NAME);
+            }
+            if (point.lon() > 180.0 || point.lon() < -180) {
+                throw new QueryParsingException(parseContext, "illegal longitude value [{}] for [{}]", point.lon(), NAME);
+            }
         }
 
-        if (geohash != null) {
-            queryBuilder.geohash(geohash);
+        if (coerce) {
+            GeoUtils.normalizePoint(point, coerce, coerce);
         }
 
+        Double from = null;
+        Double to = null;
         if (vFrom != null) {
-            queryBuilder.from(vFrom);
+            if (vFrom instanceof Number) {
+                from = unit.toMeters(((Number) vFrom).doubleValue());
+            } else {
+                from = DistanceUnit.parse((String) vFrom, unit, DistanceUnit.DEFAULT);
+            }
+            from = geoDistance.normalize(from, DistanceUnit.DEFAULT);
         }
-
         if (vTo != null) {
-            queryBuilder.to(vTo);
-        }
-
-        if (includeUpper != null) {
-            queryBuilder.includeUpper(includeUpper);
-        }
-
-        if (includeLower != null) {
-            queryBuilder.includeLower(includeLower);
-        }
-
-        if (unit != null) {
-            queryBuilder.unit(unit);
-        }
-
-        if (geoDistance != null) {
-            queryBuilder.geoDistance(geoDistance);
+            if (vTo instanceof Number) {
+                to = unit.toMeters(((Number) vTo).doubleValue());
+            } else {
+                to = DistanceUnit.parse((String) vTo, unit, DistanceUnit.DEFAULT);
+            }
+            to = geoDistance.normalize(to, DistanceUnit.DEFAULT);
         }
 
-        if (optimizeBbox != null) {
-            queryBuilder.optimizeBbox(optimizeBbox);
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType == null) {
+            throw new QueryParsingException(parseContext, "failed to find geo_point field [" + fieldName + "]");
         }
-
-        if (coerce != null) {
-            queryBuilder.coerce(coerce);
+        if (!(fieldType instanceof GeoPointFieldMapper.GeoPointFieldType)) {
+            throw new QueryParsingException(parseContext, "field [" + fieldName + "] is not a geo_point field");
         }
+        GeoPointFieldMapper.GeoPointFieldType geoFieldType = ((GeoPointFieldMapper.GeoPointFieldType) fieldType);
 
-        if (ignoreMalformed != null) {
-            queryBuilder.ignoreMalformed(ignoreMalformed);
+        IndexGeoPointFieldData indexFieldData = parseContext.getForField(fieldType);
+        Query query = new GeoDistanceRangeQuery(point, from, to, includeLower, includeUpper, geoDistance, geoFieldType, indexFieldData, optimizeBbox);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
         }
-        return queryBuilder;
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryBuilder.java
index 773731b..400384b 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryBuilder.java
@@ -19,55 +19,30 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.elasticsearch.Version;
 import org.elasticsearch.common.geo.GeoHashUtils;
 import org.elasticsearch.common.geo.GeoPoint;
-import org.elasticsearch.common.geo.GeoUtils;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.fielddata.IndexGeoPointFieldData;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.mapper.geo.GeoPointFieldMapper;
-import org.elasticsearch.index.search.geo.GeoPolygonQuery;
 
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Objects;
 
-public class GeoPolygonQueryBuilder extends AbstractQueryBuilder<GeoPolygonQueryBuilder> {
+public class GeoPolygonQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "geo_polygon";
+    public static final String POINTS = GeoPolygonQueryParser.POINTS;
+    
+    private final String name;
 
-    static final GeoPolygonQueryBuilder PROTOTYPE = new GeoPolygonQueryBuilder("");
+    private final List<GeoPoint> shell = new ArrayList<>();
 
-    private final String fieldName;
+    private String queryName;
 
-    private final List<GeoPoint> shell;
+    private Boolean coerce;
 
-    private boolean coerce = false;
+    private Boolean ignoreMalformed;
 
-    private boolean ignoreMalformed = false;
-
-    public GeoPolygonQueryBuilder(String fieldName) {
-        this(fieldName, new ArrayList<>());
-    }
-
-    public GeoPolygonQueryBuilder(String fieldName, List<GeoPoint> points) {
-        if (fieldName == null) {
-            throw new IllegalArgumentException("fieldName must not be null");
-        }
-        if (points == null) {
-            throw new IllegalArgumentException("polygon must not be null");
-        }
-        this.fieldName = fieldName;
-        this.shell = points;
-    }
-
-    public String fieldName() {
-        return fieldName;
+    public GeoPolygonQueryBuilder(String name) {
+        this.name = name;
     }
 
     /**
@@ -75,7 +50,7 @@ public class GeoPolygonQueryBuilder extends AbstractQueryBuilder<GeoPolygonQuery
      *
      * @param lat The latitude
      * @param lon The longitude
-     * @return the current builder
+     * @return
      */
     public GeoPolygonQueryBuilder addPoint(double lat, double lon) {
         return addPoint(new GeoPoint(lat, lon));
@@ -89,158 +64,47 @@ public class GeoPolygonQueryBuilder extends AbstractQueryBuilder<GeoPolygonQuery
         shell.add(point);
         return this;
     }
-
-    public List<GeoPoint> points() {
-        return shell;
+    
+    /**
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public GeoPolygonQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     public GeoPolygonQueryBuilder coerce(boolean coerce) {
-        if (coerce) {
-            this.ignoreMalformed = true;
-        }
         this.coerce = coerce;
         return this;
     }
 
-    public boolean coerce() {
-        return this.coerce;
-    }
-
     public GeoPolygonQueryBuilder ignoreMalformed(boolean ignoreMalformed) {
-        if (coerce == false) {
-            this.ignoreMalformed = ignoreMalformed;
-        }
+        this.ignoreMalformed = ignoreMalformed;
         return this;
     }
 
-    public boolean ignoreMalformed() {
-        return ignoreMalformed;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException errors = null;
-        if (fieldName == null) {
-            errors = QueryValidationException.addValidationError(NAME, "field must not be null", errors);
-        }
-        if (shell.isEmpty()) {
-            errors = QueryValidationException.addValidationError(NAME, "no points defined for geo_polygon query", errors);
-        } else {
-            GeoPoint start = shell.get(0);
-            if (start.equals(shell.get(shell.size() - 1))) {
-                if (shell.size() < 4) {
-                    errors = QueryValidationException.addValidationError(NAME, "too few points defined for geo_polygon query", errors);
-                }
-            } else {
-                if (shell.size() < 3) {
-                    errors = QueryValidationException.addValidationError(NAME, "too few points defined for geo_polygon query", errors);
-                }
-            }
-        }
-        return errors;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-
-        if (!shell.get(shell.size() - 1).equals(shell.get(0))) {
-            shell.add(shell.get(0));
-        }
-
-        final boolean indexCreatedBeforeV2_0 = context.parseContext().shardContext().indexVersionCreated().before(Version.V_2_0_0);
-        // validation was not available prior to 2.x, so to support bwc
-        // percolation queries we only ignore_malformed on 2.x created indexes
-        if (!indexCreatedBeforeV2_0 && !ignoreMalformed) {
-            for (GeoPoint point : shell) {
-                if (point.lat() > 90.0 || point.lat() < -90.0) {
-                    throw new QueryShardException(context, "illegal latitude value [{}] for [{}]", point.lat(),
-                            GeoPolygonQueryBuilder.NAME);
-                }
-                if (point.lon() > 180.0 || point.lon() < -180) {
-                    throw new QueryShardException(context, "illegal longitude value [{}] for [{}]", point.lon(),
-                            GeoPolygonQueryBuilder.NAME);
-                }
-            }
-        }
-
-        if (coerce) {
-            for (GeoPoint point : shell) {
-                GeoUtils.normalizePoint(point, coerce, coerce);
-            }
-        }
-
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType == null) {
-            throw new QueryShardException(context, "failed to find geo_point field [" + fieldName + "]");
-        }
-        if (!(fieldType instanceof GeoPointFieldMapper.GeoPointFieldType)) {
-            throw new QueryShardException(context, "field [" + fieldName + "] is not a geo_point field");
-        }
-
-        IndexGeoPointFieldData indexFieldData = context.getForField(fieldType);
-        return new GeoPolygonQuery(indexFieldData, shell.toArray(new GeoPoint[shell.size()]));
-    }
-
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(GeoPolygonQueryParser.NAME);
 
-        builder.startObject(fieldName);
-        builder.startArray(GeoPolygonQueryParser.POINTS_FIELD.getPreferredName());
+        builder.startObject(name);
+        builder.startArray(POINTS);
         for (GeoPoint point : shell) {
             builder.startArray().value(point.lon()).value(point.lat()).endArray();
         }
         builder.endArray();
         builder.endObject();
 
-        builder.field(GeoPolygonQueryParser.COERCE_FIELD.getPreferredName(), coerce);
-        builder.field(GeoPolygonQueryParser.IGNORE_MALFORMED_FIELD.getPreferredName(), ignoreMalformed);
-
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected GeoPolygonQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        String fieldName = in.readString();
-        List<GeoPoint> shell = new ArrayList<>();
-        int size = in.readVInt();
-        for (int i = 0; i < size; i++) {
-            shell.add(new GeoPoint(in.readDouble(), in.readDouble()));
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        GeoPolygonQueryBuilder builder = new GeoPolygonQueryBuilder(fieldName, shell);
-        builder.coerce = in.readBoolean();
-        builder.ignoreMalformed = in.readBoolean();
-        return builder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-        out.writeVInt(shell.size());
-        for (GeoPoint point : shell) {
-            out.writeDouble(point.lat());
-            out.writeDouble(point.lon());
+        if (coerce != null) {
+            builder.field("coerce", coerce);
+        }
+        if (ignoreMalformed != null) {
+            builder.field("ignore_malformed", ignoreMalformed);
         }
-        out.writeBoolean(coerce);
-        out.writeBoolean(ignoreMalformed);
-    }
-
-    @Override
-    protected boolean doEquals(GeoPolygonQueryBuilder other) {
-        return Objects.equals(coerce, other.coerce)
-                && Objects.equals(fieldName, other.fieldName)
-                && Objects.equals(ignoreMalformed, other.ignoreMalformed)
-                && Objects.equals(shell, other.shell);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(coerce, fieldName, ignoreMalformed, shell);
-    }
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryParser.java
index 8b7c4e5..e4cf677 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryParser.java
@@ -19,12 +19,17 @@
 
 package org.elasticsearch.index.query;
 
-import org.elasticsearch.common.ParseField;
+import org.apache.lucene.search.Query;
+import org.elasticsearch.Version;
 import org.elasticsearch.common.geo.GeoPoint;
 import org.elasticsearch.common.geo.GeoUtils;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.common.xcontent.XContentParser.Token;
+import org.elasticsearch.index.fielddata.IndexGeoPointFieldData;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.mapper.geo.GeoPointFieldMapper;
+import org.elasticsearch.index.search.geo.GeoPolygonQuery;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -42,11 +47,10 @@ import java.util.List;
  * }
  * </pre>
  */
-public class GeoPolygonQueryParser extends BaseQueryParser<GeoPolygonQueryBuilder> {
+public class GeoPolygonQueryParser implements QueryParser {
 
-    public static final ParseField COERCE_FIELD = new ParseField("coerce", "normalize");
-    public static final ParseField IGNORE_MALFORMED_FIELD = new ParseField("ignore_malformed");
-    public static final ParseField POINTS_FIELD = new ParseField("points");
+    public static final String NAME = "geo_polygon";
+    public static final String POINTS = "points";
 
     @Inject
     public GeoPolygonQueryParser() {
@@ -54,20 +58,20 @@ public class GeoPolygonQueryParser extends BaseQueryParser<GeoPolygonQueryBuilde
 
     @Override
     public String[] names() {
-        return new String[]{GeoPolygonQueryBuilder.NAME, "geoPolygon"};
+        return new String[]{NAME, "geoPolygon"};
     }
 
     @Override
-    public GeoPolygonQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldName = null;
 
-        List<GeoPoint> shell = null;
+        List<GeoPoint> shell = new ArrayList<>();
 
-        Float boost = null;
-        Boolean coerce = null;
-        Boolean ignoreMalformed = null;
+        final boolean indexCreatedBeforeV2_0 = parseContext.indexVersionCreated().before(Version.V_2_0_0);
+        boolean coerce = false;
+        boolean ignoreMalformed = false;
         String queryName = null;
         String currentFieldName = null;
         XContentParser.Token token;
@@ -84,11 +88,13 @@ public class GeoPolygonQueryParser extends BaseQueryParser<GeoPolygonQueryBuilde
                     if (token == XContentParser.Token.FIELD_NAME) {
                         currentFieldName = parser.currentName();
                     } else if (token == XContentParser.Token.START_ARRAY) {
-                        if (parseContext.parseFieldMatcher().match(currentFieldName, POINTS_FIELD)) {
-                            shell = new ArrayList<GeoPoint>();
+                        if (POINTS.equals(currentFieldName)) {
                             while ((token = parser.nextToken()) != Token.END_ARRAY) {
                                 shell.add(GeoUtils.parseGeoPoint(parser));
                             }
+                            if (!shell.get(shell.size()-1).equals(shell.get(0))) {
+                                shell.add(shell.get(0));
+                            }
                         } else {
                             throw new QueryParsingException(parseContext, "[geo_polygon] query does not support [" + currentFieldName
                                     + "]");
@@ -101,14 +107,12 @@ public class GeoPolygonQueryParser extends BaseQueryParser<GeoPolygonQueryBuilde
             } else if (token.isValue()) {
                 if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, COERCE_FIELD)) {
+                } else if ("coerce".equals(currentFieldName) || (indexCreatedBeforeV2_0 && "normalize".equals(currentFieldName))) {
                     coerce = parser.booleanValue();
                     if (coerce == true) {
                         ignoreMalformed = true;
                     }
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, IGNORE_MALFORMED_FIELD)) {
+                } else if ("ignore_malformed".equals(currentFieldName) && coerce == false) {
                     ignoreMalformed = parser.booleanValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[geo_polygon] query does not support [" + currentFieldName + "]");
@@ -117,24 +121,53 @@ public class GeoPolygonQueryParser extends BaseQueryParser<GeoPolygonQueryBuilde
                 throw new QueryParsingException(parseContext, "[geo_polygon] unexpected token type [" + token.name() + "]");
             }
         }
-        GeoPolygonQueryBuilder builder = new GeoPolygonQueryBuilder(fieldName, shell);
-        if (coerce != null) {
-            builder.coerce(coerce);
+
+        if (shell.isEmpty()) {
+            throw new QueryParsingException(parseContext, "no points defined for geo_polygon query");
+        } else {
+            if (shell.size() < 3) {
+                throw new QueryParsingException(parseContext, "too few points defined for geo_polygon query");
+            }
+            GeoPoint start = shell.get(0);
+            if (!start.equals(shell.get(shell.size() - 1))) {
+                shell.add(start);
+            }
+            if (shell.size() < 4) {
+                throw new QueryParsingException(parseContext, "too few points defined for geo_polygon query");
+            }
+        }
+
+        // validation was not available prior to 2.x, so to support bwc percolation queries we only ignore_malformed on 2.x created indexes
+        if (!indexCreatedBeforeV2_0 && !ignoreMalformed) {
+            for (GeoPoint point : shell) {
+                if (point.lat() > 90.0 || point.lat() < -90.0) {
+                    throw new QueryParsingException(parseContext, "illegal latitude value [{}] for [{}]", point.lat(), NAME);
+                }
+                if (point.lon() > 180.0 || point.lon() < -180) {
+                    throw new QueryParsingException(parseContext, "illegal longitude value [{}] for [{}]", point.lon(), NAME);
+                }
+            }
         }
-        if (ignoreMalformed != null) {
-            builder.ignoreMalformed(ignoreMalformed);
+
+        if (coerce) {
+            for (GeoPoint point : shell) {
+                GeoUtils.normalizePoint(point, coerce, coerce);
+            }
         }
-        if (queryName != null) {
-            builder.queryName(queryName);
+
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType == null) {
+            throw new QueryParsingException(parseContext, "failed to find geo_point field [" + fieldName + "]");
         }
-        if (boost != null) {
-            builder.boost(boost);
+        if (!(fieldType instanceof GeoPointFieldMapper.GeoPointFieldType)) {
+            throw new QueryParsingException(parseContext, "field [" + fieldName + "] is not a geo_point field");
         }
-        return builder;
-    }
 
-    @Override
-    public GeoPolygonQueryBuilder getBuilderPrototype() {
-        return GeoPolygonQueryBuilder.PROTOTYPE;
+        IndexGeoPointFieldData indexFieldData = parseContext.getForField(fieldType);
+        Query query = new GeoPolygonQuery(indexFieldData, shell.toArray(new GeoPoint[shell.size()]));
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java
index 52d30b4..3887874 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java
@@ -19,161 +19,95 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.spatial.prefix.PrefixTreeStrategy;
-import org.apache.lucene.spatial.prefix.RecursivePrefixTreeStrategy;
-import org.apache.lucene.spatial.query.SpatialArgs;
-import org.apache.lucene.spatial.query.SpatialOperation;
-import org.elasticsearch.action.get.GetRequest;
-import org.elasticsearch.action.get.GetResponse;
-import org.elasticsearch.client.Client;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.bytes.BytesArray;
-import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.geo.ShapeRelation;
-import org.elasticsearch.common.geo.ShapesAvailability;
 import org.elasticsearch.common.geo.SpatialStrategy;
 import org.elasticsearch.common.geo.builders.ShapeBuilder;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentHelper;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.common.xcontent.XContentType;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.mapper.geo.GeoShapeFieldMapper;
-import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
- * {@link QueryBuilder} that builds a GeoShape Query
+ * {@link QueryBuilder} that builds a GeoShape Filter
  */
-public class GeoShapeQueryBuilder extends AbstractQueryBuilder<GeoShapeQueryBuilder> {
+public class GeoShapeQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<GeoShapeQueryBuilder> {
 
-    public static final String NAME = "geo_shape";
-    public static final String DEFAULT_SHAPE_INDEX_NAME = "shapes";
-    public static final String DEFAULT_SHAPE_FIELD_NAME = "shape";
-    public static final ShapeRelation DEFAULT_SHAPE_RELATION = ShapeRelation.INTERSECTS;
+    private final String name;
 
-    static final GeoShapeQueryBuilder PROTOTYPE = new GeoShapeQueryBuilder("", new BytesArray(new byte[0]));
-
-    private final String fieldName;
-
-    // TODO make the ShapeBuilder and subclasses Writable and implement hashCode
-    // and Equals so ShapeBuilder can be used here
-    private BytesReference shapeBytes;
+    private final ShapeBuilder shape;
 
     private SpatialStrategy strategy = null;
 
+    private String queryName;
+
     private final String indexedShapeId;
     private final String indexedShapeType;
 
-    private String indexedShapeIndex = DEFAULT_SHAPE_INDEX_NAME;
-    private String indexedShapePath = DEFAULT_SHAPE_FIELD_NAME;
+    private String indexedShapeIndex;
+    private String indexedShapePath;
 
-    private ShapeRelation relation = DEFAULT_SHAPE_RELATION;
+    private ShapeRelation relation = null;
 
+    private float boost = -1;
+    
     /**
-     * Creates a new GeoShapeQueryBuilder whose Query will be against the given
-     * field name using the given Shape
+     * Creates a new GeoShapeQueryBuilder whose Filter will be against the
+     * given field name using the given Shape
      *
-     * @param name
-     *            Name of the field that will be queried
-     * @param shape
-     *            Shape used in the Query
+     * @param name  Name of the field that will be filtered
+     * @param shape Shape used in the filter
      */
-    public GeoShapeQueryBuilder(String fieldName, ShapeBuilder shape) throws IOException {
-        this(fieldName, shape, null, null);
+    public GeoShapeQueryBuilder(String name, ShapeBuilder shape) {
+        this(name, shape, null, null, null);
     }
 
     /**
-     * Creates a new GeoShapeQueryBuilder whose Query will be against the given
-     * field name and will use the Shape found with the given ID in the given
-     * type
+     * Creates a new GeoShapeQueryBuilder whose Filter will be against the
+     * given field name using the given Shape
      *
-     * @param fieldName
-     *            Name of the field that will be filtered
-     * @param indexedShapeId
-     *            ID of the indexed Shape that will be used in the Query
-     * @param indexedShapeType
-     *            Index type of the indexed Shapes
-     */
-    public GeoShapeQueryBuilder(String fieldName, String indexedShapeId, String indexedShapeType) {
-        this(fieldName, (BytesReference) null, indexedShapeId, indexedShapeType);
-    }
-
-    GeoShapeQueryBuilder(String fieldName, BytesReference shapeBytes) {
-        this(fieldName, shapeBytes, null, null);
-    }
-
-    private GeoShapeQueryBuilder(String fieldName, ShapeBuilder shape, String indexedShapeId, String indexedShapeType) throws IOException {
-        this(fieldName, new BytesArray(new byte[0]), indexedShapeId, indexedShapeType);
-        if (shape != null) {
-            XContentBuilder builder = XContentFactory.jsonBuilder();
-            shape.toXContent(builder, EMPTY_PARAMS);
-            this.shapeBytes = builder.bytes();
-        }
-    }
-
-    private GeoShapeQueryBuilder(String fieldName, BytesReference shapeBytes, String indexedShapeId, String indexedShapeType) {
-        if (fieldName == null) {
-            throw new IllegalArgumentException("fieldName is required");
-        }
-        if (shapeBytes == null && indexedShapeId == null) {
-            throw new IllegalArgumentException("either shapeBytes or indexedShapeId and indexedShapeType are required");
-        }
-        if (indexedShapeId != null && indexedShapeType == null) {
-            throw new IllegalArgumentException("indexedShapeType is required if indexedShapeId is specified");
-        }
-        this.fieldName = fieldName;
-        this.shapeBytes = shapeBytes;
-        this.indexedShapeId = indexedShapeId;
-        this.indexedShapeType = indexedShapeType;
-    }
-
-    /**
-     * @return the name of the field that will be queried
+     * @param name  Name of the field that will be filtered
+     * @param relation {@link ShapeRelation} of query and indexed shape
+     * @param shape Shape used in the filter
      */
-    public String fieldName() {
-        return fieldName;
+    public GeoShapeQueryBuilder(String name, ShapeBuilder shape, ShapeRelation relation) {
+        this(name, shape, null, null, relation);
     }
 
     /**
-     * @return the JSON bytes for the shape used in the Query
+     * Creates a new GeoShapeQueryBuilder whose Filter will be against the given field name
+     * and will use the Shape found with the given ID in the given type
+     *
+     * @param name             Name of the field that will be filtered
+     * @param indexedShapeId   ID of the indexed Shape that will be used in the Filter
+     * @param indexedShapeType Index type of the indexed Shapes
      */
-    public BytesReference shapeBytes() {
-        return shapeBytes;
+    public GeoShapeQueryBuilder(String name, String indexedShapeId, String indexedShapeType, ShapeRelation relation) {
+        this(name, null, indexedShapeId, indexedShapeType, relation);
     }
 
-    /**
-     * @return the ID of the indexed Shape that will be used in the Query
-     */
-    public String indexedShapeId() {
-        return indexedShapeId;
+    private GeoShapeQueryBuilder(String name, ShapeBuilder shape, String indexedShapeId, String indexedShapeType, ShapeRelation relation) {
+        this.name = name;
+        this.shape = shape;
+        this.indexedShapeId = indexedShapeId;
+        this.relation = relation;
+        this.indexedShapeType = indexedShapeType;
     }
 
     /**
-     * @return the document type of the indexed Shape that will be used in the
-     *         Query
+     * Sets the name of the filter
+     *
+     * @param queryName Name of the filter
+     * @return this
      */
-    public String indexedShapeType() {
-        return indexedShapeType;
+    public GeoShapeQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     /**
-     * Defines which spatial strategy will be used for building the geo shape
-     * Query. When not set, the strategy that will be used will be the one that
-     * is associated with the geo shape field in the mappings.
+     * Defines which spatial strategy will be used for building the geo shape filter. When not set, the strategy that
+     * will be used will be the one that is associated with the geo shape field in the mappings.
      *
-     * @param strategy
-     *            The spatial strategy to use for building the geo shape Query
+     * @param strategy The spatial strategy to use for building the geo shape filter
      * @return this
      */
     public GeoShapeQueryBuilder strategy(SpatialStrategy strategy) {
@@ -182,13 +116,6 @@ public class GeoShapeQueryBuilder extends AbstractQueryBuilder<GeoShapeQueryBuil
     }
 
     /**
-     * @return The spatial strategy to use for building the geo shape Query
-     */
-    public SpatialStrategy strategy() {
-        return strategy;
-    }
-
-    /**
      * Sets the name of the index where the indexed Shape can be found
      *
      * @param indexedShapeIndex Name of the index where the indexed Shape is
@@ -200,14 +127,6 @@ public class GeoShapeQueryBuilder extends AbstractQueryBuilder<GeoShapeQueryBuil
     }
 
     /**
-     * @return the index name for the indexed Shape that will be used in the
-     *         Query
-     */
-    public String indexedShapeIndex() {
-        return indexedShapeIndex;
-    }
-
-    /**
      * Sets the path of the field in the indexed Shape document that has the Shape itself
      *
      * @param indexedShapePath Path of the field where the Shape itself is defined
@@ -219,13 +138,6 @@ public class GeoShapeQueryBuilder extends AbstractQueryBuilder<GeoShapeQueryBuil
     }
 
     /**
-     * @return the path of the indexed Shape that will be used in the Query
-     */
-    public String indexedShapePath() {
-        return indexedShapePath;
-    }
-
-    /**
      * Sets the relation of query shape and indexed shape.
      *
      * @param relation relation of the shapes
@@ -236,247 +148,51 @@ public class GeoShapeQueryBuilder extends AbstractQueryBuilder<GeoShapeQueryBuil
         return this;
     }
 
-    /**
-     * @return the relation of query shape and indexed shape to use in the Query
-     */
-    public ShapeRelation relation() {
-        return relation;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException errors = null;
-        if (fieldName == null) {
-            errors = QueryValidationException.addValidationError(NAME, "No field defined", errors);
-        }
-        if ((shapeBytes == null || shapeBytes.length() == 0) && indexedShapeId == null) {
-            errors = QueryValidationException.addValidationError(NAME, "No Shape defined", errors);
-        }
-        if (relation == null) {
-            errors = QueryValidationException.addValidationError(NAME, "No Shape Relation defined", errors);
-        }
-        if (indexedShapeId != null && indexedShapeType == null) {
-            errors = QueryValidationException.addValidationError(NAME, "Type for indexed shape not provided", errors);
-        }
-        if (strategy != null && strategy == SpatialStrategy.TERM && relation != ShapeRelation.INTERSECTS) {
-            errors = QueryValidationException.addValidationError(NAME,
-                    "strategy [" + strategy.getStrategyName() + "] only supports relation ["
-                    + ShapeRelation.INTERSECTS.getRelationName() + "] found relation [" + relation.getRelationName() + "]", errors);
-        }
-        return errors;
-    }
-
     @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        ShapeBuilder shape;
-        if (shapeBytes == null) {
-            GetRequest getRequest = new GetRequest(indexedShapeIndex, indexedShapeType, indexedShapeId);
-            getRequest.copyContextAndHeadersFrom(SearchContext.current());
-            shape = fetch(context.getClient(), getRequest, indexedShapePath);
-        } else {
-            XContentParser shapeParser = XContentHelper.createParser(shapeBytes);
-            shapeParser.nextToken();
-            shape = ShapeBuilder.parse(shapeParser);
-        }
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType == null) {
-            throw new QueryShardException(context, "Failed to find geo_shape field [" + fieldName + "]");
-        }
-
-        // TODO: This isn't the nicest way to check this
-        if (!(fieldType instanceof GeoShapeFieldMapper.GeoShapeFieldType)) {
-            throw new QueryShardException(context, "Field [" + fieldName + "] is not a geo_shape");
-        }
-
-        GeoShapeFieldMapper.GeoShapeFieldType shapeFieldType = (GeoShapeFieldMapper.GeoShapeFieldType) fieldType;
-
-        PrefixTreeStrategy strategy = shapeFieldType.defaultStrategy();
-        if (this.strategy != null) {
-            strategy = shapeFieldType.resolveStrategy(this.strategy);
-        }
-        Query query;
-        if (strategy instanceof RecursivePrefixTreeStrategy && relation == ShapeRelation.DISJOINT) {
-            // this strategy doesn't support disjoint anymore: but it did
-            // before, including creating lucene fieldcache (!)
-            // in this case, execute disjoint as exists && !intersects
-            BooleanQuery.Builder bool = new BooleanQuery.Builder();
-            Query exists = ExistsQueryBuilder.newFilter(context, fieldName);
-            Filter intersects = strategy.makeFilter(getArgs(shape, ShapeRelation.INTERSECTS));
-            bool.add(exists, BooleanClause.Occur.MUST);
-            bool.add(intersects, BooleanClause.Occur.MUST_NOT);
-            query = new ConstantScoreQuery(bool.build());
-        } else {
-            query = strategy.makeQuery(getArgs(shape, relation));
-        }
-        return query;
-    }
-
-    /**
-     * Fetches the Shape with the given ID in the given type and index.
-     *
-     * @param getRequest
-     *            GetRequest containing index, type and id
-     * @param path
-     *            Name or path of the field in the Shape Document where the
-     *            Shape itself is located
-     * @return Shape with the given ID
-     * @throws IOException
-     *             Can be thrown while parsing the Shape Document and extracting
-     *             the Shape
-     */
-    private ShapeBuilder fetch(Client client, GetRequest getRequest, String path) throws IOException {
-        if (ShapesAvailability.JTS_AVAILABLE == false) {
-            throw new IllegalStateException("JTS not available");
-        }
-        getRequest.preference("_local");
-        getRequest.operationThreaded(false);
-        GetResponse response = client.get(getRequest).actionGet();
-        if (!response.isExists()) {
-            throw new IllegalArgumentException("Shape with ID [" + getRequest.id() + "] in type [" + getRequest.type() + "] not found");
-        }
-
-        String[] pathElements = Strings.splitStringToArray(path, '.');
-        int currentPathSlot = 0;
-
-        XContentParser parser = null;
-        try {
-            parser = XContentHelper.createParser(response.getSourceAsBytesRef());
-            XContentParser.Token currentToken;
-            while ((currentToken = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
-                if (currentToken == XContentParser.Token.FIELD_NAME) {
-                    if (pathElements[currentPathSlot].equals(parser.currentName())) {
-                        parser.nextToken();
-                        if (++currentPathSlot == pathElements.length) {
-                            return ShapeBuilder.parse(parser);
-                        }
-                    } else {
-                        parser.nextToken();
-                        parser.skipChildren();
-                    }
-                }
-            }
-            throw new IllegalStateException("Shape with name [" + getRequest.id() + "] found but missing " + path + " field");
-        } finally {
-            if (parser != null) {
-                parser.close();
-            }
-        }
-    }
-
-    public static SpatialArgs getArgs(ShapeBuilder shape, ShapeRelation relation) {
-        switch (relation) {
-        case DISJOINT:
-            return new SpatialArgs(SpatialOperation.IsDisjointTo, shape.build());
-        case INTERSECTS:
-            return new SpatialArgs(SpatialOperation.Intersects, shape.build());
-        case WITHIN:
-            return new SpatialArgs(SpatialOperation.IsWithin, shape.build());
-        default:
-            throw new IllegalArgumentException("invalid relation [" + relation + "]");
-        }
+    public GeoShapeQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(GeoShapeQueryParser.NAME);
 
-        builder.startObject(fieldName);
+        builder.startObject(name);
 
         if (strategy != null) {
-            builder.field(GeoShapeQueryParser.STRATEGY_FIELD.getPreferredName(), strategy.getStrategyName());
+            builder.field("strategy", strategy.getStrategyName());
         }
 
-        if (shapeBytes != null) {
-            builder.field(GeoShapeQueryParser.SHAPE_FIELD.getPreferredName());
-            XContentParser parser = XContentFactory.xContent(XContentType.JSON).createParser(shapeBytes);
-            parser.nextToken();
-            builder.copyCurrentStructure(parser);
+        if (shape != null) {
+            builder.field("shape", shape);
         } else {
-            builder.startObject(GeoShapeQueryParser.INDEXED_SHAPE_FIELD.getPreferredName())
-                    .field(GeoShapeQueryParser.SHAPE_ID_FIELD.getPreferredName(), indexedShapeId)
-                    .field(GeoShapeQueryParser.SHAPE_TYPE_FIELD.getPreferredName(), indexedShapeType);
+            builder.startObject("indexed_shape")
+                    .field("id", indexedShapeId)
+                    .field("type", indexedShapeType);
             if (indexedShapeIndex != null) {
-                builder.field(GeoShapeQueryParser.SHAPE_INDEX_FIELD.getPreferredName(), indexedShapeIndex);
+                builder.field("index", indexedShapeIndex);
             }
             if (indexedShapePath != null) {
-                builder.field(GeoShapeQueryParser.SHAPE_PATH_FIELD.getPreferredName(), indexedShapePath);
+                builder.field("path", indexedShapePath);
             }
             builder.endObject();
         }
 
         if(relation != null) {
-            builder.field(GeoShapeQueryParser.RELATION_FIELD.getPreferredName(), relation.getRelationName());
+            builder.field("relation", relation.getRelationName());
         }
 
         builder.endObject();
 
-        printBoostAndQueryName(builder);
-
-        builder.endObject();
-    }
-
-    @Override
-    protected GeoShapeQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        String fieldName = in.readString();
-        GeoShapeQueryBuilder builder;
-        if (in.readBoolean()) {
-            BytesReference shapeBytes = in.readBytesReference();
-            builder = new GeoShapeQueryBuilder(fieldName, shapeBytes);
-        } else {
-            String indexedShapeId = in.readOptionalString();
-            String indexedShapeType = in.readOptionalString();
-            String indexedShapeIndex = in.readOptionalString();
-            String indexedShapePath = in.readOptionalString();
-            builder = new GeoShapeQueryBuilder(fieldName, indexedShapeId, indexedShapeType);
-            if (indexedShapeIndex != null) {
-                builder.indexedShapeIndex = indexedShapeIndex;
-            }
-            if (indexedShapePath != null) {
-                builder.indexedShapePath = indexedShapePath;
-            }
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        builder.relation = ShapeRelation.DISJOINT.readFrom(in);
-        builder.strategy = SpatialStrategy.RECURSIVE.readFrom(in);
-        return builder;
-    }
 
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-        boolean hasShapeBytes = shapeBytes != null;
-        out.writeBoolean(hasShapeBytes);
-        if (hasShapeBytes) {
-            out.writeBytesReference(shapeBytes);
-        } else {
-            out.writeOptionalString(indexedShapeId);
-            out.writeOptionalString(indexedShapeType);
-            out.writeOptionalString(indexedShapeIndex);
-            out.writeOptionalString(indexedShapePath);
+        if (name != null) {
+            builder.field("_name", queryName);
         }
-        relation.writeTo(out);
-        strategy.writeTo(out);
-    }
-
-    @Override
-    protected boolean doEquals(GeoShapeQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName)
-                && Objects.equals(indexedShapeId, other.indexedShapeId)
-                && Objects.equals(indexedShapeIndex, other.indexedShapeIndex)
-                && Objects.equals(indexedShapePath, other.indexedShapePath)
-                && Objects.equals(indexedShapeType, other.indexedShapeType)
-                && Objects.equals(relation, other.relation)
-                && Objects.equals(shapeBytes, other.shapeBytes)
-                && Objects.equals(strategy, other.strategy);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldName, indexedShapeId, indexedShapeIndex,
-                indexedShapePath, indexedShapeType, relation, shapeBytes, strategy);
-    }
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryParser.java
index 69cadfe..e959c42 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryParser.java
@@ -19,50 +19,59 @@
 
 package org.elasticsearch.index.query;
 
-import org.elasticsearch.common.ParseField;
+import org.apache.lucene.search.*;
+import org.apache.lucene.spatial.prefix.PrefixTreeStrategy;
+import org.apache.lucene.spatial.prefix.RecursivePrefixTreeStrategy;
+import org.apache.lucene.spatial.query.SpatialArgs;
+import org.apache.lucene.spatial.query.SpatialOperation;
+import org.elasticsearch.action.get.GetRequest;
+import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.geo.ShapeRelation;
-import org.elasticsearch.common.geo.SpatialStrategy;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
+import org.elasticsearch.common.geo.builders.ShapeBuilder;
+import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.FieldMapper;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.mapper.geo.GeoShapeFieldMapper;
+import org.elasticsearch.index.search.shape.ShapeFetchService;
+import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
 
-public class GeoShapeQueryParser extends BaseQueryParser<GeoShapeQueryBuilder> {
+public class GeoShapeQueryParser implements QueryParser {
 
-    public static final ParseField SHAPE_FIELD = new ParseField("shape");
-    public static final ParseField STRATEGY_FIELD = new ParseField("strategy");
-    public static final ParseField RELATION_FIELD = new ParseField("relation");
-    public static final ParseField INDEXED_SHAPE_FIELD = new ParseField("indexed_shape");
-    public static final ParseField SHAPE_ID_FIELD = new ParseField("id");
-    public static final ParseField SHAPE_TYPE_FIELD = new ParseField("type");
-    public static final ParseField SHAPE_INDEX_FIELD = new ParseField("index");
-    public static final ParseField SHAPE_PATH_FIELD = new ParseField("path");
+    public static final String NAME = "geo_shape";
+
+    private ShapeFetchService fetchService;
+
+    public static class DEFAULTS {
+        public static final String INDEX_NAME = "shapes";
+        public static final String SHAPE_FIELD_NAME = "shape";
+    }
 
     @Override
     public String[] names() {
-        return new String[]{GeoShapeQueryBuilder.NAME, Strings.toCamelCase(GeoShapeQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public GeoShapeQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldName = null;
-        ShapeRelation shapeRelation = null;
-        SpatialStrategy strategy = null;
-        BytesReference shape = null;
+        ShapeRelation shapeRelation = ShapeRelation.INTERSECTS;
+        String strategyName = null;
+        ShapeBuilder shape = null;
 
         String id = null;
         String type = null;
-        String index = null;
-        String shapePath = null;
+        String index = DEFAULTS.INDEX_NAME;
+        String shapePath = DEFAULTS.SHAPE_FIELD_NAME;
 
         XContentParser.Token token;
         String currentFieldName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1f;
         String queryName = null;
 
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -75,78 +84,113 @@ public class GeoShapeQueryParser extends BaseQueryParser<GeoShapeQueryBuilder> {
                     if (token == XContentParser.Token.FIELD_NAME) {
                         currentFieldName = parser.currentName();
                         token = parser.nextToken();
-                        if (parseContext.parseFieldMatcher().match(currentFieldName, SHAPE_FIELD)) {
-                            XContentBuilder builder = XContentFactory.contentBuilder(parser.contentType()).copyCurrentStructure(parser);
-                            shape = builder.bytes();
-                        } else if (parseContext.parseFieldMatcher().match(currentFieldName, STRATEGY_FIELD)) {
-                            String strategyName = parser.text();
-                            strategy = SpatialStrategy.fromString(strategyName);
-                            if (strategy == null) {
-                                throw new QueryParsingException(parseContext, "Unknown strategy [" + strategyName + " ]");
-                            }
-                        } else if (parseContext.parseFieldMatcher().match(currentFieldName, RELATION_FIELD)) {
+                        if ("shape".equals(currentFieldName)) {
+                            shape = ShapeBuilder.parse(parser);
+                        } else if ("strategy".equals(currentFieldName)) {
+                            strategyName = parser.text();
+                        } else if ("relation".equals(currentFieldName)) {
                             shapeRelation = ShapeRelation.getRelationByName(parser.text());
                             if (shapeRelation == null) {
                                 throw new QueryParsingException(parseContext, "Unknown shape operation [" + parser.text() + " ]");
                             }
-                        } else if (parseContext.parseFieldMatcher().match(currentFieldName, INDEXED_SHAPE_FIELD)) {
+                        } else if ("indexed_shape".equals(currentFieldName) || "indexedShape".equals(currentFieldName)) {
                             while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
                                 if (token == XContentParser.Token.FIELD_NAME) {
                                     currentFieldName = parser.currentName();
                                 } else if (token.isValue()) {
-                                    if (parseContext.parseFieldMatcher().match(currentFieldName, SHAPE_ID_FIELD)) {
+                                    if ("id".equals(currentFieldName)) {
                                         id = parser.text();
-                                    } else if (parseContext.parseFieldMatcher().match(currentFieldName, SHAPE_TYPE_FIELD)) {
+                                    } else if ("type".equals(currentFieldName)) {
                                         type = parser.text();
-                                    } else if (parseContext.parseFieldMatcher().match(currentFieldName, SHAPE_INDEX_FIELD)) {
+                                    } else if ("index".equals(currentFieldName)) {
                                         index = parser.text();
-                                    } else if (parseContext.parseFieldMatcher().match(currentFieldName, SHAPE_PATH_FIELD)) {
+                                    } else if ("path".equals(currentFieldName)) {
                                         shapePath = parser.text();
                                     }
                                 }
                             }
+                            if (id == null) {
+                                throw new QueryParsingException(parseContext, "ID for indexed shape not provided");
+                            } else if (type == null) {
+                                throw new QueryParsingException(parseContext, "Type for indexed shape not provided");
+                            }
+                            GetRequest getRequest = new GetRequest(index, type, id);
+                            getRequest.copyContextAndHeadersFrom(SearchContext.current());
+                            shape = fetchService.fetch(getRequest, shapePath);
                         } else {
                             throw new QueryParsingException(parseContext, "[geo_shape] query does not support [" + currentFieldName + "]");
                         }
                     }
                 }
             } else if (token.isValue()) {
-                if (parseContext.parseFieldMatcher().match(currentFieldName, AbstractQueryBuilder.BOOST_FIELD)) {
+                if ("boost".equals(currentFieldName)) {
                     boost = parser.floatValue();
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, AbstractQueryBuilder.NAME_FIELD)) {
+                } else if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
                 } else {
                     throw new QueryParsingException(parseContext, "[geo_shape] query does not support [" + currentFieldName + "]");
                 }
             }
         }
-        GeoShapeQueryBuilder builder;
-        if (shape != null) {
-            builder = new GeoShapeQueryBuilder(fieldName, shape);
-        } else {
-            builder = new GeoShapeQueryBuilder(fieldName, id, type);
+
+        if (shape == null) {
+            throw new QueryParsingException(parseContext, "No Shape defined");
+        } else if (shapeRelation == null) {
+            throw new QueryParsingException(parseContext, "No Shape Relation defined");
         }
-        if (index != null) {
-            builder.indexedShapeIndex(index);
+
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType == null) {
+            throw new QueryParsingException(parseContext, "Failed to find geo_shape field [" + fieldName + "]");
         }
-        if (shapePath != null) {
-            builder.indexedShapePath(shapePath);
+
+        // TODO: This isn't the nicest way to check this
+        if (!(fieldType instanceof GeoShapeFieldMapper.GeoShapeFieldType)) {
+            throw new QueryParsingException(parseContext, "Field [" + fieldName + "] is not a geo_shape");
         }
-        if (shapeRelation != null) {
-            builder.relation(shapeRelation);
+
+        GeoShapeFieldMapper.GeoShapeFieldType shapeFieldType = (GeoShapeFieldMapper.GeoShapeFieldType) fieldType;
+
+        PrefixTreeStrategy strategy = shapeFieldType.defaultStrategy();
+        if (strategyName != null) {
+            strategy = shapeFieldType.resolveStrategy(strategyName);
         }
-        if (strategy != null) {
-            builder.strategy(strategy);
+        Query query;
+        if (strategy instanceof RecursivePrefixTreeStrategy && shapeRelation == ShapeRelation.DISJOINT) {
+            // this strategy doesn't support disjoint anymore: but it did before, including creating lucene fieldcache (!)
+            // in this case, execute disjoint as exists && !intersects
+            BooleanQuery.Builder bool = new BooleanQuery.Builder();
+            Query exists = ExistsQueryParser.newFilter(parseContext, fieldName, null);
+            Filter intersects = strategy.makeFilter(getArgs(shape, ShapeRelation.INTERSECTS));
+            bool.add(exists, BooleanClause.Occur.MUST);
+            bool.add(intersects, BooleanClause.Occur.MUST_NOT);
+            query = new ConstantScoreQuery(bool.build());
+        } else {
+            query = strategy.makeQuery(getArgs(shape, shapeRelation));
         }
+        query.setBoost(boost);
         if (queryName != null) {
-            builder.queryName(queryName);
+            parseContext.addNamedQuery(queryName, query);
         }
-            builder.boost(boost);
-        return builder;
+        return query;
     }
 
-    @Override
-    public GeoShapeQueryBuilder getBuilderPrototype() {
-        return GeoShapeQueryBuilder.PROTOTYPE;
+    @Inject(optional = true)
+    public void setFetchService(@Nullable ShapeFetchService fetchService) {
+        this.fetchService = fetchService;
+    }
+
+    public static SpatialArgs getArgs(ShapeBuilder shape, ShapeRelation relation) {
+        switch(relation) {
+        case DISJOINT:
+            return new SpatialArgs(SpatialOperation.IsDisjointTo, shape.build());
+        case INTERSECTS:
+            return new SpatialArgs(SpatialOperation.Intersects, shape.build());
+        case WITHIN:
+            return new SpatialArgs(SpatialOperation.IsWithin, shape.build());
+        default:
+            throw new IllegalArgumentException("");
+
+        }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeohashCellQuery.java b/core/src/main/java/org/elasticsearch/index/query/GeohashCellQuery.java
index 7b00ea7..814aca4 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeohashCellQuery.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeohashCellQuery.java
@@ -22,25 +22,23 @@ package org.elasticsearch.index.query;
 import org.apache.lucene.search.Query;
 import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.common.Nullable;
-import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.geo.GeoHashUtils;
 import org.elasticsearch.common.geo.GeoPoint;
 import org.elasticsearch.common.geo.GeoUtils;
 import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.unit.DistanceUnit;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.common.xcontent.XContentParser.Token;
+import org.elasticsearch.index.mapper.FieldMapper;
 import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.mapper.core.StringFieldMapper;
 import org.elasticsearch.index.mapper.geo.GeoPointFieldMapper;
 
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Objects;
 
 /**
  * A geohash cell filter that filters {@link GeoPoint}s by their geohashes. Basically the a
@@ -60,9 +58,8 @@ import java.util.Objects;
 public class GeohashCellQuery {
 
     public static final String NAME = "geohash_cell";
-    public static final ParseField NEIGHBORS_FIELD = new ParseField("neighbors");
-    public static final ParseField PRECISION_FIELD = new ParseField("precision");
-    public static final boolean DEFAULT_NEIGHBORS = false;
+    public static final String NEIGHBORS = "neighbors";
+    public static final String PRECISION = "precision";
 
     /**
      * Create a new geohash filter for a given set of geohashes. In general this method
@@ -74,7 +71,7 @@ public class GeohashCellQuery {
      * @param geohashes   optional array of additional geohashes
      * @return a new GeoBoundinboxfilter
      */
-    public static Query create(QueryShardContext context, GeoPointFieldMapper.GeoPointFieldType fieldType, String geohash, @Nullable List<CharSequence> geohashes) {
+    public static Query create(QueryParseContext context, GeoPointFieldMapper.GeoPointFieldType fieldType, String geohash, @Nullable List<CharSequence> geohashes) {
         MappedFieldType geoHashMapper = fieldType.geohashFieldType();
         if (geoHashMapper == null) {
             throw new IllegalArgumentException("geohash filter needs geohash_prefix to be enabled");
@@ -93,16 +90,15 @@ public class GeohashCellQuery {
      * <code>geohash</code> to be set. the default for a neighbor filteing is
      * <code>false</code>.
      */
-    public static class Builder extends AbstractQueryBuilder<Builder> {
+    public static class Builder extends QueryBuilder {
         // we need to store the geohash rather than the corresponding point,
         // because a transformation from a geohash to a point an back to the
         // geohash will extend the accuracy of the hash to max precision
         // i.e. by filing up with z's.
-        private String fieldName;
+        private String field;
         private String geohash;
-        private Integer levels = null;
-        private boolean neighbors = DEFAULT_NEIGHBORS;
-        private static final Builder PROTOTYPE = new Builder(null);
+        private int levels = -1;
+        private boolean neighbors;
 
 
         public Builder(String field) {
@@ -119,7 +115,7 @@ public class GeohashCellQuery {
 
         public Builder(String field, String geohash, boolean neighbors) {
             super();
-            this.fieldName = field;
+            this.field = field;
             this.geohash = geohash;
             this.neighbors = neighbors;
         }
@@ -139,19 +135,11 @@ public class GeohashCellQuery {
             return this;
         }
 
-        public String geohash() {
-            return geohash;
-        }
-
         public Builder precision(int levels) {
             this.levels = levels;
             return this;
         }
 
-        public Integer precision() {
-            return levels;
-        }
-
         public Builder precision(String precision) {
             double meters = DistanceUnit.parse(precision, DistanceUnit.DEFAULT, DistanceUnit.METERS);
             return precision(GeoUtils.geoHashLevelsForPrecision(meters));
@@ -162,123 +150,27 @@ public class GeohashCellQuery {
             return this;
         }
 
-        public boolean neighbors() {
-            return neighbors;
-        }
-
-        public Builder fieldName(String fieldName) {
-            this.fieldName = fieldName;
+        public Builder field(String field) {
+            this.field = field;
             return this;
         }
 
-        public String fieldName() {
-            return fieldName;
-        }
-
-        @Override
-        public QueryValidationException validate() {
-            QueryValidationException errors = null;
-            if (fieldName == null) {
-                errors = QueryValidationException.addValidationError(NAME, "fieldName must not be null", errors);
-            }
-            if (geohash == null) {
-                errors = QueryValidationException.addValidationError(NAME, "geohash or point must be defined", errors);
-            }
-            if (levels != null && levels <= 0) {
-                errors = QueryValidationException.addValidationError(NAME, "precision must be greater than 0. Found [" + levels + "]",
-                        errors);
-            }
-            return errors;
-        }
-
-        @Override
-        protected Query doToQuery(QueryShardContext context) throws IOException {
-            MappedFieldType fieldType = context.fieldMapper(fieldName);
-            if (fieldType == null) {
-                throw new QueryShardException(context, "failed to parse [{}] query. missing [{}] field [{}]", NAME,
-                        GeoPointFieldMapper.CONTENT_TYPE, fieldName);
-            }
-
-            if (!(fieldType instanceof GeoPointFieldMapper.GeoPointFieldType)) {
-                throw new QueryShardException(context, "failed to parse [{}] query. field [{}] is not a geo_point field", NAME, fieldName);
-            }
-
-            GeoPointFieldMapper.GeoPointFieldType geoFieldType = ((GeoPointFieldMapper.GeoPointFieldType) fieldType);
-            if (!geoFieldType.isGeohashPrefixEnabled()) {
-                throw new QueryShardException(context, "failed to parse [{}] query. [geohash_prefix] is not enabled for field [{}]", NAME,
-                        fieldName);
-            }
-
-            if (levels != null) {
-                int len = Math.min(levels, geohash.length());
-                geohash = geohash.substring(0, len);
-            }
-
-            Query query;
-            if (neighbors) {
-                query = create(context, geoFieldType, geohash, GeoHashUtils.addNeighbors(geohash, new ArrayList<CharSequence>(8)));
-            } else {
-                query = create(context, geoFieldType, geohash, null);
-            }
-            return query;
-        }
-
         @Override
         protected void doXContent(XContentBuilder builder, Params params) throws IOException {
             builder.startObject(NAME);
-            builder.field(NEIGHBORS_FIELD.getPreferredName(), neighbors);
-            if (levels != null) {
-                builder.field(PRECISION_FIELD.getPreferredName(), levels);
-            }
-            builder.field(fieldName, geohash);
-            printBoostAndQueryName(builder);
-            builder.endObject();
-        }
-
-        @Override
-        protected Builder doReadFrom(StreamInput in) throws IOException {
-            String field = in.readString();
-            String geohash = in.readString();
-            Builder builder = new Builder(field, geohash);
-            if (in.readBoolean()) {
-                builder.precision(in.readVInt());
+            if (neighbors) {
+                builder.field(NEIGHBORS, neighbors);
             }
-            builder.neighbors(in.readBoolean());
-            return builder;
-        }
-
-        @Override
-        protected void doWriteTo(StreamOutput out) throws IOException {
-            out.writeString(fieldName);
-            out.writeString(geohash);
-            boolean hasLevels = levels != null;
-            out.writeBoolean(hasLevels);
-            if (hasLevels) {
-                out.writeVInt(levels);
+            if(levels > 0) {
+                builder.field(PRECISION, levels);
             }
-            out.writeBoolean(neighbors);
-        }
-
-        @Override
-        protected boolean doEquals(Builder other) {
-            return Objects.equals(fieldName, other.fieldName)
-                    && Objects.equals(geohash, other.geohash)
-                    && Objects.equals(levels, other.levels)
-                    && Objects.equals(neighbors, other.neighbors);
-        }
+            builder.field(field, geohash);
 
-        @Override
-        protected int doHashCode() {
-            return Objects.hash(fieldName, geohash, levels, neighbors);
-        }
-
-        @Override
-        public String getWriteableName() {
-            return NAME;
+            builder.endObject();
         }
     }
 
-    public static class Parser extends BaseQueryParser<Builder> {
+    public static class Parser implements QueryParser {
 
         @Inject
         public Parser() {
@@ -290,15 +182,14 @@ public class GeohashCellQuery {
         }
 
         @Override
-        public Builder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+        public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
             XContentParser parser = parseContext.parser();
 
             String fieldName = null;
             String geohash = null;
-            Integer levels = null;
-            Boolean neighbors = null;
-            String queryName = null;
-            Float boost = null;
+            int levels = -1;
+            boolean neighbors = false;
+
 
             XContentParser.Token token;
             if ((token = parser.currentToken()) != Token.START_OBJECT) {
@@ -311,31 +202,24 @@ public class GeohashCellQuery {
 
                     if (parseContext.isDeprecatedSetting(field)) {
                         // skip
-                    } else if (parseContext.parseFieldMatcher().match(field, PRECISION_FIELD)) {
+                    } else if (PRECISION.equals(field)) {
                         token = parser.nextToken();
-                        if (token == Token.VALUE_NUMBER) {
+                        if(token == Token.VALUE_NUMBER) {
                             levels = parser.intValue();
-                        } else if (token == Token.VALUE_STRING) {
+                        } else if(token == Token.VALUE_STRING) {
                             double meters = DistanceUnit.parse(parser.text(), DistanceUnit.DEFAULT, DistanceUnit.METERS);
                             levels = GeoUtils.geoHashLevelsForPrecision(meters);
                         }
-                    } else if (parseContext.parseFieldMatcher().match(field, NEIGHBORS_FIELD)) {
+                    } else if (NEIGHBORS.equals(field)) {
                         parser.nextToken();
                         neighbors = parser.booleanValue();
-                    } else if (parseContext.parseFieldMatcher().match(field, AbstractQueryBuilder.NAME_FIELD)) {
-                        parser.nextToken();
-                        queryName = parser.text();
-                    } else if (parseContext.parseFieldMatcher().match(field, AbstractQueryBuilder.BOOST_FIELD)) {
-                        parser.nextToken();
-                        boost = parser.floatValue();
                     } else {
                         fieldName = field;
                         token = parser.nextToken();
-                        if (token == Token.VALUE_STRING) {
-                            // A string indicates either a geohash or a lat/lon
-                            // string
+                        if(token == Token.VALUE_STRING) {
+                            // A string indicates either a gehash or a lat/lon string
                             String location = parser.text();
-                            if (location.indexOf(",") > 0) {
+                            if(location.indexOf(",")>0) {
                                 geohash = GeoUtils.parseGeoPoint(parser).geohash();
                             } else {
                                 geohash = location;
@@ -348,26 +232,38 @@ public class GeohashCellQuery {
                     throw new ElasticsearchParseException("failed to parse [{}] query. unexpected token [{}]", NAME, token);
                 }
             }
-            Builder builder = new Builder(fieldName);
-            builder.geohash(geohash);
-            if (levels != null) {
-                builder.precision(levels);
+
+            if (geohash == null) {
+                throw new QueryParsingException(parseContext, "failed to parse [{}] query. missing geohash value", NAME);
             }
-            if (neighbors != null) {
-                builder.neighbors(neighbors);
+
+            MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+            if (fieldType == null) {
+                throw new QueryParsingException(parseContext, "failed to parse [{}] query. missing [{}] field [{}]", NAME, GeoPointFieldMapper.CONTENT_TYPE, fieldName);
             }
-            if (queryName != null) {
-                builder.queryName(queryName);
+
+            if (!(fieldType instanceof GeoPointFieldMapper.GeoPointFieldType)) {
+                throw new QueryParsingException(parseContext, "failed to parse [{}] query. field [{}] is not a geo_point field", NAME, fieldName);
             }
-            if (boost != null) {
-                builder.boost(boost);
+
+            GeoPointFieldMapper.GeoPointFieldType geoFieldType = ((GeoPointFieldMapper.GeoPointFieldType) fieldType);
+            if (!geoFieldType.isGeohashPrefixEnabled()) {
+                throw new QueryParsingException(parseContext, "failed to parse [{}] query. [geohash_prefix] is not enabled for field [{}]", NAME, fieldName);
             }
-            return builder;
-        }
 
-        @Override
-        public GeohashCellQuery.Builder getBuilderPrototype() {
-            return Builder.PROTOTYPE;
+            if(levels > 0) {
+                int len = Math.min(levels, geohash.length());
+                geohash = geohash.substring(0, len);
+            }
+
+            Query filter;
+            if (neighbors) {
+                filter = create(parseContext, geoFieldType, geohash, GeoHashUtils.addNeighbors(geohash, new ArrayList<CharSequence>(8)));
+            } else {
+                filter = create(parseContext, geoFieldType, geohash, null);
+            }
+
+            return filter;
         }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/HasChildQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/HasChildQueryBuilder.java
index 5de9a28..58af4c4 100644
--- a/core/src/main/java/org/elasticsearch/index/query/HasChildQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/HasChildQueryBuilder.java
@@ -18,94 +18,49 @@
  */
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.MultiDocValues;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.join.JoinUtil;
-import org.apache.lucene.search.join.ScoreMode;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.fielddata.IndexParentChildFieldData;
-import org.elasticsearch.index.fielddata.plain.ParentChildIndexFieldData;
-import org.elasticsearch.index.mapper.DocumentMapper;
-import org.elasticsearch.index.mapper.internal.ParentFieldMapper;
-import org.elasticsearch.index.query.support.QueryInnerHits;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsSubSearchContext;
+import org.elasticsearch.index.query.support.QueryInnerHitBuilder;
 
 import java.io.IOException;
-import java.util.Locale;
-import java.util.Objects;
 
-/**
- * A query builder for <tt>has_child</tt> queries.
- */
-public class HasChildQueryBuilder extends AbstractQueryBuilder<HasChildQueryBuilder> {
-
-    /**
-     * The queries name
-     */
-    public static final String NAME = "has_child";
+public class HasChildQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<HasChildQueryBuilder> {
 
-    /**
-     * The default cut off point only to evaluate parent documents that contain the matching parent id terms
-     * instead of evaluating all parent docs.
-     */
-    public static final int DEFAULT_SHORT_CIRCUIT_CUTOFF = 8192;
-    /**
-     * The default maximum number of children that are required to match for the parent to be considered a match.
-     */
-    public static final int DEFAULT_MAX_CHILDREN = Integer.MAX_VALUE;
-    /**
-     * The default minimum number of children that are required to match for the parent to be considered a match.
-     */
-    public static final int DEFAULT_MIN_CHILDREN = 0;
+    private final QueryBuilder queryBuilder;
 
-    private final QueryBuilder query;
+    private String childType;
 
-    private final String type;
+    private float boost = 1.0f;
 
-    private ScoreType scoreType = ScoreType.NONE;
+    private String scoreMode;
 
-    private int minChildren = DEFAULT_MIN_CHILDREN;
+    private Integer minChildren;
 
-    private int maxChildren = DEFAULT_MAX_CHILDREN;
+    private Integer maxChildren;
 
-    private QueryInnerHits queryInnerHits;
+    private String queryName;
 
-    static final HasChildQueryBuilder PROTOTYPE = new HasChildQueryBuilder("", EmptyQueryBuilder.PROTOTYPE);
+    private QueryInnerHitBuilder innerHit = null;
 
-    public HasChildQueryBuilder(String type, QueryBuilder query, Integer maxChildren, Integer minChildren, ScoreType scoreType, QueryInnerHits queryInnerHits) {
-        this(type, query);
-        scoreType(scoreType);
-        this.maxChildren = maxChildren;
-        this.minChildren = minChildren;
-        this.queryInnerHits = queryInnerHits;
+    public HasChildQueryBuilder(String type, QueryBuilder queryBuilder) {
+        this.childType = type;
+        this.queryBuilder = queryBuilder;
     }
 
-    public HasChildQueryBuilder(String type, QueryBuilder query) {
-        if (type == null) {
-            throw new IllegalArgumentException("[" + NAME + "] requires 'type' field");
-        }
-        if (query == null) {
-            throw new IllegalArgumentException("[" + NAME + "] requires 'query' field");
-        }
-        this.type = type;
-        this.query = query;
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
+    @Override
+    public HasChildQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
      * Defines how the scores from the matching child documents are mapped into the parent document.
      */
-    public HasChildQueryBuilder scoreType(ScoreType scoreType) {
-        if (scoreType == null) {
-            throw new IllegalArgumentException("[" + NAME + "]  requires 'score_type' field");
-        }
-        this.scoreType = scoreType;
+    public HasChildQueryBuilder scoreMode(String scoreMode) {
+        this.scoreMode = scoreMode;
         return this;
     }
 
@@ -113,9 +68,6 @@ public class HasChildQueryBuilder extends AbstractQueryBuilder<HasChildQueryBuil
      * Defines the minimum number of children that are required to match for the parent to be considered a match.
      */
     public HasChildQueryBuilder minChildren(int minChildren) {
-        if (minChildren < 0) {
-            throw new IllegalArgumentException("[" + NAME + "]  requires non-negative 'min_children' field");
-        }
         this.minChildren = minChildren;
         return this;
     }
@@ -124,9 +76,6 @@ public class HasChildQueryBuilder extends AbstractQueryBuilder<HasChildQueryBuil
      * Defines the maximum number of children that are required to match for the parent to be considered a match.
      */
     public HasChildQueryBuilder maxChildren(int maxChildren) {
-        if (maxChildren < 0) {
-            throw new IllegalArgumentException("[" + NAME + "]  requires non-negative 'max_children' field");
-        }
         this.maxChildren = maxChildren;
         return this;
     }
@@ -134,273 +83,45 @@ public class HasChildQueryBuilder extends AbstractQueryBuilder<HasChildQueryBuil
     /**
      * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public HasChildQueryBuilder innerHit(QueryInnerHits queryInnerHits) {
-        this.queryInnerHits = queryInnerHits;
+    public HasChildQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
         return this;
     }
 
     /**
-     * Returns inner hit definition in the scope of this query and reusing the defined type and query.
-     */
-    public QueryInnerHits innerHit() {
-        return queryInnerHits;
-    }
-
-    /**
-     * Returns the children query to execute.
-     */
-    public QueryBuilder query() {
-        return query;
-    }
-
-    /**
-     * Returns the child type
-     */
-    public String childType() {
-        return type;
-    }
-
-    /**
-     * Returns how the scores from the matching child documents are mapped into the parent document.
-     */
-    public ScoreType scoreType() {
-        return scoreType;
-    }
-
-    /**
-     * Returns the minimum number of children that are required to match for the parent to be considered a match.
-     * The default is {@value #DEFAULT_MAX_CHILDREN}
+     * Sets inner hit definition in the scope of this query and reusing the defined type and query.
      */
-    public int minChildren() {
-        return minChildren;
+    public HasChildQueryBuilder innerHit(QueryInnerHitBuilder innerHit) {
+        this.innerHit = innerHit;
+        return this;
     }
 
-    /**
-     * Returns the maximum number of children that are required to match for the parent to be considered a match.
-     * The default is {@value #DEFAULT_MIN_CHILDREN}
-     */
-    public int maxChildren() { return maxChildren; }
-
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(HasChildQueryParser.NAME);
         builder.field("query");
-        query.toXContent(builder, params);
-        builder.field("child_type", type);
-        builder.field("score_type", scoreType.name().toLowerCase(Locale.ROOT));
-        builder.field("min_children", minChildren);
-        builder.field("max_children", maxChildren);
-        printBoostAndQueryName(builder);
-        if (queryInnerHits != null) {
-            queryInnerHits.toXContent(builder, params);
-        }
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query innerQuery = query.toQuery(context);
-        if (innerQuery == null) {
-            return null;
-        }
-        innerQuery.setBoost(boost);
-
-        DocumentMapper childDocMapper = context.mapperService().documentMapper(type);
-        if (childDocMapper == null) {
-            throw new QueryShardException(context, "[" + NAME + "] no mapping for for type [" + type + "]");
-        }
-        ParentFieldMapper parentFieldMapper = childDocMapper.parentFieldMapper();
-        if (parentFieldMapper.active() == false) {
-            throw new QueryShardException(context, "[" + NAME + "] _parent field has no parent type configured");
-        }
-        if (queryInnerHits != null) {
-            try (XContentParser parser = queryInnerHits.getXcontentParser()) {
-                XContentParser.Token token = parser.nextToken();
-                if (token != XContentParser.Token.START_OBJECT) {
-                    throw new IllegalStateException("start object expected but was: [" + token + "]");
-                }
-                InnerHitsSubSearchContext innerHits = context.indexQueryParserService().getInnerHitsQueryParserHelper().parse(parser);
-                if (innerHits != null) {
-                    ParsedQuery parsedQuery = new ParsedQuery(innerQuery, context.copyNamedQueries());
-                    InnerHitsContext.ParentChildInnerHits parentChildInnerHits = new InnerHitsContext.ParentChildInnerHits(innerHits.getSubSearchContext(), parsedQuery, null, context.mapperService(), childDocMapper);
-                    String name = innerHits.getName() != null ? innerHits.getName() : type;
-                    context.addInnerHits(name, parentChildInnerHits);
-                }
-            }
-        }
-
-        String parentType = parentFieldMapper.type();
-        DocumentMapper parentDocMapper = context.mapperService().documentMapper(parentType);
-        if (parentDocMapper == null) {
-            throw new QueryShardException(context, "[" + NAME + "] Type [" + type + "] points to a non existent parent type ["
-                    + parentType + "]");
-        }
-
-        if (maxChildren > 0 && maxChildren < minChildren) {
-            throw new QueryShardException(context, "[" + NAME + "] 'max_children' is less than 'min_children'");
-        }
-
-        // wrap the query with type query
-        innerQuery = Queries.filtered(innerQuery, childDocMapper.typeFilter());
-
-        final ParentChildIndexFieldData parentChildIndexFieldData = context.getForField(parentFieldMapper.fieldType());
-        int maxChildren = maxChildren();
-        // 0 in pre 2.x p/c impl means unbounded
-        if (maxChildren == 0) {
-            maxChildren = Integer.MAX_VALUE;
-        }
-        return new LateParsingQuery(parentDocMapper.typeFilter(), innerQuery, minChildren(), maxChildren, parentType, scoreTypeToScoreMode(scoreType), parentChildIndexFieldData);
-    }
-
-    static ScoreMode scoreTypeToScoreMode(ScoreType scoreType) {
-        ScoreMode scoreMode;
-        // TODO: move entirely over from ScoreType to org.apache.lucene.join.ScoreMode, when we drop the 1.x parent child code.
-        switch (scoreType) {
-            case NONE:
-                scoreMode = ScoreMode.None;
-                break;
-            case MIN:
-                scoreMode = ScoreMode.Min;
-                break;
-            case MAX:
-                scoreMode = ScoreMode.Max;
-                break;
-            case SUM:
-                scoreMode = ScoreMode.Total;
-                break;
-            case AVG:
-                scoreMode = ScoreMode.Avg;
-                break;
-            default:
-                throw new IllegalArgumentException("score type [" + scoreType + "] not supported");
-        }
-        return scoreMode;
-    }
-
-    final static class LateParsingQuery extends Query {
-
-        private final Query toQuery;
-        private final Query innerQuery;
-        private final int minChildren;
-        private final int maxChildren;
-        private final String parentType;
-        private final ScoreMode scoreMode;
-        private final ParentChildIndexFieldData parentChildIndexFieldData;
-
-        LateParsingQuery(Query toQuery, Query innerQuery, int minChildren, int maxChildren, String parentType, ScoreMode scoreMode, ParentChildIndexFieldData parentChildIndexFieldData) {
-            this.toQuery = toQuery;
-            this.innerQuery = innerQuery;
-            this.minChildren = minChildren;
-            this.maxChildren = maxChildren;
-            this.parentType = parentType;
-            this.scoreMode = scoreMode;
-            this.parentChildIndexFieldData = parentChildIndexFieldData;
-        }
-
-        @Override
-        public Query rewrite(IndexReader reader) throws IOException {
-            IndexSearcher indexSearcher = new IndexSearcher(reader);
-            String joinField = ParentFieldMapper.joinField(parentType);
-            IndexParentChildFieldData indexParentChildFieldData = parentChildIndexFieldData.loadGlobal(indexSearcher.getIndexReader());
-            MultiDocValues.OrdinalMap ordinalMap = ParentChildIndexFieldData.getOrdinalMap(indexParentChildFieldData, parentType);
-            return JoinUtil.createJoinQuery(joinField, innerQuery, toQuery, indexSearcher, scoreMode, ordinalMap, minChildren, maxChildren);
-        }
-
-        @Override
-        public boolean equals(Object o) {
-            if (this == o) return true;
-            if (o == null || getClass() != o.getClass()) return false;
-            if (!super.equals(o)) return false;
-
-            LateParsingQuery that = (LateParsingQuery) o;
-
-            if (minChildren != that.minChildren) return false;
-            if (maxChildren != that.maxChildren) return false;
-            if (!toQuery.equals(that.toQuery)) return false;
-            if (!innerQuery.equals(that.innerQuery)) return false;
-            if (!parentType.equals(that.parentType)) return false;
-            return scoreMode == that.scoreMode;
-        }
-
-        @Override
-        public int hashCode() {
-            int result = super.hashCode();
-            result = 31 * result + toQuery.hashCode();
-            result = 31 * result + innerQuery.hashCode();
-            result = 31 * result + minChildren;
-            result = 31 * result + maxChildren;
-            result = 31 * result + parentType.hashCode();
-            result = 31 * result + scoreMode.hashCode();
-            return result;
-        }
-
-        @Override
-        public String toString(String s) {
-            return "LateParsingQuery {parentType=" + parentType + "}";
+        queryBuilder.toXContent(builder, params);
+        builder.field("child_type", childType);
+        if (boost != 1.0f) {
+            builder.field("boost", boost);
         }
-
-        public int getMinChildren() {
-            return minChildren;
+        if (scoreMode != null) {
+            builder.field("score_mode", scoreMode);
         }
-
-        public int getMaxChildren() {
-            return maxChildren;
+        if (minChildren != null) {
+            builder.field("min_children", minChildren);
         }
-
-        public ScoreMode getScoreMode() {
-            return scoreMode;
+        if (maxChildren != null) {
+            builder.field("max_children", maxChildren);
         }
-    }
-
-    @Override
-    protected boolean doEquals(HasChildQueryBuilder that) {
-        return Objects.equals(query, that.query)
-                && Objects.equals(type, that.type)
-                && Objects.equals(scoreType, that.scoreType)
-                && Objects.equals(minChildren, that.minChildren)
-                && Objects.equals(maxChildren, that.maxChildren)
-                && Objects.equals(queryInnerHits, that.queryInnerHits);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(query, type, scoreType, minChildren, maxChildren, queryInnerHits);
-    }
-
-    protected HasChildQueryBuilder(StreamInput in) throws IOException {
-        type = in.readString();
-        minChildren = in.readInt();
-        maxChildren = in.readInt();
-        final int ordinal = in.readVInt();
-        scoreType = ScoreType.values()[ordinal];
-        query = in.readQuery();
-        if (in.readBoolean()) {
-            queryInnerHits = new QueryInnerHits(in);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-    }
-
-    @Override
-    protected HasChildQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new HasChildQueryBuilder(in);
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(type);
-        out.writeInt(minChildren());
-        out.writeInt(maxChildren());
-        out.writeVInt(scoreType.ordinal());
-        out.writeQuery(query);
-        if (queryInnerHits != null) {
-            out.writeBoolean(true);
-            queryInnerHits.writeTo(out);
-        } else {
-            out.writeBoolean(false);
+        if (innerHit != null) {
+            builder.startObject("inner_hits");
+            builder.value(innerHit);
+            builder.endObject();
         }
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/HasChildQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/HasChildQueryParser.java
index 8ade023..6a89647 100644
--- a/core/src/main/java/org/elasticsearch/index/query/HasChildQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/HasChildQueryParser.java
@@ -19,58 +19,87 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.MultiDocValues;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.join.JoinUtil;
+import org.apache.lucene.search.join.ScoreMode;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.Strings;
+import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.support.QueryInnerHits;
+import org.elasticsearch.index.fielddata.IndexParentChildFieldData;
+import org.elasticsearch.index.fielddata.plain.ParentChildIndexFieldData;
+import org.elasticsearch.index.mapper.DocumentMapper;
+import org.elasticsearch.index.mapper.internal.ParentFieldMapper;
+import org.elasticsearch.index.query.support.InnerHitsQueryParserHelper;
+import org.elasticsearch.index.query.support.XContentStructure;
+import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
+import org.elasticsearch.search.fetch.innerhits.InnerHitsSubSearchContext;
 
 import java.io.IOException;
 
 /**
- * A query parser for <tt>has_child</tt> queries.
+ *
  */
-public class HasChildQueryParser extends BaseQueryParser {
+public class HasChildQueryParser implements QueryParser {
 
+    public static final String NAME = "has_child";
     private static final ParseField QUERY_FIELD = new ParseField("query", "filter");
 
+    private final InnerHitsQueryParserHelper innerHitsQueryParserHelper;
+
+    @Inject
+    public HasChildQueryParser(InnerHitsQueryParserHelper innerHitsQueryParserHelper) {
+        this.innerHitsQueryParserHelper = innerHitsQueryParserHelper;
+    }
+
     @Override
     public String[] names() {
-        return new String[] { HasChildQueryBuilder.NAME, Strings.toCamelCase(HasChildQueryBuilder.NAME) };
+        return new String[] { NAME, Strings.toCamelCase(NAME) };
     }
 
     @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+
+        boolean queryFound = false;
+        float boost = 1.0f;
         String childType = null;
-        ScoreType scoreType = ScoreType.NONE;
-        int minChildren = HasChildQueryBuilder.DEFAULT_MIN_CHILDREN;
-        int maxChildren = HasChildQueryBuilder.DEFAULT_MAX_CHILDREN;
+        ScoreMode scoreMode = ScoreMode.None;
+        int minChildren = 0;
+        int maxChildren = Integer.MAX_VALUE;
         String queryName = null;
-        QueryInnerHits queryInnerHits = null;
+        InnerHitsSubSearchContext innerHits = null;
+
         String currentFieldName = null;
         XContentParser.Token token;
-        QueryBuilder iqb = null;
+        XContentStructure.InnerQuery iq = null;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
             } else if (parseContext.isDeprecatedSetting(currentFieldName)) {
                 // skip
             } else if (token == XContentParser.Token.START_OBJECT) {
+                // Usually, the query would be parsed here, but the child
+                // type may not have been extracted yet, so use the
+                // XContentStructure.<type> facade to parse if available,
+                // or delay parsing if not.
                 if (parseContext.parseFieldMatcher().match(currentFieldName, QUERY_FIELD)) {
-                    iqb = parseContext.parseInnerQueryBuilder();
+                    iq = new XContentStructure.InnerQuery(parseContext, childType == null ? null : new String[] { childType });
+                    queryFound = true;
                 } else if ("inner_hits".equals(currentFieldName)) {
-                    queryInnerHits = new QueryInnerHits(parser);
+                    innerHits = innerHitsQueryParserHelper.parse(parseContext);
                 } else {
                     throw new QueryParsingException(parseContext, "[has_child] query does not support [" + currentFieldName + "]");
                 }
             } else if (token.isValue()) {
                 if ("type".equals(currentFieldName) || "child_type".equals(currentFieldName) || "childType".equals(currentFieldName)) {
                     childType = parser.text();
-                } else if ("score_type".equals(currentFieldName) || "scoreType".equals(currentFieldName)) {
-                    scoreType = ScoreType.fromString(parser.text());
                 } else if ("score_mode".equals(currentFieldName) || "scoreMode".equals(currentFieldName)) {
-                    scoreType = ScoreType.fromString(parser.text());
+                    scoreMode = parseScoreMode(parser.text());
                 } else if ("boost".equals(currentFieldName)) {
                     boost = parser.floatValue();
                 } else if ("min_children".equals(currentFieldName) || "minChildren".equals(currentFieldName)) {
@@ -84,14 +113,137 @@ public class HasChildQueryParser extends BaseQueryParser {
                 }
             }
         }
-        HasChildQueryBuilder hasChildQueryBuilder = new HasChildQueryBuilder(childType, iqb, maxChildren, minChildren, scoreType, queryInnerHits);
-        hasChildQueryBuilder.queryName(queryName);
-        hasChildQueryBuilder.boost(boost);
-        return hasChildQueryBuilder;
+        if (!queryFound) {
+            throw new QueryParsingException(parseContext, "[has_child] requires 'query' field");
+        }
+        if (childType == null) {
+            throw new QueryParsingException(parseContext, "[has_child] requires 'type' field");
+        }
+
+        Query innerQuery = iq.asQuery(childType);
+
+        if (innerQuery == null) {
+            return null;
+        }
+        innerQuery.setBoost(boost);
+
+        DocumentMapper childDocMapper = parseContext.mapperService().documentMapper(childType);
+        if (childDocMapper == null) {
+            throw new QueryParsingException(parseContext, "[has_child] No mapping for for type [" + childType + "]");
+        }
+        ParentFieldMapper parentFieldMapper = childDocMapper.parentFieldMapper();
+        if (parentFieldMapper.active() == false) {
+            throw new QueryParsingException(parseContext, "[has_child] _parent field has no parent type configured");
+        }
+
+        if (innerHits != null) {
+            ParsedQuery parsedQuery = new ParsedQuery(innerQuery, parseContext.copyNamedQueries());
+            InnerHitsContext.ParentChildInnerHits parentChildInnerHits = new InnerHitsContext.ParentChildInnerHits(innerHits.getSubSearchContext(), parsedQuery, null, parseContext.mapperService(), childDocMapper);
+            String name = innerHits.getName() != null ? innerHits.getName() : childType;
+            parseContext.addInnerHits(name, parentChildInnerHits);
+        }
+
+        String parentType = parentFieldMapper.type();
+        DocumentMapper parentDocMapper = parseContext.mapperService().documentMapper(parentType);
+        if (parentDocMapper == null) {
+            throw new QueryParsingException(parseContext, "[has_child]  Type [" + childType + "] points to a non existent parent type ["
+                    + parentType + "]");
+        }
+
+        if (maxChildren > 0 && maxChildren < minChildren) {
+            throw new QueryParsingException(parseContext, "[has_child] 'max_children' is less than 'min_children'");
+        }
+
+        // wrap the query with type query
+        innerQuery = Queries.filtered(innerQuery, childDocMapper.typeFilter());
+
+        final Query query;
+        final ParentChildIndexFieldData parentChildIndexFieldData = parseContext.getForField(parentFieldMapper.fieldType());
+        query = joinUtilHelper(parentType, parentChildIndexFieldData, parentDocMapper.typeFilter(), scoreMode, innerQuery, minChildren, maxChildren);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        query.setBoost(boost);
+        return query;
     }
 
-    @Override
-    public HasChildQueryBuilder getBuilderPrototype() {
-        return HasChildQueryBuilder.PROTOTYPE;
+    public static Query joinUtilHelper(String parentType, ParentChildIndexFieldData parentChildIndexFieldData, Query toQuery, ScoreMode scoreMode, Query innerQuery, int minChildren, int maxChildren) throws IOException {
+        return new LateParsingQuery(toQuery, innerQuery, minChildren, maxChildren, parentType, scoreMode, parentChildIndexFieldData);
+    }
+
+    public static ScoreMode parseScoreMode(String scoreModeString) {
+        if ("none".equals(scoreModeString)) {
+            return ScoreMode.None;
+        } else if ("min".equals(scoreModeString)) {
+            return ScoreMode.Min;
+        } else if ("max".equals(scoreModeString)) {
+            return ScoreMode.Max;
+        } else if ("avg".equals(scoreModeString)) {
+            return ScoreMode.Avg;
+        } else if ("total".equals(scoreModeString)) {
+            return ScoreMode.Total;
+        }
+        throw new IllegalArgumentException("No score mode for child query [" + scoreModeString + "] found");
+    }
+
+    final static class LateParsingQuery extends Query {
+
+        private final Query toQuery;
+        private final Query innerQuery;
+        private final int minChildren;
+        private final int maxChildren;
+        private final String parentType;
+        private final ScoreMode scoreMode;
+        private final ParentChildIndexFieldData parentChildIndexFieldData;
+        private final Object identity = new Object();
+
+        LateParsingQuery(Query toQuery, Query innerQuery, int minChildren, int maxChildren, String parentType, ScoreMode scoreMode, ParentChildIndexFieldData parentChildIndexFieldData) {
+            this.toQuery = toQuery;
+            this.innerQuery = innerQuery;
+            this.minChildren = minChildren;
+            this.maxChildren = maxChildren;
+            this.parentType = parentType;
+            this.scoreMode = scoreMode;
+            this.parentChildIndexFieldData = parentChildIndexFieldData;
+        }
+
+        @Override
+        public Query rewrite(IndexReader reader) throws IOException {
+            if (getBoost() != 1.0F) {
+                return super.rewrite(reader);
+            }
+            String joinField = ParentFieldMapper.joinField(parentType);
+            IndexSearcher indexSearcher = new IndexSearcher(reader);
+            indexSearcher.setQueryCache(null);
+            IndexParentChildFieldData indexParentChildFieldData = parentChildIndexFieldData.loadGlobal(indexSearcher.getIndexReader());
+            MultiDocValues.OrdinalMap ordinalMap = ParentChildIndexFieldData.getOrdinalMap(indexParentChildFieldData, parentType);
+            return JoinUtil.createJoinQuery(joinField, innerQuery, toQuery, indexSearcher, scoreMode, ordinalMap, minChildren, maxChildren);
+        }
+
+        // Even though we only cache rewritten queries it is good to let all queries implement hashCode() and equals():
+
+        // We can't check for actually equality here, since we need to IndexReader for this, but
+        // that isn't available on all cases during query parse time, so instead rely on identity:
+        @Override
+        public boolean equals(Object o) {
+            if (this == o) return true;
+            if (o == null || getClass() != o.getClass()) return false;
+            if (!super.equals(o)) return false;
+
+            LateParsingQuery that = (LateParsingQuery) o;
+            return identity.equals(that.identity);
+        }
+
+        @Override
+        public int hashCode() {
+            int result = super.hashCode();
+            result = 31 * result + identity.hashCode();
+            return result;
+        }
+
+        @Override
+        public String toString(String s) {
+            return "LateParsingQuery {parentType=" + parentType + "}";
+        }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/HasParentQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/HasParentQueryBuilder.java
index 8bcdff9..15868fe 100644
--- a/core/src/main/java/org/elasticsearch/index/query/HasParentQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/HasParentQueryBuilder.java
@@ -18,231 +18,83 @@
  */
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.*;
-import org.apache.lucene.search.join.ScoreMode;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.fielddata.plain.ParentChildIndexFieldData;
-import org.elasticsearch.index.mapper.DocumentMapper;
-import org.elasticsearch.index.mapper.internal.ParentFieldMapper;
-import org.elasticsearch.index.query.support.QueryInnerHits;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsSubSearchContext;
+import org.elasticsearch.index.query.support.QueryInnerHitBuilder;
 
 import java.io.IOException;
-import java.util.HashSet;
-import java.util.Objects;
-import java.util.Set;
 
 /**
  * Builder for the 'has_parent' query.
  */
-public class HasParentQueryBuilder extends AbstractQueryBuilder<HasParentQueryBuilder> {
+public class HasParentQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<HasParentQueryBuilder> {
 
-    public static final String NAME = "has_parent";
-    private final QueryBuilder query;
-    private final String type;
-    private boolean score = false;
-    private QueryInnerHits innerHit;
+    private final QueryBuilder queryBuilder;
+    private final String parentType;
+    private String scoreMode;
+    private float boost = 1.0f;
+    private String queryName;
+    private QueryInnerHitBuilder innerHit = null;
 
     /**
-     * @param type  The parent type
-     * @param query The query that will be matched with parent documents
+     * @param parentType  The parent type
+     * @param parentQuery The query that will be matched with parent documents
      */
-    public HasParentQueryBuilder(String type, QueryBuilder query) {
-        if (type == null) {
-            throw new IllegalArgumentException("[" + NAME + "] requires 'parent_type' field");
-        }
-        if (query == null) {
-            throw new IllegalArgumentException("[" + NAME + "] requires 'query' field");
-        }
-        this.type = type;
-        this.query = query;
-    }
-
-    public HasParentQueryBuilder(String type, QueryBuilder query, boolean score, QueryInnerHits innerHits) {
-        this(type, query);
-        this.score = score;
-        this.innerHit = innerHits;
+    public HasParentQueryBuilder(String parentType, QueryBuilder parentQuery) {
+        this.parentType = parentType;
+        this.queryBuilder = parentQuery;
     }
 
-    /**
-     * Defines if the parent score is mapped into the child documents.
-     */
-    public HasParentQueryBuilder score(boolean score) {
-        this.score = score;
+    @Override
+    public HasParentQueryBuilder boost(float boost) {
+        this.boost = boost;
         return this;
     }
 
     /**
-     * Sets inner hit definition in the scope of this query and reusing the defined type and query.
+     * Defines how the parent score is mapped into the child documents.
      */
-    public HasParentQueryBuilder innerHit(QueryInnerHits innerHit) {
-        this.innerHit = innerHit;
+    public HasParentQueryBuilder scoreMode(String scoreMode) {
+        this.scoreMode = scoreMode;
         return this;
     }
 
     /**
-     * Returns the query to execute.
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public QueryBuilder query() {
-        return query;
-    }
-
-    /**
-     * Returns <code>true</code> if the parent score is mapped into the child documents
-     */
-    public boolean score() {
-        return score;
-    }
-
-    /**
-     * Returns the parents type name
-     */
-    public String type() {
-        return type;
+    public HasParentQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     /**
-     *  Returns inner hit definition in the scope of this query and reusing the defined type and query.
+     * Sets inner hit definition in the scope of this query and reusing the defined type and query.
      */
-    public QueryInnerHits innerHit() {
-        return innerHit;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query innerQuery = query.toQuery(context);
-        if (innerQuery == null) {
-            return null;
-        }
-        innerQuery.setBoost(boost);
-        DocumentMapper parentDocMapper = context.mapperService().documentMapper(type);
-        if (parentDocMapper == null) {
-            throw new QueryParsingException(context.parseContext(), "[has_parent] query configured 'parent_type' [" + type
-                    + "] is not a valid type");
-        }
-
-        if (innerHit != null) {
-            try (XContentParser parser = innerHit.getXcontentParser()) {
-                XContentParser.Token token = parser.nextToken();
-                if (token != XContentParser.Token.START_OBJECT) {
-                    throw new IllegalStateException("start object expected but was: [" + token + "]");
-                }
-                InnerHitsSubSearchContext innerHits = context.indexQueryParserService().getInnerHitsQueryParserHelper().parse(parser);
-                if (innerHits != null) {
-                    ParsedQuery parsedQuery = new ParsedQuery(innerQuery, context.copyNamedQueries());
-                    InnerHitsContext.ParentChildInnerHits parentChildInnerHits = new InnerHitsContext.ParentChildInnerHits(innerHits.getSubSearchContext(), parsedQuery, null, context.mapperService(), parentDocMapper);
-                    String name = innerHits.getName() != null ? innerHits.getName() : type;
-                    context.addInnerHits(name, parentChildInnerHits);
-                }
-            }
-        }
-
-        Set<String> parentTypes = new HashSet<>(5);
-        parentTypes.add(parentDocMapper.type());
-        ParentChildIndexFieldData parentChildIndexFieldData = null;
-        for (DocumentMapper documentMapper : context.mapperService().docMappers(false)) {
-            ParentFieldMapper parentFieldMapper = documentMapper.parentFieldMapper();
-            if (parentFieldMapper.active()) {
-                DocumentMapper parentTypeDocumentMapper = context.mapperService().documentMapper(parentFieldMapper.type());
-                parentChildIndexFieldData = context.getForField(parentFieldMapper.fieldType());
-                if (parentTypeDocumentMapper == null) {
-                    // Only add this, if this parentFieldMapper (also a parent)  isn't a child of another parent.
-                    parentTypes.add(parentFieldMapper.type());
-                }
-            }
-        }
-        if (parentChildIndexFieldData == null) {
-            throw new QueryParsingException(context.parseContext(), "[has_parent] no _parent field configured");
-        }
-
-        Query parentTypeQuery = null;
-        if (parentTypes.size() == 1) {
-            DocumentMapper documentMapper = context.mapperService().documentMapper(parentTypes.iterator().next());
-            if (documentMapper != null) {
-                parentTypeQuery = documentMapper.typeFilter();
-            }
-        } else {
-            BooleanQuery.Builder parentsFilter = new BooleanQuery.Builder();
-            for (String parentTypeStr : parentTypes) {
-                DocumentMapper documentMapper = context.mapperService().documentMapper(parentTypeStr);
-                if (documentMapper != null) {
-                    parentsFilter.add(documentMapper.typeFilter(), BooleanClause.Occur.SHOULD);
-                }
-            }
-            parentTypeQuery = parentsFilter.build();
-        }
-
-        if (parentTypeQuery == null) {
-            return null;
-        }
-
-        // wrap the query with type query
-        innerQuery = Queries.filtered(innerQuery, parentDocMapper.typeFilter());
-        Query childrenFilter = Queries.not(parentTypeQuery);
-        return new HasChildQueryBuilder.LateParsingQuery(childrenFilter, innerQuery, HasChildQueryBuilder.DEFAULT_MIN_CHILDREN, HasChildQueryBuilder.DEFAULT_MAX_CHILDREN, type, score ? ScoreMode.Max : ScoreMode.None, parentChildIndexFieldData);
+    public HasParentQueryBuilder innerHit(QueryInnerHitBuilder innerHit) {
+        this.innerHit = innerHit;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(HasParentQueryParser.NAME);
         builder.field("query");
-        query.toXContent(builder, params);
-        builder.field("parent_type", type);
-        builder.field("score", score);
-        printBoostAndQueryName(builder);
-        if (innerHit != null) {
-           innerHit.toXContent(builder, params);
+        queryBuilder.toXContent(builder, params);
+        builder.field("parent_type", parentType);
+        if (scoreMode != null) {
+            builder.field("score_mode", scoreMode);
         }
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    protected HasParentQueryBuilder(StreamInput in) throws IOException {
-        type = in.readString();
-        score = in.readBoolean();
-        query = in.readQuery();
-        if (in.readBoolean()) {
-            innerHit = new QueryInnerHits(in);
+        if (boost != 1.0f) {
+            builder.field("boost", boost);
+        }
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-    }
-
-    @Override
-    protected HasParentQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new HasParentQueryBuilder(in);
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(type);
-        out.writeBoolean(score);
-        out.writeQuery(query);
         if (innerHit != null) {
-            out.writeBoolean(true);
-            innerHit.writeTo(out);
-        } else {
-            out.writeBoolean(false);
+            builder.startObject("inner_hits");
+            builder.value(innerHit);
+            builder.endObject();
         }
+        builder.endObject();
     }
+}
 
-    @Override
-    protected boolean doEquals(HasParentQueryBuilder that) {
-        return Objects.equals(query, that.query)
-                && Objects.equals(type, that.type)
-                && Objects.equals(score, that.score)
-                && Objects.equals(innerHit, that.innerHit);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(query, type, score, innerHit);
-    }
-}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/HasParentQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/HasParentQueryParser.java
index 4fad3eb..9988496 100644
--- a/core/src/main/java/org/elasticsearch/index/query/HasParentQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/HasParentQueryParser.java
@@ -18,39 +18,58 @@
  */
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.*;
+import org.apache.lucene.search.join.ScoreMode;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.Strings;
+import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.support.QueryInnerHits;
+import org.elasticsearch.index.fielddata.plain.ParentChildIndexFieldData;
+import org.elasticsearch.index.mapper.DocumentMapper;
+import org.elasticsearch.index.mapper.internal.ParentFieldMapper;
+import org.elasticsearch.index.query.support.InnerHitsQueryParserHelper;
+import org.elasticsearch.index.query.support.XContentStructure;
+import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
+import org.elasticsearch.search.fetch.innerhits.InnerHitsSubSearchContext;
 
 import java.io.IOException;
+import java.util.HashSet;
+import java.util.Set;
 
+import static org.elasticsearch.index.query.HasChildQueryParser.joinUtilHelper;
 
-public class HasParentQueryParser extends BaseQueryParser  {
+public class HasParentQueryParser implements QueryParser {
 
-    private static final HasParentQueryBuilder PROTOTYPE = new HasParentQueryBuilder("", EmptyQueryBuilder.PROTOTYPE);
+    public static final String NAME = "has_parent";
     private static final ParseField QUERY_FIELD = new ParseField("query", "filter");
-    private static final ParseField SCORE_FIELD = new ParseField("score_type", "score_mode").withAllDeprecated("score");
-    private static final ParseField TYPE_FIELD = new ParseField("parent_type", "type");
+
+    private final InnerHitsQueryParserHelper innerHitsQueryParserHelper;
+
+    @Inject
+    public HasParentQueryParser(InnerHitsQueryParserHelper innerHitsQueryParserHelper) {
+        this.innerHitsQueryParserHelper = innerHitsQueryParserHelper;
+    }
 
     @Override
     public String[] names() {
-        return new String[]{HasParentQueryBuilder.NAME, Strings.toCamelCase(HasParentQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        boolean queryFound = false;
+        float boost = 1.0f;
         String parentType = null;
         boolean score = false;
         String queryName = null;
-        QueryInnerHits innerHits = null;
+        InnerHitsSubSearchContext innerHits = null;
 
         String currentFieldName = null;
         XContentParser.Token token;
-        QueryBuilder iqb = null;
+        XContentStructure.InnerQuery iq = null;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
@@ -60,25 +79,23 @@ public class HasParentQueryParser extends BaseQueryParser  {
                 // XContentStructure.<type> facade to parse if available,
                 // or delay parsing if not.
                 if (parseContext.parseFieldMatcher().match(currentFieldName, QUERY_FIELD)) {
-                    iqb = parseContext.parseInnerQueryBuilder();
+                    iq = new XContentStructure.InnerQuery(parseContext, parentType == null ? null : new String[] {parentType});
+                    queryFound = true;
                 } else if ("inner_hits".equals(currentFieldName)) {
-                    innerHits = new QueryInnerHits(parser);
+                    innerHits = innerHitsQueryParserHelper.parse(parseContext);
                 } else {
                     throw new QueryParsingException(parseContext, "[has_parent] query does not support [" + currentFieldName + "]");
                 }
             } else if (token.isValue()) {
-                if (parseContext.parseFieldMatcher().match(currentFieldName, TYPE_FIELD)) {
+                if ("type".equals(currentFieldName) || "parent_type".equals(currentFieldName) || "parentType".equals(currentFieldName)) {
                     parentType = parser.text();
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, SCORE_FIELD)) {
-                    // deprecated we use a boolean now
-                    String scoreTypeValue = parser.text();
-                    if ("score".equals(scoreTypeValue)) {
+                } else if ("score_mode".equals(currentFieldName) || "scoreMode".equals(currentFieldName)) {
+                    String scoreModeValue = parser.text();
+                    if ("score".equals(scoreModeValue)) {
                         score = true;
-                    } else if ("none".equals(scoreTypeValue)) {
+                    } else if ("none".equals(scoreModeValue)) {
                         score = false;
                     }
-                } else if ("score".equals(currentFieldName)) {
-                    score = parser.booleanValue();
                 } else if ("boost".equals(currentFieldName)) {
                     boost = parser.floatValue();
                 } else if ("_name".equals(currentFieldName)) {
@@ -88,11 +105,90 @@ public class HasParentQueryParser extends BaseQueryParser  {
                 }
             }
         }
-        return new HasParentQueryBuilder(parentType, iqb, score, innerHits).queryName(queryName).boost(boost);
+        if (!queryFound) {
+            throw new QueryParsingException(parseContext, "[has_parent] query requires 'query' field");
+        }
+        if (parentType == null) {
+            throw new QueryParsingException(parseContext, "[has_parent] query requires 'parent_type' field");
+        }
+
+        Query innerQuery = iq.asQuery(parentType);
+
+        if (innerQuery == null) {
+            return null;
+        }
+
+        innerQuery.setBoost(boost);
+        Query query = createParentQuery(innerQuery, parentType, score, parseContext, innerHits);
+        if (query == null) {
+            return null;
+        }
+
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 
-    @Override
-    public HasParentQueryBuilder getBuilderPrototype() {
-        return PROTOTYPE;
+    static Query createParentQuery(Query innerQuery, String parentType, boolean score, QueryParseContext parseContext, InnerHitsSubSearchContext innerHits) throws IOException {
+        DocumentMapper parentDocMapper = parseContext.mapperService().documentMapper(parentType);
+        if (parentDocMapper == null) {
+            throw new QueryParsingException(parseContext, "[has_parent] query configured 'parent_type' [" + parentType
+                    + "] is not a valid type");
+        }
+
+        if (innerHits != null) {
+            ParsedQuery parsedQuery = new ParsedQuery(innerQuery, parseContext.copyNamedQueries());
+            InnerHitsContext.ParentChildInnerHits parentChildInnerHits = new InnerHitsContext.ParentChildInnerHits(innerHits.getSubSearchContext(), parsedQuery, null, parseContext.mapperService(), parentDocMapper);
+            String name = innerHits.getName() != null ? innerHits.getName() : parentType;
+            parseContext.addInnerHits(name, parentChildInnerHits);
+        }
+
+        Set<String> parentTypes = new HashSet<>(5);
+        parentTypes.add(parentDocMapper.type());
+        ParentChildIndexFieldData parentChildIndexFieldData = null;
+        for (DocumentMapper documentMapper : parseContext.mapperService().docMappers(false)) {
+            ParentFieldMapper parentFieldMapper = documentMapper.parentFieldMapper();
+            if (parentFieldMapper.active()) {
+                DocumentMapper parentTypeDocumentMapper = parseContext.mapperService().documentMapper(parentFieldMapper.type());
+                parentChildIndexFieldData = parseContext.getForField(parentFieldMapper.fieldType());
+                if (parentTypeDocumentMapper == null) {
+                    // Only add this, if this parentFieldMapper (also a parent)  isn't a child of another parent.
+                    parentTypes.add(parentFieldMapper.type());
+                }
+            }
+        }
+        if (parentChildIndexFieldData == null) {
+            throw new QueryParsingException(parseContext, "[has_parent] no _parent field configured");
+        }
+
+        Query parentTypeQuery = null;
+        if (parentTypes.size() == 1) {
+            DocumentMapper documentMapper = parseContext.mapperService().documentMapper(parentTypes.iterator().next());
+            if (documentMapper != null) {
+                parentTypeQuery = documentMapper.typeFilter();
+            }
+        } else {
+            BooleanQuery.Builder parentsFilter = new BooleanQuery.Builder();
+            for (String parentTypeStr : parentTypes) {
+                DocumentMapper documentMapper = parseContext.mapperService().documentMapper(parentTypeStr);
+                if (documentMapper != null) {
+                    parentsFilter.add(documentMapper.typeFilter(), BooleanClause.Occur.SHOULD);
+                }
+            }
+            parentTypeQuery = parentsFilter.build();
+        }
+
+        if (parentTypeQuery == null) {
+            return null;
+        }
+
+        // wrap the query with type query
+        innerQuery = Queries.filtered(innerQuery, parentDocMapper.typeFilter());
+        Query childrenFilter = Queries.not(parentTypeQuery);
+        ScoreMode scoreMode = score ? ScoreMode.Max : ScoreMode.None;
+        return joinUtilHelper(parentType, parentChildIndexFieldData, childrenFilter, scoreMode, innerQuery, 0, Integer.MAX_VALUE);
     }
+
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java
index 461a800..02c2a17 100644
--- a/core/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java
@@ -19,62 +19,44 @@
 
 package org.elasticsearch.index.query;
 
-import com.google.common.collect.Sets;
-
-import org.apache.lucene.queries.TermsQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.cluster.metadata.MetaData;
-import org.elasticsearch.common.Nullable;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.Uid;
-import org.elasticsearch.index.mapper.internal.UidFieldMapper;
 
 import java.io.IOException;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.List;
 
 /**
  * A query that will return only documents matching specific ids (and a type).
  */
-public class IdsQueryBuilder extends AbstractQueryBuilder<IdsQueryBuilder> {
+public class IdsQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<IdsQueryBuilder> {
 
-    public static final String NAME = "ids";
+    private final List<String> types;
 
-    private final Set<String> ids = Sets.newHashSet();
+    private List<String> values = new ArrayList<>();
 
-    private final String[] types;
+    private float boost = -1;
 
-    static final IdsQueryBuilder PROTOTYPE = new IdsQueryBuilder();
+    private String queryName;
 
-    /**
-     * Creates a new IdsQueryBuilder by optionally providing the types of the documents to look for
-     */
-    public IdsQueryBuilder(@Nullable String... types) {
-        this.types = types;
-    }
-
-    /**
-     * Returns the types used in this query
-     */
-    public String[] types() {
-        return this.types;
+    public IdsQueryBuilder(String... types) {
+        this.types = types == null ? null : Arrays.asList(types);
     }
 
     /**
-     * Adds ids to the query.
+     * Adds ids to the filter.
      */
     public IdsQueryBuilder addIds(String... ids) {
-        Collections.addAll(this.ids, ids);
+        values.addAll(Arrays.asList(ids));
         return this;
     }
 
     /**
-     * Adds ids to the query.
+     * Adds ids to the filter.
      */
     public IdsQueryBuilder addIds(Collection<String> ids) {
-        this.ids.addAll(ids);
+        values.addAll(ids);
         return this;
     }
 
@@ -93,83 +75,48 @@ public class IdsQueryBuilder extends AbstractQueryBuilder<IdsQueryBuilder> {
     }
 
     /**
-     * Returns the ids for the query.
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
      */
-    public Set<String> ids() {
-        return this.ids;
+    @Override
+    public IdsQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public IdsQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(IdsQueryParser.NAME);
         if (types != null) {
-            if (types.length == 1) {
-                builder.field("type", types[0]);
+            if (types.size() == 1) {
+                builder.field("type", types.get(0));
             } else {
-                builder.array("types", types);
+                builder.startArray("types");
+                for (Object type : types) {
+                    builder.value(type);
+                }
+                builder.endArray();
             }
         }
         builder.startArray("values");
-        for (String value : ids) {
+        for (Object value : values) {
             builder.value(value);
         }
         builder.endArray();
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query query;
-        if (this.ids.isEmpty()) {
-             query = Queries.newMatchNoDocsQuery();
-        } else {
-            Collection<String> typesForQuery;
-            if (types == null || types.length == 0) {
-                typesForQuery = context.queryTypes();
-            } else if (types.length == 1 && MetaData.ALL.equals(types[0])) {
-                typesForQuery = context.mapperService().types();
-            } else {
-                typesForQuery = Sets.newHashSet(types);
-            }
-
-            query = new TermsQuery(UidFieldMapper.NAME, Uid.createUidsForTypesAndIds(typesForQuery, ids));
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        return query;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        // all fields can be empty or null
-        return null;
-    }
-
-    @Override
-    protected IdsQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        IdsQueryBuilder idsQueryBuilder = new IdsQueryBuilder(in.readStringArray());
-        idsQueryBuilder.addIds(in.readStringArray());
-        return idsQueryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeStringArray(types);
-        out.writeStringArray(ids.toArray(new String[ids.size()]));
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(ids, Arrays.hashCode(types));
-    }
-
-    @Override
-    protected boolean doEquals(IdsQueryBuilder other) {
-        return Objects.equals(ids, other.ids) &&
-               Arrays.equals(types, other.types);
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/IdsQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/IdsQueryParser.java
index 6612140..dcbb19f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/IdsQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/IdsQueryParser.java
@@ -19,18 +19,29 @@
 
 package org.elasticsearch.index.query;
 
+import com.google.common.collect.Iterables;
+
+import org.apache.lucene.queries.TermsQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.Uid;
+import org.elasticsearch.index.mapper.internal.UidFieldMapper;
 
 import java.io.IOException;
 import java.util.ArrayList;
+import java.util.Collection;
 import java.util.Collections;
 import java.util.List;
 
 /**
- * Parser for ids query
+ *
  */
-public class IdsQueryParser extends BaseQueryParser<IdsQueryBuilder> {
+public class IdsQueryParser implements QueryParser {
+
+    public static final String NAME = "ids";
 
     @Inject
     public IdsQueryParser() {
@@ -38,21 +49,18 @@ public class IdsQueryParser extends BaseQueryParser<IdsQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{IdsQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
-    /**
-     * @return a QueryBuilder representation of the query passed in as XContent in the parse context
-     */
     @Override
-    public IdsQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
-        List<String> ids = new ArrayList<>();
-        List<String> types = new ArrayList<>();
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        String queryName = null;
 
+        List<BytesRef> ids = new ArrayList<>();
+        Collection<String> types = null;
         String currentFieldName = null;
+        float boost = 1.0f;
+        String queryName = null;
         XContentParser.Token token;
         boolean idsProvided = false;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -64,17 +72,18 @@ public class IdsQueryParser extends BaseQueryParser<IdsQueryBuilder> {
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                         if ((token == XContentParser.Token.VALUE_STRING) ||
                                 (token == XContentParser.Token.VALUE_NUMBER)) {
-                            String id = parser.textOrNull();
-                            if (id == null) {
+                            BytesRef value = parser.utf8BytesOrNull();
+                            if (value == null) {
                                 throw new QueryParsingException(parseContext, "No value specified for term filter");
                             }
-                            ids.add(id);
+                            ids.add(value);
                         } else {
                             throw new QueryParsingException(parseContext, "Illegal value for id, expecting a string or number, got: "
                                     + token);
                         }
                     }
                 } else if ("types".equals(currentFieldName) || "type".equals(currentFieldName)) {
+                    types = new ArrayList<>();
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                         String value = parser.textOrNull();
                         if (value == null) {
@@ -97,18 +106,26 @@ public class IdsQueryParser extends BaseQueryParser<IdsQueryBuilder> {
                 }
             }
         }
+
         if (!idsProvided) {
             throw new QueryParsingException(parseContext, "[ids] query, no ids values provided");
         }
 
-        IdsQueryBuilder query = new IdsQueryBuilder(types.toArray(new String[types.size()]));
-        query.addIds(ids.toArray(new String[ids.size()]));
-        query.boost(boost).queryName(queryName);
-        return query;
-    }
+        if (ids.isEmpty()) {
+            return Queries.newMatchNoDocsQuery();
+        }
 
-    @Override
-    public IdsQueryBuilder getBuilderPrototype() {
-        return IdsQueryBuilder.PROTOTYPE;
+        if (types == null || types.isEmpty()) {
+            types = parseContext.queryTypes();
+        } else if (types.size() == 1 && Iterables.getFirst(types, null).equals("_all")) {
+            types = parseContext.mapperService().types();
+        }
+
+        TermsQuery query = new TermsQuery(UidFieldMapper.NAME, Uid.createUidsForTypesAndIds(types, ids));
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/IndexQueryParserService.java b/core/src/main/java/org/elasticsearch/index/query/IndexQueryParserService.java
index fb7d3fd..810504a 100644
--- a/core/src/main/java/org/elasticsearch/index/query/IndexQueryParserService.java
+++ b/core/src/main/java/org/elasticsearch/index/query/IndexQueryParserService.java
@@ -22,16 +22,11 @@ package org.elasticsearch.index.query;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.util.CloseableThreadLocal;
 import org.elasticsearch.Version;
-import org.elasticsearch.action.support.IndicesOptions;
-import org.elasticsearch.client.Client;
-import org.elasticsearch.cluster.ClusterService;
-import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.ParseFieldMatcher;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.lucene.search.Queries;
-import org.elasticsearch.common.regex.Regex;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentHelper;
@@ -44,7 +39,6 @@ import org.elasticsearch.index.cache.bitset.BitsetFilterCache;
 import org.elasticsearch.index.fielddata.IndexFieldDataService;
 import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.mapper.internal.AllFieldMapper;
-import org.elasticsearch.index.query.support.InnerHitsQueryParserHelper;
 import org.elasticsearch.index.settings.IndexSettings;
 import org.elasticsearch.index.similarity.SimilarityService;
 import org.elasticsearch.indices.query.IndicesQueriesRegistry;
@@ -56,16 +50,13 @@ public class IndexQueryParserService extends AbstractIndexComponent {
 
     public static final String DEFAULT_FIELD = "index.query.default_field";
     public static final String QUERY_STRING_LENIENT = "index.query_string.lenient";
-    public static final String QUERY_STRING_ANALYZE_WILDCARD = "indices.query.query_string.analyze_wildcard";
-    public static final String QUERY_STRING_ALLOW_LEADING_WILDCARD = "indices.query.query_string.allowLeadingWildcard";
     public static final String PARSE_STRICT = "index.query.parse.strict";
     public static final String ALLOW_UNMAPPED = "index.query.parse.allow_unmapped_fields";
-    private final InnerHitsQueryParserHelper innerHitsQueryParserHelper;
 
-    private CloseableThreadLocal<QueryShardContext> cache = new CloseableThreadLocal<QueryShardContext>() {
+    private CloseableThreadLocal<QueryParseContext> cache = new CloseableThreadLocal<QueryParseContext>() {
         @Override
-        protected QueryShardContext initialValue() {
-            return new QueryShardContext(index, IndexQueryParserService.this);
+        protected QueryParseContext initialValue() {
+            return new QueryParseContext(index, IndexQueryParserService.this);
         }
     };
 
@@ -81,32 +72,22 @@ public class IndexQueryParserService extends AbstractIndexComponent {
 
     final IndexFieldDataService fieldDataService;
 
-    final ClusterService clusterService;
-
-    final IndexNameExpressionResolver indexNameExpressionResolver;
-
     final BitsetFilterCache bitsetFilterCache;
 
     private final IndicesQueriesRegistry indicesQueriesRegistry;
 
-    private final String defaultField;
-    private final boolean queryStringLenient;
-    private final boolean queryStringAnalyzeWildcard;
-    private final boolean queryStringAllowLeadingWildcard;
+    private String defaultField;
+    private boolean queryStringLenient;
     private final ParseFieldMatcher parseFieldMatcher;
     private final boolean defaultAllowUnmappedFields;
 
-    private Client client;
-
     @Inject
-    public IndexQueryParserService(Index index, @IndexSettings Settings indexSettings, Settings settings,
+    public IndexQueryParserService(Index index, @IndexSettings Settings indexSettings,
                                    IndicesQueriesRegistry indicesQueriesRegistry,
                                    ScriptService scriptService, AnalysisService analysisService,
                                    MapperService mapperService, IndexCache indexCache, IndexFieldDataService fieldDataService,
                                    BitsetFilterCache bitsetFilterCache,
-                                   @Nullable SimilarityService similarityService, ClusterService clusterService,
-                                   IndexNameExpressionResolver indexNameExpressionResolver,
-                                   InnerHitsQueryParserHelper innerHitsQueryParserHelper, Client client) {
+                                   @Nullable SimilarityService similarityService) {
         super(index, indexSettings);
         this.scriptService = scriptService;
         this.analysisService = analysisService;
@@ -115,18 +96,12 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         this.indexCache = indexCache;
         this.fieldDataService = fieldDataService;
         this.bitsetFilterCache = bitsetFilterCache;
-        this.clusterService = clusterService;
-        this.indexNameExpressionResolver = indexNameExpressionResolver;
 
         this.defaultField = indexSettings.get(DEFAULT_FIELD, AllFieldMapper.NAME);
         this.queryStringLenient = indexSettings.getAsBoolean(QUERY_STRING_LENIENT, false);
-        this.queryStringAnalyzeWildcard = settings.getAsBoolean(QUERY_STRING_ANALYZE_WILDCARD, false);
-        this.queryStringAllowLeadingWildcard = settings.getAsBoolean(QUERY_STRING_ALLOW_LEADING_WILDCARD, true);
         this.parseFieldMatcher = new ParseFieldMatcher(indexSettings);
         this.defaultAllowUnmappedFields = indexSettings.getAsBoolean(ALLOW_UNMAPPED, true);
         this.indicesQueriesRegistry = indicesQueriesRegistry;
-        this.innerHitsQueryParserHelper = innerHitsQueryParserHelper;
-        this.client = client;
     }
 
     public void close() {
@@ -137,20 +112,12 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         return this.defaultField;
     }
 
-    public boolean queryStringAnalyzeWildcard() {
-        return this.queryStringAnalyzeWildcard;
-    }
-
-    public boolean queryStringAllowLeadingWildcard() {
-        return this.queryStringAllowLeadingWildcard;
-    }
-
     public boolean queryStringLenient() {
         return this.queryStringLenient;
     }
 
-    IndicesQueriesRegistry indicesQueriesRegistry() {
-        return indicesQueriesRegistry;
+    public QueryParser queryParser(String name) {
+        return indicesQueriesRegistry.queryParsers().get(name);
     }
 
     public ParsedQuery parse(QueryBuilder queryBuilder) {
@@ -159,10 +126,10 @@ public class IndexQueryParserService extends AbstractIndexComponent {
             BytesReference bytes = queryBuilder.buildAsBytes();
             parser = XContentFactory.xContent(bytes).createParser(bytes);
             return parse(cache.get(), parser);
-        } catch (QueryShardException e) {
+        } catch (QueryParsingException e) {
             throw e;
         } catch (Exception e) {
-            throw new QueryParsingException(getShardContext().parseContext(), "Failed to parse", e);
+            throw new QueryParsingException(getParseContext(), "Failed to parse", e);
         } finally {
             if (parser != null) {
                 parser.close();
@@ -179,10 +146,10 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         try {
             parser = XContentFactory.xContent(source, offset, length).createParser(source, offset, length);
             return parse(cache.get(), parser);
-        } catch (QueryShardException e) {
+        } catch (QueryParsingException e) {
             throw e;
         } catch (Exception e) {
-            throw new QueryParsingException(getShardContext().parseContext(), "Failed to parse", e);
+            throw new QueryParsingException(getParseContext(), "Failed to parse", e);
         } finally {
             if (parser != null) {
                 parser.close();
@@ -194,8 +161,7 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         return parse(cache.get(), source);
     }
 
-    //norelease
-    public ParsedQuery parse(QueryShardContext context, BytesReference source) {
+    public ParsedQuery parse(QueryParseContext context, BytesReference source) {
         XContentParser parser = null;
         try {
             parser = XContentFactory.xContent(source).createParser(source);
@@ -203,7 +169,7 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         } catch (QueryParsingException e) {
             throw e;
         } catch (Exception e) {
-            throw new QueryParsingException(context.parseContext(), "Failed to parse", e);
+            throw new QueryParsingException(context, "Failed to parse", e);
         } finally {
             if (parser != null) {
                 parser.close();
@@ -211,15 +177,15 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         }
     }
 
-    public ParsedQuery parse(String source) throws QueryParsingException, QueryShardException {
+    public ParsedQuery parse(String source) throws QueryParsingException {
         XContentParser parser = null;
         try {
             parser = XContentFactory.xContent(source).createParser(source);
             return innerParse(cache.get(), parser);
-        } catch (QueryShardException|QueryParsingException e) {
+        } catch (QueryParsingException e) {
             throw e;
         } catch (Exception e) {
-            throw new QueryParsingException(getShardContext().parseContext(), "Failed to parse [" + source + "]", e);
+            throw new QueryParsingException(getParseContext(), "Failed to parse [" + source + "]", e);
         } finally {
             if (parser != null) {
                 parser.close();
@@ -231,12 +197,11 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         return parse(cache.get(), parser);
     }
 
-    //norelease
-    public ParsedQuery parse(QueryShardContext context, XContentParser parser) {
+    public ParsedQuery parse(QueryParseContext context, XContentParser parser) {
         try {
             return innerParse(context, parser);
         } catch (IOException e) {
-            throw new QueryParsingException(context.parseContext(), "Failed to parse", e);
+            throw new QueryParsingException(context, "Failed to parse", e);
         }
     }
 
@@ -244,12 +209,11 @@ public class IndexQueryParserService extends AbstractIndexComponent {
      * Parses an inner filter, returning null if the filter should be ignored.
      */
     @Nullable
-    //norelease
     public ParsedQuery parseInnerFilter(XContentParser parser) throws IOException {
-        QueryShardContext context = cache.get();
+        QueryParseContext context = cache.get();
         context.reset(parser);
         try {
-            Query filter = context.parseContext().parseInnerFilter();
+            Query filter = context.parseInnerFilter();
             if (filter == null) {
                 return null;
             }
@@ -260,22 +224,27 @@ public class IndexQueryParserService extends AbstractIndexComponent {
     }
 
     @Nullable
-    public QueryBuilder parseInnerQueryBuilder(QueryParseContext parseContext) throws IOException {
-        parseContext.parseFieldMatcher(parseFieldMatcher);
-        return parseContext.parseInnerQueryBuilder();
+    public Query parseInnerQuery(XContentParser parser) throws IOException {
+        QueryParseContext context = cache.get();
+        context.reset(parser);
+        try {
+            return context.parseInnerQuery();
+        } finally {
+            context.reset(null);
+        }
     }
 
     @Nullable
-    //norelease
-    public Query parseInnerQuery(QueryShardContext context) throws IOException {
-        Query query = context.parseContext().parseInnerQueryBuilder().toQuery(context);
+    public Query parseInnerQuery(QueryParseContext parseContext) throws IOException {
+        parseContext.parseFieldMatcher(parseFieldMatcher);
+        Query query = parseContext.parseInnerQuery();
         if (query == null) {
             query = Queries.newMatchNoDocsQuery();
         }
         return query;
     }
 
-    public QueryShardContext getShardContext() {
+    public QueryParseContext getParseContext() {
         return cache.get();
     }
 
@@ -307,60 +276,37 @@ public class IndexQueryParserService extends AbstractIndexComponent {
                         XContentParser qSourceParser = XContentFactory.xContent(querySource).createParser(querySource);
                         parsedQuery = parse(qSourceParser);
                     } else {
-                        throw new QueryParsingException(getShardContext().parseContext(), "request does not support [" + fieldName + "]");
+                        throw new QueryParsingException(getParseContext(), "request does not support [" + fieldName + "]");
                     }
                 }
             }
             if (parsedQuery != null) {
                 return parsedQuery;
             }
-        } catch (QueryShardException e) {
+        } catch (QueryParsingException e) {
             throw e;
         } catch (Throwable e) {
-            throw new QueryParsingException(getShardContext().parseContext(), "Failed to parse", e);
+            throw new QueryParsingException(getParseContext(), "Failed to parse", e);
         }
 
-        throw new QueryParsingException(getShardContext().parseContext(), "Required query is missing");
+        throw new QueryParsingException(getParseContext(), "Required query is missing");
     }
 
-    //norelease
-    private ParsedQuery innerParse(QueryShardContext context, XContentParser parser) throws IOException, QueryShardException {
-        context.reset(parser);
+    private ParsedQuery innerParse(QueryParseContext parseContext, XContentParser parser) throws IOException, QueryParsingException {
+        parseContext.reset(parser);
         try {
-            context.parseFieldMatcher(parseFieldMatcher);
-            return innerParse(context, context.parseContext().parseInnerQueryBuilder());
+            parseContext.parseFieldMatcher(parseFieldMatcher);
+            Query query = parseContext.parseInnerQuery();
+            if (query == null) {
+                query = Queries.newMatchNoDocsQuery();
+            }
+            return new ParsedQuery(query, parseContext.copyNamedQueries());
         } finally {
-            context.reset(null);
-        }
-    }
-
-    private static ParsedQuery innerParse(QueryShardContext context, QueryBuilder queryBuilder) throws IOException, QueryShardException {
-        Query query = queryBuilder.toQuery(context);
-        if (query == null) {
-            query = Queries.newMatchNoDocsQuery();
+            parseContext.reset(null);
         }
-        return new ParsedQuery(query, context.copyNamedQueries());
     }
 
     public ParseFieldMatcher parseFieldMatcher() {
         return parseFieldMatcher;
     }
-
-    public boolean matchesIndices(String... indices) {
-        final String[] concreteIndices = indexNameExpressionResolver.concreteIndices(clusterService.state(), IndicesOptions.lenientExpandOpen(), indices);
-        for (String index : concreteIndices) {
-            if (Regex.simpleMatch(index, this.index.name())) {
-                return true;
-            }
-        }
-        return false;
-    }
-
-    public InnerHitsQueryParserHelper getInnerHitsQueryParserHelper() {
-        return innerHitsQueryParserHelper;
-    }
-
-    public Client getClient() {
-        return client;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/IndicesQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/IndicesQueryBuilder.java
index 23e44df..7c2af81 100644
--- a/core/src/main/java/org/elasticsearch/index/query/IndicesQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/IndicesQueryBuilder.java
@@ -19,143 +19,69 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Arrays;
-import java.util.Objects;
 
 /**
  * A query that will execute the wrapped query only for the specified indices, and "match_all" when
  * it does not match those indices (by default).
  */
-public class IndicesQueryBuilder extends AbstractQueryBuilder<IndicesQueryBuilder> {
+public class IndicesQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "indices";
-
-    private final QueryBuilder innerQuery;
+    private final QueryBuilder queryBuilder;
 
     private final String[] indices;
 
-    private QueryBuilder noMatchQuery = defaultNoMatchQuery();
-
-    static final IndicesQueryBuilder PROTOTYPE = new IndicesQueryBuilder();
+    private String sNoMatchQuery;
+    private QueryBuilder noMatchQuery;
 
-    private IndicesQueryBuilder() {
-        this.innerQuery = null;
-        this.indices = null;
-    }
+    private String queryName;
 
-    public IndicesQueryBuilder(QueryBuilder innerQuery, String... indices) {
-        this.innerQuery = Objects.requireNonNull(innerQuery);
+    public IndicesQueryBuilder(QueryBuilder queryBuilder, String... indices) {
+        this.queryBuilder = queryBuilder;
         this.indices = indices;
     }
 
-    public QueryBuilder innerQuery() {
-        return this.innerQuery;
-    }
-
-    public String[] indices() {
-        return this.indices;
+    /**
+     * Sets the no match query, can either be <tt>all</tt> or <tt>none</tt>.
+     */
+    public IndicesQueryBuilder noMatchQuery(String type) {
+        this.sNoMatchQuery = type;
+        return this;
     }
 
     /**
      * Sets the query to use when it executes on an index that does not match the indices provided.
      */
     public IndicesQueryBuilder noMatchQuery(QueryBuilder noMatchQuery) {
-        this.noMatchQuery = (noMatchQuery != null) ? noMatchQuery : defaultNoMatchQuery();
+        this.noMatchQuery = noMatchQuery;
         return this;
     }
 
     /**
-     * Sets the no match query, can either be <tt>all</tt> or <tt>none</tt>.
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public IndicesQueryBuilder noMatchQuery(String type) {
-        this.noMatchQuery = IndicesQueryParser.parseNoMatchQuery(type);
+    public IndicesQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
         return this;
     }
 
-    public QueryBuilder noMatchQuery() {
-        return this.noMatchQuery;
-    }
-
-    static QueryBuilder defaultNoMatchQuery() {
-        return QueryBuilders.matchAllQuery();
-    }
-
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(IndicesQueryParser.NAME);
         builder.field("indices", indices);
         builder.field("query");
-        innerQuery.toXContent(builder, params);
-        builder.field("no_match_query");
-        noMatchQuery.toXContent(builder, params);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        if (context.matchesIndices(indices)) {
-            return innerQuery.toQuery(context);
-        }
-        return noMatchQuery.toQuery(context);
-    }
-
-    @Override
-    protected void setFinalBoost(Query query) {
-        if (boost != DEFAULT_BOOST) {
-            //if both the wrapped query and the wrapper hold a boost, the main one coming from the wrapper wins
-            query.setBoost(boost);
+        queryBuilder.toXContent(builder, params);
+        if (noMatchQuery != null) {
+            builder.field("no_match_query");
+            noMatchQuery.toXContent(builder, params);
+        } else if (sNoMatchQuery != null) {
+            builder.field("no_match_query", sNoMatchQuery);
         }
-    }
-    
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (this.innerQuery == null) {
-            validationException = addValidationError("inner query cannot be null", validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        if (this.indices == null || this.indices.length == 0) {
-            validationException = addValidationError("list of indices cannot be null or empty", validationException);
-        }
-        validationException = validateInnerQuery(innerQuery, validationException);
-        validationException = validateInnerQuery(noMatchQuery, validationException);
-        return validationException;
-    }
-
-    @Override
-    protected IndicesQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        IndicesQueryBuilder indicesQueryBuilder = new IndicesQueryBuilder(in.readQuery(), in.readStringArray());
-        indicesQueryBuilder.noMatchQuery = in.readQuery();
-        return indicesQueryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(innerQuery);
-        out.writeStringArray(indices);
-        out.writeQuery(noMatchQuery);
-    }
-    
-    @Override
-    public int doHashCode() {
-        return Objects.hash(innerQuery, noMatchQuery, Arrays.hashCode(indices));
-    }
-    
-    @Override
-    protected boolean doEquals(IndicesQueryBuilder other) {
-        return Objects.equals(innerQuery, other.innerQuery) &&
-                Arrays.equals(indices, other.indices) &&  // otherwise we are comparing pointers
-                Objects.equals(noMatchQuery, other.noMatchQuery);
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/IndicesQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/IndicesQueryParser.java
index b7a93ac..8a86ca0 100644
--- a/core/src/main/java/org/elasticsearch/index/query/IndicesQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/IndicesQueryParser.java
@@ -19,60 +19,78 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.elasticsearch.action.support.IndicesOptions;
+import org.elasticsearch.cluster.ClusterService;
+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;
+import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
+import org.elasticsearch.common.regex.Regex;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.query.support.XContentStructure;
 
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Collection;
 
 /**
- * Parser for {@link IndicesQueryBuilder}.
  */
-public class IndicesQueryParser extends BaseQueryParser {
+public class IndicesQueryParser implements QueryParser {
 
+    public static final String NAME = "indices";
     private static final ParseField QUERY_FIELD = new ParseField("query", "filter");
     private static final ParseField NO_MATCH_QUERY = new ParseField("no_match_query", "no_match_filter");
 
+    @Nullable
+    private final ClusterService clusterService;
+    private final IndexNameExpressionResolver indexNameExpressionResolver;
+
     @Inject
-    public IndicesQueryParser() {
+    public IndicesQueryParser(@Nullable ClusterService clusterService, IndexNameExpressionResolver indexNameExpressionResolver) {
+        this.clusterService = clusterService;
+        this.indexNameExpressionResolver = indexNameExpressionResolver;
     }
 
     @Override
     public String[] names() {
-        return new String[]{IndicesQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        QueryBuilder innerQuery = null;
-        Collection<String> indices = new ArrayList<>();
-        QueryBuilder noMatchQuery = IndicesQueryBuilder.defaultNoMatchQuery();
-
+        Query noMatchQuery = null;
+        boolean queryFound = false;
+        boolean indicesFound = false;
+        boolean currentIndexMatchesIndices = false;
         String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
 
         String currentFieldName = null;
         XContentParser.Token token;
+        XContentStructure.InnerQuery innerQuery = null;
+        XContentStructure.InnerQuery innerNoMatchQuery = null;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if (parseContext.parseFieldMatcher().match(currentFieldName, QUERY_FIELD)) {
-                    innerQuery = parseContext.parseInnerQueryBuilder();
+                    innerQuery = new XContentStructure.InnerQuery(parseContext, (String[])null);
+                    queryFound = true;
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, NO_MATCH_QUERY)) {
-                    noMatchQuery = parseContext.parseInnerQueryBuilder();
+                    innerNoMatchQuery = new XContentStructure.InnerQuery(parseContext, (String[])null);
                 } else {
                     throw new QueryParsingException(parseContext, "[indices] query does not support [" + currentFieldName + "]");
                 }
             } else if (token == XContentParser.Token.START_ARRAY) {
                 if ("indices".equals(currentFieldName)) {
-                    if (indices.isEmpty() == false) {
+                    if (indicesFound) {
                         throw new QueryParsingException(parseContext, "[indices] indices or index already specified");
                     }
+                    indicesFound = true;
+                    Collection<String> indices = new ArrayList<>();
                     while (parser.nextToken() != XContentParser.Token.END_ARRAY) {
                         String value = parser.textOrNull();
                         if (value == null) {
@@ -80,50 +98,67 @@ public class IndicesQueryParser extends BaseQueryParser {
                         }
                         indices.add(value);
                     }
+                    currentIndexMatchesIndices = matchesIndices(parseContext.index().name(), indices.toArray(new String[indices.size()]));
                 } else {
                     throw new QueryParsingException(parseContext, "[indices] query does not support [" + currentFieldName + "]");
                 }
             } else if (token.isValue()) {
                 if ("index".equals(currentFieldName)) {
-                    if (indices.isEmpty() == false) {
+                    if (indicesFound) {
                         throw new QueryParsingException(parseContext, "[indices] indices or index already specified");
                     }
-                    indices.add(parser.text());
+                    indicesFound = true;
+                    currentIndexMatchesIndices = matchesIndices(parseContext.index().name(), parser.text());
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, NO_MATCH_QUERY)) {
-                    noMatchQuery = parseNoMatchQuery(parser.text());
+                    String type = parser.text();
+                    if ("all".equals(type)) {
+                        noMatchQuery = Queries.newMatchAllQuery();
+                    } else if ("none".equals(type)) {
+                        noMatchQuery = Queries.newMatchNoDocsQuery();
+                    }
                 } else if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[indices] query does not support [" + currentFieldName + "]");
                 }
             }
         }
-        
-        if (innerQuery == null) {
+        if (!queryFound) {
             throw new QueryParsingException(parseContext, "[indices] requires 'query' element");
         }
-        if (indices.isEmpty()) {
+        if (!indicesFound) {
             throw new QueryParsingException(parseContext, "[indices] requires 'indices' or 'index' element");
         }
-        return new IndicesQueryBuilder(innerQuery, indices.toArray(new String[indices.size()]))
-                .noMatchQuery(noMatchQuery)
-                .boost(boost)
-                .queryName(queryName);
-    }
 
-    static QueryBuilder parseNoMatchQuery(String type) {
-        if ("all".equals(type)) {
-            return QueryBuilders.matchAllQuery();
-        } else if ("none".equals(type)) {
-            return new MatchNoneQueryBuilder();
+        Query chosenQuery;
+        if (currentIndexMatchesIndices) {
+            chosenQuery = innerQuery.asQuery();
+        } else {
+            // If noMatchQuery is set, it means "no_match_query" was "all" or "none"
+            if (noMatchQuery != null) {
+                chosenQuery = noMatchQuery;
+            } else {
+                // There might be no "no_match_query" set, so default to the match_all if not set
+                if (innerNoMatchQuery == null) {
+                    chosenQuery = Queries.newMatchAllQuery();
+                } else {
+                    chosenQuery = innerNoMatchQuery.asQuery();
+                }
+            }
+        }
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, chosenQuery);
         }
-        throw new IllegalArgumentException("query type can only be [all] or [none] but not " + "[" + type + "]");
+        return chosenQuery;
     }
 
-    @Override
-    public IndicesQueryBuilder getBuilderPrototype() {
-        return IndicesQueryBuilder.PROTOTYPE;
+    protected boolean matchesIndices(String currentIndex, String... indices) {
+        final String[] concreteIndices = indexNameExpressionResolver.concreteIndices(clusterService.state(), IndicesOptions.lenientExpandOpen(), indices);
+        for (String index : concreteIndices) {
+            if (Regex.simpleMatch(index, currentIndex)) {
+                return true;
+            }
+        }
+        return false;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryBuilder.java
index 00c5019..b09bc9f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryBuilder.java
@@ -19,10 +19,6 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
@@ -30,52 +26,26 @@ import java.io.IOException;
 /**
  * A query that matches on all documents.
  */
-public class MatchAllQueryBuilder extends AbstractQueryBuilder<MatchAllQueryBuilder> {
+public class MatchAllQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<MatchAllQueryBuilder> {
 
-    public static final String NAME = "match_all";
-
-    static final MatchAllQueryBuilder PROTOTYPE = new MatchAllQueryBuilder();
-
-    @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        return Queries.newMatchAllQuery();
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        // nothing to validate
-        return null;
-    }
+    private float boost = -1;
 
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
     @Override
-    protected boolean doEquals(MatchAllQueryBuilder other) {
-        return true;
+    public MatchAllQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     @Override
-    protected int doHashCode() {
-        return 0;
-    }
-
-    @Override
-    protected MatchAllQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new MatchAllQueryBuilder();
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        //nothing to write really
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+    public void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(MatchAllQueryParser.NAME);
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryParser.java
index 4066c75..933d3d3 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryParser.java
@@ -19,16 +19,21 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.MatchAllDocsQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
 
 /**
- * Parser for match_all query
+ *
  */
-public class MatchAllQueryParser extends BaseQueryParser<MatchAllQueryBuilder> {
+public class MatchAllQueryParser implements QueryParser {
+
+    public static final String NAME = "match_all";
 
     @Inject
     public MatchAllQueryParser() {
@@ -36,38 +41,35 @@ public class MatchAllQueryParser extends BaseQueryParser<MatchAllQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{MatchAllQueryBuilder.NAME, Strings.toCamelCase(MatchAllQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public MatchAllQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
+        float boost = 1.0f;
         String currentFieldName = null;
+
         XContentParser.Token token;
-        String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
         while (((token = parser.nextToken()) != XContentParser.Token.END_OBJECT && token != XContentParser.Token.END_ARRAY)) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
             } else if (token.isValue()) {
-                if ("_name".equals(currentFieldName)) {
-                    queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
+                if ("boost".equals(currentFieldName)) {
                     boost = parser.floatValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[match_all] query does not support [" + currentFieldName + "]");
                 }
             }
         }
-        MatchAllQueryBuilder queryBuilder = new MatchAllQueryBuilder();
-        queryBuilder.boost(boost);
-        queryBuilder.queryName(queryName);
-        return queryBuilder;
-    }
 
-    @Override
-    public MatchAllQueryBuilder getBuilderPrototype() {
-        return MatchAllQueryBuilder.PROTOTYPE;
+        if (boost == 1.0f) {
+            return Queries.newMatchAllQuery();
+        }
+
+        MatchAllDocsQuery query = new MatchAllDocsQuery();
+        query.setBoost(boost);
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/MatchNoneQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MatchNoneQueryBuilder.java
deleted file mode 100644
index e6d6a7d..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/MatchNoneQueryBuilder.java
+++ /dev/null
@@ -1,85 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-
-import java.io.IOException;
-
-/**
- * A query that matches no document.
- */
-public class MatchNoneQueryBuilder extends AbstractQueryBuilder<MatchNoneQueryBuilder> {
-
-    public static final String NAME = "match_none";
-
-    public static final MatchNoneQueryBuilder PROTOTYPE = new MatchNoneQueryBuilder();
-
-    @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        return Queries.newMatchNoDocsQuery();
-    }
-
-    @Override
-    protected void setFinalBoost(Query query) {
-        //no-op this query doesn't support boost
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        // nothing to validate
-        return null;
-    }
-
-    @Override
-    protected boolean doEquals(MatchNoneQueryBuilder other) {
-        return true;
-    }
-
-    @Override
-    protected int doHashCode() {
-        return 0;
-    }
-
-    @Override
-    protected MatchNoneQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new MatchNoneQueryBuilder();
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        //nothing to write really
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/MatchNoneQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/MatchNoneQueryParser.java
deleted file mode 100644
index 3536a5d..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/MatchNoneQueryParser.java
+++ /dev/null
@@ -1,55 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.xcontent.XContentParser;
-
-import java.io.IOException;
-
-public class MatchNoneQueryParser extends BaseQueryParser {
-
-    @Inject
-    public MatchNoneQueryParser() {
-    }
-
-    @Override
-    public String[] names() {
-        return new String[]{MatchNoneQueryBuilder.NAME, Strings.toCamelCase(MatchNoneQueryBuilder.NAME)};
-    }
-
-    @Override
-    public MatchNoneQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException {
-        XContentParser parser = parseContext.parser();
-
-        XContentParser.Token token = parser.nextToken();
-        if (token != XContentParser.Token.END_OBJECT) {
-            throw new QueryParsingException(parseContext, "[match_none] query malformed");
-        }
-
-        return new MatchNoneQueryBuilder();
-    }
-
-    @Override
-    public MatchNoneQueryBuilder getBuilderPrototype() {
-        return MatchNoneQueryBuilder.PROTOTYPE;
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/MatchQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MatchQueryBuilder.java
index caf4eab..6f73f08 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MatchQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MatchQueryBuilder.java
@@ -19,112 +19,97 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.queries.ExtendedCommonTermsQuery;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.FuzzyQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.unit.Fuzziness;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.query.support.QueryParsers;
-import org.elasticsearch.index.search.MatchQuery;
 
 import java.io.IOException;
 import java.util.Locale;
-import java.util.Objects;
 
 /**
  * Match query is a query that analyzes the text and constructs a query as the result of the analysis. It
  * can construct different queries based on the type provided.
  */
-public class MatchQueryBuilder extends AbstractQueryBuilder<MatchQueryBuilder> {
+public class MatchQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<MatchQueryBuilder> {
 
-    /** The default name for the match query */
-    public static final String NAME = "match";
+    public enum Operator {
+        OR,
+        AND
+    }
 
-    /** The default mode terms are combined in a match query */
-    public static final Operator DEFAULT_OPERATOR = Operator.OR;
+    public enum Type {
+        /**
+         * The text is analyzed and terms are added to a boolean query.
+         */
+        BOOLEAN,
+        /**
+         * The text is analyzed and used as a phrase query.
+         */
+        PHRASE,
+        /**
+         * The text is analyzed and used in a phrase query, with the last term acting as a prefix.
+         */
+        PHRASE_PREFIX
+    }
 
-    /** The default mode match query type */
-    public static final MatchQuery.Type DEFAULT_TYPE = MatchQuery.Type.BOOLEAN;
+    public enum ZeroTermsQuery {
+        NONE,
+        ALL
+    }
 
-    private final String fieldName;
+    private final String name;
 
-    private final Object value;
+    private final Object text;
 
-    private MatchQuery.Type type = DEFAULT_TYPE;
+    private Type type;
 
-    private Operator operator = DEFAULT_OPERATOR;
+    private Operator operator;
 
     private String analyzer;
 
-    private int slop = MatchQuery.DEFAULT_PHRASE_SLOP;
+    private Float boost;
 
-    private Fuzziness fuzziness = null;
+    private Integer slop;
 
-    private int prefixLength = FuzzyQuery.defaultPrefixLength;
+    private Fuzziness fuzziness;
 
-    private int  maxExpansions = FuzzyQuery.defaultMaxExpansions;
+    private Integer prefixLength;
 
-    private boolean fuzzyTranspositions = FuzzyQuery.defaultTranspositions;
+    private Integer maxExpansions;
 
     private String minimumShouldMatch;
 
     private String fuzzyRewrite = null;
 
-    private boolean lenient = MatchQuery.DEFAULT_LENIENCY;
+    private Boolean lenient;
+
+    private Boolean fuzzyTranspositions = null;
 
-    private MatchQuery.ZeroTermsQuery zeroTermsQuery = MatchQuery.DEFAULT_ZERO_TERMS_QUERY;
+    private ZeroTermsQuery zeroTermsQuery;
 
-    private Float cutoffFrequency = null;
+    private Float cutoff_Frequency = null;
 
-    static final MatchQueryBuilder PROTOTYPE = new MatchQueryBuilder("","");
+    private String queryName;
 
     /**
-     * Constructs a new match query.
+     * Constructs a new text query.
      */
-    public MatchQueryBuilder(String fieldName, Object value) {
-        if (fieldName == null) {
-            throw new IllegalArgumentException("[" + NAME + "] requires fieldName");
-        }
-        if (value == null) {
-            throw new IllegalArgumentException("[" + NAME + "] requires query value");
-        }
-        this.fieldName = fieldName;
-        this.value = value;
+    public MatchQueryBuilder(String name, Object text) {
+        this.name = name;
+        this.text = text;
     }
 
-    /** Returns the field name used in this query. */
-    public String fieldName() {
-        return this.fieldName;
-    }
-
-    /** Returns the value used in this query. */
-    public Object value() {
-        return this.value;
-    }
-
-    /** Sets the type of the text query. */
-    public MatchQueryBuilder type(MatchQuery.Type type) {
-        if (type == null) {
-            throw new IllegalArgumentException("[" + NAME + "] requires type to be non-null");
-        }
+    /**
+     * Sets the type of the text query.
+     */
+    public MatchQueryBuilder type(Type type) {
         this.type = type;
         return this;
     }
 
-    /** Get the type of the query. */
-    public MatchQuery.Type type() {
-        return this.type;
-    }
-
-    /** Sets the operator to use when using a boolean query. Defaults to <tt>OR</tt>. */
+    /**
+     * Sets the operator to use when using a boolean query. Defaults to <tt>OR</tt>.
+     */
     public MatchQueryBuilder operator(Operator operator) {
-        if (operator == null) {
-            throw new IllegalArgumentException("[" + NAME + "] requires operator to be non-null");
-        }
         this.operator = operator;
         return this;
     }
@@ -138,57 +123,37 @@ public class MatchQueryBuilder extends AbstractQueryBuilder<MatchQueryBuilder> {
         return this;
     }
 
-    /** Get the analyzer to use, if previously set, otherwise <tt>null</tt> */
-    public String analyzer() {
-        return this.analyzer;
+    /**
+     * Set the boost to apply to the query.
+     */
+    @Override
+    public MatchQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
-    /** Sets a slop factor for phrase queries */
+    /**
+     * Set the phrase slop if evaluated to a phrase query type.
+     */
     public MatchQueryBuilder slop(int slop) {
-        if (slop < 0 ) {
-            throw new IllegalArgumentException("No negative slop allowed.");
-        }
         this.slop = slop;
         return this;
     }
 
-    /** Get the slop factor for phrase queries. */
-    public int slop() {
-        return this.slop;
-    }
-
-    /** Sets the fuzziness used when evaluated to a fuzzy query type. Defaults to "AUTO". */
+    /**
+     * Sets the fuzziness used when evaluated to a fuzzy query type. Defaults to "AUTO".
+     */
     public MatchQueryBuilder fuzziness(Object fuzziness) {
         this.fuzziness = Fuzziness.build(fuzziness);
         return this;
     }
 
-    /**  Gets the fuzziness used when evaluated to a fuzzy query type. */
-    public Fuzziness fuzziness() {
-        return this.fuzziness;
-    }
-
-    /**
-     * Sets the length of a length of common (non-fuzzy) prefix for fuzzy match queries
-     * @param prefixLength non-negative length of prefix
-     * @throws IllegalArgumentException in case the prefix is negative
-     */
     public MatchQueryBuilder prefixLength(int prefixLength) {
-        if (prefixLength < 0 ) {
-            throw new IllegalArgumentException("No negative prefix length allowed.");
-        }
         this.prefixLength = prefixLength;
         return this;
     }
 
     /**
-     * Gets the length of a length of common (non-fuzzy) prefix for fuzzy match queries
-     */
-    public int prefixLength() {
-        return this.prefixLength;
-    }
-
-    /**
      * When using fuzzy or prefix type query, the number of term expansions to use. Defaults to unbounded
      * so its recommended to set it to a reasonable value for faster execution.
      */
@@ -198,261 +163,107 @@ public class MatchQueryBuilder extends AbstractQueryBuilder<MatchQueryBuilder> {
     }
 
     /**
-     * Get the (optional) number of term expansions when using fuzzy or prefix type query.
-     */
-    public int maxExpansions() {
-        return this.maxExpansions;
-    }
-
-    /**
-     * Sets an optional cutoff value in [0..1] (or absolute number >=1) representing the
+     * Set a cutoff value in [0..1] (or absolute number >=1) representing the
      * maximum threshold of a terms document frequency to be considered a low
      * frequency term.
      */
     public MatchQueryBuilder cutoffFrequency(float cutoff) {
-        this.cutoffFrequency = cutoff;
+        this.cutoff_Frequency = cutoff;
         return this;
     }
 
-    /** Gets the optional cutoff value, can be <tt>null</tt> if not set previously */
-    public Float cutoffFrequency() {
-        return this.cutoffFrequency;
-    }
-
-    /** Sets optional minimumShouldMatch value to apply to the query */
     public MatchQueryBuilder minimumShouldMatch(String minimumShouldMatch) {
         this.minimumShouldMatch = minimumShouldMatch;
         return this;
     }
 
-    /** Gets the minimumShouldMatch value */
-    public String minimumShouldMatch() {
-        return this.minimumShouldMatch;
-    }
-
-    /** Sets the fuzzy_rewrite parameter controlling how the fuzzy query will get rewritten */
     public MatchQueryBuilder fuzzyRewrite(String fuzzyRewrite) {
         this.fuzzyRewrite = fuzzyRewrite;
         return this;
     }
 
-    /**
-     * Get the fuzzy_rewrite parameter
-     * @see #fuzzyRewrite(String)
-     */
-    public String fuzzyRewrite() {
-        return this.fuzzyRewrite;
-    }
-
-    /**
-     * Sets whether transpositions are supported in fuzzy queries.<p>
-     * The default metric used by fuzzy queries to determine a match is the Damerau-Levenshtein
-     * distance formula which supports transpositions. Setting transposition to false will
-     * switch to classic Levenshtein distance.<br>
-     * If not set, Damerau-Levenshtein distance metric will be used.
-     */
     public MatchQueryBuilder fuzzyTranspositions(boolean fuzzyTranspositions) {
+        //LUCENE 4 UPGRADE add documentation
         this.fuzzyTranspositions = fuzzyTranspositions;
         return this;
     }
 
-    /** Gets the fuzzy query transposition setting. */
-    public boolean fuzzyTranspositions() {
-        return this.fuzzyTranspositions;
-    }
-
     /**
      * Sets whether format based failures will be ignored.
-     * @deprecated use #lenient() instead
      */
-    @Deprecated
     public MatchQueryBuilder setLenient(boolean lenient) {
-        return lenient(lenient);
-    }
-
-    /**
-     * Sets whether format based failures will be ignored.
-     */
-    public MatchQueryBuilder lenient(boolean lenient) {
         this.lenient = lenient;
         return this;
     }
 
-    /**
-     * Gets leniency setting that controls if format based failures will be ignored.
-     */
-    public boolean lenient() {
-        return this.lenient;
-    }
-
-    /**
-     * Sets query to use in case no query terms are available, e.g. after analysis removed them.
-     * Defaults to {@link MatchQuery.ZeroTermsQuery#NONE}, but can be set to
-     * {@link MatchQuery.ZeroTermsQuery#ALL} instead.
-     */
-    public MatchQueryBuilder zeroTermsQuery(MatchQuery.ZeroTermsQuery zeroTermsQuery) {
+    public MatchQueryBuilder zeroTermsQuery(ZeroTermsQuery zeroTermsQuery) {
         this.zeroTermsQuery = zeroTermsQuery;
         return this;
     }
 
     /**
-     * Get the setting for handling zero terms queries.
-     * @see #zeroTermsQuery(ZeroTermsQuery)
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public MatchQuery.ZeroTermsQuery zeroTermsQuery() {
-        return this.zeroTermsQuery;
+    public MatchQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     public void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.startObject(fieldName);
+        builder.startObject(MatchQueryParser.NAME);
+        builder.startObject(name);
 
-        builder.field("query", value);
-        builder.field("type", type.toString().toLowerCase(Locale.ENGLISH));
-        builder.field("operator", operator.toString());
+        builder.field("query", text);
+        if (type != null) {
+            builder.field("type", type.toString().toLowerCase(Locale.ENGLISH));
+        }
+        if (operator != null) {
+            builder.field("operator", operator.toString());
+        }
         if (analyzer != null) {
             builder.field("analyzer", analyzer);
         }
-        builder.field("slop", slop);
+        if (boost != null) {
+            builder.field("boost", boost);
+        }
+        if (slop != null) {
+            builder.field("slop", slop);
+        }
         if (fuzziness != null) {
             fuzziness.toXContent(builder, params);
         }
-        builder.field("prefix_length", prefixLength);
-        builder.field("max_expansions", maxExpansions);
+        if (prefixLength != null) {
+            builder.field("prefix_length", prefixLength);
+        }
+        if (maxExpansions != null) {
+            builder.field("max_expansions", maxExpansions);
+        }
         if (minimumShouldMatch != null) {
             builder.field("minimum_should_match", minimumShouldMatch);
         }
         if (fuzzyRewrite != null) {
             builder.field("fuzzy_rewrite", fuzzyRewrite);
         }
-        // LUCENE 4 UPGRADE we need to document this & test this
-        builder.field("fuzzy_transpositions", fuzzyTranspositions);
-        builder.field("lenient", lenient);
-        builder.field("zero_terms_query", zeroTermsQuery.toString());
-        if (cutoffFrequency != null) {
-            builder.field("cutoff_frequency", cutoffFrequency);
-        }
-        printBoostAndQueryName(builder);
-        builder.endObject();
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        // validate context specific fields
-        if (analyzer != null && context.analysisService().analyzer(analyzer) == null) {
-            throw new QueryShardException(context, "[match] analyzer [" + analyzer + "] not found");
+        if (fuzzyTranspositions != null) {
+            //LUCENE 4 UPGRADE we need to document this & test this
+            builder.field("fuzzy_transpositions", fuzzyTranspositions);
         }
-
-        MatchQuery matchQuery = new MatchQuery(context);
-        matchQuery.setOccur(operator.toBooleanClauseOccur());
-        matchQuery.setAnalyzer(analyzer);
-        matchQuery.setPhraseSlop(slop);
-        matchQuery.setFuzziness(fuzziness);
-        matchQuery.setFuzzyPrefixLength(prefixLength);
-        matchQuery.setMaxExpansions(maxExpansions);
-        matchQuery.setTranspositions(fuzzyTranspositions);
-        matchQuery.setFuzzyRewriteMethod(QueryParsers.parseRewriteMethod(context.parseFieldMatcher(), fuzzyRewrite, null));
-        matchQuery.setLenient(lenient);
-        matchQuery.setCommonTermsCutoff(cutoffFrequency);
-        matchQuery.setZeroTermsQuery(zeroTermsQuery);
-
-        Query query = matchQuery.parse(type, fieldName, value);
-        if (query == null) {
-            return null;
+        if (lenient != null) {
+            builder.field("lenient", lenient);
         }
-
-        if (query instanceof BooleanQuery) {
-            query = Queries.applyMinimumShouldMatch((BooleanQuery) query, minimumShouldMatch);
-        } else if (query instanceof ExtendedCommonTermsQuery) {
-            ((ExtendedCommonTermsQuery)query).setLowFreqMinimumNumberShouldMatch(minimumShouldMatch);
+        if (zeroTermsQuery != null) {
+            builder.field("zero_terms_query", zeroTermsQuery.toString());
         }
-        return query;
-    }
-
-    @Override
-    protected boolean doEquals(MatchQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-               Objects.equals(value, other.value) &&
-               Objects.equals(type, other.type) &&
-               Objects.equals(operator, other.operator) &&
-               Objects.equals(analyzer, other.analyzer) &&
-               Objects.equals(slop, other.slop) &&
-               Objects.equals(fuzziness, other.fuzziness) &&
-               Objects.equals(prefixLength, other.prefixLength) &&
-               Objects.equals(maxExpansions, other.maxExpansions) &&
-               Objects.equals(minimumShouldMatch, other.minimumShouldMatch) &&
-               Objects.equals(fuzzyRewrite, other.fuzzyRewrite) &&
-               Objects.equals(lenient, other.lenient) &&
-               Objects.equals(fuzzyTranspositions, other.fuzzyTranspositions) &&
-               Objects.equals(zeroTermsQuery, other.zeroTermsQuery) &&
-               Objects.equals(cutoffFrequency, other.cutoffFrequency);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldName, value, type, operator, analyzer, slop,
-                fuzziness, prefixLength, maxExpansions, minimumShouldMatch,
-                fuzzyRewrite, lenient, fuzzyTranspositions, zeroTermsQuery, cutoffFrequency);
-    }
-
-    @Override
-    protected MatchQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        MatchQueryBuilder matchQuery = new MatchQueryBuilder(in.readString(), in.readGenericValue());
-        matchQuery.type = MatchQuery.Type.readTypeFrom(in);
-        matchQuery.operator = Operator.readOperatorFrom(in);
-        matchQuery.slop = in.readVInt();
-        matchQuery.prefixLength = in.readVInt();
-        matchQuery.maxExpansions = in.readVInt();
-        matchQuery.fuzzyTranspositions = in.readBoolean();
-        matchQuery.lenient = in.readBoolean();
-        matchQuery.zeroTermsQuery = MatchQuery.ZeroTermsQuery.readZeroTermsQueryFrom(in);
-        // optional fields
-        matchQuery.analyzer = in.readOptionalString();
-        matchQuery.minimumShouldMatch = in.readOptionalString();
-        matchQuery.fuzzyRewrite = in.readOptionalString();
-        if (in.readBoolean()) {
-            matchQuery.fuzziness = Fuzziness.readFuzzinessFrom(in);
+        if (cutoff_Frequency != null) {
+            builder.field("cutoff_frequency", cutoff_Frequency);
         }
-        if (in.readBoolean()) {
-            matchQuery.cutoffFrequency = in.readFloat();
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return matchQuery;
-    }
 
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-        out.writeGenericValue(value);
-        type.writeTo(out);
-        operator.writeTo(out);
-        out.writeVInt(slop);
-        out.writeVInt(prefixLength);
-        out.writeVInt(maxExpansions);
-        out.writeBoolean(fuzzyTranspositions);
-        out.writeBoolean(lenient);
-        zeroTermsQuery.writeTo(out);
-        // optional fields
-        out.writeOptionalString(analyzer);
-        out.writeOptionalString(minimumShouldMatch);
-        out.writeOptionalString(fuzzyRewrite);
-        if (fuzziness == null) {
-            out.writeBoolean(false);
-        } else {
-            out.writeBoolean(true);
-            fuzziness.writeTo(out);
-        }
-        if (cutoffFrequency == null) {
-            out.writeBoolean(false);
-        } else {
-            out.writeBoolean(true);
-            out.writeFloat(cutoffFrequency);
-        }
-    }
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/MatchQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/MatchQueryParser.java
index 93bd2be..2bf0d7c 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MatchQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MatchQueryParser.java
@@ -19,19 +19,25 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.FuzzyQuery;
+import org.apache.lucene.queries.ExtendedCommonTermsQuery;
+import org.apache.lucene.search.BooleanClause;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.unit.Fuzziness;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.query.support.QueryParsers;
 import org.elasticsearch.index.search.MatchQuery;
-import org.elasticsearch.index.search.MatchQuery.ZeroTermsQuery;
 
 import java.io.IOException;
 
 /**
  *
  */
-public class MatchQueryParser extends BaseQueryParser {
+public class MatchQueryParser implements QueryParser {
+
+    public static final String NAME = "match";
 
     @Inject
     public MatchQueryParser() {
@@ -40,12 +46,12 @@ public class MatchQueryParser extends BaseQueryParser {
     @Override
     public String[] names() {
         return new String[]{
-                MatchQueryBuilder.NAME, "match_phrase", "matchPhrase", "match_phrase_prefix", "matchPhrasePrefix", "matchFuzzy", "match_fuzzy", "fuzzy_match"
+                NAME, "match_phrase", "matchPhrase", "match_phrase_prefix", "matchPhrasePrefix", "matchFuzzy", "match_fuzzy", "fuzzy_match"
         };
     }
 
     @Override
-    public MatchQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         MatchQuery.Type type = MatchQuery.Type.BOOLEAN;
@@ -64,19 +70,9 @@ public class MatchQueryParser extends BaseQueryParser {
         String fieldName = parser.currentName();
 
         Object value = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
+        MatchQuery matchQuery = new MatchQuery(parseContext);
         String minimumShouldMatch = null;
-        String analyzer = null;
-        Operator operator = MatchQueryBuilder.DEFAULT_OPERATOR;
-        int slop = MatchQuery.DEFAULT_PHRASE_SLOP;
-        Fuzziness fuzziness = null;
-        int prefixLength = FuzzyQuery.defaultPrefixLength;
-        int maxExpansion = FuzzyQuery.defaultMaxExpansions;
-        boolean fuzzyTranspositions = FuzzyQuery.defaultTranspositions;
-        String fuzzyRewrite = null;
-        boolean lenient = MatchQuery.DEFAULT_LENIENCY;
-        Float cutOffFrequency = null;
-        ZeroTermsQuery zeroTermsQuery = MatchQuery.DEFAULT_ZERO_TERMS_QUERY;
         String queryName = null;
 
         token = parser.nextToken();
@@ -100,35 +96,47 @@ public class MatchQueryParser extends BaseQueryParser {
                             throw new QueryParsingException(parseContext, "[match] query does not support type " + tStr);
                         }
                     } else if ("analyzer".equals(currentFieldName)) {
-                        analyzer = parser.text();
+                        String analyzer = parser.text();
+                        if (parseContext.analysisService().analyzer(analyzer) == null) {
+                            throw new QueryParsingException(parseContext, "[match] analyzer [" + parser.text() + "] not found");
+                        }
+                        matchQuery.setAnalyzer(analyzer);
                     } else if ("boost".equals(currentFieldName)) {
                         boost = parser.floatValue();
                     } else if ("slop".equals(currentFieldName) || "phrase_slop".equals(currentFieldName) || "phraseSlop".equals(currentFieldName)) {
-                        slop = parser.intValue();
+                        matchQuery.setPhraseSlop(parser.intValue());
                     } else if (parseContext.parseFieldMatcher().match(currentFieldName, Fuzziness.FIELD)) {
-                        fuzziness = Fuzziness.parse(parser);
+                        matchQuery.setFuzziness(Fuzziness.parse(parser));
                     } else if ("prefix_length".equals(currentFieldName) || "prefixLength".equals(currentFieldName)) {
-                        prefixLength = parser.intValue();
+                        matchQuery.setFuzzyPrefixLength(parser.intValue());
                     } else if ("max_expansions".equals(currentFieldName) || "maxExpansions".equals(currentFieldName)) {
-                        maxExpansion = parser.intValue();
+                        matchQuery.setMaxExpansions(parser.intValue());
                     } else if ("operator".equals(currentFieldName)) {
-                        operator = Operator.fromString(parser.text());
+                        String op = parser.text();
+                        if ("or".equalsIgnoreCase(op)) {
+                            matchQuery.setOccur(BooleanClause.Occur.SHOULD);
+                        } else if ("and".equalsIgnoreCase(op)) {
+                            matchQuery.setOccur(BooleanClause.Occur.MUST);
+                        } else {
+                            throw new QueryParsingException(parseContext, "text query requires operator to be either 'and' or 'or', not ["
+                                    + op + "]");
+                        }
                     } else if ("minimum_should_match".equals(currentFieldName) || "minimumShouldMatch".equals(currentFieldName)) {
                         minimumShouldMatch = parser.textOrNull();
                     } else if ("fuzzy_rewrite".equals(currentFieldName) || "fuzzyRewrite".equals(currentFieldName)) {
-                        fuzzyRewrite = parser.textOrNull();
+                        matchQuery.setFuzzyRewriteMethod(QueryParsers.parseRewriteMethod(parseContext.parseFieldMatcher(), parser.textOrNull(), null));
                     } else if ("fuzzy_transpositions".equals(currentFieldName)) {
-                        fuzzyTranspositions = parser.booleanValue();
+                        matchQuery.setTranspositions(parser.booleanValue());
                     } else if ("lenient".equals(currentFieldName)) {
-                        lenient = parser.booleanValue();
+                        matchQuery.setLenient(parser.booleanValue());
                     } else if ("cutoff_frequency".equals(currentFieldName)) {
-                        cutOffFrequency = parser.floatValue();
+                        matchQuery.setCommonTermsCutoff(parser.floatValue());
                     } else if ("zero_terms_query".equals(currentFieldName)) {
                         String zeroTermsDocs = parser.text();
                         if ("none".equalsIgnoreCase(zeroTermsDocs)) {
-                            zeroTermsQuery = MatchQuery.ZeroTermsQuery.NONE;
+                            matchQuery.setZeroTermsQuery(MatchQuery.ZeroTermsQuery.NONE);
                         } else if ("all".equalsIgnoreCase(zeroTermsDocs)) {
-                            zeroTermsQuery = MatchQuery.ZeroTermsQuery.ALL;
+                            matchQuery.setZeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL);
                         } else {
                             throw new QueryParsingException(parseContext, "Unsupported zero_terms_docs value [" + zeroTermsDocs + "]");
                         }
@@ -154,31 +162,20 @@ public class MatchQueryParser extends BaseQueryParser {
             throw new QueryParsingException(parseContext, "No text specified for text query");
         }
 
-        MatchQueryBuilder matchQuery = new MatchQueryBuilder(fieldName, value);
-        matchQuery.operator(operator);
-        matchQuery.type(type);
-        matchQuery.analyzer(analyzer);
-        matchQuery.slop(slop);
-        matchQuery.minimumShouldMatch(minimumShouldMatch);
-        if (fuzziness != null) {
-            matchQuery.fuzziness(fuzziness);
-        }
-        matchQuery.fuzzyRewrite(fuzzyRewrite);
-        matchQuery.prefixLength(prefixLength);
-        matchQuery.fuzzyTranspositions(fuzzyTranspositions);
-        matchQuery.maxExpansions(maxExpansion);
-        matchQuery.lenient(lenient);
-        if (cutOffFrequency != null) {
-            matchQuery.cutoffFrequency(cutOffFrequency);
+        Query query = matchQuery.parse(type, fieldName, value);
+        if (query == null) {
+            return null;
         }
-        matchQuery.zeroTermsQuery(zeroTermsQuery);
-        matchQuery.queryName(queryName);
-        matchQuery.boost(boost);
-        return matchQuery;
-    }
 
-    @Override
-    public MatchQueryBuilder getBuilderPrototype() {
-        return MatchQueryBuilder.PROTOTYPE;
+        if (query instanceof BooleanQuery) {
+            query = Queries.applyMinimumShouldMatch((BooleanQuery) query, minimumShouldMatch);
+        } else if (query instanceof ExtendedCommonTermsQuery) {
+            ((ExtendedCommonTermsQuery)query).setLowFreqMinimumNumberShouldMatch(minimumShouldMatch);
+        }
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MissingQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MissingQueryBuilder.java
index 4d3115c..ac3f279 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MissingQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MissingQueryBuilder.java
@@ -19,45 +19,25 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.*;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.mapper.internal.FieldNamesFieldMapper;
-import org.elasticsearch.index.mapper.object.ObjectMapper;
 
 import java.io.IOException;
-import java.util.Collection;
-import java.util.Objects;
 
 /**
- * Constructs a filter that have only null values or no value in the original field.
+ * Constructs a filter that only match on documents that the field has a value in them.
  */
-public class MissingQueryBuilder extends AbstractQueryBuilder<MissingQueryBuilder> {
+public class MissingQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "missing";
+    private String name;
 
-    public static final boolean DEFAULT_NULL_VALUE = false;
+    private String queryName;
 
-    public static final boolean DEFAULT_EXISTENCE_VALUE = true;
+    private Boolean nullValue;
 
-    private final String fieldPattern;
+    private Boolean existence;
 
-    private boolean nullValue = DEFAULT_NULL_VALUE;
-
-    private boolean existence = DEFAULT_EXISTENCE_VALUE;
-
-    static final MissingQueryBuilder PROTOTYPE = new MissingQueryBuilder(null);
-
-    public MissingQueryBuilder(String fieldPattern) {
-        this.fieldPattern = fieldPattern;
-    }
-
-    public String fieldPattern() {
-        return this.fieldPattern;
+    public MissingQueryBuilder(String name) {
+        this.name = name;
     }
 
     /**
@@ -70,15 +50,7 @@ public class MissingQueryBuilder extends AbstractQueryBuilder<MissingQueryBuilde
     }
 
     /**
-     * Returns true if the missing filter will include documents where the field contains a null value, otherwise
-     * these documents will not be included.
-     */
-    public boolean nullValue() {
-        return this.nullValue;
-    }
-
-    /**
-     * Should the missing filter include documents where the field doesn't exist in the docs.
+     * Should the missing filter include documents where the field doesn't exists in the docs.
      * Defaults to <tt>true</tt>.
      */
     public MissingQueryBuilder existence(boolean existence) {
@@ -87,156 +59,26 @@ public class MissingQueryBuilder extends AbstractQueryBuilder<MissingQueryBuilde
     }
 
     /**
-     * Returns true if the missing filter will include documents where the field has no values, otherwise
-     * these documents will not be included.
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
      */
-    public boolean existence() {
-        return this.existence;
+    public MissingQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("field", fieldPattern);
-        builder.field("null_value", nullValue);
-        builder.field("existence", existence);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        return newFilter(context, fieldPattern, existence, nullValue);
-    }
-
-    public static Query newFilter(QueryShardContext context, String fieldPattern, boolean existence, boolean nullValue) {
-        if (!existence && !nullValue) {
-            throw new QueryShardException(context, "missing must have either existence, or null_value, or both set to true");
-        }
-
-        final FieldNamesFieldMapper.FieldNamesFieldType fieldNamesFieldType = (FieldNamesFieldMapper.FieldNamesFieldType) context.mapperService().fullName(FieldNamesFieldMapper.NAME);
-        if (fieldNamesFieldType == null) {
-            // can only happen when no types exist, so no docs exist either
-            return Queries.newMatchNoDocsQuery();
-        }
-
-        ObjectMapper objectMapper = context.getObjectMapper(fieldPattern);
-        if (objectMapper != null) {
-            // automatic make the object mapper pattern
-            fieldPattern = fieldPattern + ".*";
-        }
-
-        Collection<String> fields = context.simpleMatchToIndexNames(fieldPattern);
-        if (fields.isEmpty()) {
-            if (existence) {
-                // if we ask for existence of fields, and we found none, then we should match on all
-                return Queries.newMatchAllQuery();
-            }
-            return null;
-        }
-
-        Query existenceFilter = null;
-        Query nullFilter = null;
-
-        if (existence) {
-            BooleanQuery.Builder boolFilter = new BooleanQuery.Builder();
-            for (String field : fields) {
-                MappedFieldType fieldType = context.fieldMapper(field);
-                Query filter = null;
-                if (fieldNamesFieldType.isEnabled()) {
-                    final String f;
-                    if (fieldType != null) {
-                        f = fieldType.names().indexName();
-                    } else {
-                        f = field;
-                    }
-                    filter = fieldNamesFieldType.termQuery(f, context);
-                }
-                // if _field_names are not indexed, we need to go the slow way
-                if (filter == null && fieldType != null) {
-                    filter = fieldType.rangeQuery(null, null, true, true);
-                }
-                if (filter == null) {
-                    filter = new TermRangeQuery(field, null, null, true, true);
-                }
-                boolFilter.add(filter, BooleanClause.Occur.SHOULD);
-            }
-
-            existenceFilter = boolFilter.build();
-            existenceFilter = Queries.not(existenceFilter);;
-        }
-
-        if (nullValue) {
-            for (String field : fields) {
-                MappedFieldType fieldType = context.fieldMapper(field);
-                if (fieldType != null) {
-                    nullFilter = fieldType.nullValueQuery();
-                }
-            }
-        }
-
-        Query filter;
-        if (nullFilter != null) {
-            if (existenceFilter != null) {
-                filter = new BooleanQuery.Builder()
-                        .add(existenceFilter, BooleanClause.Occur.SHOULD)
-                        .add(nullFilter, BooleanClause.Occur.SHOULD)
-                        .build();
-            } else {
-                filter = nullFilter;
-            }
-        } else {
-            filter = existenceFilter;
+        builder.startObject(MissingQueryParser.NAME);
+        builder.field("field", name);
+        if (nullValue != null) {
+            builder.field("null_value", nullValue);
         }
-
-        if (filter == null) {
-            return null;
-        }
-
-        return new ConstantScoreQuery(filter);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (Strings.isEmpty(this.fieldPattern)) {
-            validationException = addValidationError("missing must be provided with a [field]", validationException);
+        if (existence != null) {
+            builder.field("existence", existence);
         }
-        if (!existence && !nullValue) {
-            validationException = addValidationError("missing must have either existence, or null_value, or both set to true", validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return validationException;
-    }
-
-    @Override
-    protected MissingQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        MissingQueryBuilder missingQueryBuilder = new MissingQueryBuilder(in.readString());
-        missingQueryBuilder.nullValue = in.readBoolean();
-        missingQueryBuilder.existence = in.readBoolean();
-        return missingQueryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldPattern);
-        out.writeBoolean(nullValue);
-        out.writeBoolean(existence);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldPattern, nullValue, existence);
-    }
-
-    @Override
-    protected boolean doEquals(MissingQueryBuilder other) {
-        return Objects.equals(fieldPattern, other.fieldPattern) &&
-                Objects.equals(nullValue, other.nullValue) &&
-                Objects.equals(existence, other.existence);
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MissingQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/MissingQueryParser.java
index 1dd6bd1..8d13caa 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MissingQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MissingQueryParser.java
@@ -19,15 +19,29 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.BooleanClause;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.ConstantScoreQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.TermRangeQuery;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.mapper.internal.FieldNamesFieldMapper;
+import org.elasticsearch.index.mapper.object.ObjectMapper;
 
 import java.io.IOException;
+import java.util.Collection;
 
 /**
- * Parser for missing query
+ *
  */
-public class MissingQueryParser extends BaseQueryParser<MissingQueryBuilder> {
+public class MissingQueryParser implements QueryParser {
+
+    public static final String NAME = "missing";
+    public static final boolean DEFAULT_NULL_VALUE = false;
+    public static final boolean DEFAULT_EXISTENCE_VALUE = true;
 
     @Inject
     public MissingQueryParser() {
@@ -35,18 +49,17 @@ public class MissingQueryParser extends BaseQueryParser<MissingQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{MissingQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public MissingQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldPattern = null;
         String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        boolean nullValue = MissingQueryBuilder.DEFAULT_NULL_VALUE;
-        boolean existence = MissingQueryBuilder.DEFAULT_EXISTENCE_VALUE;
+        boolean nullValue = DEFAULT_NULL_VALUE;
+        boolean existence = DEFAULT_EXISTENCE_VALUE;
 
         XContentParser.Token token;
         String currentFieldName = null;
@@ -62,8 +75,6 @@ public class MissingQueryParser extends BaseQueryParser<MissingQueryBuilder> {
                     existence = parser.booleanValue();
                 } else if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[missing] query does not support [" + currentFieldName + "]");
                 }
@@ -73,15 +84,97 @@ public class MissingQueryParser extends BaseQueryParser<MissingQueryBuilder> {
         if (fieldPattern == null) {
             throw new QueryParsingException(parseContext, "missing must be provided with a [field]");
         }
-        return new MissingQueryBuilder(fieldPattern)
-                .nullValue(nullValue)
-                .existence(existence)
-                .boost(boost)
-                .queryName(queryName);
+
+        return newFilter(parseContext, fieldPattern, existence, nullValue, queryName);
     }
 
-    @Override
-    public MissingQueryBuilder getBuilderPrototype() {
-        return MissingQueryBuilder.PROTOTYPE;
+    public static Query newFilter(QueryParseContext parseContext, String fieldPattern, boolean existence, boolean nullValue, String queryName) {
+        if (!existence && !nullValue) {
+            throw new QueryParsingException(parseContext, "missing must have either existence, or null_value, or both set to true");
+        }
+
+        final FieldNamesFieldMapper.FieldNamesFieldType fieldNamesFieldType = (FieldNamesFieldMapper.FieldNamesFieldType)parseContext.mapperService().fullName(FieldNamesFieldMapper.NAME);
+        if (fieldNamesFieldType == null) {
+            // can only happen when no types exist, so no docs exist either
+            return Queries.newMatchNoDocsQuery();
+        }
+
+        ObjectMapper objectMapper = parseContext.getObjectMapper(fieldPattern);
+        if (objectMapper != null) {
+            // automatic make the object mapper pattern
+            fieldPattern = fieldPattern + ".*";
+        }
+
+        Collection<String> fields = parseContext.simpleMatchToIndexNames(fieldPattern);
+        if (fields.isEmpty()) {
+            if (existence) {
+                // if we ask for existence of fields, and we found none, then we should match on all
+                return Queries.newMatchAllQuery();
+            }
+            return null;
+        }
+
+        Query existenceFilter = null;
+        Query nullFilter = null;
+
+        if (existence) {
+            BooleanQuery.Builder boolFilter = new BooleanQuery.Builder();
+            for (String field : fields) {
+                MappedFieldType fieldType = parseContext.fieldMapper(field);
+                Query filter = null;
+                if (fieldNamesFieldType.isEnabled()) {
+                    final String f;
+                    if (fieldType != null) {
+                        f = fieldType.names().indexName();
+                    } else {
+                        f = field;
+                    }
+                    filter = fieldNamesFieldType.termQuery(f, parseContext);
+                }
+                // if _field_names are not indexed, we need to go the slow way
+                if (filter == null && fieldType != null) {
+                    filter = fieldType.rangeQuery(null, null, true, true);
+                }
+                if (filter == null) {
+                    filter = new TermRangeQuery(field, null, null, true, true);
+                }
+                boolFilter.add(filter, BooleanClause.Occur.SHOULD);
+            }
+
+            existenceFilter = boolFilter.build();
+            existenceFilter = Queries.not(existenceFilter);;
+        }
+
+        if (nullValue) {
+            for (String field : fields) {
+                MappedFieldType fieldType = parseContext.fieldMapper(field);
+                if (fieldType != null) {
+                    nullFilter = fieldType.nullValueQuery();
+                }
+            }
+        }
+
+        Query filter;
+        if (nullFilter != null) {
+            if (existenceFilter != null) {
+                filter = new BooleanQuery.Builder()
+                    .add(existenceFilter, BooleanClause.Occur.SHOULD)
+                    .add(nullFilter, BooleanClause.Occur.SHOULD)
+                    .build();
+            } else {
+                filter = nullFilter;
+            }
+        } else {
+            filter = existenceFilter;
+        }
+
+        if (filter == null) {
+            return null;
+        }
+
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, existenceFilter);
+        }
+        return new ConstantScoreQuery(filter);
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryBuilder.java
index 52b0e36..4994070 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryBuilder.java
@@ -27,11 +27,7 @@ import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.ParseFieldMatcher;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.lucene.uid.Versions;
-import org.elasticsearch.common.xcontent.ToXContent;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.common.xcontent.XContentType;
+import org.elasticsearch.common.xcontent.*;
 import org.elasticsearch.index.VersionType;
 
 import java.io.IOException;
@@ -44,7 +40,7 @@ import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
  *
  * The documents are provided as a set of strings and/or a list of {@link Item}.
  */
-public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQueryBuilder> {
+public class MoreLikeThisQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<MoreLikeThisQueryBuilder> {
 
     /**
      * A single item to be used for a {@link MoreLikeThisQueryBuilder}.
@@ -349,8 +345,6 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
         }
     }
 
-    public static final String NAME = "mlt";
-
     // document inputs
     private List<String> likeTexts = new ArrayList<>();
     private List<String> unlikeTexts = new ArrayList<>();
@@ -375,9 +369,8 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
 
     // other parameters
     private Boolean failOnUnsupportedField;
-
-    static final MoreLikeThisQueryBuilder PROTOTYPE = new MoreLikeThisQueryBuilder();
-
+    private float boost = -1;
+    private String queryName;
 
     /**
      * Constructs a new more like this query which uses the "_all" field.
@@ -518,6 +511,18 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
     }
 
     /**
+     * Set the set of stopwords.
+     * <p/>
+     * <p>Any word in this set is considered "uninteresting" and ignored. Even if your Analyzer allows stopwords, you
+     * might want to tell the MoreLikeThis code to ignore them, as for the purposes of document similarity it seems
+     * reasonable to assume that "a stop word is never interesting".
+     */
+    public MoreLikeThisQueryBuilder stopWords(String... stopWords) {
+        this.stopWords = stopWords;
+        return this;
+    }
+
+    /**
      * The analyzer that will be used to analyze the text. Defaults to the analyzer associated with the fied.
      */
     public MoreLikeThisQueryBuilder analyzer(String analyzer) {
@@ -560,6 +565,20 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
         return this;
     }
 
+    @Override
+    public MoreLikeThisQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public MoreLikeThisQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
     /**
      * The text to use in order to find documents that are "like" this.
      */
@@ -612,7 +631,7 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(MoreLikeThisQueryParser.NAME);
         if (fields != null) {
             builder.field(MoreLikeThisQueryParser.Field.FIELDS.getPreferredName(), fields);
         }
@@ -660,7 +679,12 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
         if (failOnUnsupportedField != null) {
             builder.field(MoreLikeThisQueryParser.Field.FAIL_ON_UNSUPPORTED_FIELD.getPreferredName(), failOnUnsupportedField);
         }
-        printBoostAndQueryName(builder);
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         builder.endObject();
     }
 
@@ -674,9 +698,4 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
         }
         builder.endArray();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryParser.java
index 3747855..396f83d 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryParser.java
@@ -19,29 +19,34 @@
 
 package org.elasticsearch.index.query;
 
-import com.google.common.collect.Sets;
 import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.index.Fields;
 import org.apache.lucene.queries.TermsQuery;
 import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.action.termvectors.*;
-import org.elasticsearch.client.Client;
+import org.elasticsearch.action.termvectors.MultiTermVectorsResponse;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.Strings;
+import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.lucene.search.MoreLikeThisQuery;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.analysis.Analysis;
 import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.internal.UidFieldMapper;
 import org.elasticsearch.index.query.MoreLikeThisQueryBuilder.Item;
+import org.elasticsearch.index.search.morelikethis.MoreLikeThisFetchService;
 import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Set;
 
 import static org.elasticsearch.index.mapper.Uid.createUidAsBytes;
 
@@ -50,7 +55,10 @@ import static org.elasticsearch.index.mapper.Uid.createUidAsBytes;
  *
  * The documents are provided as a set of strings and/or a list of {@link Item}.
  */
-public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
+public class MoreLikeThisQueryParser implements QueryParser {
+
+    public static final String NAME = "mlt";
+    private MoreLikeThisFetchService fetchService = null;
 
     public interface Field {
         ParseField FIELDS = new ParseField("fields");
@@ -73,18 +81,26 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
         ParseField FAIL_ON_UNSUPPORTED_FIELD = new ParseField("fail_on_unsupported_field");
     }
 
+    public MoreLikeThisQueryParser() {
+
+    }
+
+    @Inject(optional = true)
+    public void setFetchService(@Nullable MoreLikeThisFetchService fetchService) {
+        this.fetchService = fetchService;
+    }
+
     @Override
     public String[] names() {
-        return new String[]{MoreLikeThisQueryBuilder.NAME, "more_like_this", "moreLikeThis"};
+        return new String[]{NAME, "more_like_this", "moreLikeThis"};
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         MoreLikeThisQuery mltQuery = new MoreLikeThisQuery();
-        mltQuery.setSimilarity(context.searchSimilarity());
+        mltQuery.setSimilarity(parseContext.searchSimilarity());
 
         List<String> likeTexts = new ArrayList<>();
         List<String> unlikeTexts = new ArrayList<>();
@@ -123,7 +139,7 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.MAX_WORD_LENGTH)) {
                     mltQuery.setMaxWordLen(parser.intValue());
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.ANALYZER)) {
-                    analyzer = context.analysisService().analyzer(parser.text());
+                    analyzer = parseContext.analysisService().analyzer(parser.text());
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.MINIMUM_SHOULD_MATCH)) {
                     mltQuery.setMinimumShouldMatch(parser.text());
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.BOOST_TERMS)) {
@@ -132,10 +148,6 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
                         mltQuery.setBoostTerms(true);
                         mltQuery.setBoostTermsFactor(boostFactor);
                     }
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.MINIMUM_SHOULD_MATCH)) {
-                    mltQuery.setMinimumShouldMatch(parser.text());
-                } else if ("analyzer".equals(currentFieldName)) {
-                    analyzer = context.analysisService().analyzer(parser.text());
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.INCLUDE)) {
                     include = parser.booleanValue();
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.FAIL_ON_UNSUPPORTED_FIELD)) {
@@ -152,7 +164,7 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
                     moreLikeFields = new LinkedList<>();
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                         String field = parser.text();
-                        MappedFieldType fieldType = context.fieldMapper(field);
+                        MappedFieldType fieldType = parseContext.fieldMapper(field);
                         moreLikeFields.add(fieldType == null ? field : fieldType.names().indexName());
                     }
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.LIKE)) {
@@ -178,7 +190,7 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
                         likeItems.add(Item.parse(parser, parseContext.parseFieldMatcher(), new Item()));
                     }
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.STOP_WORDS)) {
-                    Set<String> stopWords = Sets.newHashSet();
+                    Set<String> stopWords = new HashSet<>();
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                         stopWords.add(parser.text());
                     }
@@ -206,14 +218,14 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
 
         // set analyzer
         if (analyzer == null) {
-            analyzer = context.mapperService().searchAnalyzer();
+            analyzer = parseContext.mapperService().searchAnalyzer();
         }
         mltQuery.setAnalyzer(analyzer);
 
         // set like text fields
         boolean useDefaultField = (moreLikeFields == null);
         if (useDefaultField) {
-            moreLikeFields = Collections.singletonList(context.defaultField());
+            moreLikeFields = Collections.singletonList(parseContext.defaultField());
         }
 
         // possibly remove unsupported fields
@@ -225,7 +237,7 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
 
         // support for named query
         if (queryName != null) {
-            context.addNamedQuery(queryName, mltQuery);
+            parseContext.addNamedQuery(queryName, mltQuery);
         }
 
         // handle like texts
@@ -238,7 +250,7 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
 
         // handle items
         if (!likeItems.isEmpty()) {
-            return handleItems(context, mltQuery, likeItems, unlikeItems, include, moreLikeFields, useDefaultField);
+            return handleItems(parseContext, mltQuery, likeItems, unlikeItems, include, moreLikeFields, useDefaultField);
         } else {
             return mltQuery;
         }
@@ -269,10 +281,8 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
         return moreLikeFields;
     }
 
-    private Query handleItems(QueryShardContext context, MoreLikeThisQuery mltQuery, List<Item> likeItems, List<Item> unlikeItems,
+    private Query handleItems(QueryParseContext parseContext, MoreLikeThisQuery mltQuery, List<Item> likeItems, List<Item> unlikeItems,
                               boolean include, List<String> moreLikeFields, boolean useDefaultField) throws IOException {
-
-        QueryParseContext parseContext = context.parseContext();
         // set default index, type and fields if not specified
         for (Item item : likeItems) {
             setDefaultIndexTypeFields(parseContext, item, moreLikeFields, useDefaultField);
@@ -282,14 +292,14 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
         }
 
         // fetching the items with multi-termvectors API
-        MultiTermVectorsResponse responses = fetchResponse(context.getClient(), likeItems, unlikeItems, SearchContext.current());
+        MultiTermVectorsResponse responses = fetchService.fetchResponse(likeItems, unlikeItems, SearchContext.current());
 
         // getting the Fields for liked items
-        mltQuery.setLikeText(getFieldsFor(responses, likeItems));
+        mltQuery.setLikeText(MoreLikeThisFetchService.getFieldsFor(responses, likeItems));
 
         // getting the Fields for unliked items
         if (!unlikeItems.isEmpty()) {
-            org.apache.lucene.index.Fields[] unlikeFields = getFieldsFor(responses, unlikeItems);
+            org.apache.lucene.index.Fields[] unlikeFields = MoreLikeThisFetchService.getFieldsFor(responses, unlikeItems);
             if (unlikeFields.length > 0) {
                 mltQuery.setUnlikeText(unlikeFields);
             }
@@ -311,11 +321,11 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
             item.index(parseContext.index().name());
         }
         if (item.type() == null) {
-            if (parseContext.shardContext().queryTypes().size() > 1) {
+            if (parseContext.queryTypes().size() > 1) {
                 throw new QueryParsingException(parseContext,
                             "ambiguous type for item with id: " + item.id() + " and index: " + item.index());
             } else {
-                item.type(parseContext.shardContext().queryTypes().iterator().next());
+                item.type(parseContext.queryTypes().iterator().next());
             }
         }
         // default fields if not present but don't override for artificial docs
@@ -342,52 +352,4 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
             boolQuery.add(query, BooleanClause.Occur.MUST_NOT);
         }
     }
-
-    @Override
-    public MoreLikeThisQueryBuilder getBuilderPrototype() {
-        return MoreLikeThisQueryBuilder.PROTOTYPE;
-    }
-
-    private MultiTermVectorsResponse fetchResponse(Client client, List<Item> likeItems, @Nullable List<Item> unlikeItems,
-                                                  SearchContext searchContext) throws IOException {
-        MultiTermVectorsRequest request = new MultiTermVectorsRequest();
-        for (Item item : likeItems) {
-            request.add(item.toTermVectorsRequest());
-        }
-        if (unlikeItems != null) {
-            for (Item item : unlikeItems) {
-                request.add(item.toTermVectorsRequest());
-            }
-        }
-        request.copyContextAndHeadersFrom(searchContext);
-        return client.multiTermVectors(request).actionGet();
-    }
-
-    private static Fields[] getFieldsFor(MultiTermVectorsResponse responses, List<Item> items) throws IOException {
-        List<Fields> likeFields = new ArrayList<>();
-
-        Set<Item> selectedItems = new HashSet<>();
-        for (Item request : items) {
-            selectedItems.add(new Item(request.index(), request.type(), request.id()));
-        }
-
-        for (MultiTermVectorsItemResponse response : responses) {
-            if (!hasResponseFromRequest(response, selectedItems)) {
-                continue;
-            }
-            if (response.isFailed()) {
-                continue;
-            }
-            TermVectorsResponse getResponse = response.getResponse();
-            if (!getResponse.isExists()) {
-                continue;
-            }
-            likeFields.add(getResponse.getFields());
-        }
-        return likeFields.toArray(Fields.EMPTY_ARRAY);
-    }
-
-    private static boolean hasResponseFromRequest(MultiTermVectorsItemResponse response, Set<Item> selectedItems) {
-        return selectedItems.contains(new Item(response.getIndex(), response.getType(), response.getId()));
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryBuilder.java
index 1cc8a1e..9059865 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryBuilder.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.index.query;
 
 import com.carrotsearch.hppc.ObjectFloatHashMap;
-
 import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.ParseFieldMatcher;
@@ -37,9 +36,7 @@ import java.util.Locale;
 /**
  * Same as {@link MatchQueryBuilder} but supports multiple fields.
  */
-public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQueryBuilder> {
-
-    public static final String NAME = "multi_match";
+public class MultiMatchQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<MultiMatchQueryBuilder> {
 
     private final Object text;
 
@@ -48,10 +45,12 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
 
     private MultiMatchQueryBuilder.Type type;
 
-    private Operator operator;
+    private MatchQueryBuilder.Operator operator;
 
     private String analyzer;
 
+    private Float boost;
+
     private Integer slop;
 
     private Fuzziness fuzziness;
@@ -72,9 +71,10 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
 
     private Float cutoffFrequency = null;
 
-    private MatchQuery.ZeroTermsQuery zeroTermsQuery = null;
+    private MatchQueryBuilder.ZeroTermsQuery zeroTermsQuery = null;
+
+    private String queryName;
 
-    static final MultiMatchQueryBuilder PROTOTYPE = new MultiMatchQueryBuilder(null);
 
     public enum Type {
 
@@ -141,7 +141,7 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
                 }
             }
             if (type == null) {
-                throw new ElasticsearchParseException("failed to parse [{}] query type [{}]. unknown type.", NAME, value);
+                throw new ElasticsearchParseException("failed to parse [{}] query type [{}]. unknown type.", MultiMatchQueryParser.NAME, value);
             }
             return type;
         }
@@ -195,7 +195,7 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
     /**
      * Sets the operator to use when using a boolean query. Defaults to <tt>OR</tt>.
      */
-    public MultiMatchQueryBuilder operator(Operator operator) {
+    public MultiMatchQueryBuilder operator(MatchQueryBuilder.Operator operator) {
         this.operator = operator;
         return this;
     }
@@ -210,6 +210,15 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
     }
 
     /**
+     * Set the boost to apply to the query.
+     */
+    @Override
+    public MultiMatchQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
+    /**
      * Set the phrase slop if evaluated to a phrase query type.
      */
     public MultiMatchQueryBuilder slop(int slop) {
@@ -296,14 +305,22 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
     }
 
 
-    public MultiMatchQueryBuilder zeroTermsQuery(MatchQuery.ZeroTermsQuery zeroTermsQuery) {
+    public MultiMatchQueryBuilder zeroTermsQuery(MatchQueryBuilder.ZeroTermsQuery zeroTermsQuery) {
         this.zeroTermsQuery = zeroTermsQuery;
         return this;
     }
 
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public MultiMatchQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
     @Override
     public void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(MultiMatchQueryParser.NAME);
 
         builder.field("query", text);
         builder.startArray("fields");
@@ -325,6 +342,9 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
         if (analyzer != null) {
             builder.field("analyzer", analyzer);
         }
+        if (boost != null) {
+            builder.field("boost", boost);
+        }
         if (slop != null) {
             builder.field("slop", slop);
         }
@@ -364,13 +384,11 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
             builder.field("zero_terms_query", zeroTermsQuery.toString());
         }
 
-        printBoostAndQueryName(builder);
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
 
         builder.endObject();
     }
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryParser.java
index 9b5199e..15d21c3 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryParser.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.regex.Regex;
@@ -35,7 +36,9 @@ import java.util.Map;
 /**
  * Same as {@link MatchQueryParser} but has support for multiple fields.
  */
-public class MultiMatchQueryParser extends BaseQueryParserTemp {
+public class MultiMatchQueryParser implements QueryParser {
+
+    public static final String NAME = "multi_match";
 
     @Inject
     public MultiMatchQueryParser() {
@@ -44,20 +47,19 @@ public class MultiMatchQueryParser extends BaseQueryParserTemp {
     @Override
     public String[] names() {
         return new String[]{
-                MultiMatchQueryBuilder.NAME, "multiMatch"
+                NAME, "multiMatch"
         };
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         Object value = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
         Float tieBreaker = null;
         MultiMatchQueryBuilder.Type type = null;
-        MultiMatchQuery multiMatchQuery = new MultiMatchQuery(context);
+        MultiMatchQuery multiMatchQuery = new MultiMatchQuery(parseContext);
         String minimumShouldMatch = null;
         Map<String, Float> fieldNameWithBoosts = new HashMap<>();
         String queryName = null;
@@ -70,12 +72,12 @@ public class MultiMatchQueryParser extends BaseQueryParserTemp {
             } else if ("fields".equals(currentFieldName)) {
                 if (token == XContentParser.Token.START_ARRAY) {
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                        extractFieldAndBoost(context, parser, fieldNameWithBoosts);
+                        extractFieldAndBoost(parseContext, parser, fieldNameWithBoosts);
                     }
                 } else if (token.isValue()) {
-                    extractFieldAndBoost(context, parser, fieldNameWithBoosts);
+                    extractFieldAndBoost(parseContext, parser, fieldNameWithBoosts);
                 } else {
-                    throw new QueryParsingException(parseContext, "[" + MultiMatchQueryBuilder.NAME + "] query does not support [" + currentFieldName + "]");
+                    throw new QueryParsingException(parseContext, "[" + NAME + "] query does not support [" + currentFieldName + "]");
                 }
             } else if (token.isValue()) {
                 if ("query".equals(currentFieldName)) {
@@ -84,8 +86,8 @@ public class MultiMatchQueryParser extends BaseQueryParserTemp {
                     type = MultiMatchQueryBuilder.Type.parse(parser.text(), parseContext.parseFieldMatcher());
                 } else if ("analyzer".equals(currentFieldName)) {
                     String analyzer = parser.text();
-                    if (context.analysisService().analyzer(analyzer) == null) {
-                        throw new QueryParsingException(parseContext, "[" + MultiMatchQueryBuilder.NAME + "] analyzer [" + parser.text() + "] not found");
+                    if (parseContext.analysisService().analyzer(analyzer) == null) {
+                        throw new QueryParsingException(parseContext, "[" + NAME + "] analyzer [" + parser.text() + "] not found");
                     }
                     multiMatchQuery.setAnalyzer(analyzer);
                 } else if ("boost".equals(currentFieldName)) {
@@ -99,7 +101,15 @@ public class MultiMatchQueryParser extends BaseQueryParserTemp {
                 } else if ("max_expansions".equals(currentFieldName) || "maxExpansions".equals(currentFieldName)) {
                     multiMatchQuery.setMaxExpansions(parser.intValue());
                 } else if ("operator".equals(currentFieldName)) {
-                    multiMatchQuery.setOccur(Operator.fromString(parser.text()).toBooleanClauseOccur());
+                    String op = parser.text();
+                    if ("or".equalsIgnoreCase(op)) {
+                        multiMatchQuery.setOccur(BooleanClause.Occur.SHOULD);
+                    } else if ("and".equalsIgnoreCase(op)) {
+                        multiMatchQuery.setOccur(BooleanClause.Occur.MUST);
+                    } else {
+                        throw new QueryParsingException(parseContext, "text query requires operator to be either 'and' or 'or', not [" + op
+                                + "]");
+                    }
                 } else if ("minimum_should_match".equals(currentFieldName) || "minimumShouldMatch".equals(currentFieldName)) {
                     minimumShouldMatch = parser.textOrNull();
                 } else if ("fuzzy_rewrite".equals(currentFieldName) || "fuzzyRewrite".equals(currentFieldName)) {
@@ -156,12 +166,12 @@ public class MultiMatchQueryParser extends BaseQueryParserTemp {
 
         query.setBoost(boost);
         if (queryName != null) {
-            context.addNamedQuery(queryName, query);
+            parseContext.addNamedQuery(queryName, query);
         }
         return query;
     }
 
-    private void extractFieldAndBoost(QueryShardContext context, XContentParser parser, Map<String, Float> fieldNameWithBoosts) throws IOException {
+    private void extractFieldAndBoost(QueryParseContext parseContext, XContentParser parser, Map<String, Float> fieldNameWithBoosts) throws IOException {
         String fField = null;
         Float fBoost = null;
         char[] fieldText = parser.textCharacters();
@@ -179,16 +189,11 @@ public class MultiMatchQueryParser extends BaseQueryParserTemp {
         }
 
         if (Regex.isSimpleMatchPattern(fField)) {
-            for (String field : context.mapperService().simpleMatchToIndexNames(fField)) {
+            for (String field : parseContext.mapperService().simpleMatchToIndexNames(fField)) {
                 fieldNameWithBoosts.put(field, fBoost);
             }
         } else {
             fieldNameWithBoosts.put(fField, fBoost);
         }
     }
-
-    @Override
-    public MultiMatchQueryBuilder getBuilderPrototype() {
-        return MultiMatchQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MultiTermQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MultiTermQueryBuilder.java
index 0e946d6..9c7383d 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MultiTermQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MultiTermQueryBuilder.java
@@ -18,6 +18,6 @@
  */
 package org.elasticsearch.index.query;
 
-public interface MultiTermQueryBuilder<QB extends MultiTermQueryBuilder<QB>> extends QueryBuilder<QB> {
+public abstract class MultiTermQueryBuilder extends QueryBuilder {
 
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/NestedQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/NestedQueryBuilder.java
index e012c52..63b40dc 100644
--- a/core/src/main/java/org/elasticsearch/index/query/NestedQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/NestedQueryBuilder.java
@@ -19,211 +19,85 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.join.BitSetProducer;
-import org.apache.lucene.search.join.ScoreMode;
-import org.apache.lucene.search.join.ToParentBlockJoinQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.mapper.object.ObjectMapper;
-import org.elasticsearch.index.query.support.QueryInnerHits;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsSubSearchContext;
+import org.elasticsearch.index.query.support.QueryInnerHitBuilder;
 
 import java.io.IOException;
-import java.util.Locale;
 import java.util.Objects;
 
-public class NestedQueryBuilder extends AbstractQueryBuilder<NestedQueryBuilder> {
+public class NestedQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<NestedQueryBuilder> {
 
-    /**
-     * The default score move for nested queries.
-     */
-    public static final ScoreMode DEFAULT_SCORE_MODE = ScoreMode.Avg;
+    private final QueryBuilder queryBuilder;
 
-    /**
-     * The queries name used while parsing
-     */
-    public static final String NAME = "nested";
+    private final String path;
 
-    private final QueryBuilder query;
+    private String scoreMode;
 
-    private final String path;
+    private float boost = 1.0f;
 
-    private ScoreMode scoreMode = DEFAULT_SCORE_MODE;
+    private String queryName;
 
-    private QueryInnerHits queryInnerHits;
+    private QueryInnerHitBuilder innerHit;
 
-    public NestedQueryBuilder(String path, QueryBuilder query) {
-        if (path == null) {
-            throw new IllegalArgumentException("[" + NAME + "] requires 'path' field");
-        }
-        if (query == null) {
-            throw new IllegalArgumentException("[" + NAME + "] requires 'query' field");
-        }
+    public NestedQueryBuilder(String path, QueryBuilder queryBuilder) {
         this.path = path;
-        this.query = query;
-    }
-
-    public NestedQueryBuilder(String path, QueryBuilder query, ScoreMode scoreMode, QueryInnerHits queryInnerHits) {
-        this(path, query);
-        scoreMode(scoreMode);
-        this.queryInnerHits = queryInnerHits;
+        this.queryBuilder = Objects.requireNonNull(queryBuilder);
     }
-
     /**
-     * The score mode how the scores from the matching child documents are mapped into the nested parent document.
+     * The score mode.
      */
-    public NestedQueryBuilder scoreMode(ScoreMode scoreMode) {
-        if (scoreMode == null) {
-            throw new IllegalArgumentException("[" + NAME + "] requires 'score_mode' field");
-        }
+    public NestedQueryBuilder scoreMode(String scoreMode) {
         this.scoreMode = scoreMode;
         return this;
     }
 
     /**
-     * Sets inner hit definition in the scope of this nested query and reusing the defined path and query.
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
      */
-    public NestedQueryBuilder innerHit(QueryInnerHits innerHit) {
-        this.queryInnerHits = innerHit;
+    @Override
+    public NestedQueryBuilder boost(float boost) {
+        this.boost = boost;
         return this;
     }
 
     /**
-     * Returns the nested query to execute.
-     */
-    public QueryBuilder query() {
-        return query;
-    }
-
-    /**
-     * Returns inner hit definition in the scope of this query and reusing the defined type and query.
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public QueryInnerHits innerHit() {
-        return queryInnerHits;
+    public NestedQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     /**
-     * Returns how the scores from the matching child documents are mapped into the nested parent document.
+     * Sets inner hit definition in the scope of this nested query and reusing the defined path and query.
      */
-    public ScoreMode scoreMode() {
-        return scoreMode;
+    public NestedQueryBuilder innerHit(QueryInnerHitBuilder innerHit) {
+        this.innerHit = innerHit;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(NestedQueryParser.NAME);
         builder.field("query");
-        query.toXContent(builder, params);
+        queryBuilder.toXContent(builder, params);
         builder.field("path", path);
         if (scoreMode != null) {
-            builder.field("score_mode", scoreMode.name().toLowerCase(Locale.ROOT));
-        }
-        printBoostAndQueryName(builder);
-        if (queryInnerHits != null) {
-            queryInnerHits.toXContent(builder, params);
-        }
-        builder.endObject();
-    }
-
-    @Override
-    public final String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected boolean doEquals(NestedQueryBuilder that) {
-        return Objects.equals(query, that.query)
-                && Objects.equals(path, that.path)
-                && Objects.equals(scoreMode, that.scoreMode)
-                && Objects.equals(queryInnerHits, that.queryInnerHits);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(query, path, scoreMode, queryInnerHits);
-    }
-
-    private NestedQueryBuilder(StreamInput in) throws IOException {
-        path = in.readString();
-        final int ordinal = in.readVInt();
-        scoreMode = ScoreMode.values()[ordinal];
-        query = in.readQuery();
-        if (in.readBoolean()) {
-            queryInnerHits = new QueryInnerHits(in);
-        }
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(path);
-        out.writeVInt(scoreMode.ordinal());
-        out.writeQuery(query);
-        if (queryInnerHits != null) {
-            out.writeBoolean(true);
-            queryInnerHits.writeTo(out);
-        } else {
-            out.writeBoolean(false);
-        }
-    }
-
-    @Override
-    protected NestedQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new NestedQueryBuilder(in);
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        ObjectMapper nestedObjectMapper = context.getObjectMapper(path);
-        if (nestedObjectMapper == null) {
-            throw new IllegalStateException("[" + NAME + "] failed to find nested object under path [" + path + "]");
+            builder.field("score_mode", scoreMode);
         }
-        if (!nestedObjectMapper.nested().isNested()) {
-            throw new IllegalStateException("[" + NAME + "] nested object under path [" + path + "] is not of nested type");
+        if (boost != 1.0f) {
+            builder.field("boost", boost);
         }
-        final BitSetProducer parentFilter;
-        final Filter childFilter;
-        final ObjectMapper parentObjectMapper;
-        final Query innerQuery;
-        ObjectMapper objectMapper = context.nestedScope().getObjectMapper();
-        try {
-            if (objectMapper == null) {
-                parentFilter = context.bitsetFilter(Queries.newNonNestedFilter());
-            } else {
-                parentFilter = context.bitsetFilter(objectMapper.nestedTypeFilter());
-            }
-            childFilter = nestedObjectMapper.nestedTypeFilter();
-            parentObjectMapper = context.nestedScope().nextLevel(nestedObjectMapper);
-            innerQuery = this.query.toQuery(context);
-            if (innerQuery == null) {
-                return null;
-            }
-        } finally {
-            context.nestedScope().previousLevel();
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-
-        if (queryInnerHits != null) {
-            try (XContentParser parser = queryInnerHits.getXcontentParser()) {
-                XContentParser.Token token = parser.nextToken();
-                if (token != XContentParser.Token.START_OBJECT) {
-                    throw new IllegalStateException("start object expected but was: [" + token + "]");
-                }
-                InnerHitsSubSearchContext innerHits = context.indexQueryParserService().getInnerHitsQueryParserHelper().parse(parser);
-                if (innerHits != null) {
-                    ParsedQuery parsedQuery = new ParsedQuery(innerQuery, context.copyNamedQueries());
-
-                    InnerHitsContext.NestedInnerHits nestedInnerHits = new InnerHitsContext.NestedInnerHits(innerHits.getSubSearchContext(), parsedQuery, null, parentObjectMapper, nestedObjectMapper);
-                    String name = innerHits.getName() != null ? innerHits.getName() : path;
-                    context.addInnerHits(name, nestedInnerHits);
-                }
-            }
+        if (innerHit != null) {
+            builder.startObject("inner_hits");
+            builder.value(innerHit);
+            builder.endObject();
         }
-        return new ToParentBlockJoinQuery(Queries.filtered(innerQuery, childFilter), parentFilter, scoreMode);
+        builder.endObject();
     }
 
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/NestedQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/NestedQueryParser.java
index ce6770a..e14720b 100644
--- a/core/src/main/java/org/elasticsearch/index/query/NestedQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/NestedQueryParser.java
@@ -31,50 +31,55 @@ import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.query.support.InnerHitsQueryParserHelper;
 import org.elasticsearch.index.query.support.NestedInnerQueryParseSupport;
-import org.elasticsearch.index.query.support.QueryInnerHits;
 import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
 import org.elasticsearch.search.fetch.innerhits.InnerHitsSubSearchContext;
 
 import java.io.IOException;
 
-public class NestedQueryParser extends BaseQueryParser<NestedQueryBuilder> {
+public class NestedQueryParser implements QueryParser {
 
+    public static final String NAME = "nested";
     private static final ParseField FILTER_FIELD = new ParseField("filter").withAllDeprecated("query");
-    private static final NestedQueryBuilder PROTOTYPE = new NestedQueryBuilder("", EmptyQueryBuilder.PROTOTYPE);
 
+    private final InnerHitsQueryParserHelper innerHitsQueryParserHelper;
+
+    @Inject
+    public NestedQueryParser(InnerHitsQueryParserHelper innerHitsQueryParserHelper) {
+        this.innerHitsQueryParserHelper = innerHitsQueryParserHelper;
+    }
 
     @Override
     public String[] names() {
-        return new String[]{NestedQueryBuilder.NAME, Strings.toCamelCase(NestedQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public NestedQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        ScoreMode scoreMode = NestedQueryBuilder.DEFAULT_SCORE_MODE;
+        final ToBlockJoinQueryBuilder builder = new ToBlockJoinQueryBuilder(parseContext);
+
+        float boost = 1.0f;
+        ScoreMode scoreMode = ScoreMode.Avg;
         String queryName = null;
-        QueryBuilder query = null;
-        String path = null;
+
         String currentFieldName = null;
-        QueryInnerHits queryInnerHits = null;
         XContentParser.Token token;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("query".equals(currentFieldName)) {
-                    query = parseContext.parseInnerQueryBuilder();
+                    builder.query();
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, FILTER_FIELD)) {
-                    query = parseContext.parseInnerFilterToQueryBuilder();
+                    builder.filter();
                 } else if ("inner_hits".equals(currentFieldName)) {
-                    queryInnerHits = new QueryInnerHits(parser);
+                    builder.setInnerHits(innerHitsQueryParserHelper.parse(parseContext));
                 } else {
                     throw new QueryParsingException(parseContext, "[nested] query does not support [" + currentFieldName + "]");
                 }
             } else if (token.isValue()) {
                 if ("path".equals(currentFieldName)) {
-                    path = parser.text();
+                    builder.setPath(parser.text());
                 } else if ("boost".equals(currentFieldName)) {
                     boost = parser.floatValue();
                 } else if ("score_mode".equals(currentFieldName) || "scoreMode".equals(currentFieldName)) {
@@ -99,11 +104,64 @@ public class NestedQueryParser extends BaseQueryParser<NestedQueryBuilder> {
                 }
             }
         }
-        return new NestedQueryBuilder(path, query, scoreMode, queryInnerHits).queryName(queryName).boost(boost);
+
+        builder.setScoreMode(scoreMode);
+        ToParentBlockJoinQuery joinQuery = builder.build();
+        if (joinQuery != null) {
+            joinQuery.setBoost(boost);
+            if (queryName != null) {
+                parseContext.addNamedQuery(queryName, joinQuery);
+            }
+        }
+        return joinQuery;
     }
 
-    @Override
-    public NestedQueryBuilder getBuilderPrototype() {
-        return PROTOTYPE;
+    public static class ToBlockJoinQueryBuilder extends NestedInnerQueryParseSupport {
+
+        private ScoreMode scoreMode;
+        private InnerHitsSubSearchContext innerHits;
+
+        public ToBlockJoinQueryBuilder(QueryParseContext parseContext) throws IOException {
+            super(parseContext);
+        }
+
+        public void setScoreMode(ScoreMode scoreMode) {
+            this.scoreMode = scoreMode;
+        }
+
+        public void setInnerHits(InnerHitsSubSearchContext innerHits) {
+            this.innerHits = innerHits;
+        }
+
+        @Nullable
+        public ToParentBlockJoinQuery build() throws IOException {
+            Query innerQuery;
+            if (queryFound) {
+                innerQuery = getInnerQuery();
+            } else if (filterFound) {
+                Query innerFilter = getInnerFilter();
+                if (innerFilter != null) {
+                    innerQuery = new ConstantScoreQuery(getInnerFilter());
+                } else {
+                    innerQuery = null;
+                }
+            } else {
+                throw new QueryParsingException(parseContext, "[nested] requires either 'query' or 'filter' field");
+            }
+
+            if (innerHits != null) {
+                ParsedQuery parsedQuery = new ParsedQuery(innerQuery, parseContext.copyNamedQueries());
+                InnerHitsContext.NestedInnerHits nestedInnerHits = new InnerHitsContext.NestedInnerHits(innerHits.getSubSearchContext(), parsedQuery, null, getParentObjectMapper(), nestedObjectMapper);
+                String name = innerHits.getName() != null ? innerHits.getName() : path;
+                parseContext.addInnerHits(name, nestedInnerHits);
+            }
+
+            if (innerQuery != null) {
+                return new ToParentBlockJoinQuery(Queries.filtered(innerQuery, childFilter), parentFilter, scoreMode);
+            } else {
+                return null;
+            }
+        }
+
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/NotQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/NotQueryBuilder.java
index a26ebb7..c16cf64 100644
--- a/core/src/main/java/org/elasticsearch/index/query/NotQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/NotQueryBuilder.java
@@ -19,10 +19,6 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
@@ -31,71 +27,29 @@ import java.util.Objects;
 /**
  * A filter that matches documents matching boolean combinations of other filters.
  */
-public class NotQueryBuilder extends AbstractQueryBuilder<NotQueryBuilder> {
-
-    public static final String NAME = "not";
+public class NotQueryBuilder extends QueryBuilder {
 
     private final QueryBuilder filter;
 
-    static final NotQueryBuilder PROTOTYPE = new NotQueryBuilder(null);
+    private String queryName;
 
     public NotQueryBuilder(QueryBuilder filter) {
-        this.filter = filter;
+        this.filter = Objects.requireNonNull(filter);
     }
 
-    /**
-     * @return the query added to "not".
-     */
-    public QueryBuilder innerQuery() {
-        return this.filter;
+    public NotQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(NotQueryParser.NAME);
         builder.field("query");
         filter.toXContent(builder, params);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query luceneQuery = filter.toFilter(context);
-        if (luceneQuery == null) {
-            return null;
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return Queries.not(luceneQuery);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        return validateInnerQuery(filter, null);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(filter);
-    }
-
-    @Override
-    protected boolean doEquals(NotQueryBuilder other) {
-        return Objects.equals(filter, other.filter);
-    }
-
-    @Override
-    protected NotQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        QueryBuilder queryBuilder = in.readQuery();
-        return new NotQueryBuilder(queryBuilder);
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(filter);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/NotQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/NotQueryParser.java
index f500031..6bfe4c7 100644
--- a/core/src/main/java/org/elasticsearch/index/query/NotQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/NotQueryParser.java
@@ -19,18 +19,21 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
 
 /**
- * Parser for not query
+ *
  */
-public class NotQueryParser extends BaseQueryParser<NotQueryBuilder> {
+public class NotQueryParser implements QueryParser {
 
-    private static final ParseField QUERY_FIELD = new ParseField("query", "filter");
+    public static final String NAME = "not";
+    private static final ParseField QUERY_FIELD = new ParseField("filter", "query");
 
     @Inject
     public NotQueryParser() {
@@ -38,19 +41,18 @@ public class NotQueryParser extends BaseQueryParser<NotQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{NotQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public NotQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        QueryBuilder query = null;
+        Query query = null;
         boolean queryFound = false;
 
         String queryName = null;
         String currentFieldName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
         XContentParser.Token token;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
@@ -59,18 +61,16 @@ public class NotQueryParser extends BaseQueryParser<NotQueryBuilder> {
                 // skip
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if (parseContext.parseFieldMatcher().match(currentFieldName, QUERY_FIELD)) {
-                    query = parseContext.parseInnerFilterToQueryBuilder();
+                    query = parseContext.parseInnerFilter();
                     queryFound = true;
                 } else {
                     queryFound = true;
                     // its the filter, and the name is the field
-                    query = parseContext.parseInnerFilterToQueryBuilder(currentFieldName);
+                    query = parseContext.parseInnerFilter(currentFieldName);
                 }
             } else if (token.isValue()) {
                 if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[not] query does not support [" + currentFieldName + "]");
                 }
@@ -78,17 +78,17 @@ public class NotQueryParser extends BaseQueryParser<NotQueryBuilder> {
         }
 
         if (!queryFound) {
-            throw new QueryParsingException(parseContext, "query is required when using `not` query");
+            throw new QueryParsingException(parseContext, "filter is required when using `not` query");
         }
 
-        NotQueryBuilder notQueryBuilder = new NotQueryBuilder(query);
-        notQueryBuilder.queryName(queryName);
-        notQueryBuilder.boost(boost);
-        return notQueryBuilder;
-    }
+        if (query == null) {
+            return null;
+        }
 
-    @Override
-    public NotQueryBuilder getBuilderPrototype() {
-        return NotQueryBuilder.PROTOTYPE;
+        Query notQuery = Queries.not(query);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, notQuery);
+        }
+        return notQuery;
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/Operator.java b/core/src/main/java/org/elasticsearch/index/query/Operator.java
deleted file mode 100644
index 22b5469..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/Operator.java
+++ /dev/null
@@ -1,83 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.queryparser.classic.QueryParser;
-import org.apache.lucene.search.BooleanClause;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.io.stream.Writeable;
-import org.elasticsearch.common.util.CollectionUtils;
-
-import java.io.IOException;
-
-public enum Operator implements Writeable<Operator> {
-    OR, AND;
-
-    private static final Operator PROTOTYPE = OR;
-
-    public BooleanClause.Occur toBooleanClauseOccur() {
-        switch (this) {
-            case OR:
-                return BooleanClause.Occur.SHOULD;
-            case AND:
-                return BooleanClause.Occur.MUST;
-            default:
-                throw Operator.newOperatorException(this.toString());
-        }
-    }
-
-    public QueryParser.Operator toQueryParserOperator() {
-        switch (this) {
-            case OR:
-                return QueryParser.Operator.OR;
-            case AND:
-                return QueryParser.Operator.AND;
-            default:
-                throw Operator.newOperatorException(this.toString());
-        }
-    }
-
-    @Override
-    public Operator readFrom(StreamInput in) throws IOException {
-        return Operator.values()[in.readVInt()];
-    }
-
-    public static Operator readOperatorFrom(StreamInput in) throws IOException {
-        return PROTOTYPE.readFrom(in);
-    }
-
-    @Override
-    public void writeTo(StreamOutput out) throws IOException {
-        out.writeVInt(this.ordinal());
-    }
-
-    public static Operator fromString(String op) {
-        for (Operator operator : Operator.values()) {
-            if (operator.name().equalsIgnoreCase(op)) {
-                return operator;
-            }
-        }
-        throw Operator.newOperatorException(op);
-    }
-
-    private static IllegalArgumentException newOperatorException(String op) {
-        return new IllegalArgumentException("operator needs to be either " + CollectionUtils.arrayAsArrayList(Operator.values()) + ", but not [" + op + "]");
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/PrefixQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/PrefixQueryBuilder.java
index a49580c..e0e5b2f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/PrefixQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/PrefixQueryBuilder.java
@@ -19,53 +19,44 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.PrefixQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * A Query that matches documents containing terms with a specified prefix.
  */
-public class PrefixQueryBuilder extends AbstractQueryBuilder<PrefixQueryBuilder> implements MultiTermQueryBuilder<PrefixQueryBuilder> {
+public class PrefixQueryBuilder extends MultiTermQueryBuilder implements BoostableQueryBuilder<PrefixQueryBuilder> {
 
-    public static final String NAME = "prefix";
+    private final String name;
 
-    private final String fieldName;
+    private final String prefix;
 
-    private final String value;
+    private float boost = -1;
 
     private String rewrite;
 
-    static final PrefixQueryBuilder PROTOTYPE = new PrefixQueryBuilder(null, null);
+    private String queryName;
 
     /**
      * A Query that matches documents containing terms with a specified prefix.
      *
-     * @param fieldName The name of the field
-     * @param value The prefix query
+     * @param name   The name of the field
+     * @param prefix The prefix query
      */
-    public PrefixQueryBuilder(String fieldName, String value) {
-        this.fieldName = fieldName;
-        this.value = value;
+    public PrefixQueryBuilder(String name, String prefix) {
+        this.name = name;
+        this.prefix = prefix;
     }
 
-    public String fieldName() {
-        return this.fieldName;
-    }
-
-    public String value() {
-        return this.value;
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
+    @Override
+    public PrefixQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     public PrefixQueryBuilder rewrite(String rewrite) {
@@ -73,83 +64,33 @@ public class PrefixQueryBuilder extends AbstractQueryBuilder<PrefixQueryBuilder>
         return this;
     }
 
-    public String rewrite() {
-        return this.rewrite;
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public PrefixQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     public void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.startObject(fieldName);
-        builder.field("prefix", this.value);
-        if (rewrite != null) {
-            builder.field("rewrite", rewrite);
-        }
-        printBoostAndQueryName(builder);
-        builder.endObject();
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        MultiTermQuery.RewriteMethod method = QueryParsers.parseRewriteMethod(context.parseFieldMatcher(), rewrite, null);
-
-        Query query = null;
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType != null) {
-            query = fieldType.prefixQuery(value, method, context);
-        }
-        if (query == null) {
-            PrefixQuery prefixQuery = new PrefixQuery(new Term(fieldName, BytesRefs.toBytesRef(value)));
-            if (method != null) {
-                prefixQuery.setRewriteMethod(method);
+        builder.startObject(PrefixQueryParser.NAME);
+        if (boost == -1 && rewrite == null && queryName == null) {
+            builder.field(name, prefix);
+        } else {
+            builder.startObject(name);
+            builder.field("prefix", prefix);
+            if (boost != -1) {
+                builder.field("boost", boost);
             }
-            query = prefixQuery;
-        }
-
-        return query;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (Strings.isEmpty(this.fieldName)) {
-            validationException = addValidationError("field name cannot be null or empty.", validationException);
-        }
-        if (this.value == null) {
-            validationException = addValidationError("query text cannot be null", validationException);
+            if (rewrite != null) {
+                builder.field("rewrite", rewrite);
+            }
+            if (queryName != null) {
+                builder.field("_name", queryName);
+            }
+            builder.endObject();
         }
-        return validationException;
-    }
-
-    @Override
-    protected PrefixQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        PrefixQueryBuilder prefixQueryBuilder = new PrefixQueryBuilder(in.readString(), in.readString());
-        prefixQueryBuilder.rewrite = in.readOptionalString();
-        return prefixQueryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-        out.writeString(value);
-        out.writeOptionalString(rewrite);
-    }
-
-    @Override
-    protected final int doHashCode() {
-        return Objects.hash(fieldName, value, rewrite);
-    }
-
-    @Override
-    protected boolean doEquals(PrefixQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-                Objects.equals(value, other.value) &&
-                Objects.equals(rewrite, other.rewrite);
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/PrefixQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/PrefixQueryParser.java
index eac29fa..d61fec7 100644
--- a/core/src/main/java/org/elasticsearch/index/query/PrefixQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/PrefixQueryParser.java
@@ -19,16 +19,25 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.MultiTermQuery;
+import org.apache.lucene.search.PrefixQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
 
 /**
- * Parser for prefix query
+ *
  */
-public class PrefixQueryParser extends BaseQueryParser<PrefixQueryBuilder> {
+public class PrefixQueryParser implements QueryParser {
+
+    public static final String NAME = "prefix";
 
     private static final ParseField NAME_FIELD = new ParseField("_name").withAllDeprecated("query name is not supported in short version of prefix query");
 
@@ -38,19 +47,19 @@ public class PrefixQueryParser extends BaseQueryParser<PrefixQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{PrefixQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public PrefixQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldName = parser.currentName();
-        String value = null;
-        String rewrite = null;
-
+        String rewriteMethod = null;
         String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+
+        String value = null;
+        float boost = 1.0f;
         String currentFieldName = null;
         XContentParser.Token token;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -71,7 +80,7 @@ public class PrefixQueryParser extends BaseQueryParser<PrefixQueryBuilder> {
                         } else if ("boost".equals(currentFieldName)) {
                             boost = parser.floatValue();
                         } else if ("rewrite".equals(currentFieldName)) {
-                            rewrite = parser.textOrNull();
+                            rewriteMethod = parser.textOrNull();
                         } else {
                             throw new QueryParsingException(parseContext, "[regexp] query does not support [" + currentFieldName + "]");
                         }
@@ -90,14 +99,25 @@ public class PrefixQueryParser extends BaseQueryParser<PrefixQueryBuilder> {
         if (value == null) {
             throw new QueryParsingException(parseContext, "No value specified for prefix query");
         }
-        return new PrefixQueryBuilder(fieldName, value)
-                .rewrite(rewrite)
-                .boost(boost)
-                .queryName(queryName);
-    }
 
-    @Override
-    public PrefixQueryBuilder getBuilderPrototype() {
-        return PrefixQueryBuilder.PROTOTYPE;
+        MultiTermQuery.RewriteMethod method = QueryParsers.parseRewriteMethod(parseContext.parseFieldMatcher(), rewriteMethod, null);
+
+        Query query = null;
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            query = fieldType.prefixQuery(value, method, parseContext);
+        }
+        if (query == null) {
+            PrefixQuery prefixQuery = new PrefixQuery(new Term(fieldName, BytesRefs.toBytesRef(value)));
+            if (method != null) {
+                prefixQuery.setRewriteMethod(method);
+            }
+            query = prefixQuery;
+        }
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return  query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/QueryBuilder.java
index 3f69375..fa11d32 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryBuilder.java
@@ -19,79 +19,25 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.elasticsearch.client.Requests;
-import org.elasticsearch.common.bytes.BytesReference;
-import org.elasticsearch.common.io.stream.NamedWriteable;
-import org.elasticsearch.common.xcontent.ToXContent;
+import org.elasticsearch.action.support.ToXContentToBytes;
+import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentType;
 
 import java.io.IOException;
 
-public interface QueryBuilder<QB extends QueryBuilder> extends NamedWriteable<QB>, ToXContent {
+public abstract class QueryBuilder extends ToXContentToBytes {
 
-    /**
-     * Validate the query.
-     * @return a {@link QueryValidationException} containing error messages, {@code null} if query is valid.
-     * e.g. if fields that are needed to create the lucene query are missing.
-     */
-    QueryValidationException validate();
+    protected QueryBuilder() {
+        super(XContentType.JSON);
+    }
 
-    /**
-     * Converts this QueryBuilder to a lucene {@link Query}.
-     * Returns <tt>null</tt> if this query should be ignored in the context of
-     * parent queries.
-     *
-     * @param context additional information needed to construct the queries
-     * @return the {@link Query} or <tt>null</tt> if this query should be ignored upstream
-     * @throws QueryShardException
-     * @throws IOException
-     */
-    Query toQuery(QueryShardContext context) throws IOException;
+    @Override
+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject();
+        doXContent(builder, params);
+        builder.endObject();
+        return builder;
+    }
 
-    /**
-     * Converts this QueryBuilder to an unscored lucene {@link Query} that acts as a filter.
-     * Returns <tt>null</tt> if this query should be ignored in the context of
-     * parent queries.
-     *
-     * @param context additional information needed to construct the queries
-     * @return the {@link Query} or <tt>null</tt> if this query should be ignored upstream
-     * @throws QueryShardException
-     * @throws IOException
-     */
-    Query toFilter(QueryShardContext context) throws IOException;
-
-    /**
-     * Returns a {@link org.elasticsearch.common.bytes.BytesReference}
-     * containing the {@link ToXContent} output in binary format.
-     * Builds the request based on the default {@link XContentType}, either {@link Requests#CONTENT_TYPE} or provided as a constructor argument
-     */
-    //norelease once we move to serializing queries over the wire in Streamable format, this method shouldn't be needed anymore
-    BytesReference buildAsBytes();
-
-    /**
-     * Sets the arbitrary name to be assigned to the query (see named queries).
-     */
-    QB queryName(String queryName);
-
-    /**
-     * Returns the arbitrary name assigned to the query (see named queries).
-     */
-    String queryName();
-
-    /**
-     * Returns the boost for this query.
-     */
-    float boost();
-
-    /**
-     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
-     * weightings) have their score multiplied by the boost provided.
-     */
-    QB boost(float boost);
-
-    /**
-     * Returns the name that identifies uniquely the query
-     */
-    String getName();
+    protected abstract void doXContent(XContentBuilder builder, Params params) throws IOException;
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryBuilders.java b/core/src/main/java/org/elasticsearch/index/query/QueryBuilders.java
index 7f3f141..aa2dd1d 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryBuilders.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryBuilders.java
@@ -26,12 +26,10 @@ import org.elasticsearch.common.geo.ShapeRelation;
 import org.elasticsearch.common.geo.builders.ShapeBuilder;
 import org.elasticsearch.index.query.functionscore.FunctionScoreQueryBuilder;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilder;
-import org.elasticsearch.index.search.MatchQuery;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.script.ScriptService;
 import org.elasticsearch.script.Template;
 
-import java.io.IOException;
 import java.util.Collection;
 import java.util.Map;
 
@@ -41,7 +39,7 @@ import java.util.Map;
 public abstract class QueryBuilders {
 
     /**
-     * A query that matches on all documents.
+     * A query that match on all documents.
      */
     public static MatchAllQueryBuilder matchAllQuery() {
         return new MatchAllQueryBuilder();
@@ -54,17 +52,17 @@ public abstract class QueryBuilders {
      * @param text The query text (to be analyzed).
      */
     public static MatchQueryBuilder matchQuery(String name, Object text) {
-        return new MatchQueryBuilder(name, text).type(MatchQuery.Type.BOOLEAN);
+        return new MatchQueryBuilder(name, text).type(MatchQueryBuilder.Type.BOOLEAN);
     }
 
     /**
      * Creates a common query for the provided field name and text.
      *
-     * @param fieldName The field name.
+     * @param name The field name.
      * @param text The query text (to be analyzed).
      */
-    public static CommonTermsQueryBuilder commonTermsQuery(String fieldName, Object text) {
-        return new CommonTermsQueryBuilder(fieldName, text);
+    public static CommonTermsQueryBuilder commonTermsQuery(String name, Object text) {
+        return new CommonTermsQueryBuilder(name, text);
     }
 
     /**
@@ -84,7 +82,7 @@ public abstract class QueryBuilders {
      * @param text The query text (to be analyzed).
      */
     public static MatchQueryBuilder matchPhraseQuery(String name, Object text) {
-        return new MatchQueryBuilder(name, text).type(MatchQuery.Type.PHRASE);
+        return new MatchQueryBuilder(name, text).type(MatchQueryBuilder.Type.PHRASE);
     }
 
     /**
@@ -94,7 +92,7 @@ public abstract class QueryBuilders {
      * @param text The query text (to be analyzed).
      */
     public static MatchQueryBuilder matchPhrasePrefixQuery(String name, Object text) {
-        return new MatchQueryBuilder(name, text).type(MatchQuery.Type.PHRASE_PREFIX);
+        return new MatchQueryBuilder(name, text).type(MatchQueryBuilder.Type.PHRASE_PREFIX);
     }
 
     /**
@@ -278,8 +276,8 @@ public abstract class QueryBuilders {
      * Unlike the "NOT" clause, this still selects documents that contain undesirable terms,
      * but reduces their overall score:
      */
-    public static BoostingQueryBuilder boostingQuery(QueryBuilder positiveQuery, QueryBuilder negativeQuery) {
-        return new BoostingQueryBuilder(positiveQuery, negativeQuery);
+    public static BoostingQueryBuilder boostingQuery() {
+        return new BoostingQueryBuilder();
     }
 
     /**
@@ -313,33 +311,26 @@ public abstract class QueryBuilders {
         return new SpanFirstQueryBuilder(match, end);
     }
 
-    public static SpanNearQueryBuilder spanNearQuery(int slop) {
-        return new SpanNearQueryBuilder(slop);
+    public static SpanNearQueryBuilder spanNearQuery() {
+        return new SpanNearQueryBuilder();
     }
 
-    public static SpanNotQueryBuilder spanNotQuery(SpanQueryBuilder include, SpanQueryBuilder exclude) {
-        return new SpanNotQueryBuilder(include, exclude);
+    public static SpanNotQueryBuilder spanNotQuery() {
+        return new SpanNotQueryBuilder();
     }
 
     public static SpanOrQueryBuilder spanOrQuery() {
         return new SpanOrQueryBuilder();
     }
 
-    /** Creates a new {@code span_within} builder.
-    * @param big the big clause, it must enclose {@code little} for a match.
-    * @param little the little clause, it must be contained within {@code big} for a match.
-    */
-    public static SpanWithinQueryBuilder spanWithinQuery(SpanQueryBuilder big, SpanQueryBuilder little) {
-        return new SpanWithinQueryBuilder(big, little);
+    /** Creates a new {@code span_within} builder. */
+    public static SpanWithinQueryBuilder spanWithinQuery() {
+        return new SpanWithinQueryBuilder();
     }
 
-    /**
-     * Creates a new {@code span_containing} builder.
-     * @param big the big clause, it must enclose {@code little} for a match.
-     * @param little the little clause, it must be contained within {@code big} for a match.
-     */
-    public static SpanContainingQueryBuilder spanContainingQuery(SpanQueryBuilder big, SpanQueryBuilder little) {
-        return new SpanContainingQueryBuilder(big, little);
+    /** Creates a new {@code span_containing} builder. */
+    public static SpanContainingQueryBuilder spanContainingQuery() {
+        return new SpanContainingQueryBuilder();
     }
 
     /**
@@ -544,8 +535,19 @@ public abstract class QueryBuilders {
     /**
      * A Query builder which allows building a query thanks to a JSON string or binary data.
      */
-    public static WrapperQueryBuilder wrapperQuery(byte[] source) {
-        return new WrapperQueryBuilder(source);
+    public static WrapperQueryBuilder wrapperQuery(byte[] source, int offset, int length) {
+        return new WrapperQueryBuilder(source, offset, length);
+    }
+
+    /**
+     * Query that matches Documents based on the relationship between the given shape and
+     * indexed shapes
+     *
+     * @param name  The shape field name
+     * @param shape Shape to use in the Query
+     */
+    public static GeoShapeQueryBuilder geoShapeQuery(String name, ShapeBuilder shape) {
+        return new GeoShapeQueryBuilder(name, shape);
     }
 
     /**
@@ -577,10 +579,11 @@ public abstract class QueryBuilders {
     }
 
     /**
-     * A terms query that can extract the terms from another doc in an index.
+     * A terms lookup filter for the provided field name. A lookup terms filter can
+     * extract the terms to filter by from another doc in an index.
      */
-    public static TermsQueryBuilder termsLookupQuery(String name) {
-        return new TermsQueryBuilder(name);
+    public static TermsLookupQueryBuilder termsLookupQuery(String name) {
+        return new TermsLookupQueryBuilder(name);
     }
 
     /**
@@ -667,7 +670,7 @@ public abstract class QueryBuilders {
     public static GeohashCellQuery.Builder geoHashCellQuery(String name, String geohash, boolean neighbors) {
         return new GeohashCellQuery.Builder(name, geohash, neighbors);
     }
-
+    
     /**
      * A filter to filter based on a polygon defined by a set of locations  / points.
      *
@@ -684,12 +687,16 @@ public abstract class QueryBuilders {
      * @param shape Shape to use in the filter
      * @param relation relation of the shapes
      */
-    public static GeoShapeQueryBuilder geoShapeQuery(String name, ShapeBuilder shape) throws IOException {
-        return new GeoShapeQueryBuilder(name, shape);
+    public static GeoShapeQueryBuilder geoShapeQuery(String name, ShapeBuilder shape, ShapeRelation relation) {
+        return new GeoShapeQueryBuilder(name, shape, relation);
+    }
+
+    public static GeoShapeQueryBuilder geoShapeQuery(String name, String indexedShapeId, String indexedShapeType, ShapeRelation relation) {
+        return new GeoShapeQueryBuilder(name, indexedShapeId, indexedShapeType, relation);
     }
 
     public static GeoShapeQueryBuilder geoShapeQuery(String name, String indexedShapeId, String indexedShapeType) {
-        return new GeoShapeQueryBuilder(name, indexedShapeId, indexedShapeType);
+        return geoShapeQuery(name, indexedShapeId, indexedShapeType, null);
     }
 
     /**
@@ -698,16 +705,12 @@ public abstract class QueryBuilders {
      * @param name  The shape field name
      * @param shape Shape to use in the filter
      */
-    public static GeoShapeQueryBuilder geoIntersectionQuery(String name, ShapeBuilder shape) throws IOException {
-        GeoShapeQueryBuilder builder = geoShapeQuery(name, shape);
-        builder.relation(ShapeRelation.INTERSECTS);
-        return builder;
+    public static GeoShapeQueryBuilder geoIntersectionQuery(String name, ShapeBuilder shape) {
+        return geoShapeQuery(name, shape, ShapeRelation.INTERSECTS);
     }
 
     public static GeoShapeQueryBuilder geoIntersectionQuery(String name, String indexedShapeId, String indexedShapeType) {
-        GeoShapeQueryBuilder builder = geoShapeQuery(name, indexedShapeId, indexedShapeType);
-        builder.relation(ShapeRelation.INTERSECTS);
-        return builder;
+        return geoShapeQuery(name, indexedShapeId, indexedShapeType, ShapeRelation.INTERSECTS);
     }
 
     /**
@@ -716,16 +719,12 @@ public abstract class QueryBuilders {
      * @param name  The shape field name
      * @param shape Shape to use in the filter
      */
-    public static GeoShapeQueryBuilder geoWithinQuery(String name, ShapeBuilder shape) throws IOException {
-        GeoShapeQueryBuilder builder = geoShapeQuery(name, shape);
-        builder.relation(ShapeRelation.WITHIN);
-        return builder;
+    public static GeoShapeQueryBuilder geoWithinQuery(String name, ShapeBuilder shape) {
+        return geoShapeQuery(name, shape, ShapeRelation.WITHIN);
     }
 
     public static GeoShapeQueryBuilder geoWithinQuery(String name, String indexedShapeId, String indexedShapeType) {
-        GeoShapeQueryBuilder builder = geoShapeQuery(name, indexedShapeId, indexedShapeType);
-        builder.relation(ShapeRelation.WITHIN);
-        return builder;
+        return geoShapeQuery(name, indexedShapeId, indexedShapeType, ShapeRelation.WITHIN);
     }
 
     /**
@@ -734,16 +733,12 @@ public abstract class QueryBuilders {
      * @param name  The shape field name
      * @param shape Shape to use in the filter
      */
-    public static GeoShapeQueryBuilder geoDisjointQuery(String name, ShapeBuilder shape) throws IOException {
-        GeoShapeQueryBuilder builder = geoShapeQuery(name, shape);
-        builder.relation(ShapeRelation.DISJOINT);
-        return builder;
+    public static GeoShapeQueryBuilder geoDisjointQuery(String name, ShapeBuilder shape) {
+        return geoShapeQuery(name, shape, ShapeRelation.DISJOINT);
     }
 
     public static GeoShapeQueryBuilder geoDisjointQuery(String name, String indexedShapeId, String indexedShapeType) {
-        GeoShapeQueryBuilder builder = geoShapeQuery(name, indexedShapeId, indexedShapeType);
-        builder.relation(ShapeRelation.DISJOINT);
-        return builder;
+        return geoShapeQuery(name, indexedShapeId, indexedShapeType, ShapeRelation.DISJOINT);
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryFilterBuilder.java b/core/src/main/java/org/elasticsearch/index/query/QueryFilterBuilder.java
index 2b918c8..1e03ef1 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryFilterBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryFilterBuilder.java
@@ -19,14 +19,9 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * A filter that simply wraps a query.
@@ -35,14 +30,10 @@ import java.util.Objects;
  */
 //TODO: remove when https://github.com/elastic/elasticsearch/issues/13326 is fixed
 @Deprecated
-public class QueryFilterBuilder extends AbstractQueryBuilder<QueryFilterBuilder> {
-
-    public static final String NAME = "query";
+public class QueryFilterBuilder extends QueryBuilder {
 
     private final QueryBuilder queryBuilder;
 
-    static final QueryFilterBuilder PROTOTYPE = new QueryFilterBuilder(null);
-
     /**
      * A filter that simply wraps a query.
      *
@@ -52,62 +43,9 @@ public class QueryFilterBuilder extends AbstractQueryBuilder<QueryFilterBuilder>
         this.queryBuilder = queryBuilder;
     }
 
-    /**
-     * @return the query builder that is wrapped by this {@link QueryFilterBuilder}
-     */
-    public QueryBuilder innerQuery() {
-        return this.queryBuilder;
-    }
-
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.field(NAME);
+        builder.field(QueryFilterParser.NAME);
         queryBuilder.toXContent(builder, params);
     }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        // inner query builder can potentially be `null`, in that case we ignore it
-        Query innerQuery = this.queryBuilder.toQuery(context);
-        if (innerQuery == null) {
-            return null;
-        }
-        return new ConstantScoreQuery(innerQuery);
-    }
-
-    @Override
-    protected void setFinalBoost(Query query) {
-        //no-op this query doesn't support boost
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        return validateInnerQuery(queryBuilder, null);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(queryBuilder);
-    }
-
-    @Override
-    protected boolean doEquals(QueryFilterBuilder other) {
-        return Objects.equals(queryBuilder, other.queryBuilder);
-    }
-
-    @Override
-    protected QueryFilterBuilder doReadFrom(StreamInput in) throws IOException {
-        QueryBuilder innerQueryBuilder = in.readQuery();
-        return new QueryFilterBuilder(innerQueryBuilder);
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(queryBuilder);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryFilterParser.java b/core/src/main/java/org/elasticsearch/index/query/QueryFilterParser.java
index 84e4a59..9af4a2e 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryFilterParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryFilterParser.java
@@ -19,17 +19,16 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
 
 import java.io.IOException;
 
-/**
- * Parser for query filter
- * @deprecated use any query instead directly, possible since queries and filters are merged.
- */
 // TODO: remove when https://github.com/elastic/elasticsearch/issues/13326 is fixed
 @Deprecated
-public class QueryFilterParser extends BaseQueryParser<QueryFilterBuilder> {
+public class QueryFilterParser implements QueryParser {
+
+    public static final String NAME = "query";
 
     @Inject
     public QueryFilterParser() {
@@ -37,16 +36,11 @@ public class QueryFilterParser extends BaseQueryParser<QueryFilterBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{QueryFilterBuilder.NAME};
-    }
-
-    @Override
-    public QueryFilterBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
-        return new QueryFilterBuilder(parseContext.parseInnerQueryBuilder());
+        return new String[]{NAME};
     }
 
     @Override
-    public QueryFilterBuilder getBuilderPrototype() {
-        return QueryFilterBuilder.PROTOTYPE;
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
+        return parseContext.parseInnerQuery();
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryParseContext.java b/core/src/main/java/org/elasticsearch/index/query/QueryParseContext.java
index 11058f2..7c78a43 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryParseContext.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryParseContext.java
@@ -19,15 +19,42 @@
 
 package org.elasticsearch.index.query;
 
+import com.google.common.collect.ImmutableMap;
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.queryparser.classic.MapperQueryParser;
+import org.apache.lucene.queryparser.classic.QueryParserSettings;
+import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.Query;
+import org.apache.lucene.search.join.BitSetProducer;
+import org.apache.lucene.search.similarities.Similarity;
+import org.elasticsearch.Version;
+import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.ParseFieldMatcher;
+import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.Index;
-import org.elasticsearch.indices.query.IndicesQueriesRegistry;
+import org.elasticsearch.index.analysis.AnalysisService;
+import org.elasticsearch.index.fielddata.IndexFieldData;
+import org.elasticsearch.index.mapper.ContentPath;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.mapper.Mapper;
+import org.elasticsearch.index.mapper.MapperBuilders;
+import org.elasticsearch.index.mapper.MapperService;
+import org.elasticsearch.index.mapper.core.StringFieldMapper;
+import org.elasticsearch.index.mapper.object.ObjectMapper;
+import org.elasticsearch.index.query.support.NestedScope;
+import org.elasticsearch.index.similarity.SimilarityService;
+import org.elasticsearch.script.ScriptService;
+import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
+import org.elasticsearch.search.internal.SearchContext;
+import org.elasticsearch.search.lookup.SearchLookup;
 
 import java.io.IOException;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.HashMap;
 import java.util.Map;
 
 public class QueryParseContext {
@@ -35,90 +62,169 @@ public class QueryParseContext {
     private static final ParseField CACHE = new ParseField("_cache").withAllDeprecated("Elasticsearch makes its own caching decisions");
     private static final ParseField CACHE_KEY = new ParseField("_cache_key").withAllDeprecated("Filters are always used as cache keys");
 
-    private XContentParser parser;
+    private static ThreadLocal<String[]> typesContext = new ThreadLocal<>();
+
+    public static void setTypes(String[] types) {
+        typesContext.set(types);
+    }
+
+    public static String[] getTypes() {
+        return typesContext.get();
+    }
+
+    public static String[] setTypesWithPrevious(String[] types) {
+        String[] old = typesContext.get();
+        setTypes(types);
+        return old;
+    }
+
+    public static void removeTypes() {
+        typesContext.remove();
+    }
+
     private final Index index;
-    //norelease this flag is also used in the QueryShardContext, we need to make sure we set it there correctly in doToQuery()
+
+    private final Version indexVersionCreated;
+
+    private final IndexQueryParserService indexQueryParser;
+
+    private final Map<String, Query> namedQueries = new HashMap<>();
+
+    private final MapperQueryParser queryParser = new MapperQueryParser(this);
+
+    private XContentParser parser;
+
     private ParseFieldMatcher parseFieldMatcher;
 
-    //norelease this can eventually be deleted when context() method goes away
-    private final QueryShardContext shardContext;
-    private IndicesQueriesRegistry indicesQueriesRegistry;
+    private boolean allowUnmappedFields;
+
+    private boolean mapUnmappedFieldAsString;
 
-    public QueryParseContext(Index index, IndicesQueriesRegistry registry) {
+    private NestedScope nestedScope;
+
+    private boolean isFilter;
+
+    public QueryParseContext(Index index, IndexQueryParserService indexQueryParser) {
         this.index = index;
-        this.indicesQueriesRegistry = registry;
-        this.shardContext = null;
+        this.indexVersionCreated = Version.indexCreated(indexQueryParser.indexSettings());
+        this.indexQueryParser = indexQueryParser;
+    }
+
+    public void parseFieldMatcher(ParseFieldMatcher parseFieldMatcher) {
+        this.parseFieldMatcher = parseFieldMatcher;
     }
 
-    QueryParseContext(QueryShardContext context) {
-        this.shardContext = context;
-        this.index = context.index();
-        this.indicesQueriesRegistry = context.indexQueryParserService().indicesQueriesRegistry();
+    public ParseFieldMatcher parseFieldMatcher() {
+        return parseFieldMatcher;
     }
 
     public void reset(XContentParser jp) {
+        allowUnmappedFields = indexQueryParser.defaultAllowUnmappedFields();
         this.parseFieldMatcher = ParseFieldMatcher.EMPTY;
+        this.lookup = null;
         this.parser = jp;
+        this.namedQueries.clear();
+        this.nestedScope = new NestedScope();
+        this.isFilter = false;
+    }
+
+    public Index index() {
+        return this.index;
     }
 
-    //norelease this is still used in BaseQueryParserTemp and FunctionScoreQueryParser, remove if not needed there anymore
-    @Deprecated
-    public QueryShardContext shardContext() {
-        return this.shardContext;
+    public void parser(XContentParser parser) {
+        this.parser = parser;
     }
 
     public XContentParser parser() {
-        return this.parser;
+        return parser;
+    }
+    
+    public IndexQueryParserService indexQueryParserService() {
+        return indexQueryParser;
     }
 
-    public void parseFieldMatcher(ParseFieldMatcher parseFieldMatcher) {
-        this.parseFieldMatcher = parseFieldMatcher;
+    public AnalysisService analysisService() {
+        return indexQueryParser.analysisService;
     }
 
-    public boolean isDeprecatedSetting(String setting) {
-        return parseFieldMatcher.match(setting, CACHE) || parseFieldMatcher.match(setting, CACHE_KEY);
+    public ScriptService scriptService() {
+        return indexQueryParser.scriptService;
     }
 
-    public Index index() {
-        return this.index;
+    public MapperService mapperService() {
+        return indexQueryParser.mapperService;
     }
 
-    /**
-     * @deprecated replaced by calls to parseInnerFilterToQueryBuilder() for the resulting queries
-     */
     @Nullable
-    @Deprecated
-    //norelease should be possible to remove after refactoring all queries
-    public Query parseInnerFilter() throws QueryShardException, IOException {
-        assert this.shardContext != null;
-        QueryBuilder builder = parseInnerFilterToQueryBuilder();
-        Query result = null;
-        if (builder != null) {
-            result = builder.toQuery(this.shardContext);
+    public SimilarityService similarityService() {
+        return indexQueryParser.similarityService;
+    }
+
+    public Similarity searchSimilarity() {
+        return indexQueryParser.similarityService != null ? indexQueryParser.similarityService.similarity() : null;
+    }
+
+    public String defaultField() {
+        return indexQueryParser.defaultField();
+    }
+
+    public boolean queryStringLenient() {
+        return indexQueryParser.queryStringLenient();
+    }
+
+    public MapperQueryParser queryParser(QueryParserSettings settings) {
+        queryParser.reset(settings);
+        return queryParser;
+    }
+
+    public BitSetProducer bitsetFilter(Filter filter) {
+        return indexQueryParser.bitsetFilterCache.getBitSetProducer(filter);
+    }
+
+    public <IFD extends IndexFieldData<?>> IFD getForField(MappedFieldType mapper) {
+        return indexQueryParser.fieldDataService.getForField(mapper);
+    }
+
+    public void addNamedQuery(String name, Query query) {
+        if (query != null) {
+            namedQueries.put(name, query);
         }
-        return result;
+    }
+
+    public ImmutableMap<String, Query> copyNamedQueries() {
+        return ImmutableMap.copyOf(namedQueries);
+    }
+
+    public void combineNamedQueries(QueryParseContext context) {
+        namedQueries.putAll(context.namedQueries);
     }
 
     /**
-     * @deprecated replaced by calls to parseInnerQueryBuilder() for the resulting queries
+     * Return whether we are currently parsing a filter or a query.
      */
-    @Nullable
-    @Deprecated
-    //norelease this method will be removed once all queries are refactored
-    public Query parseInnerQuery() throws IOException, QueryShardException {
-        QueryBuilder builder = parseInnerQueryBuilder();
-        Query result = null;
-        if (builder != null) {
-            result = builder.toQuery(this.shardContext);
+    public boolean isFilter() {
+        return isFilter;
+    }
+
+    public void addInnerHits(String name, InnerHitsContext.BaseInnerHits context) {
+        SearchContext sc = SearchContext.current();
+        if (sc == null) {
+            throw new QueryParsingException(this, "inner_hits unsupported");
         }
-        return result;
+
+        InnerHitsContext innerHitsContext;
+        if (sc.innerHits() == null) {
+            innerHitsContext = new InnerHitsContext(new HashMap<String, InnerHitsContext.BaseInnerHits>());
+            sc.innerHits(innerHitsContext);
+        } else {
+            innerHitsContext = sc.innerHits();
+        }
+        innerHitsContext.addInnerHitDefinition(name, context);
     }
 
-    /**
-     * @return a new QueryBuilder based on the current state of the parser
-     * @throws IOException
-     */
-    public QueryBuilder parseInnerQueryBuilder() throws IOException {
+    @Nullable
+    public Query parseInnerQuery() throws QueryParsingException, IOException {
         // move to START object
         XContentParser.Token token;
         if (parser.currentToken() != XContentParser.Token.START_OBJECT) {
@@ -130,7 +236,7 @@ public class QueryParseContext {
         token = parser.nextToken();
         if (token == XContentParser.Token.END_OBJECT) {
             // empty query
-            return EmptyQueryBuilder.PROTOTYPE;
+            return null;
         }
         if (token != XContentParser.Token.FIELD_NAME) {
             throw new QueryParsingException(this, "[_na] query malformed, no field after start_object");
@@ -142,11 +248,11 @@ public class QueryParseContext {
             throw new QueryParsingException(this, "[_na] query malformed, no field after start_object");
         }
 
-        QueryParser queryParser = queryParser(queryName);
+        QueryParser queryParser = indexQueryParser.queryParser(queryName);
         if (queryParser == null) {
             throw new QueryParsingException(this, "No query registered for [" + queryName + "]");
         }
-        QueryBuilder result = queryParser.fromXContent(this);
+        Query result = queryParser.parse(this);
         if (parser.currentToken() == XContentParser.Token.END_OBJECT || parser.currentToken() == XContentParser.Token.END_ARRAY) {
             // if we are at END_OBJECT, move to the next one...
             parser.nextToken();
@@ -154,46 +260,137 @@ public class QueryParseContext {
         return result;
     }
 
-    /**
-     * @return a new QueryBuilder based on the current state of the parser, but does so that the inner query
-     * is parsed to a filter
-     * @throws IOException
-     */
-    //norelease setting and checking the isFilter Flag should completely be moved to toQuery/toFilter after query refactoring
-    public QueryBuilder parseInnerFilterToQueryBuilder() throws IOException {
-        final boolean originalIsFilter = this.shardContext.isFilter;
+    @Nullable
+    public Query parseInnerFilter() throws QueryParsingException, IOException {
+        final boolean originalIsFilter = isFilter;
         try {
-            this.shardContext.isFilter = true;
-            return parseInnerQueryBuilder();
+            isFilter = true;
+            return parseInnerQuery();
         } finally {
-            this.shardContext.isFilter = originalIsFilter;
+            isFilter = originalIsFilter;
         }
     }
 
-    //norelease setting and checking the isFilter Flag should completely be moved to toQuery/toFilter after query refactoring
-    public QueryBuilder parseInnerFilterToQueryBuilder(String queryName) throws IOException, QueryParsingException {
-        final boolean originalIsFilter = this.shardContext.isFilter;
+    public Query parseInnerFilter(String queryName) throws IOException, QueryParsingException {
+        final boolean originalIsFilter = isFilter;
         try {
-            this.shardContext.isFilter = true;
-            QueryParser queryParser = queryParser(queryName);
+            isFilter = true;
+            QueryParser queryParser = indexQueryParser.queryParser(queryName);
             if (queryParser == null) {
                 throw new QueryParsingException(this, "No query registered for [" + queryName + "]");
             }
-            return queryParser.fromXContent(this);
+            return queryParser.parse(this);
         } finally {
-            this.shardContext.isFilter = originalIsFilter;
+            isFilter = originalIsFilter;
         }
     }
 
-    public ParseFieldMatcher parseFieldMatcher() {
-        return parseFieldMatcher;
+    public Collection<String> simpleMatchToIndexNames(String pattern) {
+        return indexQueryParser.mapperService.simpleMatchToIndexNames(pattern, getTypes());
+    }
+
+    public MappedFieldType fieldMapper(String name) {
+        return failIfFieldMappingNotFound(name, indexQueryParser.mapperService.smartNameFieldType(name, getTypes()));
+    }
+
+    public ObjectMapper getObjectMapper(String name) {
+        return indexQueryParser.mapperService.getObjectMapper(name, getTypes());
+    }
+
+    /** Gets the search analyzer for the given field, or the default if there is none present for the field
+     * TODO: remove this by moving defaults into mappers themselves
+     */
+    public Analyzer getSearchAnalyzer(MappedFieldType fieldType) {
+        if (fieldType.searchAnalyzer() != null) {
+            return fieldType.searchAnalyzer();
+        }
+        return mapperService().searchAnalyzer();
+    }
+
+    /** Gets the search quote nalyzer for the given field, or the default if there is none present for the field
+     * TODO: remove this by moving defaults into mappers themselves
+     */
+    public Analyzer getSearchQuoteAnalyzer(MappedFieldType fieldType) {
+        if (fieldType.searchQuoteAnalyzer() != null) {
+            return fieldType.searchQuoteAnalyzer();
+        }
+        return mapperService().searchQuoteAnalyzer();
     }
 
-    public void parser(XContentParser innerParser) {
-        this.parser = innerParser;
+    public void setAllowUnmappedFields(boolean allowUnmappedFields) {
+        this.allowUnmappedFields = allowUnmappedFields;
+    }
+
+    public void setMapUnmappedFieldAsString(boolean mapUnmappedFieldAsString) {
+        this.mapUnmappedFieldAsString = mapUnmappedFieldAsString;
+    }
+
+    private MappedFieldType failIfFieldMappingNotFound(String name, MappedFieldType fieldMapping) {
+        if (allowUnmappedFields) {
+            return fieldMapping;
+        } else if (mapUnmappedFieldAsString){
+            StringFieldMapper.Builder builder = MapperBuilders.stringField(name);
+            // it would be better to pass the real index settings, but they are not easily accessible from here...
+            Settings settings = Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, indexQueryParser.getIndexCreatedVersion()).build();
+            return builder.build(new Mapper.BuilderContext(settings, new ContentPath(1))).fieldType();
+        } else {
+            Version indexCreatedVersion = indexQueryParser.getIndexCreatedVersion();
+            if (fieldMapping == null && indexCreatedVersion.onOrAfter(Version.V_1_4_0_Beta1)) {
+                throw new QueryParsingException(this, "Strict field resolution and no field mapping can be found for the field with name ["
+                        + name + "]");
+            } else {
+                return fieldMapping;
+            }
+        }
+    }
+
+    /**
+     * Returns the narrowed down explicit types, or, if not set, all types.
+     */
+    public Collection<String> queryTypes() {
+        String[] types = getTypes();
+        if (types == null || types.length == 0) {
+            return mapperService().types();
+        }
+        if (types.length == 1 && types[0].equals("_all")) {
+            return mapperService().types();
+        }
+        return Arrays.asList(types);
+    }
+
+    private SearchLookup lookup = null;
+
+    public SearchLookup lookup() {
+        SearchContext current = SearchContext.current();
+        if (current != null) {
+            return current.lookup();
+        }
+        if (lookup == null) {
+            lookup = new SearchLookup(mapperService(), indexQueryParser.fieldDataService, null);
+        }
+        return lookup;
+    }
+
+    public long nowInMillis() {
+        SearchContext current = SearchContext.current();
+        if (current != null) {
+            return current.nowInMillis();
+        }
+        return System.currentTimeMillis();
+    }
+
+    public NestedScope nestedScope() {
+        return nestedScope;
+    }
+
+    /**
+     * Return whether the setting is deprecated.
+     */
+    public boolean isDeprecatedSetting(String setting) {
+        return parseFieldMatcher.match(setting, CACHE) || parseFieldMatcher.match(setting, CACHE_KEY);
     }
 
-    QueryParser queryParser(String name) {
-        return indicesQueriesRegistry.queryParsers().get(name);
+    public Version indexVersionCreated() {
+        return indexVersionCreated;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryParser.java b/core/src/main/java/org/elasticsearch/index/query/QueryParser.java
index d54971b..eff585a 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryParser.java
@@ -25,10 +25,9 @@ import org.elasticsearch.common.Nullable;
 import java.io.IOException;
 
 /**
- * Defines a query parser that is able to read and parse a query object in {@link org.elasticsearch.common.xcontent.XContent}
- * format and create an internal object representing the query, implementing {@link QueryBuilder}, which can be streamed to other nodes.
+ *
  */
-public interface QueryParser<QB extends QueryBuilder<QB>> {
+public interface QueryParser {
 
     /**
      * The names this query parser is registered under.
@@ -36,33 +35,11 @@ public interface QueryParser<QB extends QueryBuilder<QB>> {
     String[] names();
 
     /**
-     * Parses the into a query from the current parser location. Will be at
-     * "START_OBJECT" location, and should end when the token is at the matching
-     * "END_OBJECT".
+     * Parses the into a query from the current parser location. Will be at "START_OBJECT" location,
+     * and should end when the token is at the matching "END_OBJECT".
      * <p/>
-     * Returns <tt>null</tt> if this query should be ignored in the context of
-     * the DSL.
+     * Returns <tt>null</tt> if this query should be ignored in the context of the DSL.
      */
-    //norelease can be removed in favour of fromXContent once search requests can be parsed on the coordinating node
     @Nullable
-    Query parse(QueryShardContext context) throws IOException, QueryParsingException;
-
-    /**
-     * Creates a new {@link QueryBuilder} from the query held by the {@link QueryShardContext}
-     * in {@link org.elasticsearch.common.xcontent.XContent} format
-     *
-     * @param parseContext
-     *            the input parse context. The state on the parser contained in
-     *            this context will be changed as a side effect of this method
-     *            call
-     * @return the new QueryBuilder
-     * @throws IOException
-     * @throws QueryParsingException
-     */
-    QB fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException;
-
-    /**
-     * @return an empty {@link QueryBuilder} instance for this parser that can be used for deserialization
-     */
-    QB getBuilderPrototype();
+    Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException;
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryParsingException.java b/core/src/main/java/org/elasticsearch/index/query/QueryParsingException.java
index 80acae7..c606953 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryParsingException.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryParsingException.java
@@ -31,8 +31,7 @@ import org.elasticsearch.rest.RestStatus;
 import java.io.IOException;
 
 /**
- * Exception that can be used when parsing queries with a given {@link QueryParseContext}.
- * Can contain information about location of the error.
+ *
  */
 public class QueryParsingException extends ElasticsearchException {
 
@@ -72,15 +71,9 @@ public class QueryParsingException extends ElasticsearchException {
         this.columnNumber = col;
     }
 
-    public QueryParsingException(StreamInput in) throws IOException{
-        super(in);
-        lineNumber = in.readInt();
-        columnNumber = in.readInt();
-    }
-
     /**
      * Line number of the location of the error
-     *
+     * 
      * @return the line number or -1 if unknown
      */
     public int getLineNumber() {
@@ -89,7 +82,7 @@ public class QueryParsingException extends ElasticsearchException {
 
     /**
      * Column number of the location of the error
-     *
+     * 
      * @return the column number or -1 if unknown
      */
     public int getColumnNumber() {
@@ -116,4 +109,11 @@ public class QueryParsingException extends ElasticsearchException {
         out.writeInt(lineNumber);
         out.writeInt(columnNumber);
     }
+
+    public QueryParsingException(StreamInput in) throws IOException{
+        super(in);
+        lineNumber = in.readInt();
+        columnNumber = in.readInt();
+    }
+
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryShardContext.java b/core/src/main/java/org/elasticsearch/index/query/QueryShardContext.java
deleted file mode 100644
index 8ce547e..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/QueryShardContext.java
+++ /dev/null
@@ -1,357 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import com.google.common.collect.ImmutableMap;
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.queryparser.classic.MapperQueryParser;
-import org.apache.lucene.queryparser.classic.QueryParserSettings;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.join.BitSetProducer;
-import org.apache.lucene.search.similarities.Similarity;
-import org.elasticsearch.Version;
-import org.elasticsearch.client.Client;
-import org.elasticsearch.cluster.metadata.IndexMetaData;
-import org.elasticsearch.common.ParseFieldMatcher;
-import org.elasticsearch.common.bytes.BytesReference;
-import org.elasticsearch.common.geo.builders.ShapeBuilder;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.Index;
-import org.elasticsearch.index.analysis.AnalysisService;
-import org.elasticsearch.index.fielddata.IndexFieldData;
-import org.elasticsearch.index.mapper.ContentPath;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.mapper.Mapper;
-import org.elasticsearch.index.mapper.MapperBuilders;
-import org.elasticsearch.index.mapper.MapperService;
-import org.elasticsearch.index.mapper.core.StringFieldMapper;
-import org.elasticsearch.index.mapper.object.ObjectMapper;
-import org.elasticsearch.index.query.support.NestedScope;
-import org.elasticsearch.indices.cache.query.terms.TermsLookup;
-import org.elasticsearch.script.ExecutableScript;
-import org.elasticsearch.script.ScriptContext;
-import org.elasticsearch.script.ScriptService;
-import org.elasticsearch.script.Template;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
-import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.search.lookup.SearchLookup;
-
-import java.io.IOException;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-
-/**
- * Context object used to create lucene queries on the shard level.
- */
-public class QueryShardContext {
-
-    private static ThreadLocal<String[]> typesContext = new ThreadLocal<>();
-
-    public static void setTypes(String[] types) {
-        typesContext.set(types);
-    }
-
-    public static String[] getTypes() {
-        return typesContext.get();
-    }
-
-    public static String[] setTypesWithPrevious(String[] types) {
-        String[] old = typesContext.get();
-        setTypes(types);
-        return old;
-    }
-
-    public static void removeTypes() {
-        typesContext.remove();
-    }
-
-    private final Index index;
-
-    private final Version indexVersionCreated;
-
-    private final IndexQueryParserService indexQueryParser;
-
-    private final Map<String, Query> namedQueries = new HashMap<>();
-
-    private final MapperQueryParser queryParser = new MapperQueryParser(this);
-
-    private ParseFieldMatcher parseFieldMatcher;
-
-    private boolean allowUnmappedFields;
-
-    private boolean mapUnmappedFieldAsString;
-
-    private NestedScope nestedScope;
-
-    //norelease this should be possible to remove once query context are completely separated
-    private QueryParseContext parseContext;
-
-    boolean isFilter;
-
-    public QueryShardContext(Index index, IndexQueryParserService indexQueryParser) {
-        this.index = index;
-        this.indexVersionCreated = Version.indexCreated(indexQueryParser.indexSettings());
-        this.indexQueryParser = indexQueryParser;
-        this.parseContext = new QueryParseContext(this);
-    }
-
-    public void parseFieldMatcher(ParseFieldMatcher parseFieldMatcher) {
-        this.parseFieldMatcher = parseFieldMatcher;
-    }
-
-    public ParseFieldMatcher parseFieldMatcher() {
-        return parseFieldMatcher;
-    }
-
-    public void reset() {
-        allowUnmappedFields = indexQueryParser.defaultAllowUnmappedFields();
-        this.parseFieldMatcher = ParseFieldMatcher.EMPTY;
-        this.lookup = null;
-        this.namedQueries.clear();
-        this.nestedScope = new NestedScope();
-    }
-
-    //norelease remove parser argument once query contexts are separated
-    public void reset(XContentParser jp) {
-        this.reset();
-        this.parseContext.reset(jp);
-    }
-
-    public Index index() {
-        return this.index;
-    }
-
-    //norelease we might be able to avoid exposing the service to the outside world once all queries are refactored
-    public IndexQueryParserService indexQueryParserService() {
-        return indexQueryParser;
-    }
-
-    public AnalysisService analysisService() {
-        return indexQueryParser.analysisService;
-    }
-
-    public ScriptService scriptService() {
-        return indexQueryParser.scriptService;
-    }
-
-    public MapperService mapperService() {
-        return indexQueryParser.mapperService;
-    }
-
-    public Similarity searchSimilarity() {
-        return indexQueryParser.similarityService != null ? indexQueryParser.similarityService.similarity() : null;
-    }
-
-    public String defaultField() {
-        return indexQueryParser.defaultField();
-    }
-
-    public boolean queryStringLenient() {
-        return indexQueryParser.queryStringLenient();
-    }
-
-    public boolean queryStringAnalyzeWildcard() {
-        return indexQueryParser.queryStringAnalyzeWildcard();
-    }
-
-    public boolean queryStringAllowLeadingWildcard() {
-        return indexQueryParser.queryStringAllowLeadingWildcard();
-    }
-
-    public MapperQueryParser queryParser(QueryParserSettings settings) {
-        queryParser.reset(settings);
-        return queryParser;
-    }
-
-    public BitSetProducer bitsetFilter(Filter filter) {
-        return indexQueryParser.bitsetFilterCache.getBitSetProducer(filter);
-    }
-
-    public <IFD extends IndexFieldData<?>> IFD getForField(MappedFieldType mapper) {
-        return indexQueryParser.fieldDataService.getForField(mapper);
-    }
-
-    public void addNamedQuery(String name, Query query) {
-        if (query != null) {
-            namedQueries.put(name, query);
-        }
-    }
-
-    public ImmutableMap<String, Query> copyNamedQueries() {
-        return ImmutableMap.copyOf(namedQueries);
-    }
-
-    public void combineNamedQueries(QueryShardContext context) {
-        namedQueries.putAll(context.namedQueries);
-    }
-
-    /**
-     * Return whether we are currently parsing a filter or a query.
-     */
-    public boolean isFilter() {
-        return isFilter;
-    }
-
-    public void addInnerHits(String name, InnerHitsContext.BaseInnerHits context) {
-        SearchContext sc = SearchContext.current();
-        if (sc == null) {
-            throw new QueryShardException(this, "inner_hits unsupported");
-        }
-
-        InnerHitsContext innerHitsContext;
-        if (sc.innerHits() == null) {
-            innerHitsContext = new InnerHitsContext(new HashMap<String, InnerHitsContext.BaseInnerHits>());
-            sc.innerHits(innerHitsContext);
-        } else {
-            innerHitsContext = sc.innerHits();
-        }
-        innerHitsContext.addInnerHitDefinition(name, context);
-    }
-
-    public Collection<String> simpleMatchToIndexNames(String pattern) {
-        return indexQueryParser.mapperService.simpleMatchToIndexNames(pattern);
-    }
-
-    public MappedFieldType fieldMapper(String name) {
-        return failIfFieldMappingNotFound(name, indexQueryParser.mapperService.smartNameFieldType(name, getTypes()));
-    }
-
-    public ObjectMapper getObjectMapper(String name) {
-        return indexQueryParser.mapperService.getObjectMapper(name, getTypes());
-    }
-
-    /**
-     * Gets the search analyzer for the given field, or the default if there is none present for the field
-     * TODO: remove this by moving defaults into mappers themselves
-     */
-    public Analyzer getSearchAnalyzer(MappedFieldType fieldType) {
-        if (fieldType.searchAnalyzer() != null) {
-            return fieldType.searchAnalyzer();
-        }
-        return mapperService().searchAnalyzer();
-    }
-
-    /**
-     * Gets the search quote analyzer for the given field, or the default if there is none present for the field
-     * TODO: remove this by moving defaults into mappers themselves
-     */
-    public Analyzer getSearchQuoteAnalyzer(MappedFieldType fieldType) {
-        if (fieldType.searchQuoteAnalyzer() != null) {
-            return fieldType.searchQuoteAnalyzer();
-        }
-        return mapperService().searchQuoteAnalyzer();
-    }
-
-    public void setAllowUnmappedFields(boolean allowUnmappedFields) {
-        this.allowUnmappedFields = allowUnmappedFields;
-    }
-
-    public void setMapUnmappedFieldAsString(boolean mapUnmappedFieldAsString) {
-        this.mapUnmappedFieldAsString = mapUnmappedFieldAsString;
-    }
-
-    private MappedFieldType failIfFieldMappingNotFound(String name, MappedFieldType fieldMapping) {
-        if (allowUnmappedFields) {
-            return fieldMapping;
-        } else if (mapUnmappedFieldAsString) {
-            StringFieldMapper.Builder builder = MapperBuilders.stringField(name);
-            // it would be better to pass the real index settings, but they are not easily accessible from here...
-            Settings settings = Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, indexQueryParser.getIndexCreatedVersion()).build();
-            return builder.build(new Mapper.BuilderContext(settings, new ContentPath(1))).fieldType();
-        } else {
-            Version indexCreatedVersion = indexQueryParser.getIndexCreatedVersion();
-            if (fieldMapping == null && indexCreatedVersion.onOrAfter(Version.V_1_4_0_Beta1)) {
-                throw new QueryShardException(this, "Strict field resolution and no field mapping can be found for the field with name ["
-                        + name + "]");
-            } else {
-                return fieldMapping;
-            }
-        }
-    }
-
-    /**
-     * Returns the narrowed down explicit types, or, if not set, all types.
-     */
-    public Collection<String> queryTypes() {
-        String[] types = getTypes();
-        if (types == null || types.length == 0) {
-            return mapperService().types();
-        }
-        if (types.length == 1 && types[0].equals("_all")) {
-            return mapperService().types();
-        }
-        return Arrays.asList(types);
-    }
-
-    private SearchLookup lookup = null;
-
-    public SearchLookup lookup() {
-        SearchContext current = SearchContext.current();
-        if (current != null) {
-            return current.lookup();
-        }
-        if (lookup == null) {
-            lookup = new SearchLookup(mapperService(), indexQueryParser.fieldDataService, null);
-        }
-        return lookup;
-    }
-
-    public long nowInMillis() {
-        SearchContext current = SearchContext.current();
-        if (current != null) {
-            return current.nowInMillis();
-        }
-        return System.currentTimeMillis();
-    }
-
-    public NestedScope nestedScope() {
-        return nestedScope;
-    }
-
-    public Version indexVersionCreated() {
-        return indexVersionCreated;
-    }
-
-    public QueryParseContext parseContext() {
-        return this.parseContext;
-    }
-
-    public boolean matchesIndices(String... indices) {
-        return this.indexQueryParser.matchesIndices(indices);
-    }
-
-    /*
-    * Executes the given template, and returns the response.
-    */
-    public BytesReference executeQueryTemplate(Template template, SearchContext searchContext) {
-        ExecutableScript executable = scriptService().executable(template, ScriptContext.Standard.SEARCH, searchContext);
-        return (BytesReference) executable.run();
-    }
-
-    public Client getClient() {
-        return indexQueryParser.getClient();
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryShardException.java b/core/src/main/java/org/elasticsearch/index/query/QueryShardException.java
deleted file mode 100644
index 1e31c7c..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/QueryShardException.java
+++ /dev/null
@@ -1,72 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.elasticsearch.ElasticsearchException;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.Index;
-import org.elasticsearch.rest.RestStatus;
-
-import java.io.IOException;
-
-/**
- * Exception that is thrown when creating lucene queries on the shard
- */
-public class QueryShardException extends ElasticsearchException {
-
-    public QueryShardException(QueryShardContext context, String msg, Object... args) {
-        this(context, msg, null, args);
-    }
-
-    public QueryShardException(QueryShardContext context, String msg, Throwable cause, Object... args) {
-        super(msg, cause, args);
-        setIndex(context.index());
-    }
-
-    /**
-     * This constructor is provided for use in unit tests where a
-     * {@link QueryShardContext} may not be available
-     */
-    public QueryShardException(Index index, String msg, Throwable cause) {
-        super(msg, cause);
-        setIndex(index);
-    }
-
-    public QueryShardException(StreamInput in) throws IOException{
-        super(in);
-    }
-
-    @Override
-    public RestStatus status() {
-        return RestStatus.BAD_REQUEST;
-    }
-
-    @Override
-    protected void innerToXContent(XContentBuilder builder, Params params) throws IOException {
-        super.innerToXContent(builder, params);
-    }
-
-    @Override
-    public void writeTo(StreamOutput out) throws IOException {
-        super.writeTo(out);
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryBuilder.java
index fb13083..c7a297e 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryBuilder.java
@@ -19,27 +19,14 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.queryparser.classic.MapperQueryParser;
-import org.apache.lucene.queryparser.classic.QueryParserSettings;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.FuzzyQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.util.automaton.Operations;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
-import org.elasticsearch.common.regex.Regex;
+import com.carrotsearch.hppc.ObjectFloatHashMap;
 import org.elasticsearch.common.unit.Fuzziness;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.analysis.NamedAnalyzer;
-import org.elasticsearch.index.query.support.QueryParsers;
-import org.joda.time.DateTimeZone;
 
 import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
 import java.util.Locale;
-import java.util.Map;
-import java.util.Objects;
-import java.util.TreeMap;
 
 /**
  * A query that parses a query string and runs it. There are two modes that this operates. The first,
@@ -49,93 +36,72 @@ import java.util.TreeMap;
  * them either using DisMax or a plain boolean query (see {@link #useDisMax(boolean)}).
  * <p/>
  */
-public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQueryBuilder> {
-
-    public static final String NAME = "query_string";
-
-    public static final boolean DEFAULT_AUTO_GENERATE_PHRASE_QUERIES = false;
-    public static final int DEFAULT_MAX_DETERMINED_STATES = Operations.DEFAULT_MAX_DETERMINIZED_STATES;
-    public static final boolean DEFAULT_LOWERCASE_EXPANDED_TERMS = true;
-    public static final boolean DEFAULT_ENABLE_POSITION_INCREMENTS = true;
-    public static final boolean DEFAULT_ESCAPE = false;
-    public static final boolean DEFAULT_USE_DIS_MAX = true;
-    public static final int DEFAULT_FUZZY_PREFIX_LENGTH = FuzzyQuery.defaultPrefixLength;
-    public static final int DEFAULT_FUZZY_MAX_EXPANSIONS = FuzzyQuery.defaultMaxExpansions;
-    public static final int DEFAULT_PHRASE_SLOP = 0;
-    public static final float DEFAULT_TIE_BREAKER = 0.0f;
-    public static final Fuzziness DEFAULT_FUZZINESS = Fuzziness.AUTO;
-    public static final Operator DEFAULT_OPERATOR = Operator.OR;
-    public static final Locale DEFAULT_LOCALE = Locale.ROOT;
-
-    static final QueryStringQueryBuilder PROTOTYPE = new QueryStringQueryBuilder(null);
-    
+public class QueryStringQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<QueryStringQueryBuilder> {
+
+    public enum Operator {
+        OR,
+        AND
+    }
+
     private final String queryString;
-    
+
     private String defaultField;
-    /**
-     * Fields to query against. If left empty will query default field,
-     * currently _ALL. Uses a TreeMap to hold the fields so boolean clauses are
-     * always sorted in same order for generated Lucene query for easier
-     * testing.
-     *
-     * Can be changed back to HashMap once https://issues.apache.org/jira/browse/LUCENE-6305 is fixed.
-     */
-    private final Map<String, Float> fieldsAndWeights = new TreeMap<>();
 
-    private Operator defaultOperator = DEFAULT_OPERATOR;
+    private Operator defaultOperator;
 
     private String analyzer;
     private String quoteAnalyzer;
 
     private String quoteFieldSuffix;
 
-    private boolean autoGeneratePhraseQueries = DEFAULT_AUTO_GENERATE_PHRASE_QUERIES;
+    private Boolean autoGeneratePhraseQueries;
 
     private Boolean allowLeadingWildcard;
 
-    private Boolean analyzeWildcard;
+    private Boolean lowercaseExpandedTerms;
 
-    private boolean lowercaseExpandedTerms = DEFAULT_LOWERCASE_EXPANDED_TERMS;
+    private Boolean enablePositionIncrements;
 
-    private boolean enablePositionIncrements = DEFAULT_ENABLE_POSITION_INCREMENTS;
+    private Boolean analyzeWildcard;
 
-    private Locale locale = DEFAULT_LOCALE;
+    private Locale locale;
 
-    private Fuzziness fuzziness = DEFAULT_FUZZINESS;
+    private float boost = -1;
 
-    private int fuzzyPrefixLength = DEFAULT_FUZZY_PREFIX_LENGTH;
-    
-    private int fuzzyMaxExpansions = DEFAULT_FUZZY_MAX_EXPANSIONS;
+    private Fuzziness fuzziness;
+    private int fuzzyPrefixLength = -1;
+    private int fuzzyMaxExpansions = -1;
+    private String fuzzyRewrite;
 
-    private String rewrite;
+    private int phraseSlop = -1;
 
-    private String fuzzyRewrite;
+    private List<String> fields;
 
-    private boolean escape = DEFAULT_ESCAPE;
+    private ObjectFloatHashMap<String> fieldsBoosts;
 
-    private int phraseSlop = DEFAULT_PHRASE_SLOP;
+    private Boolean useDisMax;
 
-    private boolean useDisMax = DEFAULT_USE_DIS_MAX;
+    private float tieBreaker = -1;
 
-    private float tieBreaker = DEFAULT_TIE_BREAKER;
+    private String rewrite = null;
 
     private String minimumShouldMatch;
 
     private Boolean lenient;
 
-    private DateTimeZone timeZone;
+    private String queryName;
+
+    private String timeZone;
 
     /** To limit effort spent determinizing regexp queries. */
-    private int maxDeterminizedStates = DEFAULT_MAX_DETERMINED_STATES;
-    
+    private Integer maxDeterminizedStates;
+
+    private Boolean escape;
+
     public QueryStringQueryBuilder(String queryString) {
         this.queryString = queryString;
     }
 
-    public String queryString() {
-        return this.queryString;
-    }
-
     /**
      * The default field to run against when no prefix field is specified. Only relevant when
      * not explicitly adding fields the query string will run against.
@@ -145,16 +111,14 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
         return this;
     }
 
-    public String defaultField() {
-        return this.defaultField;
-    }
-
     /**
-     * Adds a field to run the query string against. The field will be associated with the default boost of {@link AbstractQueryBuilder#DEFAULT_BOOST}.
-     * Use {@link #field(String, float)} to set a specific boost for the field.
+     * Adds a field to run the query string against.
      */
     public QueryStringQueryBuilder field(String field) {
-        this.fieldsAndWeights.put(field, AbstractQueryBuilder.DEFAULT_BOOST);
+        if (fields == null) {
+            fields = new ArrayList<>();
+        }
+        fields.add(field);
         return this;
     }
 
@@ -162,23 +126,17 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
      * Adds a field to run the query string against with a specific boost.
      */
     public QueryStringQueryBuilder field(String field, float boost) {
-        this.fieldsAndWeights.put(field, boost);
-        return this;
-    }
-
-    /**
-     * Add several fields to run the query against with a specific boost.
-     */
-    public QueryStringQueryBuilder fields(Map<String, Float> fields) {
-        this.fieldsAndWeights.putAll(fields);
+        if (fields == null) {
+            fields = new ArrayList<>();
+        }
+        fields.add(field);
+        if (fieldsBoosts == null) {
+            fieldsBoosts = new ObjectFloatHashMap<>();
+        }
+        fieldsBoosts.put(field, boost);
         return this;
     }
 
-    /** Returns the fields including their respective boosts to run the query against. */
-    public Map<String, Float> fields() {
-        return this.fieldsAndWeights;
-    }
-
     /**
      * When more than one field is used with the query string, should queries be combined using
      * dis max, or boolean query. Defaults to dis max (<tt>true</tt>).
@@ -188,10 +146,6 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
         return this;
     }
 
-    public boolean useDisMax() {
-        return this.useDisMax;
-    }
-
     /**
      * When more than one field is used with the query string, and combined queries are using
      * dis max, control the tie breaker for it.
@@ -201,10 +155,6 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
         return this;
     }
 
-    public float tieBreaker() {
-        return this.tieBreaker;
-    }
-
     /**
      * Sets the boolean operator of the query parser used to parse the query string.
      * <p/>
@@ -216,14 +166,10 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
      * above mentioned query is parsed as <code>capital AND of AND Hungary</code>
      */
     public QueryStringQueryBuilder defaultOperator(Operator defaultOperator) {
-        this.defaultOperator = defaultOperator == null ? DEFAULT_OPERATOR : defaultOperator;
+        this.defaultOperator = defaultOperator;
         return this;
     }
 
-    public Operator defaultOperator() {
-        return this.defaultOperator;
-    }
-
     /**
      * The optional analyzer used to analyze the query string. Note, if a field has search analyzer
      * defined for it, then it will be used automatically. Defaults to the smart search analyzer.
@@ -237,11 +183,12 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
      * The optional analyzer used to analyze the query string for phrase searches. Note, if a field has search (quote) analyzer
      * defined for it, then it will be used automatically. Defaults to the smart search analyzer.
      */
-    public QueryStringQueryBuilder quoteAnalyzer(String quoteAnalyzer) {
-        this.quoteAnalyzer = quoteAnalyzer;
+    public QueryStringQueryBuilder quoteAnalyzer(String analyzer) {
+        this.quoteAnalyzer = analyzer;
         return this;
     }
 
+
     /**
      * Set to true if phrase queries will be automatically generated
      * when the analyzer returns more than one term from whitespace
@@ -256,10 +203,6 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
         return this;
     }
 
-    public boolean autoGeneratePhraseQueries() {
-        return this.autoGeneratePhraseQueries;
-    }
-
     /**
      * Protects against too-difficult regular expression queries.
      */
@@ -268,22 +211,14 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
         return this;
     }
 
-    public int maxDeterminizedStates() {
-        return this.maxDeterminizedStates;
-    }
-
     /**
      * Should leading wildcards be allowed or not. Defaults to <tt>true</tt>.
      */
-    public QueryStringQueryBuilder allowLeadingWildcard(Boolean allowLeadingWildcard) {
+    public QueryStringQueryBuilder allowLeadingWildcard(boolean allowLeadingWildcard) {
         this.allowLeadingWildcard = allowLeadingWildcard;
         return this;
     }
 
-    public Boolean allowLeadingWildcard() {
-        return this.allowLeadingWildcard;
-    }
-
     /**
      * Whether terms of wildcard, prefix, fuzzy and range queries are to be automatically
      * lower-cased or not.  Default is <tt>true</tt>.
@@ -293,10 +228,6 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
         return this;
     }
 
-    public boolean lowercaseExpandedTerms() {
-        return this.lowercaseExpandedTerms;
-    }
-
     /**
      * Set to <tt>true</tt> to enable position increments in result query. Defaults to
      * <tt>true</tt>.
@@ -309,22 +240,14 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
         return this;
     }
 
-    public boolean enablePositionIncrements() {
-        return this.enablePositionIncrements;
-    }
-
     /**
      * Set the edit distance for fuzzy queries. Default is "AUTO".
      */
     public QueryStringQueryBuilder fuzziness(Fuzziness fuzziness) {
-        this.fuzziness = fuzziness == null ? DEFAULT_FUZZINESS : fuzziness;
+        this.fuzziness = fuzziness;
         return this;
     }
 
-    public Fuzziness fuzziness() {
-        return this.fuzziness;
-    }
-
     /**
      * Set the minimum prefix length for fuzzy queries. Default is 1.
      */
@@ -333,28 +256,16 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
         return this;
     }
 
-    public int fuzzyPrefixLength() {
-        return fuzzyPrefixLength;
-    }
-
     public QueryStringQueryBuilder fuzzyMaxExpansions(int fuzzyMaxExpansions) {
         this.fuzzyMaxExpansions = fuzzyMaxExpansions;
         return this;
     }
 
-    public int fuzzyMaxExpansions() {
-        return fuzzyMaxExpansions;
-    }
-
     public QueryStringQueryBuilder fuzzyRewrite(String fuzzyRewrite) {
         this.fuzzyRewrite = fuzzyRewrite;
         return this;
     }
 
-    public String fuzzyRewrite() {
-        return fuzzyRewrite;
-    }
-
     /**
      * Sets the default slop for phrases.  If zero, then exact phrase matches
      * are required. Default value is zero.
@@ -364,38 +275,32 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
         return this;
     }
 
-    public int phraseSlop() {
-        return phraseSlop;
-    }
-
     /**
      * Set to <tt>true</tt> to enable analysis on wildcard and prefix queries.
      */
-    public QueryStringQueryBuilder analyzeWildcard(Boolean analyzeWildcard) {
+    public QueryStringQueryBuilder analyzeWildcard(boolean analyzeWildcard) {
         this.analyzeWildcard = analyzeWildcard;
         return this;
     }
 
-    public Boolean analyzeWildcard() {
-        return this.analyzeWildcard;
-    }
-
     public QueryStringQueryBuilder rewrite(String rewrite) {
         this.rewrite = rewrite;
         return this;
     }
 
-    public String rewrite() {
-        return this.rewrite;
-    }
-
     public QueryStringQueryBuilder minimumShouldMatch(String minimumShouldMatch) {
         this.minimumShouldMatch = minimumShouldMatch;
         return this;
     }
 
-    public String minimumShouldMatch() {
-        return this.minimumShouldMatch;
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
+    @Override
+    public QueryStringQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
@@ -406,10 +311,6 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
         return this;
     }
 
-    public String quoteFieldSuffix() {
-        return this.quoteFieldSuffix;
-    }
-
     /**
      * Sets the query string parser to be lenient when parsing field values, defaults to the index
      * setting and if not set, defaults to false.
@@ -419,40 +320,27 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
         return this;
     }
 
-    public Boolean lenient() {
-        return this.lenient;
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public QueryStringQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     public QueryStringQueryBuilder locale(Locale locale) {
-        this.locale = locale == null ? DEFAULT_LOCALE : locale;
+        this.locale = locale;
         return this;
     }
 
-    public Locale locale() {
-        return this.locale;
-    }
-
     /**
      * In case of date field, we can adjust the from/to fields using a timezone
      */
     public QueryStringQueryBuilder timeZone(String timeZone) {
-        if (timeZone != null) {
-            this.timeZone = DateTimeZone.forID(timeZone);
-        } else {
-            this.timeZone = null;
-        }
-        return this;
-    }
-
-    public QueryStringQueryBuilder timeZone(DateTimeZone timeZone) {
         this.timeZone = timeZone;
         return this;
     }
 
-    public DateTimeZone timeZone() {
-        return this.timeZone;
-    }
-
     /**
      * Set to <tt>true</tt> to enable escaping of the query string
      */
@@ -461,284 +349,98 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
         return this;
     }
 
-    public boolean escape() {
-        return this.escape;
-    }
-
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("query", this.queryString);
-        if (this.defaultField != null) {
-            builder.field("default_field", this.defaultField);
+        builder.startObject(QueryStringQueryParser.NAME);
+        builder.field("query", queryString);
+        if (defaultField != null) {
+            builder.field("default_field", defaultField);
         }
-        builder.startArray("fields");
-        for (Map.Entry<String, Float> fieldEntry : this.fieldsAndWeights.entrySet()) {
-            builder.value(fieldEntry.getKey() + "^" + fieldEntry.getValue());
+        if (fields != null) {
+            builder.startArray("fields");
+            for (String field : fields) {
+                if (fieldsBoosts != null && fieldsBoosts.containsKey(field)) {
+                    field += "^" + fieldsBoosts.get(field);
+                }
+                builder.value(field);
+            }
+            builder.endArray();
         }
-        builder.endArray();
-        builder.field("use_dis_max", this.useDisMax);
-        builder.field("tie_breaker", this.tieBreaker);
-        builder.field("default_operator", this.defaultOperator.name().toLowerCase(Locale.ROOT));
-        if (this.analyzer != null) {
-            builder.field("analyzer", this.analyzer);
+        if (useDisMax != null) {
+            builder.field("use_dis_max", useDisMax);
         }
-        if (this.quoteAnalyzer != null) {
-            builder.field("quote_analyzer", this.quoteAnalyzer);
+        if (tieBreaker != -1) {
+            builder.field("tie_breaker", tieBreaker);
         }
-        builder.field("auto_generate_phrase_queries", this.autoGeneratePhraseQueries);
-        builder.field("max_determinized_states", this.maxDeterminizedStates);
-        if (this.allowLeadingWildcard != null) {
-            builder.field("allow_leading_wildcard", this.allowLeadingWildcard);
+        if (defaultOperator != null) {
+            builder.field("default_operator", defaultOperator.name().toLowerCase(Locale.ROOT));
         }
-        builder.field("lowercase_expanded_terms", this.lowercaseExpandedTerms);
-        builder.field("enable_position_increments", this.enablePositionIncrements);
-        this.fuzziness.toXContent(builder, params);
-        builder.field("fuzzy_prefix_length", this.fuzzyPrefixLength);
-        builder.field("fuzzy_max_expansions", this.fuzzyMaxExpansions);
-        if (this.fuzzyRewrite != null) {
-            builder.field("fuzzy_rewrite", this.fuzzyRewrite);
+        if (analyzer != null) {
+            builder.field("analyzer", analyzer);
         }
-        builder.field("phrase_slop", this.phraseSlop);
-        if (this.analyzeWildcard != null) {
-            builder.field("analyze_wildcard", this.analyzeWildcard);
+        if (quoteAnalyzer != null) {
+            builder.field("quote_analyzer", quoteAnalyzer);
         }
-        if (this.rewrite != null) {
-            builder.field("rewrite", this.rewrite);
+        if (autoGeneratePhraseQueries != null) {
+            builder.field("auto_generate_phrase_queries", autoGeneratePhraseQueries);
         }
-        if (this.minimumShouldMatch != null) {
-            builder.field("minimum_should_match", this.minimumShouldMatch);
+        if (maxDeterminizedStates != null) {
+            builder.field("max_determinized_states", maxDeterminizedStates);
         }
-        if (this.quoteFieldSuffix != null) {
-            builder.field("quote_field_suffix", this.quoteFieldSuffix);
+        if (allowLeadingWildcard != null) {
+            builder.field("allow_leading_wildcard", allowLeadingWildcard);
         }
-        if (this.lenient != null) {
-            builder.field("lenient", this.lenient);
+        if (lowercaseExpandedTerms != null) {
+            builder.field("lowercase_expanded_terms", lowercaseExpandedTerms);
         }
-        builder.field("locale", this.locale.toLanguageTag());
-        if (this.timeZone != null) {
-            builder.field("time_zone", this.timeZone.getID());
+        if (enablePositionIncrements != null) {
+            builder.field("enable_position_increments", enablePositionIncrements);
         }
-        builder.field("escape", this.escape);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (queryString == null) {
-            validationException = addValidationError("query text missing", null);
+        if (fuzziness != null) {
+            fuzziness.toXContent(builder, params);
         }
-        return validationException;
-    }
-
-    @Override
-    protected QueryStringQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        QueryStringQueryBuilder queryStringQueryBuilder = new QueryStringQueryBuilder(in.readString());
-        queryStringQueryBuilder.defaultField = in.readOptionalString();
-        int size = in.readVInt();
-        for (int i = 0; i < size; i++) {
-            queryStringQueryBuilder.fieldsAndWeights.put(in.readString(), in.readFloat());
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        queryStringQueryBuilder.defaultOperator = Operator.readOperatorFrom(in);
-        queryStringQueryBuilder.analyzer = in.readOptionalString();
-        queryStringQueryBuilder.quoteAnalyzer = in.readOptionalString();
-        queryStringQueryBuilder.quoteFieldSuffix = in.readOptionalString();
-        queryStringQueryBuilder.autoGeneratePhraseQueries = in.readBoolean();
-        queryStringQueryBuilder.allowLeadingWildcard = in.readOptionalBoolean();
-        queryStringQueryBuilder.analyzeWildcard = in.readOptionalBoolean();
-        queryStringQueryBuilder.lowercaseExpandedTerms = in.readBoolean();
-        queryStringQueryBuilder.enablePositionIncrements = in.readBoolean();
-        queryStringQueryBuilder.locale = Locale.forLanguageTag(in.readString());
-        queryStringQueryBuilder.fuzziness = Fuzziness.readFuzzinessFrom(in);
-        queryStringQueryBuilder.fuzzyPrefixLength = in.readVInt();
-        queryStringQueryBuilder.fuzzyMaxExpansions = in.readVInt();
-        queryStringQueryBuilder.fuzzyRewrite = in.readOptionalString();
-        queryStringQueryBuilder.phraseSlop = in.readVInt();
-        queryStringQueryBuilder.useDisMax = in.readBoolean();
-        queryStringQueryBuilder.tieBreaker = in.readFloat();
-        queryStringQueryBuilder.rewrite = in.readOptionalString();
-        queryStringQueryBuilder.minimumShouldMatch = in.readOptionalString();
-        queryStringQueryBuilder.lenient = in.readOptionalBoolean();
-        if (in.readBoolean()) {
-            queryStringQueryBuilder.timeZone = DateTimeZone.forID(in.readString());
+        if (fuzzyPrefixLength != -1) {
+            builder.field("fuzzy_prefix_length", fuzzyPrefixLength);
         }
-        queryStringQueryBuilder.escape = in.readBoolean();
-        queryStringQueryBuilder.maxDeterminizedStates = in.readVInt();
-        return queryStringQueryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(this.queryString);
-        out.writeOptionalString(this.defaultField);
-        out.writeVInt(this.fieldsAndWeights.size());
-        for (Map.Entry<String, Float> fieldsEntry : this.fieldsAndWeights.entrySet()) {
-            out.writeString(fieldsEntry.getKey());
-            out.writeFloat(fieldsEntry.getValue());
+        if (fuzzyMaxExpansions != -1) {
+            builder.field("fuzzy_max_expansions", fuzzyMaxExpansions);
         }
-        this.defaultOperator.writeTo(out);
-        out.writeOptionalString(this.analyzer);
-        out.writeOptionalString(this.quoteAnalyzer);
-        out.writeOptionalString(this.quoteFieldSuffix);
-        out.writeBoolean(this.autoGeneratePhraseQueries);
-        out.writeOptionalBoolean(this.allowLeadingWildcard);
-        out.writeOptionalBoolean(this.analyzeWildcard);
-        out.writeBoolean(this.lowercaseExpandedTerms);
-        out.writeBoolean(this.enablePositionIncrements);
-        out.writeString(this.locale.toLanguageTag());
-        this.fuzziness.writeTo(out);
-        out.writeVInt(this.fuzzyPrefixLength);
-        out.writeVInt(this.fuzzyMaxExpansions);
-        out.writeOptionalString(this.fuzzyRewrite);
-        out.writeVInt(this.phraseSlop);
-        out.writeBoolean(this.useDisMax);
-        out.writeFloat(this.tieBreaker);
-        out.writeOptionalString(this.rewrite);
-        out.writeOptionalString(this.minimumShouldMatch);
-        out.writeOptionalBoolean(this.lenient);
-        if (this.timeZone == null) {
-            out.writeBoolean(false);
-        } else {
-            out.writeBoolean(true);
-            out.writeString(this.timeZone.getID());
+        if (fuzzyRewrite != null) {
+            builder.field("fuzzy_rewrite", fuzzyRewrite);
         }
-        out.writeBoolean(this.escape);
-        out.writeVInt(this.maxDeterminizedStates);
-    }
-
-    @Override
-    protected boolean doEquals(QueryStringQueryBuilder other) {
-        return Objects.equals(queryString, other.queryString) &&
-                Objects.equals(defaultField, other.defaultField) &&
-                Objects.equals(fieldsAndWeights, other.fieldsAndWeights) &&
-                Objects.equals(defaultOperator, other.defaultOperator) &&
-                Objects.equals(analyzer, other.analyzer) &&
-                Objects.equals(quoteAnalyzer, other.quoteAnalyzer) &&
-                Objects.equals(quoteFieldSuffix, other.quoteFieldSuffix) &&
-                Objects.equals(autoGeneratePhraseQueries, other.autoGeneratePhraseQueries) &&
-                Objects.equals(allowLeadingWildcard, other.allowLeadingWildcard) &&
-                Objects.equals(lowercaseExpandedTerms, other.lowercaseExpandedTerms) &&
-                Objects.equals(enablePositionIncrements, other.enablePositionIncrements) &&
-                Objects.equals(analyzeWildcard, other.analyzeWildcard) &&
-                Objects.equals(locale.toLanguageTag(), other.locale.toLanguageTag()) &&
-                Objects.equals(fuzziness, other.fuzziness) &&
-                Objects.equals(fuzzyPrefixLength, other.fuzzyPrefixLength) &&
-                Objects.equals(fuzzyMaxExpansions, other.fuzzyMaxExpansions) &&
-                Objects.equals(fuzzyRewrite, other.fuzzyRewrite) &&
-                Objects.equals(phraseSlop, other.phraseSlop) &&
-                Objects.equals(useDisMax, other.useDisMax) &&
-                Objects.equals(tieBreaker, other.tieBreaker) &&
-                Objects.equals(rewrite, other.rewrite) &&
-                Objects.equals(minimumShouldMatch, other.minimumShouldMatch) &&
-                Objects.equals(lenient, other.lenient) &&
-                timeZone == null ? other.timeZone == null : other.timeZone != null && Objects.equals(timeZone.getID(), other.timeZone.getID()) &&
-                Objects.equals(escape, other.escape) &&
-                Objects.equals(maxDeterminizedStates, other.maxDeterminizedStates);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(queryString, defaultField, fieldsAndWeights, defaultOperator, analyzer, quoteAnalyzer,
-                quoteFieldSuffix, autoGeneratePhraseQueries, allowLeadingWildcard, lowercaseExpandedTerms,
-                enablePositionIncrements, analyzeWildcard, locale.toLanguageTag(), fuzziness, fuzzyPrefixLength,
-                fuzzyMaxExpansions, fuzzyRewrite, phraseSlop, useDisMax, tieBreaker, rewrite, minimumShouldMatch, lenient,
-                timeZone == null ? 0 : timeZone.getID(), escape, maxDeterminizedStates);
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        //TODO would be nice to have all the settings in one place: some change though at query execution time
-        //e.g. field names get expanded to concrete names, defaults get resolved sometimes to settings values etc.
-        QueryParserSettings qpSettings;
-        if (this.escape) {
-            qpSettings = new QueryParserSettings(org.apache.lucene.queryparser.classic.QueryParser.escape(this.queryString));
-        } else {
-            qpSettings = new QueryParserSettings(this.queryString);
+        if (phraseSlop != -1) {
+            builder.field("phrase_slop", phraseSlop);
         }
-        qpSettings.defaultField(this.defaultField == null ? context.defaultField() : this.defaultField);
-        Map<String, Float> resolvedFields = new TreeMap<>();
-        for (Map.Entry<String, Float> fieldsEntry : fieldsAndWeights.entrySet()) {
-            String fieldName = fieldsEntry.getKey();
-            Float weight = fieldsEntry.getValue();
-            if (Regex.isSimpleMatchPattern(fieldName)) {
-                for (String resolvedFieldName : context.mapperService().simpleMatchToIndexNames(fieldName)) {
-                    resolvedFields.put(resolvedFieldName, weight);
-                }
-            } else {
-                resolvedFields.put(fieldName, weight);
-            }
+        if (analyzeWildcard != null) {
+            builder.field("analyze_wildcard", analyzeWildcard);
         }
-        qpSettings.fieldsAndWeights(resolvedFields);
-        qpSettings.defaultOperator(defaultOperator.toQueryParserOperator());
-
-        if (analyzer == null) {
-            qpSettings.defaultAnalyzer(context.mapperService().searchAnalyzer());
-        } else {
-            NamedAnalyzer namedAnalyzer = context.analysisService().analyzer(analyzer);
-            if (namedAnalyzer == null) {
-                throw new QueryShardException(context, "[query_string] analyzer [" + analyzer + "] not found");
-            }
-            qpSettings.forceAnalyzer(namedAnalyzer);
+        if (rewrite != null) {
+            builder.field("rewrite", rewrite);
         }
-        if (quoteAnalyzer != null) {
-            NamedAnalyzer namedAnalyzer = context.analysisService().analyzer(quoteAnalyzer);
-            if (namedAnalyzer == null) {
-                throw new QueryShardException(context, "[query_string] quote_analyzer [" + quoteAnalyzer + "] not found");
-            }
-            qpSettings.forceQuoteAnalyzer(namedAnalyzer);
-        } else if (analyzer != null) {
-            qpSettings.forceQuoteAnalyzer(qpSettings.analyzer());
-        } else {
-            qpSettings.defaultQuoteAnalyzer(context.mapperService().searchQuoteAnalyzer());
+        if (minimumShouldMatch != null) {
+            builder.field("minimum_should_match", minimumShouldMatch);
         }
-
-        qpSettings.quoteFieldSuffix(quoteFieldSuffix);
-        qpSettings.autoGeneratePhraseQueries(autoGeneratePhraseQueries);
-        qpSettings.allowLeadingWildcard(allowLeadingWildcard == null ? context.queryStringAllowLeadingWildcard() : allowLeadingWildcard);
-        qpSettings.analyzeWildcard(analyzeWildcard == null ? context.queryStringAnalyzeWildcard() : analyzeWildcard);
-        qpSettings.lowercaseExpandedTerms(lowercaseExpandedTerms);
-        qpSettings.enablePositionIncrements(enablePositionIncrements);
-        qpSettings.locale(locale);
-        qpSettings.fuzziness(fuzziness);
-        qpSettings.fuzzyPrefixLength(fuzzyPrefixLength);
-        qpSettings.fuzzyMaxExpansions(fuzzyMaxExpansions);
-        qpSettings.fuzzyRewriteMethod(QueryParsers.parseRewriteMethod(context.parseFieldMatcher(), this.fuzzyRewrite));
-        qpSettings.phraseSlop(phraseSlop);
-        qpSettings.useDisMax(useDisMax);
-        qpSettings.tieBreaker(tieBreaker);
-        qpSettings.rewriteMethod(QueryParsers.parseRewriteMethod(context.parseFieldMatcher(), this.rewrite));
-        qpSettings.lenient(lenient == null ? context.queryStringLenient() : lenient);
-        qpSettings.timeZone(timeZone);
-        qpSettings.maxDeterminizedStates(maxDeterminizedStates);
-
-        MapperQueryParser queryParser = context.queryParser(qpSettings);
-        Query query;
-        try {
-            query = queryParser.parse(queryString);
-        } catch (org.apache.lucene.queryparser.classic.ParseException e) {
-            throw new QueryShardException(context, "Failed to parse query [" + this.queryString + "]", e);
+        if (quoteFieldSuffix != null) {
+            builder.field("quote_field_suffix", quoteFieldSuffix);
         }
-
-        if (query == null) {
-            return null;
+        if (lenient != null) {
+            builder.field("lenient", lenient);
         }
-        query = Queries.fixNegativeQueryIfNeeded(query);
-        if (query instanceof BooleanQuery) {
-            query = Queries.applyMinimumShouldMatch((BooleanQuery) query, this.minimumShouldMatch());
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return query;
-    }
-
-    @Override
-    protected void setFinalBoost(Query query) {
-        //we need to preserve the boost that came out of the parsing phase
-        query.setBoost(query.getBoost() * boost);
+        if (locale != null) {
+            builder.field("locale", locale.toString());
+        }
+        if (timeZone != null) {
+            builder.field("time_zone", timeZone);
+        }
+        if (escape != null) {
+            builder.field("escape", escape);
+        }
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryParser.java
index fdf1a18..64afdd2 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryParser.java
@@ -19,66 +19,66 @@
 
 package org.elasticsearch.index.query;
 
+import com.carrotsearch.hppc.ObjectFloatHashMap;
+import org.apache.lucene.queryparser.classic.MapperQueryParser;
+import org.apache.lucene.queryparser.classic.QueryParserSettings;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
+import org.elasticsearch.common.regex.Regex;
+import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.Fuzziness;
+import org.elasticsearch.common.util.LocaleUtils;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.analysis.NamedAnalyzer;
+import org.elasticsearch.index.query.support.QueryParsers;
+import org.joda.time.DateTimeZone;
 
 import java.io.IOException;
-import java.util.HashMap;
+import java.util.ArrayList;
 import java.util.Locale;
-import java.util.Map;
+
+import static org.elasticsearch.common.lucene.search.Queries.fixNegativeQueryIfNeeded;
 
 /**
- * Parser for query_string query
+ *
  */
-public class QueryStringQueryParser extends BaseQueryParser {
+public class QueryStringQueryParser implements QueryParser {
 
+    public static final String NAME = "query_string";
     private static final ParseField FUZZINESS = Fuzziness.FIELD.withDeprecation("fuzzy_min_sim");
 
+    private final boolean defaultAnalyzeWildcard;
+    private final boolean defaultAllowLeadingWildcard;
+
     @Inject
-    public QueryStringQueryParser() {
+    public QueryStringQueryParser(Settings settings) {
+        this.defaultAnalyzeWildcard = settings.getAsBoolean("indices.query.query_string.analyze_wildcard", QueryParserSettings.DEFAULT_ANALYZE_WILDCARD);
+        this.defaultAllowLeadingWildcard = settings.getAsBoolean("indices.query.query_string.allowLeadingWildcard", QueryParserSettings.DEFAULT_ALLOW_LEADING_WILDCARD);
     }
 
     @Override
     public String[] names() {
-        return new String[]{QueryStringQueryBuilder.NAME, Strings.toCamelCase(QueryStringQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
+
+        String queryName = null;
+        QueryParserSettings qpSettings = new QueryParserSettings();
+        qpSettings.defaultField(parseContext.defaultField());
+        qpSettings.lenient(parseContext.queryStringLenient());
+        qpSettings.analyzeWildcard(defaultAnalyzeWildcard);
+        qpSettings.allowLeadingWildcard(defaultAllowLeadingWildcard);
+        qpSettings.locale(Locale.ROOT);
+
         String currentFieldName = null;
         XContentParser.Token token;
-        String queryString = null;
-        String defaultField = null;
-        String analyzer = null;
-        String quoteAnalyzer = null;
-        String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        boolean autoGeneratePhraseQueries = QueryStringQueryBuilder.DEFAULT_AUTO_GENERATE_PHRASE_QUERIES;
-        int maxDeterminizedStates = QueryStringQueryBuilder.DEFAULT_MAX_DETERMINED_STATES;
-        boolean lowercaseExpandedTerms = QueryStringQueryBuilder.DEFAULT_LOWERCASE_EXPANDED_TERMS;
-        boolean enablePositionIncrements = QueryStringQueryBuilder.DEFAULT_ENABLE_POSITION_INCREMENTS;
-        boolean escape = QueryStringQueryBuilder.DEFAULT_ESCAPE;
-        boolean useDisMax = QueryStringQueryBuilder.DEFAULT_USE_DIS_MAX;
-        int fuzzyPrefixLength = QueryStringQueryBuilder.DEFAULT_FUZZY_PREFIX_LENGTH;
-        int fuzzyMaxExpansions = QueryStringQueryBuilder.DEFAULT_FUZZY_MAX_EXPANSIONS;
-        int phraseSlop = QueryStringQueryBuilder.DEFAULT_PHRASE_SLOP;
-        float tieBreaker = QueryStringQueryBuilder.DEFAULT_TIE_BREAKER;
-        Boolean analyzeWildcard = null;
-        Boolean allowLeadingWildcard = null;
-        String minimumShouldMatch = null;
-        String quoteFieldSuffix = null;
-        Boolean lenient = null;
-        Operator defaultOperator = QueryStringQueryBuilder.DEFAULT_OPERATOR;
-        String timeZone = null;
-        Locale locale = QueryStringQueryBuilder.DEFAULT_LOCALE;
-        Fuzziness fuzziness = QueryStringQueryBuilder.DEFAULT_FUZZINESS;
-        String fuzzyRewrite = null;
-        String rewrite = null;
-        Map<String, Float> fieldsAndWeights = new HashMap<>();
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
@@ -86,7 +86,7 @@ public class QueryStringQueryParser extends BaseQueryParser {
                 if ("fields".equals(currentFieldName)) {
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                         String fField = null;
-                        float fBoost = AbstractQueryBuilder.DEFAULT_BOOST;
+                        float fBoost = -1;
                         char[] text = parser.textCharacters();
                         int end = parser.textOffset() + parser.textLength();
                         for (int i = parser.textOffset(); i < end; i++) {
@@ -100,113 +100,147 @@ public class QueryStringQueryParser extends BaseQueryParser {
                         if (fField == null) {
                             fField = parser.text();
                         }
-                        fieldsAndWeights.put(fField, fBoost);
+                        if (qpSettings.fields() == null) {
+                            qpSettings.fields(new ArrayList<String>());
+                        }
+
+                        if (Regex.isSimpleMatchPattern(fField)) {
+                            for (String field : parseContext.mapperService().simpleMatchToIndexNames(fField)) {
+                                qpSettings.fields().add(field);
+                                if (fBoost != -1) {
+                                    if (qpSettings.boosts() == null) {
+                                        qpSettings.boosts(new ObjectFloatHashMap<String>());
+                                    }
+                                    qpSettings.boosts().put(field, fBoost);
+                                }
+                            }
+                        } else {
+                            qpSettings.fields().add(fField);
+                            if (fBoost != -1) {
+                                if (qpSettings.boosts() == null) {
+                                    qpSettings.boosts(new ObjectFloatHashMap<String>());
+                                }
+                                qpSettings.boosts().put(fField, fBoost);
+                            }
+                        }
                     }
                 } else {
-                    throw new QueryParsingException(parseContext, "[query_string] query does not support [" + currentFieldName + "]");
+                    throw new QueryParsingException(parseContext, "[query_string] query does not support [" + currentFieldName
+                            + "]");
                 }
             } else if (token.isValue()) {
                 if ("query".equals(currentFieldName)) {
-                    queryString = parser.text();
+                    qpSettings.queryString(parser.text());
                 } else if ("default_field".equals(currentFieldName) || "defaultField".equals(currentFieldName)) {
-                    defaultField = parser.text();
+                    qpSettings.defaultField(parser.text());
                 } else if ("default_operator".equals(currentFieldName) || "defaultOperator".equals(currentFieldName)) {
-                    defaultOperator = Operator.fromString(parser.text());
+                    String op = parser.text();
+                    if ("or".equalsIgnoreCase(op)) {
+                        qpSettings.defaultOperator(org.apache.lucene.queryparser.classic.QueryParser.Operator.OR);
+                    } else if ("and".equalsIgnoreCase(op)) {
+                        qpSettings.defaultOperator(org.apache.lucene.queryparser.classic.QueryParser.Operator.AND);
+                    } else {
+                        throw new QueryParsingException(parseContext, "Query default operator [" + op + "] is not allowed");
+                    }
                 } else if ("analyzer".equals(currentFieldName)) {
-                    analyzer = parser.text();
+                    NamedAnalyzer analyzer = parseContext.analysisService().analyzer(parser.text());
+                    if (analyzer == null) {
+                        throw new QueryParsingException(parseContext, "[query_string] analyzer [" + parser.text() + "] not found");
+                    }
+                    qpSettings.forcedAnalyzer(analyzer);
                 } else if ("quote_analyzer".equals(currentFieldName) || "quoteAnalyzer".equals(currentFieldName)) {
-                    quoteAnalyzer = parser.text();
+                    NamedAnalyzer analyzer = parseContext.analysisService().analyzer(parser.text());
+                    if (analyzer == null) {
+                        throw new QueryParsingException(parseContext, "[query_string] quote_analyzer [" + parser.text()
+                                + "] not found");
+                    }
+                    qpSettings.forcedQuoteAnalyzer(analyzer);
                 } else if ("allow_leading_wildcard".equals(currentFieldName) || "allowLeadingWildcard".equals(currentFieldName)) {
-                    allowLeadingWildcard = parser.booleanValue();
+                    qpSettings.allowLeadingWildcard(parser.booleanValue());
                 } else if ("auto_generate_phrase_queries".equals(currentFieldName) || "autoGeneratePhraseQueries".equals(currentFieldName)) {
-                    autoGeneratePhraseQueries = parser.booleanValue();
+                    qpSettings.autoGeneratePhraseQueries(parser.booleanValue());
                 } else if ("max_determinized_states".equals(currentFieldName) || "maxDeterminizedStates".equals(currentFieldName)) {
-                    maxDeterminizedStates = parser.intValue();
+                    qpSettings.maxDeterminizedStates(parser.intValue());
                 } else if ("lowercase_expanded_terms".equals(currentFieldName) || "lowercaseExpandedTerms".equals(currentFieldName)) {
-                    lowercaseExpandedTerms = parser.booleanValue();
+                    qpSettings.lowercaseExpandedTerms(parser.booleanValue());
                 } else if ("enable_position_increments".equals(currentFieldName) || "enablePositionIncrements".equals(currentFieldName)) {
-                    enablePositionIncrements = parser.booleanValue();
+                    qpSettings.enablePositionIncrements(parser.booleanValue());
                 } else if ("escape".equals(currentFieldName)) {
-                    escape = parser.booleanValue();
+                    qpSettings.escape(parser.booleanValue());
                 } else if ("use_dis_max".equals(currentFieldName) || "useDisMax".equals(currentFieldName)) {
-                    useDisMax = parser.booleanValue();
+                    qpSettings.useDisMax(parser.booleanValue());
                 } else if ("fuzzy_prefix_length".equals(currentFieldName) || "fuzzyPrefixLength".equals(currentFieldName)) {
-                    fuzzyPrefixLength = parser.intValue();
+                    qpSettings.fuzzyPrefixLength(parser.intValue());
                 } else if ("fuzzy_max_expansions".equals(currentFieldName) || "fuzzyMaxExpansions".equals(currentFieldName)) {
-                    fuzzyMaxExpansions = parser.intValue();
+                    qpSettings.fuzzyMaxExpansions(parser.intValue());
                 } else if ("fuzzy_rewrite".equals(currentFieldName) || "fuzzyRewrite".equals(currentFieldName)) {
-                    fuzzyRewrite = parser.textOrNull();
+                    qpSettings.fuzzyRewriteMethod(QueryParsers.parseRewriteMethod(parseContext.parseFieldMatcher(), parser.textOrNull()));
                 } else if ("phrase_slop".equals(currentFieldName) || "phraseSlop".equals(currentFieldName)) {
-                    phraseSlop = parser.intValue();
+                    qpSettings.phraseSlop(parser.intValue());
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, FUZZINESS)) {
-                    fuzziness = Fuzziness.parse(parser);
+                    qpSettings.setFuzziness(Fuzziness.parse(parser));
                 } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
+                    qpSettings.boost(parser.floatValue());
                 } else if ("tie_breaker".equals(currentFieldName) || "tieBreaker".equals(currentFieldName)) {
-                    tieBreaker = parser.floatValue();
+                    qpSettings.tieBreaker(parser.floatValue());
                 } else if ("analyze_wildcard".equals(currentFieldName) || "analyzeWildcard".equals(currentFieldName)) {
-                    analyzeWildcard = parser.booleanValue();
+                    qpSettings.analyzeWildcard(parser.booleanValue());
                 } else if ("rewrite".equals(currentFieldName)) {
-                    rewrite = parser.textOrNull();
+                    qpSettings.rewriteMethod(QueryParsers.parseRewriteMethod(parseContext.parseFieldMatcher(), parser.textOrNull()));
                 } else if ("minimum_should_match".equals(currentFieldName) || "minimumShouldMatch".equals(currentFieldName)) {
-                    minimumShouldMatch = parser.textOrNull();
+                    qpSettings.minimumShouldMatch(parser.textOrNull());
                 } else if ("quote_field_suffix".equals(currentFieldName) || "quoteFieldSuffix".equals(currentFieldName)) {
-                    quoteFieldSuffix = parser.textOrNull();
+                    qpSettings.quoteFieldSuffix(parser.textOrNull());
                 } else if ("lenient".equalsIgnoreCase(currentFieldName)) {
-                    lenient = parser.booleanValue();
+                    qpSettings.lenient(parser.booleanValue());
                 } else if ("locale".equals(currentFieldName)) {
                     String localeStr = parser.text();
-                    locale = Locale.forLanguageTag(localeStr);
-                } else if ("time_zone".equals(currentFieldName) || "timeZone".equals(currentFieldName)) {
+                    qpSettings.locale(LocaleUtils.parse(localeStr));
+                } else if ("time_zone".equals(currentFieldName)) {
                     try {
-                        timeZone = parser.text();
+                        qpSettings.timeZone(DateTimeZone.forID(parser.text()));
                     } catch (IllegalArgumentException e) {
-                        throw new QueryParsingException(parseContext, "[query_string] time_zone [" + parser.text() + "] is unknown");
+                        throw new QueryParsingException(parseContext,
+                                "[query_string] time_zone [" + parser.text() + "] is unknown");
                     }
                 } else if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
                 } else {
-                    throw new QueryParsingException(parseContext, "[query_string] query does not support [" + currentFieldName + "]");
+                    throw new QueryParsingException(parseContext, "[query_string] query does not support [" + currentFieldName
+ + "]");
                 }
             }
         }
-        if (queryString == null) {
+        if (qpSettings.queryString() == null) {
             throw new QueryParsingException(parseContext, "query_string must be provided with a [query]");
         }
+        qpSettings.defaultAnalyzer(parseContext.mapperService().searchAnalyzer());
+        qpSettings.defaultQuoteAnalyzer(parseContext.mapperService().searchQuoteAnalyzer());
 
-        QueryStringQueryBuilder queryStringQuery = new QueryStringQueryBuilder(queryString);
-        queryStringQuery.fields(fieldsAndWeights);
-        queryStringQuery.defaultField(defaultField);
-        queryStringQuery.defaultOperator(defaultOperator);
-        queryStringQuery.analyzer(analyzer);
-        queryStringQuery.quoteAnalyzer(quoteAnalyzer);
-        queryStringQuery.allowLeadingWildcard(allowLeadingWildcard);
-        queryStringQuery.autoGeneratePhraseQueries(autoGeneratePhraseQueries);
-        queryStringQuery.maxDeterminizedStates(maxDeterminizedStates);
-        queryStringQuery.lowercaseExpandedTerms(lowercaseExpandedTerms);
-        queryStringQuery.enablePositionIncrements(enablePositionIncrements);
-        queryStringQuery.escape(escape);
-        queryStringQuery.useDisMax(useDisMax);
-        queryStringQuery.fuzzyPrefixLength(fuzzyPrefixLength);
-        queryStringQuery.fuzzyMaxExpansions(fuzzyMaxExpansions);
-        queryStringQuery.fuzzyRewrite(fuzzyRewrite);
-        queryStringQuery.phraseSlop(phraseSlop);
-        queryStringQuery.fuzziness(fuzziness);
-        queryStringQuery.tieBreaker(tieBreaker);
-        queryStringQuery.analyzeWildcard(analyzeWildcard);
-        queryStringQuery.rewrite(rewrite);
-        queryStringQuery.minimumShouldMatch(minimumShouldMatch);
-        queryStringQuery.quoteFieldSuffix(quoteFieldSuffix);
-        queryStringQuery.lenient(lenient);
-        queryStringQuery.timeZone(timeZone);
-        queryStringQuery.locale(locale);
-        queryStringQuery.boost(boost);
-        queryStringQuery.queryName(queryName);
-        return queryStringQuery;
-    }
+        if (qpSettings.escape()) {
+            qpSettings.queryString(org.apache.lucene.queryparser.classic.QueryParser.escape(qpSettings.queryString()));
+        }
 
-    @Override
-    public QueryStringQueryBuilder getBuilderPrototype() {
-        return QueryStringQueryBuilder.PROTOTYPE;
+        MapperQueryParser queryParser = parseContext.queryParser(qpSettings);
+
+        try {
+            Query query = queryParser.parse(qpSettings.queryString());
+            if (query == null) {
+                return null;
+            }
+            if (qpSettings.boost() != QueryParserSettings.DEFAULT_BOOST) {
+                query.setBoost(query.getBoost() * qpSettings.boost());
+            }
+            query = fixNegativeQueryIfNeeded(query);
+            if (query instanceof BooleanQuery) {
+                query = Queries.applyMinimumShouldMatch((BooleanQuery) query, qpSettings.minimumShouldMatch());
+            }
+            if (queryName != null) {
+                parseContext.addNamedQuery(queryName, query);
+            }
+            return query;
+        } catch (org.apache.lucene.queryparser.classic.ParseException e) {
+            throw new QueryParsingException(parseContext, "Failed to parse query [" + qpSettings.queryString() + "]", e);
+        }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryValidationException.java b/core/src/main/java/org/elasticsearch/index/query/QueryValidationException.java
deleted file mode 100644
index 9e0ee2a..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/QueryValidationException.java
+++ /dev/null
@@ -1,62 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.elasticsearch.common.ValidationException;
-
-import java.util.List;
-
-/**
- * This exception can be used to indicate various reasons why validation of a query has failed.
- */
-public class QueryValidationException extends ValidationException {
-
-    /**
-     * Helper method than can be used to add error messages to an existing {@link QueryValidationException}.
-     * When passing {@code null} as the initial exception, a new exception is created.
-     *
-     * @param queryId the query that caused the error
-     * @param validationError the error message to add to an initial exception
-     * @param validationException an initial exception. Can be {@code null}, in which case a new exception is created.
-     * @return a {@link QueryValidationException} with added validation error message
-     */
-    public static QueryValidationException addValidationError(String queryId, String validationError, QueryValidationException validationException) {
-        if (validationException == null) {
-            validationException = new QueryValidationException();
-        }
-        validationException.addValidationError("[" + queryId + "] " + validationError);
-        return validationException;
-    }
-
-    /**
-     * Helper method than can be used to add error messages to an existing {@link QueryValidationException}.
-     * When passing {@code null} as the initial exception, a new exception is created.
-     * @param validationErrors the error messages to add to an initial exception
-     * @param validationException an initial exception. Can be {@code null}, in which case a new exception is created.
-     * @return a {@link QueryValidationException} with added validation error message
-     */
-    public static QueryValidationException addValidationErrors(List<String> validationErrors, QueryValidationException validationException) {
-        if (validationException == null) {
-            validationException = new QueryValidationException();
-        }
-        validationException.addValidationErrors(validationErrors);
-        return validationException;
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryWrappingQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/QueryWrappingQueryBuilder.java
deleted file mode 100644
index e905de1..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/QueryWrappingQueryBuilder.java
+++ /dev/null
@@ -1,60 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-
-import java.io.IOException;
-
-/**
- * QueryBuilder implementation that  holds a lucene query, which can be returned by {@link QueryBuilder#toQuery(QueryShardContext)}.
- * Doesn't support conversion to {@link org.elasticsearch.common.xcontent.XContent} via {@link #doXContent(XContentBuilder, Params)}.
- */
-//norelease to be removed once all queries support separate fromXContent and toQuery methods. Make AbstractQueryBuilder#toQuery final as well then.
-public class QueryWrappingQueryBuilder extends AbstractQueryBuilder<QueryWrappingQueryBuilder> implements SpanQueryBuilder<QueryWrappingQueryBuilder>, MultiTermQueryBuilder<QueryWrappingQueryBuilder>{
-
-    private Query query;
-
-    public QueryWrappingQueryBuilder(Query query) {
-        this.query = query;
-    }
-
-    @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        throw new UnsupportedOperationException();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        return query;
-    }
-
-    @Override
-    public String getWriteableName() {
-        // this should not be called since we overwrite BaseQueryBuilder#toQuery() in this class
-        throw new UnsupportedOperationException();
-    }
-
-    @Override
-    protected void setFinalBoost(Query query) {
-        //no-op the wrapper lucene query has already its boost set
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/RangeQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/RangeQueryBuilder.java
index 0db4152..da23698 100644
--- a/core/src/main/java/org/elasticsearch/index/query/RangeQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/RangeQueryBuilder.java
@@ -19,111 +19,187 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermRangeQuery;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.joda.DateMathParser;
-import org.elasticsearch.common.joda.Joda;
-import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.mapper.core.DateFieldMapper;
-import org.joda.time.DateTimeZone;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * A Query that matches documents within an range of terms.
  */
-public class RangeQueryBuilder extends AbstractQueryBuilder<RangeQueryBuilder> implements MultiTermQueryBuilder<RangeQueryBuilder> {
+public class RangeQueryBuilder extends MultiTermQueryBuilder implements BoostableQueryBuilder<RangeQueryBuilder> {
 
-    public static final boolean DEFAULT_INCLUDE_UPPER = true;
+    private final String name;
+    private Object from;
+    private Object to;
+    private String timeZone;
+    private boolean includeLower = true;
+    private boolean includeUpper = true;
+    private float boost = -1;
+    private String queryName;
+    private String format;
 
-    public static final boolean DEFAULT_INCLUDE_LOWER = true;
+    /**
+     * A Query that matches documents within an range of terms.
+     *
+     * @param name The field name
+     */
+    public RangeQueryBuilder(String name) {
+        this.name = name;
+    }
 
-    public static final String NAME = "range";
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder from(Object from) {
+        this.from = from;
+        return this;
+    }
 
-    private final String fieldName;
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder from(String from) {
+        this.from = from;
+        return this;
+    }
 
-    private Object from;
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder from(int from) {
+        this.from = from;
+        return this;
+    }
 
-    private Object to;
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder from(long from) {
+        this.from = from;
+        return this;
+    }
 
-    private String timeZone;
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder from(float from) {
+        this.from = from;
+        return this;
+    }
 
-    private boolean includeLower = DEFAULT_INCLUDE_LOWER;
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder from(double from) {
+        this.from = from;
+        return this;
+    }
 
-    private boolean includeUpper = DEFAULT_INCLUDE_UPPER;
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder gt(String from) {
+        this.from = from;
+        this.includeLower = false;
+        return this;
+    }
 
-    private String format;
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder gt(Object from) {
+        this.from = from;
+        this.includeLower = false;
+        return this;
+    }
 
-    static final RangeQueryBuilder PROTOTYPE = new RangeQueryBuilder(null);
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder gt(int from) {
+        this.from = from;
+        this.includeLower = false;
+        return this;
+    }
 
     /**
-     * A Query that matches documents within an range of terms.
-     *
-     * @param fieldName The field name
+     * The from part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder(String fieldName) {
-        this.fieldName = fieldName;
+    public RangeQueryBuilder gt(long from) {
+        this.from = from;
+        this.includeLower = false;
+        return this;
     }
 
     /**
-     * Get the field name for this query.
+     * The from part of the range query. Null indicates unbounded.
      */
-    public String fieldName() {
-        return this.fieldName;
+    public RangeQueryBuilder gt(float from) {
+        this.from = from;
+        this.includeLower = false;
+        return this;
     }
 
     /**
      * The from part of the range query. Null indicates unbounded.
-     * In case lower bound is assigned to a string, we internally convert it to a {@link BytesRef} because
-     * in {@link RangeQueryParser} field are later parsed as {@link BytesRef} and we need internal representation
-     * of query to be equal regardless of whether it was created from XContent or via Java API.
      */
-    public RangeQueryBuilder from(Object from, boolean includeLower) {
-        this.from = convertToBytesRefIfString(from);
-        this.includeLower = includeLower;
+    public RangeQueryBuilder gt(double from) {
+        this.from = from;
+        this.includeLower = false;
         return this;
     }
 
     /**
      * The from part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder from(Object from) {
-        return from(from, this.includeLower);
+    public RangeQueryBuilder gte(String from) {
+        this.from = from;
+        this.includeLower = true;
+        return this;
     }
 
     /**
-     * Gets the lower range value for this query.
+     * The from part of the range query. Null indicates unbounded.
      */
-    public Object from() {
-        return convertToStringIfBytesRef(this.from);
+    public RangeQueryBuilder gte(Object from) {
+        this.from = from;
+        this.includeLower = true;
+        return this;
     }
 
     /**
      * The from part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder gt(Object from) {
-        return from(from, false);
+    public RangeQueryBuilder gte(int from) {
+        this.from = from;
+        this.includeLower = true;
+        return this;
     }
 
     /**
      * The from part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder gte(Object from) {
-        return from(from, true);
+    public RangeQueryBuilder gte(long from) {
+        this.from = from;
+        this.includeLower = true;
+        return this;
     }
 
     /**
-     * The to part of the range query. Null indicates unbounded.
+     * The from part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder to(Object to, boolean includeUpper) {
-        this.to = convertToBytesRefIfString(to);
-        this.includeUpper = includeUpper;
+    public RangeQueryBuilder gte(float from) {
+        this.from = from;
+        this.includeLower = true;
+        return this;
+    }
+
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder gte(double from) {
+        this.from = from;
+        this.includeLower = true;
         return this;
     }
 
@@ -131,214 +207,229 @@ public class RangeQueryBuilder extends AbstractQueryBuilder<RangeQueryBuilder> i
      * The to part of the range query. Null indicates unbounded.
      */
     public RangeQueryBuilder to(Object to) {
-        return to(to, this.includeUpper);
+        this.to = to;
+        return this;
     }
 
     /**
-     * Gets the upper range value for this query.
-     * In case upper bound is assigned to a string, we internally convert it to a {@link BytesRef} because
-     * in {@link RangeQueryParser} field are later parsed as {@link BytesRef} and we need internal representation
-     * of query to be equal regardless of whether it was created from XContent or via Java API.
+     * The to part of the range query. Null indicates unbounded.
      */
-    public Object to() {
-        return convertToStringIfBytesRef(this.to);
+    public RangeQueryBuilder to(String to) {
+        this.to = to;
+        return this;
     }
 
     /**
      * The to part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder lt(Object to) {
-        return to(to, false);
+    public RangeQueryBuilder to(int to) {
+        this.to = to;
+        return this;
     }
 
     /**
      * The to part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder lte(Object to) {
-        return to(to, true);
+    public RangeQueryBuilder to(long to) {
+        this.to = to;
+        return this;
     }
 
     /**
-     * Should the lower bound be included or not. Defaults to <tt>true</tt>.
+     * The to part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder includeLower(boolean includeLower) {
-        this.includeLower = includeLower;
+    public RangeQueryBuilder to(float to) {
+        this.to = to;
         return this;
     }
 
     /**
-     * Gets the includeLower flag for this query.
+     * The to part of the range query. Null indicates unbounded.
      */
-    public boolean includeLower() {
-        return this.includeLower;
+    public RangeQueryBuilder to(double to) {
+        this.to = to;
+        return this;
     }
 
     /**
-     * Should the upper bound be included or not. Defaults to <tt>true</tt>.
+     * The to part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder includeUpper(boolean includeUpper) {
-        this.includeUpper = includeUpper;
+    public RangeQueryBuilder lt(String to) {
+        this.to = to;
+        this.includeUpper = false;
         return this;
     }
 
     /**
-     * Gets the includeUpper flag for this query.
+     * The to part of the range query. Null indicates unbounded.
      */
-    public boolean includeUpper() {
-        return this.includeUpper;
+    public RangeQueryBuilder lt(Object to) {
+        this.to = to;
+        this.includeUpper = false;
+        return this;
     }
 
     /**
-     * In case of date field, we can adjust the from/to fields using a timezone
+     * The to part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder timeZone(String timezone) {
-        this.timeZone = timezone;
+    public RangeQueryBuilder lt(int to) {
+        this.to = to;
+        this.includeUpper = false;
         return this;
     }
 
     /**
-     * In case of date field, gets the from/to fields timezone adjustment
+     * The to part of the range query. Null indicates unbounded.
      */
-    public String timeZone() {
-        return this.timeZone;
+    public RangeQueryBuilder lt(long to) {
+        this.to = to;
+        this.includeUpper = false;
+        return this;
     }
 
     /**
-     * In case of format field, we can parse the from/to fields using this time format
+     * The to part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder format(String format) {
-        this.format = format;
+    public RangeQueryBuilder lt(float to) {
+        this.to = to;
+        this.includeUpper = false;
         return this;
     }
 
     /**
-     * Gets the format field to parse the from/to fields
+     * The to part of the range query. Null indicates unbounded.
      */
-    public String format() {
-        return this.format;
+    public RangeQueryBuilder lt(double to) {
+        this.to = to;
+        this.includeUpper = false;
+        return this;
     }
 
-    @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.startObject(fieldName);
-        builder.field("from", convertToStringIfBytesRef(this.from));
-        builder.field("to", convertToStringIfBytesRef(this.to));
-        builder.field("include_lower", includeLower);
-        builder.field("include_upper", includeUpper);
-        if (timeZone != null) {
-            builder.field("time_zone", timeZone);
-        }
-        if (format != null) {
-            builder.field("format", format);
-        }
-        printBoostAndQueryName(builder);
-        builder.endObject();
-        builder.endObject();
+    /**
+     * The to part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder lte(String to) {
+        this.to = to;
+        this.includeUpper = true;
+        return this;
     }
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
+    /**
+     * The to part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder lte(Object to) {
+        this.to = to;
+        this.includeUpper = true;
+        return this;
     }
 
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query query = null;
-        MappedFieldType mapper = context.fieldMapper(this.fieldName);
-        if (mapper != null) {
-            if (mapper instanceof DateFieldMapper.DateFieldType) {
-                DateMathParser forcedDateParser = null;
-                if (this.format  != null) {
-                    forcedDateParser = new DateMathParser(Joda.forPattern(this.format));
-                }
-                DateTimeZone dateTimeZone = null;
-                if (this.timeZone != null) {
-                    dateTimeZone = DateTimeZone.forID(this.timeZone);
-                }
-                query = ((DateFieldMapper.DateFieldType) mapper).rangeQuery(from, to, includeLower, includeUpper, dateTimeZone, forcedDateParser);
-            } else  {
-                if (timeZone != null) {
-                    throw new QueryShardException(context, "[range] time_zone can not be applied to non date field ["
-                            + fieldName + "]");
-                }
-                //LUCENE 4 UPGRADE Mapper#rangeQuery should use bytesref as well?
-                query = mapper.rangeQuery(from, to, includeLower, includeUpper);
-            }
-        } else {
-            if (timeZone != null) {
-                throw new QueryShardException(context, "[range] time_zone can not be applied to non unmapped field ["
-                        + fieldName + "]");
-            }
-        }
+    /**
+     * The to part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder lte(int to) {
+        this.to = to;
+        this.includeUpper = true;
+        return this;
+    }
 
-        if (query == null) {
-            query = new TermRangeQuery(this.fieldName, BytesRefs.toBytesRef(from), BytesRefs.toBytesRef(to), includeLower, includeUpper);
-        }
-        return query;
+    /**
+     * The to part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder lte(long to) {
+        this.to = to;
+        this.includeUpper = true;
+        return this;
     }
 
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (this.fieldName == null || this.fieldName.isEmpty()) {
-            validationException = addValidationError("field name cannot be null or empty.", validationException);
-        }
-        if (this.timeZone != null) {
-            try {
-                DateTimeZone.forID(this.timeZone);
-            } catch (Exception e) {
-                validationException = addValidationError("error parsing timezone." + e.getMessage(),
-                        validationException);
-            }
-        }
-        if (this.format != null) {
-            try {
-                Joda.forPattern(this.format);
-            } catch (Exception e) {
-                validationException = addValidationError("error parsing format." + e.getMessage(),
-                        validationException);
-            }
-        }
-        return validationException;
+    /**
+     * The to part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder lte(float to) {
+        this.to = to;
+        this.includeUpper = true;
+        return this;
     }
 
-    @Override
-    protected RangeQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        RangeQueryBuilder rangeQueryBuilder = new RangeQueryBuilder(in.readString());
-        rangeQueryBuilder.from = in.readGenericValue();
-        rangeQueryBuilder.to = in.readGenericValue();
-        rangeQueryBuilder.includeLower = in.readBoolean();
-        rangeQueryBuilder.includeUpper = in.readBoolean();
-        rangeQueryBuilder.timeZone = in.readOptionalString();
-        rangeQueryBuilder.format = in.readOptionalString();
-        return rangeQueryBuilder;
+    /**
+     * The to part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder lte(double to) {
+        this.to = to;
+        this.includeUpper = true;
+        return this;
     }
 
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(this.fieldName);
-        out.writeGenericValue(this.from);
-        out.writeGenericValue(this.to);
-        out.writeBoolean(this.includeLower);
-        out.writeBoolean(this.includeUpper);
-        out.writeOptionalString(this.timeZone);
-        out.writeOptionalString(this.format);
+    /**
+     * Should the lower bound be included or not. Defaults to <tt>true</tt>.
+     */
+    public RangeQueryBuilder includeLower(boolean includeLower) {
+        this.includeLower = includeLower;
+        return this;
     }
 
+    /**
+     * Should the upper bound be included or not. Defaults to <tt>true</tt>.
+     */
+    public RangeQueryBuilder includeUpper(boolean includeUpper) {
+        this.includeUpper = includeUpper;
+        return this;
+    }
+
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
     @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldName, from, to, timeZone, includeLower, includeUpper, format);
+    public RangeQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public RangeQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
+    /**
+     * In case of date field, we can adjust the from/to fields using a timezone
+     */
+    public RangeQueryBuilder timeZone(String timezone) {
+        this.timeZone = timezone;
+        return this;
+    }
+
+    /**
+     * In case of date field, we can set the format to be used instead of the mapper format
+     */
+    public RangeQueryBuilder format(String format) {
+        this.format = format;
+        return this;
     }
 
     @Override
-    protected boolean doEquals(RangeQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-               Objects.equals(from, other.from) &&
-               Objects.equals(to, other.to) &&
-               Objects.equals(timeZone, other.timeZone) &&
-               Objects.equals(includeLower, other.includeLower) &&
-               Objects.equals(includeUpper, other.includeUpper) &&
-               Objects.equals(format, other.format);
+    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(RangeQueryParser.NAME);
+        builder.startObject(name);
+        builder.field("from", from);
+        builder.field("to", to);
+        if (timeZone != null) {
+            builder.field("time_zone", timeZone);
+        }
+        if (format != null) {
+            builder.field("format", format);
+        }
+        builder.field("include_lower", includeLower);
+        builder.field("include_upper", includeUpper);
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
+        builder.endObject();
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/RangeQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/RangeQueryParser.java
index d10f6b0..355f9f2 100644
--- a/core/src/main/java/org/elasticsearch/index/query/RangeQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/RangeQueryParser.java
@@ -19,17 +19,26 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.TermRangeQuery;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.joda.DateMathParser;
+import org.elasticsearch.common.joda.Joda;
+import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.mapper.core.DateFieldMapper;
+import org.joda.time.DateTimeZone;
 
 import java.io.IOException;
 
 /**
- * Parser for range query
+ *
  */
-public class RangeQueryParser extends BaseQueryParser<RangeQueryBuilder> {
+public class RangeQueryParser implements QueryParser {
 
+    public static final String NAME = "range";
     private static final ParseField FIELDDATA_FIELD = new ParseField("fielddata").withAllDeprecated("[no replacement]");
     private static final ParseField NAME_FIELD = new ParseField("_name").withAllDeprecated("query name is not supported in short version of range query");
 
@@ -39,22 +48,22 @@ public class RangeQueryParser extends BaseQueryParser<RangeQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{RangeQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public RangeQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldName = null;
         Object from = null;
         Object to = null;
-        boolean includeLower = RangeQueryBuilder.DEFAULT_INCLUDE_LOWER;
-        boolean includeUpper = RangeQueryBuilder.DEFAULT_INCLUDE_UPPER;
-        String timeZone = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        boolean includeLower = true;
+        boolean includeUpper = true;
+        DateTimeZone timeZone = null;
+        DateMathParser forcedDateParser = null;
+        float boost = 1.0f;
         String queryName = null;
-        String format = null;
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -92,11 +101,9 @@ public class RangeQueryParser extends BaseQueryParser<RangeQueryBuilder> {
                             to = parser.objectBytes();
                             includeUpper = true;
                         } else if ("time_zone".equals(currentFieldName) || "timeZone".equals(currentFieldName)) {
-                            timeZone = parser.text();
+                            timeZone = DateTimeZone.forID(parser.text());
                         } else if ("format".equals(currentFieldName)) {
-                            format = parser.text();
-                        } else if ("_name".equals(currentFieldName)) {
-                            queryName = parser.text();
+                            forcedDateParser = new DateMathParser(Joda.forPattern(parser.text()));
                         } else {
                             throw new QueryParsingException(parseContext, "[range] query does not support [" + currentFieldName + "]");
                         }
@@ -113,20 +120,27 @@ public class RangeQueryParser extends BaseQueryParser<RangeQueryBuilder> {
             }
         }
 
-        RangeQueryBuilder rangeQuery = new RangeQueryBuilder(fieldName);
-        rangeQuery.from(from);
-        rangeQuery.to(to);
-        rangeQuery.includeLower(includeLower);
-        rangeQuery.includeUpper(includeUpper);
-        rangeQuery.timeZone(timeZone);
-        rangeQuery.boost(boost);
-        rangeQuery.queryName(queryName);
-        rangeQuery.format(format);
-        return rangeQuery;
-    }
-
-    @Override
-    public RangeQueryBuilder getBuilderPrototype() {
-        return RangeQueryBuilder.PROTOTYPE;
+        Query query = null;
+        MappedFieldType mapper = parseContext.fieldMapper(fieldName);
+        if (mapper != null) {
+            if (mapper instanceof DateFieldMapper.DateFieldType) {
+                query = ((DateFieldMapper.DateFieldType) mapper).rangeQuery(from, to, includeLower, includeUpper, timeZone, forcedDateParser);
+            } else  {
+                if (timeZone != null) {
+                    throw new QueryParsingException(parseContext, "[range] time_zone can not be applied to non date field ["
+                            + fieldName + "]");
+                }
+                //LUCENE 4 UPGRADE Mapper#rangeQuery should use bytesref as well?
+                query = mapper.rangeQuery(from, to, includeLower, includeUpper);
+            }
+        }
+        if (query == null) {
+            query = new TermRangeQuery(fieldName, BytesRefs.toBytesRef(from), BytesRefs.toBytesRef(to), includeLower, includeUpper);
+        }
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/RegexpQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/RegexpQueryBuilder.java
index 6399089..ee143eb 100644
--- a/core/src/main/java/org/elasticsearch/index/query/RegexpQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/RegexpQueryBuilder.java
@@ -19,73 +19,48 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.RegexpQuery;
 import org.apache.lucene.util.automaton.Operations;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * A Query that does fuzzy matching for a specific value.
  */
-public class RegexpQueryBuilder extends AbstractQueryBuilder<RegexpQueryBuilder> implements MultiTermQueryBuilder<RegexpQueryBuilder> {
+public class RegexpQueryBuilder extends MultiTermQueryBuilder implements BoostableQueryBuilder<RegexpQueryBuilder> {
 
-    public static final String NAME = "regexp";
+    private final String name;
+    private final String regexp;
 
-    public static final int DEFAULT_FLAGS_VALUE = RegexpFlag.ALL.value();
-
-    public static final int DEFAULT_MAX_DETERMINIZED_STATES = Operations.DEFAULT_MAX_DETERMINIZED_STATES;
-
-    private final String fieldName;
-    
-    private final String value;
-    
-    private int flagsValue = DEFAULT_FLAGS_VALUE;
-    
-    private int maxDeterminizedStates = DEFAULT_MAX_DETERMINIZED_STATES;
-    
+    private int flags = RegexpQueryParser.DEFAULT_FLAGS_VALUE;
+    private float boost = -1;
     private String rewrite;
-    
-    static final RegexpQueryBuilder PROTOTYPE = new RegexpQueryBuilder(null, null);
+    private String queryName;
+    private int maxDeterminizedStates = Operations.DEFAULT_MAX_DETERMINIZED_STATES;
+    private boolean maxDetermizedStatesSet;
 
     /**
-     * Constructs a new regex query.
-     * 
-     * @param fieldName  The name of the field
-     * @param value The regular expression
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param regexp The regular expression
      */
-    public RegexpQueryBuilder(String fieldName, String value) {
-        this.fieldName = fieldName;
-        this.value = value;
-    }
-
-    /** Returns the field name used in this query. */
-    public String fieldName() {
-        return this.fieldName;
+    public RegexpQueryBuilder(String name, String regexp) {
+        this.name = name;
+        this.regexp = regexp;
     }
 
     /**
-     *  Returns the value used in this query.
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
      */
-    public String value() {
-        return this.value;
+    @Override
+    public RegexpQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     public RegexpQueryBuilder flags(RegexpFlag... flags) {
-        if (flags == null) {
-            this.flagsValue = DEFAULT_FLAGS_VALUE;
-            return this;
-        }
         int value = 0;
         if (flags.length == 0) {
             value = RegexpFlag.ALL.value;
@@ -94,120 +69,53 @@ public class RegexpQueryBuilder extends AbstractQueryBuilder<RegexpQueryBuilder>
                 value |= flag.value;
             }
         }
-        this.flagsValue = value;
-        return this;
-    }
-
-    public RegexpQueryBuilder flags(int flags) {
-        this.flagsValue = flags;
+        this.flags = value;
         return this;
     }
 
-    public int flags() {
-        return this.flagsValue;
-    }
-
     /**
      * Sets the regexp maxDeterminizedStates.
      */
     public RegexpQueryBuilder maxDeterminizedStates(int value) {
         this.maxDeterminizedStates = value;
+        this.maxDetermizedStatesSet = true;
         return this;
     }
-    
-    public int maxDeterminizedStates() {
-        return this.maxDeterminizedStates;
-    }
 
     public RegexpQueryBuilder rewrite(String rewrite) {
         this.rewrite = rewrite;
         return this;
     }
-    
-    public String rewrite() {
-        return this.rewrite;
+
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public RegexpQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     public void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.startObject(fieldName);
-        builder.field("value", this.value);
-        builder.field("flags_value", flagsValue);
-        builder.field("max_determinized_states", maxDeterminizedStates);
-        if (rewrite != null) {
-            builder.field("rewrite", rewrite);
+        builder.startObject(RegexpQueryParser.NAME);
+        builder.startObject(name);
+        builder.field("value", regexp);
+        if (flags != -1) {
+            builder.field("flags_value", flags);
         }
-        printBoostAndQueryName(builder);
-        builder.endObject();
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    public Query doToQuery(QueryShardContext context) throws QueryShardException, IOException {
-        MultiTermQuery.RewriteMethod method = QueryParsers.parseRewriteMethod(context.parseFieldMatcher(), rewrite, null);
-
-        Query query = null;
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType != null) {
-            query = fieldType.regexpQuery(value, flagsValue, maxDeterminizedStates, method, context);
+        if (maxDetermizedStatesSet) {
+            builder.field("max_determinized_states", maxDeterminizedStates);
         }
-        if (query == null) {
-            RegexpQuery regexpQuery = new RegexpQuery(new Term(fieldName, BytesRefs.toBytesRef(value)), flagsValue, maxDeterminizedStates);
-            if (method != null) {
-                regexpQuery.setRewriteMethod(method);
-            }
-            query = regexpQuery;
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        return query;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (Strings.isEmpty(this.fieldName)) {
-            validationException = addValidationError("field name cannot be null or empty.", validationException);
+        if (rewrite != null) {
+            builder.field("rewrite", rewrite);
         }
-        if (this.value == null) {
-            validationException = addValidationError("query text cannot be null", validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return validationException;
-    }
-
-    @Override
-    public RegexpQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        RegexpQueryBuilder regexpQueryBuilder = new RegexpQueryBuilder(in.readString(), in.readString());
-        regexpQueryBuilder.flagsValue = in.readVInt();
-        regexpQueryBuilder.maxDeterminizedStates = in.readVInt();
-        regexpQueryBuilder.rewrite = in.readOptionalString();
-        return regexpQueryBuilder;
-    }
-
-    @Override
-    public void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-        out.writeString(value);
-        out.writeVInt(flagsValue);
-        out.writeVInt(maxDeterminizedStates);
-        out.writeOptionalString(rewrite);
-    }
-
-    @Override
-    public int doHashCode() {
-        return Objects.hash(fieldName, value, flagsValue, maxDeterminizedStates, rewrite);
-    }
-
-    @Override
-    public boolean doEquals(RegexpQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-                Objects.equals(value, other.value) &&
-                Objects.equals(flagsValue, other.flagsValue) &&
-                Objects.equals(maxDeterminizedStates, other.maxDeterminizedStates) &&
-                Objects.equals(rewrite, other.rewrite);
+        builder.endObject();
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/RegexpQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/RegexpQueryParser.java
index 66fd44a..5844c17 100644
--- a/core/src/main/java/org/elasticsearch/index/query/RegexpQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/RegexpQueryParser.java
@@ -19,16 +19,28 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.MultiTermQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.RegexpQuery;
+import org.apache.lucene.util.automaton.Operations;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
 
 /**
- * Parser for regexp query
+ *
  */
-public class RegexpQueryParser extends BaseQueryParser<RegexpQueryBuilder> {
+public class RegexpQueryParser implements QueryParser {
+
+    public static final String NAME = "regexp";
+
+    public static final int DEFAULT_FLAGS_VALUE = RegexpFlag.ALL.value();
 
     private static final ParseField NAME_FIELD = new ParseField("_name").withAllDeprecated("query name is not supported in short version of regexp query");
 
@@ -38,20 +50,20 @@ public class RegexpQueryParser extends BaseQueryParser<RegexpQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{RegexpQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public RegexpQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldName = parser.currentName();
-        String rewrite = null;
+        String rewriteMethod = null;
 
         String value = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        int flagsValue = RegexpQueryBuilder.DEFAULT_FLAGS_VALUE;
-        int maxDeterminizedStates = RegexpQueryBuilder.DEFAULT_MAX_DETERMINIZED_STATES;
+        float boost = 1.0f;
+        int flagsValue = DEFAULT_FLAGS_VALUE;
+        int maxDeterminizedStates = Operations.DEFAULT_MAX_DETERMINIZED_STATES;
         String queryName = null;
         String currentFieldName = null;
         XContentParser.Token token;
@@ -71,7 +83,7 @@ public class RegexpQueryParser extends BaseQueryParser<RegexpQueryBuilder> {
                         } else if ("boost".equals(currentFieldName)) {
                             boost = parser.floatValue();
                         } else if ("rewrite".equals(currentFieldName)) {
-                            rewrite = parser.textOrNull();
+                            rewriteMethod = parser.textOrNull();
                         } else if ("flags".equals(currentFieldName)) {
                             String flags = parser.textOrNull();
                             flagsValue = RegexpFlag.resolveValue(flags);
@@ -99,16 +111,27 @@ public class RegexpQueryParser extends BaseQueryParser<RegexpQueryBuilder> {
         if (value == null) {
             throw new QueryParsingException(parseContext, "No value specified for regexp query");
         }
-        return new RegexpQueryBuilder(fieldName, value)
-                .flags(flagsValue)
-                .maxDeterminizedStates(maxDeterminizedStates)
-                .rewrite(rewrite)
-                .boost(boost)
-                .queryName(queryName);
-    }
 
-    @Override
-    public RegexpQueryBuilder getBuilderPrototype() {
-        return RegexpQueryBuilder.PROTOTYPE;
+        MultiTermQuery.RewriteMethod method = QueryParsers.parseRewriteMethod(parseContext.parseFieldMatcher(), rewriteMethod, null);
+
+        Query query = null;
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            query = fieldType.regexpQuery(value, flagsValue, maxDeterminizedStates, method, parseContext);
+        }
+        if (query == null) {
+            RegexpQuery regexpQuery = new RegexpQuery(new Term(fieldName, BytesRefs.toBytesRef(value)), flagsValue, maxDeterminizedStates);
+            if (method != null) {
+                regexpQuery.setRewriteMethod(method);
+            }
+            query = regexpQuery;
+        }
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
+
+
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/ScoreType.java b/core/src/main/java/org/elasticsearch/index/query/ScoreType.java
deleted file mode 100644
index 6286a9d..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/ScoreType.java
+++ /dev/null
@@ -1,71 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.query;
-
-
-/**
- * Defines how scores from child documents are mapped into the parent document.
- */
-public enum ScoreType {
-    /**
-     * Only the lowest score of all matching child documents is mapped into the
-     * parent.
-     */
-    MIN,
-    /**
-     * Only the highest score of all matching child documents is mapped into the
-     * parent.
-     */
-    MAX,
-
-    /**
-     * The average score based on all matching child documents are mapped into
-     * the parent.
-     */
-    AVG,
-
-    /**
-     * The matching children scores is summed up and mapped into the parent.
-     */
-    SUM,
-
-    /**
-     * Scores are not taken into account
-     */
-    NONE;
-
-
-    public static ScoreType fromString(String type) {
-        if ("none".equals(type)) {
-            return NONE;
-        } else if ("min".equals(type)) {
-            return MIN;
-        } else if ("max".equals(type)) {
-            return MAX;
-        } else if ("avg".equals(type)) {
-            return AVG;
-        } else if ("sum".equals(type)) {
-            return SUM;
-        } else if ("total".equals(type)) { // This name is consistent with: ScoreMode.Total
-            return SUM;
-        }
-        throw new IllegalArgumentException("No score type for child query [" + type + "] found");
-    }
-
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/ScriptQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/ScriptQueryBuilder.java
index 519f065..a9a35ac 100644
--- a/core/src/main/java/org/elasticsearch/index/query/ScriptQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/ScriptQueryBuilder.java
@@ -19,155 +19,40 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.RandomAccessWeight;
-import org.apache.lucene.search.Weight;
-import org.apache.lucene.util.Bits;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.script.*;
+import org.elasticsearch.script.Script;
 import org.elasticsearch.script.Script.ScriptField;
-import org.elasticsearch.search.lookup.SearchLookup;
 
 import java.io.IOException;
-import java.util.Objects;
+import java.util.HashMap;
+import java.util.Map;
 
-public class ScriptQueryBuilder extends AbstractQueryBuilder<ScriptQueryBuilder> {
+public class ScriptQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "script";
+    private Script script;
 
-    static final ScriptQueryBuilder PROTOTYPE = new ScriptQueryBuilder(null);
-
-    private final Script script;
+    private String queryName;
 
     public ScriptQueryBuilder(Script script) {
         this.script = script;
     }
 
-    public Script script() {
-        return this.script;
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+    /**
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public ScriptQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params builderParams) throws IOException {
-        builder.startObject(NAME);
-        builder.field(ScriptField.SCRIPT.getPreferredName(), script);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        return new ScriptQuery(script, context.scriptService(), context.lookup());
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (this.script == null) {
-            validationException = addValidationError("script cannot be null", validationException);
-        }
-        return validationException;
-    }
-
-    static class ScriptQuery extends Query {
-
-        private final Script script;
-
-        private final SearchScript searchScript;
-
-        public ScriptQuery(Script script, ScriptService scriptService, SearchLookup searchLookup) {
-            this.script = script;
-            this.searchScript = scriptService.search(searchLookup, script, ScriptContext.Standard.SEARCH);
-        }
-
-        @Override
-        public String toString(String field) {
-            StringBuilder buffer = new StringBuilder();
-            buffer.append("ScriptFilter(");
-            buffer.append(script);
-            buffer.append(")");
-            return buffer.toString();
-        }
 
-        @Override
-        public boolean equals(Object obj) {
-            if (this == obj)
-                return true;
-            if (!super.equals(obj))
-                return false;
-            ScriptQuery other = (ScriptQuery) obj;
-            return Objects.equals(script, other.script);
-        }
-
-        @Override
-        public int hashCode() {
-            final int prime = 31;
-            int result = super.hashCode();
-            result = prime * result + Objects.hashCode(script);
-            return result;
-        }
-
-        @Override
-        public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
-            return new RandomAccessWeight(this) {
-                @Override
-                protected Bits getMatchingDocs(final LeafReaderContext context) throws IOException {
-                    final LeafSearchScript leafScript = searchScript.getLeafSearchScript(context);
-                    return new Bits() {
-
-                        @Override
-                        public boolean get(int doc) {
-                            leafScript.setDocument(doc);
-                            Object val = leafScript.run();
-                            if (val == null) {
-                                return false;
-                            }
-                            if (val instanceof Boolean) {
-                                return (Boolean) val;
-                            }
-                            if (val instanceof Number) {
-                                return ((Number) val).longValue() != 0;
-                            }
-                            throw new IllegalArgumentException("Can't handle type [" + val + "] in script filter");
-                        }
-
-                        @Override
-                        public int length() {
-                            return context.reader().maxDoc();
-                        }
-
-                    };
-                }
-            };
+        builder.startObject(ScriptQueryParser.NAME);
+        builder.field(ScriptField.SCRIPT.getPreferredName(), script);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-    }
-
-    @Override
-    protected ScriptQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new ScriptQueryBuilder(Script.readScript(in));
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        script.writeTo(out);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(script);
-    }
-
-    @Override
-    protected boolean doEquals(ScriptQueryBuilder other) {
-        return Objects.equals(script, other.script);
+        builder.endObject();
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/ScriptQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/ScriptQueryParser.java
index b37844e..43f6aed 100644
--- a/core/src/main/java/org/elasticsearch/index/query/ScriptQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/ScriptQueryParser.java
@@ -19,21 +19,35 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.RandomAccessWeight;
+import org.apache.lucene.search.Weight;
+import org.apache.lucene.util.Bits;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.script.LeafSearchScript;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.script.Script.ScriptField;
+import org.elasticsearch.script.ScriptContext;
 import org.elasticsearch.script.ScriptParameterParser;
 import org.elasticsearch.script.ScriptParameterParser.ScriptParameterValue;
+import org.elasticsearch.script.ScriptService;
+import org.elasticsearch.script.SearchScript;
+import org.elasticsearch.search.lookup.SearchLookup;
 
 import java.io.IOException;
 import java.util.HashMap;
 import java.util.Map;
+import java.util.Objects;
 
 /**
- * Parser for script query
+ *
  */
-public class ScriptQueryParser extends BaseQueryParser<ScriptQueryBuilder> {
+public class ScriptQueryParser implements QueryParser {
+
+    public static final String NAME = "script";
 
     @Inject
     public ScriptQueryParser() {
@@ -41,23 +55,23 @@ public class ScriptQueryParser extends BaseQueryParser<ScriptQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{ScriptQueryBuilder.NAME};
+        return new String[] { NAME };
     }
 
     @Override
-    public ScriptQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
         ScriptParameterParser scriptParameterParser = new ScriptParameterParser();
-        
+
+        XContentParser.Token token;
+
         // also, when caching, since its isCacheable is false, will result in loading all bit set...
         Script script = null;
         Map<String, Object> params = null;
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
         String queryName = null;
-
-        XContentParser.Token token;
         String currentFieldName = null;
+
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
@@ -74,8 +88,6 @@ public class ScriptQueryParser extends BaseQueryParser<ScriptQueryBuilder> {
             } else if (token.isValue()) {
                 if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else if (!scriptParameterParser.token(currentFieldName, token, parser, parseContext.parseFieldMatcher())) {
                     throw new QueryParsingException(parseContext, "[script] query does not support [" + currentFieldName + "]");
                 }
@@ -98,13 +110,83 @@ public class ScriptQueryParser extends BaseQueryParser<ScriptQueryBuilder> {
             throw new QueryParsingException(parseContext, "script must be provided with a [script] filter");
         }
 
-        return new ScriptQueryBuilder(script)
-                .boost(boost)
-                .queryName(queryName);
+        Query query = new ScriptQuery(script, parseContext.scriptService(), parseContext.lookup());
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 
-    @Override
-    public ScriptQueryBuilder getBuilderPrototype() {
-        return ScriptQueryBuilder.PROTOTYPE;
+    static class ScriptQuery extends Query {
+
+        private final Script script;
+
+        private final SearchScript searchScript;
+
+        public ScriptQuery(Script script, ScriptService scriptService, SearchLookup searchLookup) {
+            this.script = script;
+            this.searchScript = scriptService.search(searchLookup, script, ScriptContext.Standard.SEARCH);
+        }
+
+        @Override
+        public String toString(String field) {
+            StringBuilder buffer = new StringBuilder();
+            buffer.append("ScriptFilter(");
+            buffer.append(script);
+            buffer.append(")");
+            return buffer.toString();
+        }
+
+        @Override
+        public boolean equals(Object obj) {
+            if (this == obj)
+                return true;
+            if (!super.equals(obj))
+                return false;
+            ScriptQuery other = (ScriptQuery) obj;
+            return Objects.equals(script, other.script);
+        }
+
+        @Override
+        public int hashCode() {
+            final int prime = 31;
+            int result = super.hashCode();
+            result = prime * result + Objects.hashCode(script);
+            return result;
+        }
+
+        @Override
+        public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+            return new RandomAccessWeight(this) {
+                @Override
+                protected Bits getMatchingDocs(final LeafReaderContext context) throws IOException {
+                    final LeafSearchScript leafScript = searchScript.getLeafSearchScript(context);
+                    return new Bits() {
+
+                        @Override
+                        public boolean get(int doc) {
+                            leafScript.setDocument(doc);
+                            Object val = leafScript.run();
+                            if (val == null) {
+                                return false;
+                            }
+                            if (val instanceof Boolean) {
+                                return (Boolean) val;
+                            }
+                            if (val instanceof Number) {
+                                return ((Number) val).longValue() != 0;
+                            }
+                            throw new IllegalArgumentException("Can't handle type [" + val + "] in script filter");
+                        }
+
+                        @Override
+                        public int length() {
+                            return context.reader().maxDoc();
+                        }
+
+                    };
+                }
+            };
+        }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryParser.java
index f8b0dea..9ae0703 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryParser.java
@@ -29,7 +29,6 @@ import org.apache.lucene.util.BytesRef;
 import java.io.IOException;
 import java.util.Locale;
 import java.util.Map;
-import java.util.Objects;
 
 /**
  * Wrapper class for Lucene's SimpleQueryParser that allows us to redefine
@@ -202,102 +201,51 @@ public class SimpleQueryParser extends org.apache.lucene.queryparser.simple.Simp
             return new PrefixQuery(new Term(field, termStr));
         }
     }
+
     /**
      * Class encapsulating the settings for the SimpleQueryString query, with
      * their default values
      */
-    static class Settings {
-        /** Locale to use for parsing. */
-        private Locale locale = SimpleQueryStringBuilder.DEFAULT_LOCALE;
-        /** Specifies whether parsed terms should be lowercased. */
-        private boolean lowercaseExpandedTerms = SimpleQueryStringBuilder.DEFAULT_LOWERCASE_EXPANDED_TERMS;
-        /** Specifies whether lenient query parsing should be used. */
-        private boolean lenient = SimpleQueryStringBuilder.DEFAULT_LENIENT;
-        /** Specifies whether wildcards should be analyzed. */
-        private boolean analyzeWildcard = SimpleQueryStringBuilder.DEFAULT_ANALYZE_WILDCARD;
+    public static class Settings {
+        private Locale locale = Locale.ROOT;
+        private boolean lowercaseExpandedTerms = true;
+        private boolean lenient = false;
+        private boolean analyzeWildcard = false;
 
-        /**
-         * Generates default {@link Settings} object (uses ROOT locale, does
-         * lowercase terms, no lenient parsing, no wildcard analysis).
-         * */
         public Settings() {
-        }
 
-        public Settings(Locale locale, Boolean lowercaseExpandedTerms, Boolean lenient, Boolean analyzeWildcard) {
-            this.locale = locale;
-            this.lowercaseExpandedTerms = lowercaseExpandedTerms;
-            this.lenient = lenient;
-            this.analyzeWildcard = analyzeWildcard;
         }
 
-        /** Specifies the locale to use for parsing, Locale.ROOT by default. */
         public void locale(Locale locale) {
-            this.locale = (locale != null) ? locale : SimpleQueryStringBuilder.DEFAULT_LOCALE;
+            this.locale = locale;
         }
 
-        /** Returns the locale to use for parsing. */
         public Locale locale() {
             return this.locale;
         }
 
-        /**
-         * Specifies whether to lowercase parse terms, defaults to true if
-         * unset.
-         */
         public void lowercaseExpandedTerms(boolean lowercaseExpandedTerms) {
             this.lowercaseExpandedTerms = lowercaseExpandedTerms;
         }
 
-        /** Returns whether to lowercase parse terms. */
         public boolean lowercaseExpandedTerms() {
             return this.lowercaseExpandedTerms;
         }
 
-        /** Specifies whether to use lenient parsing, defaults to false. */
         public void lenient(boolean lenient) {
             this.lenient = lenient;
         }
 
-        /** Returns whether to use lenient parsing. */
         public boolean lenient() {
             return this.lenient;
         }
 
-        /** Specifies whether to analyze wildcards. Defaults to false if unset. */
         public void analyzeWildcard(boolean analyzeWildcard) {
             this.analyzeWildcard = analyzeWildcard;
         }
 
-        /** Returns whether to analyze wildcards. */
         public boolean analyzeWildcard() {
             return analyzeWildcard;
         }
-
-        @Override
-        public int hashCode() {
-            // checking the return value of toLanguageTag() for locales only.
-            // For further reasoning see
-            // https://issues.apache.org/jira/browse/LUCENE-4021
-            return Objects.hash(locale.toLanguageTag(), lowercaseExpandedTerms, lenient, analyzeWildcard);
-        }
-
-        @Override
-        public boolean equals(Object obj) {
-            if (this == obj) {
-                return true;
-            }
-            if (obj == null || getClass() != obj.getClass()) {
-                return false;
-            }
-            Settings other = (Settings) obj;
-
-            // checking the return value of toLanguageTag() for locales only.
-            // For further reasoning see
-            // https://issues.apache.org/jira/browse/LUCENE-4021
-            return (Objects.equals(locale.toLanguageTag(), other.locale.toLanguageTag())
-                    && Objects.equals(lowercaseExpandedTerms, other.lowercaseExpandedTerms) 
-                    && Objects.equals(lenient, other.lenient)
-                    && Objects.equals(analyzeWildcard, other.analyzeWildcard));
-        }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringBuilder.java
index 4f90097..700ad41 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringBuilder.java
@@ -19,393 +19,202 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
-import org.elasticsearch.common.regex.Regex;
+import org.elasticsearch.common.xcontent.ToXContent.Params;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.SimpleQueryParser.Settings;
 
 import java.io.IOException;
 import java.util.HashMap;
 import java.util.Locale;
 import java.util.Map;
-import java.util.Objects;
-import java.util.TreeMap;
 
 /**
- * SimpleQuery is a query parser that acts similar to a query_string query, but
- * won't throw exceptions for any weird string syntax.
- *
- * For more detailed explanation of the query string syntax see also the <a
- * href=
- * "https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-simple-query-string-query.html"
- * > online documentation</a>.
+ * SimpleQuery is a query parser that acts similar to a query_string
+ * query, but won't throw exceptions for any weird string syntax.
  */
-public class SimpleQueryStringBuilder extends AbstractQueryBuilder<SimpleQueryStringBuilder> {
-    /** Default locale used for parsing.*/
-    public static final Locale DEFAULT_LOCALE = Locale.ROOT;
-    /** Default for lowercasing parsed terms.*/
-    public static final boolean DEFAULT_LOWERCASE_EXPANDED_TERMS = true;
-    /** Default for using lenient query parsing.*/
-    public static final boolean DEFAULT_LENIENT = false;
-    /** Default for wildcard analysis.*/
-    public static final boolean DEFAULT_ANALYZE_WILDCARD = false;
-    /** Default for default operator to use for linking boolean clauses.*/
-    public static final Operator DEFAULT_OPERATOR = Operator.OR;
-    /** Default for search flags to use. */
-    public static final int DEFAULT_FLAGS = SimpleQueryStringFlag.ALL.value;
-    /** Name for (de-)serialization. */
-    public static final String NAME = "simple_query_string";
-
-    static final SimpleQueryStringBuilder PROTOTYPE = new SimpleQueryStringBuilder(null);
-
-    /** Query text to parse. */
-    private final String queryText;
-    /**
-     * Fields to query against. If left empty will query default field,
-     * currently _ALL. Uses a TreeMap to hold the fields so boolean clauses are
-     * always sorted in same order for generated Lucene query for easier
-     * testing.
-     *
-     * Can be changed back to HashMap once https://issues.apache.org/jira/browse/LUCENE-6305 is fixed.
-     */
-    private final Map<String, Float> fieldsAndWeights = new TreeMap<>();
-    /** If specified, analyzer to use to parse the query text, defaults to registered default in toQuery. */
+public class SimpleQueryStringBuilder extends QueryBuilder implements BoostableQueryBuilder<SimpleQueryStringBuilder> {
+    private Map<String, Float> fields = new HashMap<>();
     private String analyzer;
-    /** Default operator to use for linking boolean clauses. Defaults to OR according to docs. */
-    private Operator defaultOperator = DEFAULT_OPERATOR;
-    /** If result is a boolean query, minimumShouldMatch parameter to apply. Ignored otherwise. */
+    private Operator operator;
+    private final String queryText;
+    private String queryName;
     private String minimumShouldMatch;
-    /** Any search flags to be used, ALL by default. */
-    private int flags = DEFAULT_FLAGS;
+    private int flags = -1;
+    private float boost = -1.0f;
+    private Boolean lowercaseExpandedTerms;
+    private Boolean lenient;
+    private Boolean analyzeWildcard;
+    private Locale locale;
 
-    /** Further search settings needed by the ES specific query string parser only. */
-    private Settings settings = new Settings();
+    /**
+     * Operators for the default_operator
+     */
+    public static enum Operator {
+        AND,
+        OR
+    }
 
-    /** Construct a new simple query with this query string. */
-    public SimpleQueryStringBuilder(String queryText) {
-        this.queryText = queryText;
+    /**
+     * Construct a new simple query with the given text
+     */
+    public SimpleQueryStringBuilder(String text) {
+        this.queryText = text;
     }
 
-    /** Returns the text to parse the query from. */
-    public String value() {
-        return this.queryText;
+    /** Set the boost of this query. */
+    @Override
+    public SimpleQueryStringBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+    
+    /** Returns the boost of this query. */
+    public float boost() {
+        return this.boost;
     }
 
-    /** Add a field to run the query against. */
+    /**
+     * Add a field to run the query against
+     */
     public SimpleQueryStringBuilder field(String field) {
-        if (Strings.isEmpty(field)) {
-            throw new IllegalArgumentException("supplied field is null or empty.");
-        }
-        this.fieldsAndWeights.put(field, AbstractQueryBuilder.DEFAULT_BOOST);
+        this.fields.put(field, null);
         return this;
     }
 
-    /** Add a field to run the query against with a specific boost. */
+    /**
+     * Add a field to run the query against with a specific boost
+     */
     public SimpleQueryStringBuilder field(String field, float boost) {
-        if (Strings.isEmpty(field)) {
-            throw new IllegalArgumentException("supplied field is null or empty.");
-        }
-        this.fieldsAndWeights.put(field, boost);
+        this.fields.put(field, boost);
         return this;
     }
 
-    /** Add several fields to run the query against with a specific boost. */
-    public SimpleQueryStringBuilder fields(Map<String, Float> fields) {
-        this.fieldsAndWeights.putAll(fields);
+    /**
+     * Specify a name for the query
+     */
+    public SimpleQueryStringBuilder queryName(String name) {
+        this.queryName = name;
         return this;
     }
 
-    /** Returns the fields including their respective boosts to run the query against. */
-    public Map<String, Float> fields() {
-        return this.fieldsAndWeights;
-    }
-
-    /** Specify an analyzer to use for the query. */
+    /**
+     * Specify an analyzer to use for the query
+     */
     public SimpleQueryStringBuilder analyzer(String analyzer) {
         this.analyzer = analyzer;
         return this;
     }
 
-    /** Returns the analyzer to use for the query. */
-    public String analyzer() {
-        return this.analyzer;
-    }
-
     /**
      * Specify the default operator for the query. Defaults to "OR" if no
-     * operator is specified.
+     * operator is specified
      */
     public SimpleQueryStringBuilder defaultOperator(Operator defaultOperator) {
-        this.defaultOperator = (defaultOperator != null) ? defaultOperator : DEFAULT_OPERATOR;
+        this.operator = defaultOperator;
         return this;
     }
 
-    /** Returns the default operator for the query. */
-    public Operator defaultOperator() {
-        return this.defaultOperator;
-    }
-
     /**
-     * Specify the enabled features of the SimpleQueryString. Defaults to ALL if
-     * none are specified.
+     * Specify the enabled features of the SimpleQueryString.
      */
     public SimpleQueryStringBuilder flags(SimpleQueryStringFlag... flags) {
-        if (flags != null && flags.length > 0) {
-            int value = 0;
+        int value = 0;
+        if (flags.length == 0) {
+            value = SimpleQueryStringFlag.ALL.value;
+        } else {
             for (SimpleQueryStringFlag flag : flags) {
                 value |= flag.value;
             }
-            this.flags = value;
-        } else {
-            this.flags = DEFAULT_FLAGS;
         }
-
+        this.flags = value;
         return this;
     }
 
-    /** For testing and serialisation only. */
-    SimpleQueryStringBuilder flags(int flags) {
-        this.flags = flags;
-        return this;
-    }
-
-    /** For testing only: Return the flags set for this query. */
-    int flags() {
-        return this.flags;
-    }
-
-    /**
-     * Specifies whether parsed terms for this query should be lower-cased.
-     * Defaults to true if not set.
-     */
     public SimpleQueryStringBuilder lowercaseExpandedTerms(boolean lowercaseExpandedTerms) {
-        this.settings.lowercaseExpandedTerms(lowercaseExpandedTerms);
+        this.lowercaseExpandedTerms = lowercaseExpandedTerms;
         return this;
     }
 
-    /** Returns whether parsed terms should be lower cased for this query. */
-    public boolean lowercaseExpandedTerms() {
-        return this.settings.lowercaseExpandedTerms();
-    }
-
-    /** Specifies the locale for parsing terms. Defaults to ROOT if none is set. */
     public SimpleQueryStringBuilder locale(Locale locale) {
-        this.settings.locale(locale);
+        this.locale = locale;
         return this;
     }
 
-    /** Returns the locale for parsing terms for this query. */
-    public Locale locale() {
-        return this.settings.locale();
-    }
-
-    /** Specifies whether query parsing should be lenient. Defaults to false. */
     public SimpleQueryStringBuilder lenient(boolean lenient) {
-        this.settings.lenient(lenient);
+        this.lenient = lenient;
         return this;
     }
 
-    /** Returns whether query parsing should be lenient. */
-    public boolean lenient() {
-        return this.settings.lenient();
-    }
-
-    /** Specifies whether wildcards should be analyzed. Defaults to false. */
     public SimpleQueryStringBuilder analyzeWildcard(boolean analyzeWildcard) {
-        this.settings.analyzeWildcard(analyzeWildcard);
+        this.analyzeWildcard = analyzeWildcard;
         return this;
     }
 
-    /** Returns whether wildcards should by analyzed. */
-    public boolean analyzeWildcard() {
-        return this.settings.analyzeWildcard();
-    }
-
-    /**
-     * Specifies the minimumShouldMatch to apply to the resulting query should
-     * that be a Boolean query.
-     */
     public SimpleQueryStringBuilder minimumShouldMatch(String minimumShouldMatch) {
         this.minimumShouldMatch = minimumShouldMatch;
         return this;
     }
 
-    /**
-     * Returns the minimumShouldMatch to apply to the resulting query should
-     * that be a Boolean query.
-     */
-    public String minimumShouldMatch() {
-        return minimumShouldMatch;
-    }
-
-    /**
-     * {@inheritDoc}
-     *
-     * Checks that mandatory queryText is neither null nor empty.
-     * */
     @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        // Query text is required
-        if (queryText == null) {
-            validationException = addValidationError("query text missing", validationException);
-        }
+    public void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(SimpleQueryStringParser.NAME);
 
-        return validationException;
-    }
+        builder.field("query", queryText);
 
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        // field names in builder can have wildcards etc, need to resolve them here
-        Map<String, Float> resolvedFieldsAndWeights = new TreeMap<>();
-        // Use the default field if no fields specified
-        if (fieldsAndWeights.isEmpty()) {
-            resolvedFieldsAndWeights.put(resolveIndexName(context.defaultField(), context), AbstractQueryBuilder.DEFAULT_BOOST);
-        } else {
-            for (Map.Entry<String, Float> fieldEntry : fieldsAndWeights.entrySet()) {
-                if (Regex.isSimpleMatchPattern(fieldEntry.getKey())) {
-                    for (String fieldName : context.mapperService().simpleMatchToIndexNames(fieldEntry.getKey())) {
-                        resolvedFieldsAndWeights.put(fieldName, fieldEntry.getValue());
-                    }
+        if (fields.size() > 0) {
+            builder.startArray("fields");
+            for (Map.Entry<String, Float> entry : fields.entrySet()) {
+                String field = entry.getKey();
+                Float boost = entry.getValue();
+                if (boost != null) {
+                    builder.value(field + "^" + boost);
                 } else {
-                    resolvedFieldsAndWeights.put(resolveIndexName(fieldEntry.getKey(), context), fieldEntry.getValue());
+                    builder.value(field);
                 }
             }
+            builder.endArray();
         }
 
-        // Use standard analyzer by default if none specified
-        Analyzer luceneAnalyzer;
-        if (analyzer == null) {
-            luceneAnalyzer = context.mapperService().searchAnalyzer();
-        } else {
-            luceneAnalyzer = context.analysisService().analyzer(analyzer);
-            if (luceneAnalyzer == null) {
-                throw new QueryShardException(context, "[" + SimpleQueryStringBuilder.NAME + "] analyzer [" + analyzer
-                        + "] not found");
-            }
-
+        if (flags != -1) {
+            builder.field("flags", flags);
         }
 
-        SimpleQueryParser sqp = new SimpleQueryParser(luceneAnalyzer, resolvedFieldsAndWeights, flags, settings);
-        sqp.setDefaultOperator(defaultOperator.toBooleanClauseOccur());
-
-        Query query = sqp.parse(queryText);
-        if (minimumShouldMatch != null && query instanceof BooleanQuery) {
-            query = Queries.applyMinimumShouldMatch((BooleanQuery) query, minimumShouldMatch);
+        if (analyzer != null) {
+            builder.field("analyzer", analyzer);
         }
-        return query;
-    }
 
-    private static String resolveIndexName(String fieldName, QueryShardContext context) {
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType != null) {
-            return fieldType.names().indexName();
+        if (operator != null) {
+            builder.field("default_operator", operator.name().toLowerCase(Locale.ROOT));
         }
-        return fieldName;
-    }
 
-    @Override
-    protected void setFinalBoost(Query query) {
-        query.setBoost(boost * query.getBoost());
-    }
-
-    @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        if (lowercaseExpandedTerms != null) {
+            builder.field("lowercase_expanded_terms", lowercaseExpandedTerms);
+        }
 
-        builder.field("query", queryText);
+        if (lenient != null) {
+            builder.field("lenient", lenient);
+        }
 
-        if (fieldsAndWeights.size() > 0) {
-            builder.startArray("fields");
-            for (Map.Entry<String, Float> entry : fieldsAndWeights.entrySet()) {
-                builder.value(entry.getKey() + "^" + entry.getValue());
-            }
-            builder.endArray();
+        if (analyzeWildcard != null) {
+            builder.field("analyze_wildcard", analyzeWildcard);
         }
 
-        if (analyzer != null) {
-            builder.field("analyzer", analyzer);
+        if (locale != null) {
+            builder.field("locale", locale.toString());
         }
 
-        builder.field("flags", flags);
-        builder.field("default_operator", defaultOperator.name().toLowerCase(Locale.ROOT));
-        builder.field("lowercase_expanded_terms", settings.lowercaseExpandedTerms());
-        builder.field("lenient", settings.lenient());
-        builder.field("analyze_wildcard", settings.analyzeWildcard());
-        builder.field("locale", (settings.locale().toLanguageTag()));
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
 
         if (minimumShouldMatch != null) {
             builder.field("minimum_should_match", minimumShouldMatch);
         }
-
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected SimpleQueryStringBuilder doReadFrom(StreamInput in) throws IOException {
-        SimpleQueryStringBuilder result = new SimpleQueryStringBuilder(in.readString());
-        int size = in.readInt();
-        Map<String, Float> fields = new HashMap<>();
-        for (int i = 0; i < size; i++) {
-            String field = in.readString();
-            Float weight = in.readFloat();
-            fields.put(field, weight);
-        }
-        result.fieldsAndWeights.putAll(fields);
-        result.flags = in.readInt();
-        result.analyzer = in.readOptionalString();
-        result.defaultOperator = Operator.readOperatorFrom(in);
-        result.settings.lowercaseExpandedTerms(in.readBoolean());
-        result.settings.lenient(in.readBoolean());
-        result.settings.analyzeWildcard(in.readBoolean());
-        String localeStr = in.readString();
-        result.settings.locale(Locale.forLanguageTag(localeStr));
-        result.minimumShouldMatch = in.readOptionalString();
-        return result;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(queryText);
-        out.writeInt(fieldsAndWeights.size());
-        for (Map.Entry<String, Float> entry : fieldsAndWeights.entrySet()) {
-            out.writeString(entry.getKey());
-            out.writeFloat(entry.getValue());
+        
+        if (boost != -1.0f) {
+            builder.field("boost", boost);
         }
-        out.writeInt(flags);
-        out.writeOptionalString(analyzer);
-        defaultOperator.writeTo(out);
-        out.writeBoolean(settings.lowercaseExpandedTerms());
-        out.writeBoolean(settings.lenient());
-        out.writeBoolean(settings.analyzeWildcard());
-        out.writeString(settings.locale().toLanguageTag());
-        out.writeOptionalString(minimumShouldMatch);
-    }
 
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldsAndWeights, analyzer, defaultOperator, queryText, minimumShouldMatch, settings, flags);
+        builder.endObject();
     }
 
-    @Override
-    protected boolean doEquals(SimpleQueryStringBuilder other) {
-        return Objects.equals(fieldsAndWeights, other.fieldsAndWeights) && Objects.equals(analyzer, other.analyzer)
-                && Objects.equals(defaultOperator, other.defaultOperator) && Objects.equals(queryText, other.queryText)
-                && Objects.equals(minimumShouldMatch, other.minimumShouldMatch)
-                && Objects.equals(settings, other.settings) && (flags == other.flags);
-    }
 }
-
diff --git a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringFlag.java b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringFlag.java
index 68d19db..ce0ce88 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringFlag.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringFlag.java
@@ -71,7 +71,7 @@ public enum SimpleQueryStringFlag {
                         magic |= flag.value();
                 }
             } catch (IllegalArgumentException iae) {
-                throw new IllegalArgumentException("Unknown " + SimpleQueryStringBuilder.NAME + " flag [" + s + "]");
+                throw new IllegalArgumentException("Unknown " + SimpleQueryStringParser.NAME + " flag [" + s + "]");
             }
         }
         return magic;
diff --git a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringParser.java b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringParser.java
index 89f94ed..fa65e51 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringParser.java
@@ -19,12 +19,20 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
+import org.elasticsearch.common.regex.Regex;
+import org.elasticsearch.common.util.LocaleUtils;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
 
 import java.io.IOException;
+import java.util.Collections;
 import java.util.HashMap;
 import java.util.Locale;
 import java.util.Map;
@@ -60,7 +68,9 @@ import java.util.Map;
  * {@code fields} - fields to search, defaults to _all if not set, allows
  * boosting a field with ^n
  */
-public class SimpleQueryStringParser extends BaseQueryParser<SimpleQueryStringBuilder> {
+public class SimpleQueryStringParser implements QueryParser {
+
+    public static final String NAME = "simple_query_string";
 
     @Inject
     public SimpleQueryStringParser() {
@@ -69,26 +79,23 @@ public class SimpleQueryStringParser extends BaseQueryParser<SimpleQueryStringBu
 
     @Override
     public String[] names() {
-        return new String[]{SimpleQueryStringBuilder.NAME, Strings.toCamelCase(SimpleQueryStringBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SimpleQueryStringBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String currentFieldName = null;
         String queryBody = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f; 
         String queryName = null;
         String minimumShouldMatch = null;
-        Map<String, Float> fieldsAndWeights = new HashMap<>();
-        Operator defaultOperator = null;
-        String analyzerName = null;
-        int flags = SimpleQueryStringFlag.ALL.value();
-        boolean lenient = SimpleQueryStringBuilder.DEFAULT_LENIENT;
-        boolean lowercaseExpandedTerms = SimpleQueryStringBuilder.DEFAULT_LOWERCASE_EXPANDED_TERMS;
-        boolean analyzeWildcard = SimpleQueryStringBuilder.DEFAULT_ANALYZE_WILDCARD;
-        Locale locale = null;
+        Map<String, Float> fieldsAndWeights = null;
+        BooleanClause.Occur defaultOperator = null;
+        Analyzer analyzer = null;
+        int flags = -1;
+        SimpleQueryParser.Settings sqsSettings = new SimpleQueryParser.Settings();
 
         XContentParser.Token token;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -112,10 +119,26 @@ public class SimpleQueryStringParser extends BaseQueryParser<SimpleQueryStringBu
                         if (fField == null) {
                             fField = parser.text();
                         }
-                        fieldsAndWeights.put(fField, fBoost);
+
+                        if (fieldsAndWeights == null) {
+                            fieldsAndWeights = new HashMap<>();
+                        }
+
+                        if (Regex.isSimpleMatchPattern(fField)) {
+                            for (String fieldName : parseContext.mapperService().simpleMatchToIndexNames(fField)) {
+                                fieldsAndWeights.put(fieldName, fBoost);
+                            }
+                        } else {
+                            MappedFieldType fieldType = parseContext.fieldMapper(fField);
+                            if (fieldType != null) {
+                                fieldsAndWeights.put(fieldType.names().indexName(), fBoost);
+                            } else {
+                                fieldsAndWeights.put(fField, fBoost);
+                            }
+                        }
                     }
                 } else {
-                    throw new QueryParsingException(parseContext, "[" + SimpleQueryStringBuilder.NAME + "] query does not support [" + currentFieldName + "]");
+                    throw new QueryParsingException(parseContext, "[" + NAME + "] query does not support [" + currentFieldName + "]");
                 }
             } else if (token.isValue()) {
                 if ("query".equals(currentFieldName)) {
@@ -123,9 +146,19 @@ public class SimpleQueryStringParser extends BaseQueryParser<SimpleQueryStringBu
                 } else if ("boost".equals(currentFieldName)) {
                     boost = parser.floatValue();
                 } else if ("analyzer".equals(currentFieldName)) {
-                    analyzerName = parser.text();
+                    analyzer = parseContext.analysisService().analyzer(parser.text());
+                    if (analyzer == null) {
+                        throw new QueryParsingException(parseContext, "[" + NAME + "] analyzer [" + parser.text() + "] not found");
+                    }
                 } else if ("default_operator".equals(currentFieldName) || "defaultOperator".equals(currentFieldName)) {
-                    defaultOperator = Operator.fromString(parser.text());
+                    String op = parser.text();
+                    if ("or".equalsIgnoreCase(op)) {
+                        defaultOperator = BooleanClause.Occur.SHOULD;
+                    } else if ("and".equalsIgnoreCase(op)) {
+                        defaultOperator = BooleanClause.Occur.MUST;
+                    } else {
+                        throw new QueryParsingException(parseContext, "[" + NAME + "] default operator [" + op + "] is not allowed");
+                    }
                 } else if ("flags".equals(currentFieldName)) {
                     if (parser.currentToken() != XContentParser.Token.VALUE_NUMBER) {
                         // Possible options are:
@@ -139,37 +172,56 @@ public class SimpleQueryStringParser extends BaseQueryParser<SimpleQueryStringBu
                     }
                 } else if ("locale".equals(currentFieldName)) {
                     String localeStr = parser.text();
-                    locale = Locale.forLanguageTag(localeStr);
+                    Locale locale = LocaleUtils.parse(localeStr);
+                    sqsSettings.locale(locale);
                 } else if ("lowercase_expanded_terms".equals(currentFieldName)) {
-                    lowercaseExpandedTerms = parser.booleanValue();
+                    sqsSettings.lowercaseExpandedTerms(parser.booleanValue());
                 } else if ("lenient".equals(currentFieldName)) {
-                    lenient = parser.booleanValue();
+                    sqsSettings.lenient(parser.booleanValue());
                 } else if ("analyze_wildcard".equals(currentFieldName)) {
-                    analyzeWildcard = parser.booleanValue();
+                    sqsSettings.analyzeWildcard(parser.booleanValue());
                 } else if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
                 } else if ("minimum_should_match".equals(currentFieldName)) {
                     minimumShouldMatch = parser.textOrNull();
                 } else {
-                    throw new QueryParsingException(parseContext, "[" + SimpleQueryStringBuilder.NAME + "] unsupported field [" + parser.currentName() + "]");
+                    throw new QueryParsingException(parseContext, "[" + NAME + "] unsupported field [" + parser.currentName() + "]");
                 }
             }
         }
 
         // Query text is required
         if (queryBody == null) {
-            throw new QueryParsingException(parseContext, "[" + SimpleQueryStringBuilder.NAME + "] query text missing");
+            throw new QueryParsingException(parseContext, "[" + NAME + "] query text missing");
         }
 
-        SimpleQueryStringBuilder qb = new SimpleQueryStringBuilder(queryBody);
-        qb.boost(boost).fields(fieldsAndWeights).analyzer(analyzerName).queryName(queryName).minimumShouldMatch(minimumShouldMatch);
-        qb.flags(flags).defaultOperator(defaultOperator).locale(locale).lowercaseExpandedTerms(lowercaseExpandedTerms);
-        qb.lenient(lenient).analyzeWildcard(analyzeWildcard).boost(boost);
-        return qb;
-    }
+        // Use standard analyzer by default
+        if (analyzer == null) {
+            analyzer = parseContext.mapperService().searchAnalyzer();
+        }
 
-    @Override
-    public SimpleQueryStringBuilder getBuilderPrototype() {
-        return SimpleQueryStringBuilder.PROTOTYPE;
+        if (fieldsAndWeights == null) {
+            fieldsAndWeights = Collections.singletonMap(parseContext.defaultField(), 1.0F);
+        }
+        SimpleQueryParser sqp = new SimpleQueryParser(analyzer, fieldsAndWeights, flags, sqsSettings);
+
+        if (defaultOperator != null) {
+            sqp.setDefaultOperator(defaultOperator);
+        }
+
+        Query query = sqp.parse(queryBody);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+
+        if (minimumShouldMatch != null && query instanceof BooleanQuery) {
+            query = Queries.applyMinimumShouldMatch((BooleanQuery) query, minimumShouldMatch);
+        }
+
+        if (query != null) {
+            query.setBoost(boost * query.getBoost());
+        }
+
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryBuilder.java
index 1d55bbe..0b7a3cd 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryBuilder.java
@@ -19,119 +19,74 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanContainingQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * Builder for {@link org.apache.lucene.search.spans.SpanContainingQuery}.
  */
-public class SpanContainingQueryBuilder extends AbstractQueryBuilder<SpanContainingQueryBuilder> implements SpanQueryBuilder<SpanContainingQueryBuilder> {
+public class SpanContainingQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<SpanContainingQueryBuilder> {
 
-    public static final String NAME = "span_containing";
-    private final SpanQueryBuilder big;
-    private final SpanQueryBuilder little;
-    static final SpanContainingQueryBuilder PROTOTYPE = new SpanContainingQueryBuilder(null, null);
+    private SpanQueryBuilder big;
+    private SpanQueryBuilder little;
+    private float boost = -1;
+    private String queryName;
 
-    /**
-     * @param big the big clause, it must enclose {@code little} for a match.
-     * @param little the little clause, it must be contained within {@code big} for a match.
-     */
-    public SpanContainingQueryBuilder(SpanQueryBuilder big, SpanQueryBuilder little) {
-        this.little = little;
-        this.big = big;
-    }
-
-    /**
-     * @return the big clause, it must enclose {@code little} for a match.
+    /** 
+     * Sets the little clause, it must be contained within {@code big} for a match.
      */
-    public SpanQueryBuilder bigQuery() {
-        return this.big;
+    public SpanContainingQueryBuilder little(SpanQueryBuilder clause) {
+        this.little = clause;
+        return this;
     }
 
-    /**
-     * @return the little clause, it must be contained within {@code big} for a match.
+    /** 
+     * Sets the big clause, it must enclose {@code little} for a match.
      */
-    public SpanQueryBuilder littleQuery() {
-        return this.little;
+    public SpanContainingQueryBuilder big(SpanQueryBuilder clause) {
+        this.big = clause;
+        return this;
     }
 
     @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("big");
-        big.toXContent(builder, params);
-        builder.field("little");
-        little.toXContent(builder, params);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query innerBig = big.toQuery(context);
-        assert innerBig instanceof SpanQuery;
-        Query innerLittle = little.toQuery(context);
-        assert innerLittle instanceof SpanQuery;
-        return new SpanContainingQuery((SpanQuery) innerBig, (SpanQuery) innerLittle);
+    public SpanContainingQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
-    @Override
-    protected void setFinalBoost(Query query) {
-        if (boost != AbstractQueryBuilder.DEFAULT_BOOST) {
-            //preserve potential inner boost coming from lucene (default is big.boost)
-            query.setBoost(boost);
-        }
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public SpanContainingQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
+    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
         if (big == null) {
-            validationException = addValidationError("inner clause [big] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(big, validationException);
+            throw new IllegalArgumentException("Must specify big clause when building a span_containing query");
         }
         if (little == null) {
-            validationException = addValidationError("inner clause [little] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(little, validationException);
+            throw new IllegalArgumentException("Must specify little clause when building a span_containing query");
         }
-        return validationException;
-    }
+        builder.startObject(SpanContainingQueryParser.NAME);
 
-    @Override
-    protected SpanContainingQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        SpanQueryBuilder big = (SpanQueryBuilder)in.readQuery();
-        SpanQueryBuilder little = (SpanQueryBuilder)in.readQuery();
-        return new SpanContainingQueryBuilder(big, little);
-    }
+        builder.field("big");
+        big.toXContent(builder, params);
 
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(big);
-        out.writeQuery(little);
-    }
+        builder.field("little");
+        little.toXContent(builder, params);
 
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(big, little);
-    }
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
 
-    @Override
-    protected boolean doEquals(SpanContainingQueryBuilder other) {
-        return Objects.equals(big, other.big) &&
-               Objects.equals(little, other.little);
-    }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryParser.java
index affc853..e2dc813 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryParser.java
@@ -19,6 +19,9 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanContainingQuery;
+import org.apache.lucene.search.spans.SpanQuery;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
@@ -26,9 +29,11 @@ import org.elasticsearch.common.xcontent.XContentParser;
 import java.io.IOException;
 
 /**
- * Parser for span_containing query
+ * Parser for {@link SpanContainingQuery}
  */
-public class SpanContainingQueryParser extends BaseQueryParser<SpanContainingQueryBuilder> {
+public class SpanContainingQueryParser implements QueryParser {
+
+    public static final String NAME = "span_containing";
 
     @Inject
     public SpanContainingQueryParser() {
@@ -36,16 +41,17 @@ public class SpanContainingQueryParser extends BaseQueryParser<SpanContainingQue
 
     @Override
     public String[] names() {
-        return new String[]{SpanContainingQueryBuilder.NAME, Strings.toCamelCase(SpanContainingQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanContainingQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+
+        float boost = 1.0f;
         String queryName = null;
-        SpanQueryBuilder<?> big = null;
-        SpanQueryBuilder<?> little = null;
+        SpanQuery big = null;
+        SpanQuery little = null;
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -54,17 +60,17 @@ public class SpanContainingQueryParser extends BaseQueryParser<SpanContainingQue
                 currentFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("big".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (!(query instanceof SpanQueryBuilder<?>)) {
+                    Query query = parseContext.parseInnerQuery();
+                    if (!(query instanceof SpanQuery)) {
                         throw new QueryParsingException(parseContext, "span_containing [big] must be of type span query");
                     }
-                    big = (SpanQueryBuilder<?>) query;
+                    big = (SpanQuery) query;
                 } else if ("little".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (!(query instanceof SpanQueryBuilder<?>)) {
+                    Query query = parseContext.parseInnerQuery();
+                    if (!(query instanceof SpanQuery)) {
                         throw new QueryParsingException(parseContext, "span_containing [little] must be of type span query");
                     }
-                    little = (SpanQueryBuilder<?>) query;
+                    little = (SpanQuery) query;
                 } else {
                     throw new QueryParsingException(parseContext, "[span_containing] query does not support [" + currentFieldName + "]");
                 }
@@ -75,15 +81,22 @@ public class SpanContainingQueryParser extends BaseQueryParser<SpanContainingQue
             } else {
                 throw new QueryParsingException(parseContext, "[span_containing] query does not support [" + currentFieldName + "]");
             }
+        }        
+        
+        if (big == null) {
+            throw new QueryParsingException(parseContext, "span_containing must include [big]");
+        }
+        if (little == null) {
+            throw new QueryParsingException(parseContext, "span_containing must include [little]");
         }
 
-        SpanContainingQueryBuilder query = new SpanContainingQueryBuilder(big, little);
-        query.boost(boost).queryName(queryName);
+        Query query = new SpanContainingQuery(big, little);
+        if (boost != 1.0F) {
+            query.setBoost(boost);
+        }
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
         return query;
     }
-
-    @Override
-    public SpanContainingQueryBuilder getBuilderPrototype() {
-        return SpanContainingQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryBuilder.java
index a7c4572..f967a1c 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryBuilder.java
@@ -19,109 +19,51 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanFirstQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
-public class SpanFirstQueryBuilder extends AbstractQueryBuilder<SpanFirstQueryBuilder> implements SpanQueryBuilder<SpanFirstQueryBuilder>{
-
-    public static final String NAME = "span_first";
+public class SpanFirstQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<SpanFirstQueryBuilder> {
 
     private final SpanQueryBuilder matchBuilder;
 
     private final int end;
 
-    static final SpanFirstQueryBuilder PROTOTYPE = new SpanFirstQueryBuilder(null, -1);
+    private float boost = -1;
+
+    private String queryName;
 
-    /**
-     * Query that matches spans queries defined in <code>matchBuilder</code>
-     * whose end position is less than or equal to <code>end</code>.
-     * @param matchBuilder inner {@link SpanQueryBuilder}
-     * @param end maximum end position of the match, needs to be positive
-     * @throws IllegalArgumentException for negative <code>end</code> positions
-     */
     public SpanFirstQueryBuilder(SpanQueryBuilder matchBuilder, int end) {
         this.matchBuilder = matchBuilder;
         this.end = end;
     }
 
-    /**
-     * @return the inner {@link SpanQueryBuilder} defined in this query
-     */
-    public SpanQueryBuilder innerQuery() {
-        return this.matchBuilder;
+    @Override
+    public SpanFirstQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
-     * @return maximum end position of the matching inner span query
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public int end() {
-        return this.end;
+    public SpanFirstQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(SpanFirstQueryParser.NAME);
         builder.field("match");
         matchBuilder.toXContent(builder, params);
         builder.field("end", end);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query innerSpanQuery = matchBuilder.toQuery(context);
-        assert innerSpanQuery instanceof SpanQuery;
-        return new SpanFirstQuery((SpanQuery) innerSpanQuery, end);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (matchBuilder == null) {
-            validationException = addValidationError("inner clause [match] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(matchBuilder, validationException);
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        if (end < 0) {
-            validationException = addValidationError("parameter [end] needs to be positive.", validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return validationException;
-    }
-
-    @Override
-    protected SpanFirstQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        SpanQueryBuilder matchBuilder = (SpanQueryBuilder)in.readQuery();
-        int end = in.readInt();
-        return new SpanFirstQueryBuilder(matchBuilder, end);
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(matchBuilder);
-        out.writeInt(end);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(matchBuilder, end);
-    }
-
-    @Override
-    protected boolean doEquals(SpanFirstQueryBuilder other) {
-        return Objects.equals(matchBuilder, other.matchBuilder) &&
-               Objects.equals(end, other.end);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryParser.java
index 995bb4d..5a302eb 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryParser.java
@@ -19,6 +19,9 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanFirstQuery;
+import org.apache.lucene.search.spans.SpanQuery;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
@@ -26,9 +29,11 @@ import org.elasticsearch.common.xcontent.XContentParser;
 import java.io.IOException;
 
 /**
- * Parser for span_first query
+ *
  */
-public class SpanFirstQueryParser extends BaseQueryParser<SpanFirstQueryBuilder> {
+public class SpanFirstQueryParser implements QueryParser {
+
+    public static final String NAME = "span_first";
 
     @Inject
     public SpanFirstQueryParser() {
@@ -36,17 +41,17 @@ public class SpanFirstQueryParser extends BaseQueryParser<SpanFirstQueryBuilder>
 
     @Override
     public String[] names() {
-        return new String[]{SpanFirstQueryBuilder.NAME, Strings.toCamelCase(SpanFirstQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanFirstQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
 
-        SpanQueryBuilder match = null;
-        Integer end = null;
+        SpanQuery match = null;
+        int end = -1;
         String queryName = null;
 
         String currentFieldName = null;
@@ -56,11 +61,11 @@ public class SpanFirstQueryParser extends BaseQueryParser<SpanFirstQueryBuilder>
                 currentFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("match".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (!(query instanceof SpanQueryBuilder)) {
+                    Query query = parseContext.parseInnerQuery();
+                    if (!(query instanceof SpanQuery)) {
                         throw new QueryParsingException(parseContext, "spanFirst [match] must be of type span query");
                     }
-                    match = (SpanQueryBuilder) query;
+                    match = (SpanQuery) query;
                 } else {
                     throw new QueryParsingException(parseContext, "[span_first] query does not support [" + currentFieldName + "]");
                 }
@@ -79,16 +84,15 @@ public class SpanFirstQueryParser extends BaseQueryParser<SpanFirstQueryBuilder>
         if (match == null) {
             throw new QueryParsingException(parseContext, "spanFirst must have [match] span query clause");
         }
-        if (end == null) {
+        if (end == -1) {
             throw new QueryParsingException(parseContext, "spanFirst must have [end] set for it");
         }
-        SpanFirstQueryBuilder queryBuilder = new SpanFirstQueryBuilder(match, end);
-        queryBuilder.boost(boost).queryName(queryName);
-        return queryBuilder;
-    }
 
-    @Override
-    public SpanFirstQueryBuilder getBuilderPrototype() {
-        return SpanFirstQueryBuilder.PROTOTYPE;
+        SpanFirstQuery query = new SpanFirstQuery(match, end);
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilder.java
index a31b17e..11b9897 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilder.java
@@ -18,88 +18,25 @@
  */
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanMultiTermQueryWrapper;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
-/**
- * Query that allows wraping a {@link MultiTermQueryBuilder} (one of wildcard, fuzzy, prefix, term, range or regexp query)
- * as a {@link SpanQueryBuilder} so it can be nested.
- */
-public class SpanMultiTermQueryBuilder extends AbstractQueryBuilder<SpanMultiTermQueryBuilder> implements SpanQueryBuilder<SpanMultiTermQueryBuilder> {
+public class SpanMultiTermQueryBuilder extends SpanQueryBuilder {
 
-    public static final String NAME = "span_multi";
-    private final MultiTermQueryBuilder multiTermQueryBuilder;
-    static final SpanMultiTermQueryBuilder PROTOTYPE = new SpanMultiTermQueryBuilder(null);
+    private MultiTermQueryBuilder multiTermQueryBuilder;
 
     public SpanMultiTermQueryBuilder(MultiTermQueryBuilder multiTermQueryBuilder) {
         this.multiTermQueryBuilder = multiTermQueryBuilder;
     }
 
-    public MultiTermQueryBuilder innerQuery() {
-        return this.multiTermQueryBuilder;
-    }
-
     @Override
     protected void doXContent(XContentBuilder builder, Params params)
             throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(SpanMultiTermQueryParser.NAME);
         builder.field(SpanMultiTermQueryParser.MATCH_NAME);
         multiTermQueryBuilder.toXContent(builder, params);
-        printBoostAndQueryName(builder);
         builder.endObject();
     }
 
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query subQuery = multiTermQueryBuilder.toQuery(context);
-        if (subQuery instanceof MultiTermQuery == false) {
-            throw new UnsupportedOperationException("unsupported inner query, should be " + MultiTermQuery.class.getName() +" but was "
-                    + subQuery.getClass().getName());
-        }
-        return new SpanMultiTermQueryWrapper<>((MultiTermQuery) subQuery);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (multiTermQueryBuilder == null) {
-            validationException = addValidationError("inner clause ["+ SpanMultiTermQueryParser.MATCH_NAME +"] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(multiTermQueryBuilder, validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    protected SpanMultiTermQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        MultiTermQueryBuilder multiTermBuilder = (MultiTermQueryBuilder)in.readQuery();
-        return new SpanMultiTermQueryBuilder(multiTermBuilder);
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(multiTermQueryBuilder);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(multiTermQueryBuilder);
-    }
-
-    @Override
-    protected boolean doEquals(SpanMultiTermQueryBuilder other) {
-        return Objects.equals(multiTermQueryBuilder, other.multiTermQueryBuilder);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryParser.java
index 77e9def..a44580a 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryParser.java
@@ -18,17 +18,22 @@
  */
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.MultiTermQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanMultiTermQueryWrapper;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.common.xcontent.XContentParser.Token;
 
 import java.io.IOException;
 
 /**
- * Parser for span_multi query
+ *
  */
-public class SpanMultiTermQueryParser extends BaseQueryParser<SpanMultiTermQueryBuilder> {
+public class SpanMultiTermQueryParser implements QueryParser {
 
+    public static final String NAME = "span_multi";
     public static final String MATCH_NAME = "match";
 
     @Inject
@@ -37,50 +42,29 @@ public class SpanMultiTermQueryParser extends BaseQueryParser<SpanMultiTermQuery
 
     @Override
     public String[] names() {
-        return new String[]{SpanMultiTermQueryBuilder.NAME, Strings.toCamelCase(SpanMultiTermQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanMultiTermQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
-        String currentFieldName = null;
-        MultiTermQueryBuilder subQuery = null;
-        String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        XContentParser.Token token;
-        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
-            if (token == XContentParser.Token.FIELD_NAME) {
-                currentFieldName = parser.currentName();
-            } else if (token == XContentParser.Token.START_OBJECT) {
-                if (MATCH_NAME.equals(currentFieldName)) {
-                    QueryBuilder innerQuery = parseContext.parseInnerQueryBuilder();
-                    if (innerQuery instanceof MultiTermQueryBuilder == false) {
-                        throw new QueryParsingException(parseContext, "[span_multi] [" + MATCH_NAME + "] must be of type multi term query");
-                    }
-                    subQuery = (MultiTermQueryBuilder) innerQuery;
-                } else {
-                    throw new QueryParsingException(parseContext, "[span_multi] query does not support [" + currentFieldName + "]");
-                }
-            } else if (token.isValue()) {
-                if ("_name".equals(currentFieldName)) {
-                    queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
-                } else {
-                    throw new QueryParsingException(parseContext, "[span_multi] query does not support [" + currentFieldName + "]");
-                }
-            }
+
+        Token token = parser.nextToken();
+        if (!MATCH_NAME.equals(parser.currentName()) || token != XContentParser.Token.FIELD_NAME) {
+            throw new QueryParsingException(parseContext, "spanMultiTerm must have [" + MATCH_NAME + "] multi term query clause");
         }
 
-        if (subQuery == null) {
-            throw new QueryParsingException(parseContext, "[span_multi] must have [" + MATCH_NAME + "] multi term query clause");
+        token = parser.nextToken();
+        if (token != XContentParser.Token.START_OBJECT) {
+            throw new QueryParsingException(parseContext, "spanMultiTerm must have [" + MATCH_NAME + "] multi term query clause");
         }
 
-        return new SpanMultiTermQueryBuilder(subQuery).queryName(queryName).boost(boost);
-    }
+        Query subQuery = parseContext.parseInnerQuery();
+        if (!(subQuery instanceof MultiTermQuery)) {
+            throw new QueryParsingException(parseContext, "spanMultiTerm [" + MATCH_NAME + "] must be of type multi term query");
+        }
 
-    @Override
-    public SpanMultiTermQueryBuilder getBuilderPrototype() {
-        return SpanMultiTermQueryBuilder.PROTOTYPE;
+        parser.nextToken();
+        return new SpanMultiTermQueryWrapper<>((MultiTermQuery) subQuery);
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryBuilder.java
index e00cc32..cb05e08 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryBuilder.java
@@ -19,179 +19,86 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanNearQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.List;
-import java.util.Objects;
 
-/**
- * Matches spans which are near one another. One can specify slop, the maximum number
- * of intervening unmatched positions, as well as whether matches are required to be in-order.
- * The span near query maps to Lucene {@link SpanNearQuery}.
- */
-public class SpanNearQueryBuilder extends AbstractQueryBuilder<SpanNearQueryBuilder> implements SpanQueryBuilder<SpanNearQueryBuilder> {
-
-    public static final String NAME = "span_near";
-
-    /** Default for flag controlling whether matches are required to be in-order */
-    public static boolean DEFAULT_IN_ORDER = true;
-
-    /** Default for flag controlling whether payloads are collected */
-    public static boolean DEFAULT_COLLECT_PAYLOADS = true;
+public class SpanNearQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<SpanNearQueryBuilder> {
 
-    private final List<SpanQueryBuilder> clauses = new ArrayList<>();
+    private ArrayList<SpanQueryBuilder> clauses = new ArrayList<>();
 
-    private final int slop;
+    private Integer slop = null;
 
-    private boolean inOrder = DEFAULT_IN_ORDER;
+    private Boolean inOrder;
 
-    private boolean collectPayloads = DEFAULT_COLLECT_PAYLOADS;
+    private Boolean collectPayloads;
 
-    static final SpanNearQueryBuilder PROTOTYPE = new SpanNearQueryBuilder(0);
+    private float boost = -1;
 
-    /**
-     * @param slop controls the maximum number of intervening unmatched positions permitted
-     */
-    public SpanNearQueryBuilder(int slop) {
-        this.slop = slop;
-    }
-
-    /**
-     * @return the maximum number of intervening unmatched positions permitted
-     */
-    public int slop() {
-        return this.slop;
-    }
+    private String queryName;
 
     public SpanNearQueryBuilder clause(SpanQueryBuilder clause) {
         clauses.add(clause);
         return this;
     }
 
-    /**
-     * @return the {@link SpanQueryBuilder} clauses that were set for this query
-     */
-    public List<SpanQueryBuilder> clauses() {
-        return this.clauses;
+    public SpanNearQueryBuilder slop(int slop) {
+        this.slop = slop;
+        return this;
     }
 
-    /**
-     * When <code>inOrder</code> is true, the spans from each clause
-     * must be in the same order as in <code>clauses</code> and must be non-overlapping.
-     * Defaults to <code>true</code>
-     */
     public SpanNearQueryBuilder inOrder(boolean inOrder) {
         this.inOrder = inOrder;
         return this;
     }
 
-    /**
-     * @see SpanNearQueryBuilder#inOrder(boolean))
-     */
-    public boolean inOrder() {
-        return this.inOrder;
-    }
-
-    /**
-     * @param collectPayloads flag controlling whether payloads are collected
-     */
     public SpanNearQueryBuilder collectPayloads(boolean collectPayloads) {
         this.collectPayloads = collectPayloads;
         return this;
     }
 
+    @Override
+    public SpanNearQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
     /**
-     * @see SpanNearQueryBuilder#collectPayloads(boolean))
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public boolean collectPayloads() {
-        return this.collectPayloads;
+    public SpanNearQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        if (clauses.isEmpty()) {
+            throw new IllegalArgumentException("Must have at least one clause when building a spanNear query");
+        }
+        if (slop == null) {
+            throw new IllegalArgumentException("Must set the slop when building a spanNear query");
+        }
+        builder.startObject(SpanNearQueryParser.NAME);
         builder.startArray("clauses");
         for (SpanQueryBuilder clause : clauses) {
             clause.toXContent(builder, params);
         }
         builder.endArray();
-        builder.field("slop", slop);
-        builder.field("in_order", inOrder);
-        builder.field("collect_payloads", collectPayloads);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        SpanQuery[] spanQueries = new SpanQuery[clauses.size()];
-        for (int i = 0; i < clauses.size(); i++) {
-            Query query = clauses.get(i).toQuery(context);
-            assert query instanceof SpanQuery;
-            spanQueries[i] = (SpanQuery) query;
+        builder.field("slop", slop.intValue());
+        if (inOrder != null) {
+            builder.field("in_order", inOrder);
         }
-        return new SpanNearQuery(spanQueries, slop, inOrder, collectPayloads);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (clauses.isEmpty()) {
-            validationException =  addValidationError("query must include [clauses]", validationException);
+        if (collectPayloads != null) {
+            builder.field("collect_payloads", collectPayloads);
         }
-        for (SpanQueryBuilder innerClause : clauses) {
-            if (innerClause == null) {
-                validationException =  addValidationError("[clauses] contains null element", validationException);
-            } else {
-                validationException = validateInnerQuery(innerClause, validationException);
-            }
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        return validationException;
-    }
-
-    @Override
-    protected SpanNearQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        SpanNearQueryBuilder queryBuilder = new SpanNearQueryBuilder(in.readVInt());
-        List<QueryBuilder> clauses = readQueries(in);
-        for (QueryBuilder subClause : clauses) {
-            queryBuilder.clauses.add((SpanQueryBuilder)subClause);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        queryBuilder.collectPayloads = in.readBoolean();
-        queryBuilder.inOrder = in.readBoolean();
-        return queryBuilder;
-
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeVInt(slop);
-        writeQueries(out, clauses);
-        out.writeBoolean(collectPayloads);
-        out.writeBoolean(inOrder);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(clauses, slop, collectPayloads, inOrder);
-    }
-
-    @Override
-    protected boolean doEquals(SpanNearQueryBuilder other) {
-        return Objects.equals(clauses, other.clauses) &&
-               Objects.equals(slop, other.slop) &&
-               Objects.equals(collectPayloads, other.collectPayloads) &&
-               Objects.equals(inOrder, other.inOrder);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryParser.java
index cc6d8bc..506bce2 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryParser.java
@@ -19,6 +19,9 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanNearQuery;
+import org.apache.lucene.search.spans.SpanQuery;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
@@ -28,9 +31,11 @@ import java.util.ArrayList;
 import java.util.List;
 
 /**
- * Parser for span_near query
+ *
  */
-public class SpanNearQueryParser extends BaseQueryParser<SpanNearQueryBuilder> {
+public class SpanNearQueryParser implements QueryParser {
+
+    public static final String NAME = "span_near";
 
     @Inject
     public SpanNearQueryParser() {
@@ -38,20 +43,20 @@ public class SpanNearQueryParser extends BaseQueryParser<SpanNearQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{SpanNearQueryBuilder.NAME, Strings.toCamelCase(SpanNearQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanNearQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
         Integer slop = null;
-        boolean inOrder = SpanNearQueryBuilder.DEFAULT_IN_ORDER;
-        boolean collectPayloads = SpanNearQueryBuilder.DEFAULT_COLLECT_PAYLOADS;
+        boolean inOrder = true;
+        boolean collectPayloads = true;
         String queryName = null;
 
-        List<SpanQueryBuilder> clauses = new ArrayList<>();
+        List<SpanQuery> clauses = new ArrayList<>();
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -61,11 +66,11 @@ public class SpanNearQueryParser extends BaseQueryParser<SpanNearQueryBuilder> {
             } else if (token == XContentParser.Token.START_ARRAY) {
                 if ("clauses".equals(currentFieldName)) {
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                        QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                        if (!(query instanceof SpanQueryBuilder)) {
+                        Query query = parseContext.parseInnerQuery();
+                        if (!(query instanceof SpanQuery)) {
                             throw new QueryParsingException(parseContext, "spanNear [clauses] must be of type span query");
                         }
-                        clauses.add((SpanQueryBuilder) query);
+                        clauses.add((SpanQuery) query);
                     }
                 } else {
                     throw new QueryParsingException(parseContext, "[span_near] query does not support [" + currentFieldName + "]");
@@ -76,7 +81,7 @@ public class SpanNearQueryParser extends BaseQueryParser<SpanNearQueryBuilder> {
                 } else if ("collect_payloads".equals(currentFieldName) || "collectPayloads".equals(currentFieldName)) {
                     collectPayloads = parser.booleanValue();
                 } else if ("slop".equals(currentFieldName)) {
-                    slop = parser.intValue();
+                    slop = Integer.valueOf(parser.intValue());
                 } else if ("boost".equals(currentFieldName)) {
                     boost = parser.floatValue();
                 } else if ("_name".equals(currentFieldName)) {
@@ -88,24 +93,18 @@ public class SpanNearQueryParser extends BaseQueryParser<SpanNearQueryBuilder> {
                 throw new QueryParsingException(parseContext, "[span_near] query does not support [" + currentFieldName + "]");
             }
         }
-
+        if (clauses.isEmpty()) {
+            throw new QueryParsingException(parseContext, "span_near must include [clauses]");
+        }
         if (slop == null) {
             throw new QueryParsingException(parseContext, "span_near must include [slop]");
         }
 
-        SpanNearQueryBuilder queryBuilder = new SpanNearQueryBuilder(slop);
-        for (SpanQueryBuilder subQuery : clauses) {
-            queryBuilder.clause(subQuery);
+        SpanNearQuery query = new SpanNearQuery(clauses.toArray(new SpanQuery[clauses.size()]), slop.intValue(), inOrder, collectPayloads);
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
         }
-        queryBuilder.inOrder(inOrder);
-        queryBuilder.collectPayloads(collectPayloads);
-        queryBuilder.boost(boost);
-        queryBuilder.queryName(queryName);
-        return queryBuilder;
-    }
-
-    @Override
-    public SpanNearQueryBuilder getBuilderPrototype() {
-        return SpanNearQueryBuilder.PROTOTYPE;
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryBuilder.java
index 3af88e3..e37cd80 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryBuilder.java
@@ -19,176 +19,100 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanNotQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
-public class SpanNotQueryBuilder extends AbstractQueryBuilder<SpanNotQueryBuilder> implements SpanQueryBuilder<SpanNotQueryBuilder> {
+public class SpanNotQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<SpanNotQueryBuilder> {
 
-    public static final String NAME = "span_not";
+    private SpanQueryBuilder include;
 
-    /** the default pre parameter size */
-    public static final int DEFAULT_PRE = 0;
-    /** the default post parameter size */
-    public static final int DEFAULT_POST = 0;
+    private SpanQueryBuilder exclude;
 
-    private final SpanQueryBuilder include;
+    private Integer dist;
 
-    private final SpanQueryBuilder exclude;
+    private Integer pre;
 
-    private int pre = DEFAULT_PRE;
+    private Integer post;
 
-    private int post = DEFAULT_POST;
+    private Float boost;
 
-    static final SpanNotQueryBuilder PROTOTYPE = new SpanNotQueryBuilder(null, null);
+    private String queryName;
 
-    /**
-     * Construct a span query matching spans from <code>include</code> which
-     * have no overlap with spans from <code>exclude</code>.
-     * @param include the span query whose matches are filtered
-     * @param exclude the span query whose matches must not overlap
-     */
-    public SpanNotQueryBuilder(SpanQueryBuilder include, SpanQueryBuilder exclude) {
+    public SpanNotQueryBuilder include(SpanQueryBuilder include) {
         this.include = include;
-        this.exclude = exclude;
-    }
-
-    /**
-     * @return the span query whose matches are filtered
-     */
-    public SpanQueryBuilder includeQuery() {
-        return this.include;
+        return this;
     }
 
-    /**
-     * @return the span query whose matches must not overlap
-     */
-    public SpanQueryBuilder excludeQuery() {
-        return this.exclude;
+    public SpanNotQueryBuilder exclude(SpanQueryBuilder exclude) {
+        this.exclude = exclude;
+        return this;
     }
 
-    /**
-     * @param dist the amount of tokens from within the include span cant have overlap with the exclude span.
-     * Equivalent to setting both pre and post parameter.
-     */
     public SpanNotQueryBuilder dist(int dist) {
-        pre(dist);
-        post(dist);
+        this.dist = dist;
         return this;
     }
 
-    /**
-     * @param pre the amount of tokens before the include span that cant have overlap with the exclude span. Values
-     * smaller than 0 will be ignored and 0 used instead.
-     */
     public SpanNotQueryBuilder pre(int pre) {
-        this.pre = (pre >= 0) ? pre : 0;
+        this.pre = (pre >=0) ? pre : 0;
         return this;
     }
 
-    /**
-     * @return the amount of tokens before the include span that cant have overlap with the exclude span.
-     * @see SpanNotQueryBuilder#pre(int)
-     */
-    public Integer pre() {
-        return this.pre;
-    }
-
-    /**
-     * @param post the amount of tokens after the include span that cant have overlap with the exclude span.
-     */
     public SpanNotQueryBuilder post(int post) {
         this.post = (post >= 0) ? post : 0;
         return this;
     }
 
-    /**
-     * @return the amount of tokens after the include span that cant have overlap with the exclude span.
-     * @see SpanNotQueryBuilder#post(int)
-     */
-    public Integer post() {
-        return this.post;
-    }
-
     @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("include");
-        include.toXContent(builder, params);
-        builder.field("exclude");
-        exclude.toXContent(builder, params);
-        builder.field("pre", pre);
-        builder.field("post", post);
-        printBoostAndQueryName(builder);
-        builder.endObject();
+    public SpanNotQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-
-        Query includeQuery = this.include.toQuery(context);
-        assert includeQuery instanceof SpanQuery;
-        Query excludeQuery = this.exclude.toQuery(context);
-        assert excludeQuery instanceof SpanQuery;
-
-        return new SpanNotQuery((SpanQuery) includeQuery, (SpanQuery) excludeQuery, pre, post);
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     * @param queryName The query name
+     * @return this
+     */
+    public SpanNotQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
+    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
         if (include == null) {
-            validationException = addValidationError("inner clause [include] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(include, validationException);
+            throw new IllegalArgumentException("Must specify include when using spanNot query");
         }
         if (exclude == null) {
-            validationException = addValidationError("inner clause [exclude] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(exclude, validationException);
+            throw new IllegalArgumentException("Must specify exclude when using spanNot query");
         }
-        return validationException;
-    }
-
-    @Override
-    protected SpanNotQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        SpanQueryBuilder include = (SpanQueryBuilder)in.readQuery();
-        SpanQueryBuilder exclude = (SpanQueryBuilder)in.readQuery();
-        SpanNotQueryBuilder queryBuilder = new SpanNotQueryBuilder(include, exclude);
-        queryBuilder.pre(in.readVInt());
-        queryBuilder.post(in.readVInt());
-        return queryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(include);
-        out.writeQuery(exclude);
-        out.writeVInt(pre);
-        out.writeVInt(post);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(include, exclude, pre, post);
-    }
 
-    @Override
-    protected boolean doEquals(SpanNotQueryBuilder other) {
-        return Objects.equals(include, other.include) &&
-               Objects.equals(exclude, other.exclude) &&
-               (pre == other.pre) &&
-               (post == other.post);
-    }
+        if (dist != null && (pre != null || post != null)) {
+             throw new IllegalArgumentException("spanNot can either use [dist] or [pre] & [post] (or none)");
+        }
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.startObject(SpanNotQueryParser.NAME);
+        builder.field("include");
+        include.toXContent(builder, params);
+        builder.field("exclude");
+        exclude.toXContent(builder, params);
+        if (dist != null) {
+            builder.field("dist", dist);
+        }
+        if (pre != null) {
+            builder.field("pre", pre);
+        }
+        if (post != null) {
+            builder.field("post", post);
+        }
+        if (boost != null) {
+            builder.field("boost", boost);
+        }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryParser.java
index bc9ee51..bcb62e7 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryParser.java
@@ -19,6 +19,9 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanNotQuery;
+import org.apache.lucene.search.spans.SpanQuery;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
@@ -26,9 +29,11 @@ import org.elasticsearch.common.xcontent.XContentParser;
 import java.io.IOException;
 
 /**
- * Parser for span_not query
+ *
  */
-public class SpanNotQueryParser extends BaseQueryParser<SpanNotQueryBuilder> {
+public class SpanNotQueryParser implements QueryParser {
+
+    public static final String NAME = "span_not";
 
     @Inject
     public SpanNotQueryParser() {
@@ -36,17 +41,17 @@ public class SpanNotQueryParser extends BaseQueryParser<SpanNotQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{SpanNotQueryBuilder.NAME, Strings.toCamelCase(SpanNotQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanNotQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
 
-        SpanQueryBuilder include = null;
-        SpanQueryBuilder exclude = null;
+        SpanQuery include = null;
+        SpanQuery exclude = null;
 
         Integer dist = null;
         Integer pre  = null;
@@ -61,17 +66,17 @@ public class SpanNotQueryParser extends BaseQueryParser<SpanNotQueryBuilder> {
                 currentFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("include".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (!(query instanceof SpanQueryBuilder)) {
+                    Query query = parseContext.parseInnerQuery();
+                    if (!(query instanceof SpanQuery)) {
                         throw new QueryParsingException(parseContext, "spanNot [include] must be of type span query");
                     }
-                    include = (SpanQueryBuilder) query;
+                    include = (SpanQuery) query;
                 } else if ("exclude".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (!(query instanceof SpanQueryBuilder)) {
+                    Query query = parseContext.parseInnerQuery();
+                    if (!(query instanceof SpanQuery)) {
                         throw new QueryParsingException(parseContext, "spanNot [exclude] must be of type span query");
                     }
-                    exclude = (SpanQueryBuilder) query;
+                    exclude = (SpanQuery) query;
                 } else {
                     throw new QueryParsingException(parseContext, "[span_not] query does not support [" + currentFieldName + "]");
                 }
@@ -101,23 +106,26 @@ public class SpanNotQueryParser extends BaseQueryParser<SpanNotQueryBuilder> {
             throw new QueryParsingException(parseContext, "spanNot can either use [dist] or [pre] & [post] (or none)");
         }
 
-        SpanNotQueryBuilder spanNotQuery = new SpanNotQueryBuilder(include, exclude);
-        if (dist != null) {
-            spanNotQuery.dist(dist);
+        // set appropriate defaults
+        if (pre != null && post == null) {
+            post = 0;
+        } else if (pre == null && post != null){
+            pre = 0;
         }
-        if (pre != null) {
-            spanNotQuery.pre(pre);
-        }
-        if (post != null) {
-            spanNotQuery.post(post);
+
+        SpanNotQuery query;
+        if (pre != null && post != null) {
+            query = new SpanNotQuery(include, exclude, pre, post);
+        } else if (dist != null) {
+            query = new SpanNotQuery(include, exclude, dist);
+        } else {
+            query = new SpanNotQuery(include, exclude);
         }
-        spanNotQuery.boost(boost);
-        spanNotQuery.queryName(queryName);
-        return spanNotQuery;
-    }
 
-    @Override
-    public SpanNotQueryBuilder getBuilderPrototype() {
-        return SpanNotQueryBuilder.PROTOTYPE;
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryBuilder.java
index 8e9b7ae..0042aa7 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryBuilder.java
@@ -19,108 +19,55 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanOrQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.List;
-import java.util.Objects;
 
-/**
- * Span query that matches the union of its clauses. Maps to {@link SpanOrQuery}.
- */
-public class SpanOrQueryBuilder extends AbstractQueryBuilder<SpanOrQueryBuilder> implements SpanQueryBuilder<SpanOrQueryBuilder> {
+public class SpanOrQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<SpanOrQueryBuilder> {
 
-    public static final String NAME = "span_or";
+    private ArrayList<SpanQueryBuilder> clauses = new ArrayList<>();
 
-    private final List<SpanQueryBuilder> clauses = new ArrayList<>();
+    private float boost = -1;
 
-    static final SpanOrQueryBuilder PROTOTYPE = new SpanOrQueryBuilder();
+    private String queryName;
 
     public SpanOrQueryBuilder clause(SpanQueryBuilder clause) {
         clauses.add(clause);
         return this;
     }
 
+    @Override
+    public SpanOrQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
     /**
-     * @return the {@link SpanQueryBuilder} clauses that were set for this query
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public List<SpanQueryBuilder> clauses() {
-        return this.clauses;
+    public SpanOrQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        if (clauses.isEmpty()) {
+            throw new IllegalArgumentException("Must have at least one clause when building a spanOr query");
+        }
+        builder.startObject(SpanOrQueryParser.NAME);
         builder.startArray("clauses");
         for (SpanQueryBuilder clause : clauses) {
             clause.toXContent(builder, params);
         }
         builder.endArray();
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        SpanQuery[] spanQueries = new SpanQuery[clauses.size()];
-        for (int i = 0; i < clauses.size(); i++) {
-            Query query = clauses.get(i).toQuery(context);
-            assert query instanceof SpanQuery;
-            spanQueries[i] = (SpanQuery) query;
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        return new SpanOrQuery(spanQueries);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (clauses.isEmpty()) {
-            validationException =  addValidationError("query must include [clauses]", validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        for (SpanQueryBuilder innerClause : clauses) {
-            if (innerClause == null) {
-                validationException =  addValidationError("[clauses] contains null element", validationException);
-            } else {
-                validationException = validateInnerQuery(innerClause, validationException);
-            }
-        }
-        return validationException;
-    }
-
-    @Override
-    protected SpanOrQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        SpanOrQueryBuilder queryBuilder = new SpanOrQueryBuilder();
-        List<QueryBuilder> clauses = readQueries(in);
-        for (QueryBuilder subClause : clauses) {
-            queryBuilder.clauses.add((SpanQueryBuilder)subClause);
-        }
-        return queryBuilder;
-
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        writeQueries(out, clauses);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(clauses);
-    }
-
-    @Override
-    protected boolean doEquals(SpanOrQueryBuilder other) {
-        return Objects.equals(clauses, other.clauses);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryParser.java
index c424f66..e28a9cc 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryParser.java
@@ -19,7 +19,11 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanOrQuery;
+import org.apache.lucene.search.spans.SpanQuery;
 import org.elasticsearch.common.Strings;
+import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
@@ -27,23 +31,29 @@ import java.util.ArrayList;
 import java.util.List;
 
 /**
- * Parser for span_or query
+ *
  */
-public class SpanOrQueryParser extends BaseQueryParser<SpanOrQueryBuilder> {
+public class SpanOrQueryParser implements QueryParser {
+
+    public static final String NAME = "span_or";
+
+    @Inject
+    public SpanOrQueryParser() {
+    }
 
     @Override
     public String[] names() {
-        return new String[]{SpanOrQueryBuilder.NAME, Strings.toCamelCase(SpanOrQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanOrQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
         String queryName = null;
 
-        List<SpanQueryBuilder> clauses = new ArrayList<>();
+        List<SpanQuery> clauses = new ArrayList<>();
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -53,11 +63,11 @@ public class SpanOrQueryParser extends BaseQueryParser<SpanOrQueryBuilder> {
             } else if (token == XContentParser.Token.START_ARRAY) {
                 if ("clauses".equals(currentFieldName)) {
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                        QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                        if (!(query instanceof SpanQueryBuilder)) {
+                        Query query = parseContext.parseInnerQuery();
+                        if (!(query instanceof SpanQuery)) {
                             throw new QueryParsingException(parseContext, "spanOr [clauses] must be of type span query");
                         }
-                        clauses.add((SpanQueryBuilder) query);
+                        clauses.add((SpanQuery) query);
                     }
                 } else {
                     throw new QueryParsingException(parseContext, "[span_or] query does not support [" + currentFieldName + "]");
@@ -76,17 +86,11 @@ public class SpanOrQueryParser extends BaseQueryParser<SpanOrQueryBuilder> {
             throw new QueryParsingException(parseContext, "spanOr must include [clauses]");
         }
 
-        SpanOrQueryBuilder queryBuilder = new SpanOrQueryBuilder();
-        for (SpanQueryBuilder clause : clauses) {
-            queryBuilder.clause(clause);
+        SpanOrQuery query = new SpanOrQuery(clauses.toArray(new SpanQuery[clauses.size()]));
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
         }
-        queryBuilder.boost(boost);
-        queryBuilder.queryName(queryName);
-        return queryBuilder;
-    }
-
-    @Override
-    public SpanOrQueryBuilder getBuilderPrototype() {
-        return SpanOrQueryBuilder.PROTOTYPE;
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanQueryBuilder.java
index d35dcbc..4216f22 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanQueryBuilder.java
@@ -19,9 +19,6 @@
 
 package org.elasticsearch.index.query;
 
-/**
- * Marker interface for a specific type of {@link QueryBuilder} that allows to build span queries
- */
-public interface SpanQueryBuilder<QB extends SpanQueryBuilder> extends QueryBuilder<QB> {
+public abstract class SpanQueryBuilder extends QueryBuilder {
 
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryBuilder.java
index 24cd816..9d0176e 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryBuilder.java
@@ -19,76 +19,75 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.apache.lucene.search.spans.SpanTermQuery;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.lucene.BytesRefs;
-import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 
-/**
- * A Span Query that matches documents containing a term.
- * @see SpanTermQuery
- */
-public class SpanTermQueryBuilder extends BaseTermQueryBuilder<SpanTermQueryBuilder> implements SpanQueryBuilder<SpanTermQueryBuilder> {
+public class SpanTermQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<SpanTermQueryBuilder> {
+
+    private final String name;
+
+    private final Object value;
+
+    private float boost = -1;
 
-    public static final String NAME = "span_term";
-    static final SpanTermQueryBuilder PROTOTYPE = new SpanTermQueryBuilder(null, null);
+    private String queryName;
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, String) */
     public SpanTermQueryBuilder(String name, String value) {
-        super(name, (Object) value);
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, int) */
     public SpanTermQueryBuilder(String name, int value) {
-        super(name, (Object) value);
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, long) */
     public SpanTermQueryBuilder(String name, long value) {
-        super(name, (Object) value);
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, float) */
     public SpanTermQueryBuilder(String name, float value) {
-        super(name, (Object) value);
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, double) */
     public SpanTermQueryBuilder(String name, double value) {
-        super(name, (Object) value);
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, Object) */
-    public SpanTermQueryBuilder(String name, Object value) {
-        super(name, value);
+    private SpanTermQueryBuilder(String name, Object value) {
+        this.name = name;
+        this.value = value;
     }
 
     @Override
-    public SpanQuery doToQuery(QueryShardContext context) throws IOException {
-        BytesRef valueBytes = null;
-        String fieldName = this.fieldName;
-        MappedFieldType mapper = context.fieldMapper(fieldName);
-        if (mapper != null) {
-            fieldName = mapper.names().indexName();
-            valueBytes = mapper.indexedValueForSearch(value);
-        }
-        if (valueBytes == null) {
-            valueBytes = BytesRefs.toBytesRef(this.value);
-        }
-        return new SpanTermQuery(new Term(fieldName, valueBytes));
+    public SpanTermQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
-    @Override
-    protected SpanTermQueryBuilder createBuilder(String fieldName, Object value) {
-        return new SpanTermQueryBuilder(fieldName, value);
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public SpanTermQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
-    public String getWriteableName() {
-        return NAME;
+    public void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(SpanTermQueryParser.NAME);
+        if (boost == -1 && queryName != null) {
+            builder.field(name, value);
+        } else {
+            builder.startObject(name);
+            builder.field("value", value);
+            if (boost != -1) {
+                builder.field("boost", boost);
+            }
+            if (queryName != null) {
+                builder.field("_name", queryName);
+            }
+            builder.endObject();
+        }
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryParser.java
index 824b474..c4ff2ee 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryParser.java
@@ -19,16 +19,23 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanTermQuery;
+import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
 
 import java.io.IOException;
 
 /**
- * Parser for span_term query
+ *
  */
-public class SpanTermQueryParser extends BaseQueryParser<SpanTermQueryBuilder> {
+public class SpanTermQueryParser implements QueryParser {
+
+    public static final String NAME = "span_term";
 
     @Inject
     public SpanTermQueryParser() {
@@ -36,24 +43,23 @@ public class SpanTermQueryParser extends BaseQueryParser<SpanTermQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{SpanTermQueryBuilder.NAME, Strings.toCamelCase(SpanTermQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanTermQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         XContentParser.Token token = parser.currentToken();
         if (token == XContentParser.Token.START_OBJECT) {
             token = parser.nextToken();
         }
-
         assert token == XContentParser.Token.FIELD_NAME;
         String fieldName = parser.currentName();
 
 
-        Object value = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        String value = null;
+        float boost = 1.0f;
         String queryName = null;
         token = parser.nextToken();
         if (token == XContentParser.Token.START_OBJECT) {
@@ -63,9 +69,9 @@ public class SpanTermQueryParser extends BaseQueryParser<SpanTermQueryBuilder> {
                     currentFieldName = parser.currentName();
                 } else {
                     if ("term".equals(currentFieldName)) {
-                        value = parser.objectBytes();
+                        value = parser.text();
                     } else if ("value".equals(currentFieldName)) {
-                        value = parser.objectBytes();
+                        value = parser.text();
                     } else if ("boost".equals(currentFieldName)) {
                         boost = parser.floatValue();
                     } else if ("_name".equals(currentFieldName)) {
@@ -77,7 +83,7 @@ public class SpanTermQueryParser extends BaseQueryParser<SpanTermQueryBuilder> {
             }
             parser.nextToken();
         } else {
-            value = parser.objectBytes();
+            value = parser.text();
             // move to the next token
             parser.nextToken();
         }
@@ -86,13 +92,21 @@ public class SpanTermQueryParser extends BaseQueryParser<SpanTermQueryBuilder> {
             throw new QueryParsingException(parseContext, "No value specified for term query");
         }
 
-        SpanTermQueryBuilder result = new SpanTermQueryBuilder(fieldName, value);
-        result.boost(boost).queryName(queryName);
-        return result;
-    }
+        BytesRef valueBytes = null;
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            fieldName = fieldType.names().indexName();
+            valueBytes = fieldType.indexedValueForSearch(value);
+        }
+        if (valueBytes == null) {
+            valueBytes = new BytesRef(value);
+        }
 
-    @Override
-    public SpanTermQueryBuilder getBuilderPrototype() {
-        return SpanTermQueryBuilder.PROTOTYPE;
+        SpanTermQuery query = new SpanTermQuery(new Term(fieldName, valueBytes));
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryBuilder.java
index 8751a16..d2b2fdc 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryBuilder.java
@@ -19,53 +19,59 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.apache.lucene.search.spans.SpanWithinQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * Builder for {@link org.apache.lucene.search.spans.SpanWithinQuery}.
  */
-public class SpanWithinQueryBuilder extends AbstractQueryBuilder<SpanWithinQueryBuilder> implements SpanQueryBuilder<SpanWithinQueryBuilder> {
+public class SpanWithinQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<SpanWithinQueryBuilder> {
 
-    public static final String NAME = "span_within";
-    private final SpanQueryBuilder big;
-    private final SpanQueryBuilder little;
-    static final SpanWithinQueryBuilder PROTOTYPE = new SpanWithinQueryBuilder(null, null);
+    private SpanQueryBuilder big;
+    private SpanQueryBuilder little;
+    private float boost = -1;
+    private String queryName;
 
-    /**
-     * Query that returns spans from <code>little</code> that are contained in a spans from <code>big</code>.
-     * @param big clause that must enclose {@code little} for a match.
-     * @param little the little clause, it must be contained within {@code big} for a match.
+    /** 
+     * Sets the little clause, it must be contained within {@code big} for a match.
      */
-    public SpanWithinQueryBuilder(SpanQueryBuilder big, SpanQueryBuilder little) {
-        this.little = little;
-        this.big = big;
+    public SpanWithinQueryBuilder little(SpanQueryBuilder clause) {
+        this.little = clause;
+        return this;
     }
 
-    /**
-     * @return the little clause, contained within {@code big} for a match.
+    /** 
+     * Sets the big clause, it must enclose {@code little} for a match.
      */
-    public SpanQueryBuilder littleQuery() {
-        return this.little;
+    public SpanWithinQueryBuilder big(SpanQueryBuilder clause) {
+        this.big = clause;
+        return this;
+    }
+
+    @Override
+    public SpanWithinQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
-     * @return the big clause that must enclose {@code little} for a match.
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public SpanQueryBuilder bigQuery() {
-        return this.big;
+    public SpanWithinQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        if (big == null) {
+            throw new IllegalArgumentException("Must specify big clause when building a span_within query");
+        }
+        if (little == null) {
+            throw new IllegalArgumentException("Must specify little clause when building a span_within query");
+        }
+        builder.startObject(SpanWithinQueryParser.NAME);
 
         builder.field("big");
         big.toXContent(builder, params);
@@ -73,70 +79,14 @@ public class SpanWithinQueryBuilder extends AbstractQueryBuilder<SpanWithinQuery
         builder.field("little");
         little.toXContent(builder, params);
 
-        printBoostAndQueryName(builder);
-
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query innerBig = big.toQuery(context);
-        assert innerBig instanceof SpanQuery;
-        Query innerLittle = little.toQuery(context);
-        assert innerLittle instanceof SpanQuery;
-        return new SpanWithinQuery((SpanQuery) innerBig, (SpanQuery) innerLittle);
-    }
-
-    @Override
-    protected void setFinalBoost(Query query) {
-        if (boost != AbstractQueryBuilder.DEFAULT_BOOST) {
-            //preserve potential inner boost coming from lucene (default is little.boost)
-            query.setBoost(boost);
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-    }
 
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (big == null) {
-            validationException = addValidationError("inner clause [big] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(big, validationException);
-        }
-        if (little == null) {
-            validationException = addValidationError("inner clause [little] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(little, validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return validationException;
-    }
-
-    @Override
-    protected SpanWithinQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        SpanQueryBuilder big = (SpanQueryBuilder)in.readQuery();
-        SpanQueryBuilder little = (SpanQueryBuilder)in.readQuery();
-        return new SpanWithinQueryBuilder(big, little);
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(big);
-        out.writeQuery(little);
-    }
 
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(big, little);
-    }
-
-    @Override
-    protected boolean doEquals(SpanWithinQueryBuilder other) {
-        return Objects.equals(big, other.big) &&
-               Objects.equals(little, other.little);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryParser.java
index 00ddb0e..c801e0d 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryParser.java
@@ -19,6 +19,9 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanQuery;
+import org.apache.lucene.search.spans.SpanWithinQuery;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
@@ -26,9 +29,11 @@ import org.elasticsearch.common.xcontent.XContentParser;
 import java.io.IOException;
 
 /**
- * Parser for span_within query
+ * Parser for {@link SpanWithinQuery}
  */
-public class SpanWithinQueryParser extends BaseQueryParser<SpanWithinQueryBuilder> {
+public class SpanWithinQueryParser implements QueryParser {
+
+    public static final String NAME = "span_within";
 
     @Inject
     public SpanWithinQueryParser() {
@@ -36,17 +41,17 @@ public class SpanWithinQueryParser extends BaseQueryParser<SpanWithinQueryBuilde
 
     @Override
     public String[] names() {
-        return new String[]{SpanWithinQueryBuilder.NAME, Strings.toCamelCase(SpanWithinQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanWithinQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
         String queryName = null;
-        SpanQueryBuilder big = null;
-        SpanQueryBuilder little = null;
+        SpanQuery big = null;
+        SpanQuery little = null;
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -55,17 +60,17 @@ public class SpanWithinQueryParser extends BaseQueryParser<SpanWithinQueryBuilde
                 currentFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("big".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (query instanceof SpanQueryBuilder == false) {
+                    Query query = parseContext.parseInnerQuery();
+                    if (query instanceof SpanQuery == false) {
                         throw new QueryParsingException(parseContext, "span_within [big] must be of type span query");
                     }
-                    big = (SpanQueryBuilder) query;
+                    big = (SpanQuery) query;
                 } else if ("little".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (query instanceof SpanQueryBuilder == false) {
+                    Query query = parseContext.parseInnerQuery();
+                    if (query instanceof SpanQuery == false) {
                         throw new QueryParsingException(parseContext, "span_within [little] must be of type span query");
                     }
-                    little = (SpanQueryBuilder) query;
+                    little = (SpanQuery) query;
                 } else {
                     throw new QueryParsingException(parseContext, "[span_within] query does not support [" + currentFieldName + "]");
                 }
@@ -76,8 +81,8 @@ public class SpanWithinQueryParser extends BaseQueryParser<SpanWithinQueryBuilde
             } else {
                 throw new QueryParsingException(parseContext, "[span_within] query does not support [" + currentFieldName + "]");
             }
-        }
-
+        }        
+        
         if (big == null) {
             throw new QueryParsingException(parseContext, "span_within must include [big]");
         }
@@ -85,13 +90,13 @@ public class SpanWithinQueryParser extends BaseQueryParser<SpanWithinQueryBuilde
             throw new QueryParsingException(parseContext, "span_within must include [little]");
         }
 
-        SpanWithinQueryBuilder query = new SpanWithinQueryBuilder(big, little);
-        query.boost(boost).queryName(queryName);
+        Query query = new SpanWithinQuery(big, little);
+        if (boost != 1.0F) {
+            query.setBoost(boost);
+        }
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
         return query;
     }
-
-    @Override
-    public SpanWithinQueryBuilder getBuilderPrototype() {
-        return SpanWithinQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/TemplateQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/TemplateQueryBuilder.java
index 5c912de..852977f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TemplateQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TemplateQueryBuilder.java
@@ -18,33 +18,26 @@
  */
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.bytes.BytesReference;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.script.ScriptService;
 import org.elasticsearch.script.Template;
-import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
 import java.util.Map;
-import java.util.Objects;
 
 /**
  * Facilitates creating template query requests.
  * */
-public class TemplateQueryBuilder extends AbstractQueryBuilder<TemplateQueryBuilder> {
-
-    /** Name to reference this type of query. */
-    public static final String NAME = "template";
+public class TemplateQueryBuilder extends QueryBuilder {
 
     /** Template to fill. */
-    private final Template template;
+    private Template template;
+    /** Parameters to fill the template with. */
+    private Map<String, Object> vars;
+    /** Template to fill.*/
+    private String templateString;
 
-    static final TemplateQueryBuilder PROTOTYPE = new TemplateQueryBuilder(null);
+    private ScriptService.ScriptType templateType;
 
     /**
      * @param template
@@ -54,10 +47,6 @@ public class TemplateQueryBuilder extends AbstractQueryBuilder<TemplateQueryBuil
         this.template = template;
     }
 
-    public Template template() {
-        return template;
-    }
-
     /**
      * @param template
      *            the template to use for that query.
@@ -67,7 +56,7 @@ public class TemplateQueryBuilder extends AbstractQueryBuilder<TemplateQueryBuil
      * */
     @Deprecated
     public TemplateQueryBuilder(String template, Map<String, Object> vars) {
-        this(new Template(template, ScriptService.ScriptType.INLINE, null, null, vars));
+        this(template, ScriptService.ScriptType.INLINE, vars);
     }
 
     /**
@@ -81,64 +70,18 @@ public class TemplateQueryBuilder extends AbstractQueryBuilder<TemplateQueryBuil
      * */
     @Deprecated
     public TemplateQueryBuilder(String template, ScriptService.ScriptType templateType, Map<String, Object> vars) {
-        this(new Template(template, templateType, null, null, vars));
+        this.templateString = template;
+        this.vars = vars;
+        this.templateType = templateType;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params builderParams) throws IOException {
-        builder.field(TemplateQueryBuilder.NAME);
-        template.toXContent(builder, builderParams);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        BytesReference querySource = context.executeQueryTemplate(template, SearchContext.current());
-        try (XContentParser qSourceParser = XContentFactory.xContent(querySource).createParser(querySource)) {
-            final QueryShardContext contextCopy = new QueryShardContext(context.index(), context.indexQueryParserService());
-            contextCopy.reset(qSourceParser);
-            QueryBuilder result = contextCopy.parseContext().parseInnerQueryBuilder();
-            context.combineNamedQueries(contextCopy);
-            return result.toQuery(context);
-        }
-    }
-
-    @Override
-    protected void setFinalBoost(Query query) {
-        //no-op this query doesn't support boost
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (this.template == null) {
-            validationException = addValidationError("query template cannot be null", validationException);
+        builder.field(TemplateQueryParser.NAME);
+        if (template == null) {
+            new Template(templateString, templateType, null, null, this.vars).toXContent(builder, builderParams);
+        } else {
+            template.toXContent(builder, builderParams);
         }
-        return validationException;
-    }
-
-    @Override
-    protected TemplateQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        TemplateQueryBuilder templateQueryBuilder = new TemplateQueryBuilder(Template.readTemplate(in));
-        return templateQueryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        template.writeTo(out);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(template);
-    }
-
-    @Override
-    protected boolean doEquals(TemplateQueryBuilder other) {
-        return Objects.equals(template, other.template);
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/TemplateQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/TemplateQueryParser.java
index b74e276..1b5210d 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TemplateQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TemplateQueryParser.java
@@ -18,11 +18,18 @@
  */
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.ParseFieldMatcher;
+import org.elasticsearch.common.bytes.BytesReference;
+import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.script.ExecutableScript;
+import org.elasticsearch.script.ScriptContext;
 import org.elasticsearch.script.ScriptService;
 import org.elasticsearch.script.Template;
+import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
 import java.util.HashMap;
@@ -32,7 +39,14 @@ import java.util.Map;
  * In the simplest case, parse template string and variables from the request,
  * compile the template and execute the template against the given variables.
  * */
-public class TemplateQueryParser extends BaseQueryParser<TemplateQueryBuilder> {
+public class TemplateQueryParser implements QueryParser {
+
+    /** Name to reference this type of query. */
+    public static final String NAME = "template";
+    /** Name of query parameter containing the template string. */
+    public static final String QUERY = "query";
+
+    private final ScriptService scriptService;
 
     private final static Map<String, ScriptService.ScriptType> parametersToTypes = new HashMap<>();
     static {
@@ -41,9 +55,14 @@ public class TemplateQueryParser extends BaseQueryParser<TemplateQueryBuilder> {
         parametersToTypes.put("id", ScriptService.ScriptType.INDEXED);
     }
 
+    @Inject
+    public TemplateQueryParser(ScriptService scriptService) {
+        this.scriptService = scriptService;
+    }
+
     @Override
     public String[] names() {
-        return new String[] {TemplateQueryBuilder.NAME};
+        return new String[] { NAME };
     }
 
     /**
@@ -51,17 +70,27 @@ public class TemplateQueryParser extends BaseQueryParser<TemplateQueryBuilder> {
      * values. Handles both submitting the template as part of the request as
      * well as referencing only the template name.
      *
-     * @param parseContext parse context containing the templated query.
+     * @param parseContext
+     *            parse context containing the templated query.
      */
     @Override
     @Nullable
-    public TemplateQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException {
         XContentParser parser = parseContext.parser();
         Template template = parse(parser, parseContext.parseFieldMatcher());
-        return new TemplateQueryBuilder(template);
+        ExecutableScript executable = this.scriptService.executable(template, ScriptContext.Standard.SEARCH, SearchContext.current());
+
+        BytesReference querySource = (BytesReference) executable.run();
+
+        try (XContentParser qSourceParser = XContentFactory.xContent(querySource).createParser(querySource)) {
+            final QueryParseContext context = new QueryParseContext(parseContext.index(), parseContext.indexQueryParserService());
+            context.reset(qSourceParser);
+            return context.parseInnerQuery();
+        }
     }
 
     public static Template parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher, String... parameters) throws IOException {
+
         Map<String, ScriptService.ScriptType> parameterMap = new HashMap<>(parametersToTypes);
         for (String parameter : parameters) {
             parameterMap.put(parameter, ScriptService.ScriptType.INLINE);
@@ -85,9 +114,4 @@ public class TemplateQueryParser extends BaseQueryParser<TemplateQueryBuilder> {
     public static Template parse(XContentParser parser, Map<String, ScriptService.ScriptType> parameterMap, ParseFieldMatcher parseFieldMatcher) throws IOException {
         return Template.parse(parser, parameterMap, parseFieldMatcher);
     }
-
-    @Override
-    public TemplateQueryBuilder getBuilderPrototype() {
-        return TemplateQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/TermQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/TermQueryBuilder.java
index 5c8bf3f..5bd911a 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TermQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TermQueryBuilder.java
@@ -19,77 +19,128 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.elasticsearch.common.lucene.BytesRefs;
-import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 
 /**
  * A Query that matches documents containing a term.
  */
-public class TermQueryBuilder extends BaseTermQueryBuilder<TermQueryBuilder> {
+public class TermQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<TermQueryBuilder> {
 
-    public static final String NAME = "term";
-    static final TermQueryBuilder PROTOTYPE = new TermQueryBuilder(null, null);
+    private final String name;
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, String) */
-    public TermQueryBuilder(String fieldName, String value) {
-        super(fieldName, (Object) value);
+    private final Object value;
+
+    private float boost = -1;
+
+    private String queryName;
+
+    /**
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param value The value of the term
+     */
+    public TermQueryBuilder(String name, String value) {
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, int) */
-    public TermQueryBuilder(String fieldName, int value) {
-        super(fieldName, (Object) value);
+    /**
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param value The value of the term
+     */
+    public TermQueryBuilder(String name, int value) {
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, long) */
-    public TermQueryBuilder(String fieldName, long value) {
-        super(fieldName, (Object) value);
+    /**
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param value The value of the term
+     */
+    public TermQueryBuilder(String name, long value) {
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, float) */
-    public TermQueryBuilder(String fieldName, float value) {
-        super(fieldName, (Object) value);
+    /**
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param value The value of the term
+     */
+    public TermQueryBuilder(String name, float value) {
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, double) */
-    public TermQueryBuilder(String fieldName, double value) {
-        super(fieldName, (Object) value);
+    /**
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param value The value of the term
+     */
+    public TermQueryBuilder(String name, double value) {
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, boolean) */
-    public TermQueryBuilder(String fieldName, boolean value) {
-        super(fieldName, (Object) value);
+    /**
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param value The value of the term
+     */
+    public TermQueryBuilder(String name, boolean value) {
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, Object) */
-    public TermQueryBuilder(String fieldName, Object value) {
-        super(fieldName, value);
+    /**
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param value The value of the term
+     */
+    public TermQueryBuilder(String name, Object value) {
+        this.name = name;
+        this.value = value;
     }
 
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
     @Override
-    public Query doToQuery(QueryShardContext context) throws IOException {
-        Query query = null;
-        MappedFieldType mapper = context.fieldMapper(this.fieldName);
-        if (mapper != null) {
-            query = mapper.termQuery(this.value, context);
-        }
-        if (query == null) {
-            query = new TermQuery(new Term(this.fieldName, BytesRefs.toBytesRef(this.value)));
-        }
-        return query;
+    public TermQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
-    @Override
-    protected TermQueryBuilder createBuilder(String fieldName, Object value) {
-        return new TermQueryBuilder(fieldName, value);
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public TermQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
-    public String getWriteableName() {
-        return NAME;
+    public void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(TermQueryParser.NAME);
+        if (boost == -1 && queryName == null) {
+            builder.field(name, value);
+        } else {
+            builder.startObject(name);
+            builder.field("value", value);
+            if (boost != -1) {
+                builder.field("boost", boost);
+            }
+            if (queryName != null) {
+                builder.field("_name", queryName);
+            }
+            builder.endObject();
+        }
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/TermQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/TermQueryParser.java
index 43d4d95..1c3876f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TermQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TermQueryParser.java
@@ -19,16 +19,23 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.TermQuery;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
 
 import java.io.IOException;
 
 /**
- * Parser for the term query
+ *
  */
-public class TermQueryParser extends BaseQueryParser<TermQueryBuilder> {
+public class TermQueryParser implements QueryParser {
+
+    public static final String NAME = "term";
 
     private static final ParseField NAME_FIELD = new ParseField("_name").withAllDeprecated("query name is not supported in short version of term query");
     private static final ParseField BOOST_FIELD = new ParseField("boost").withAllDeprecated("boost is not supported in short version of term query");
@@ -39,17 +46,17 @@ public class TermQueryParser extends BaseQueryParser<TermQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{TermQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public TermQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String queryName = null;
         String fieldName = null;
         Object value = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
         String currentFieldName = null;
         XContentParser.Token token;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -97,16 +104,22 @@ public class TermQueryParser extends BaseQueryParser<TermQueryBuilder> {
             }
         }
 
-        TermQueryBuilder termQuery = new TermQueryBuilder(fieldName, value);
-        termQuery.boost(boost);
-        if (queryName != null) {
-            termQuery.queryName(queryName);
+        if (value == null) {
+            throw new QueryParsingException(parseContext, "No value specified for term query");
         }
-        return termQuery;
-    }
 
-    @Override
-    public TermQueryBuilder getBuilderPrototype() {
-        return TermQueryBuilder.PROTOTYPE;
+        Query query = null;
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            query = fieldType.termQuery(value, parseContext);
+        }
+        if (query == null) {
+            query = new TermQuery(new Term(fieldName, BytesRefs.toBytesRef(value)));
+        }
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/TermsLookupQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/TermsLookupQueryBuilder.java
index a074e2a..4bdd0da 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TermsLookupQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TermsLookupQueryBuilder.java
@@ -19,20 +19,93 @@
 
 package org.elasticsearch.index.query;
 
+import org.elasticsearch.common.xcontent.XContentBuilder;
+
+import java.io.IOException;
 
 /**
- * A filter for a field based on several terms matching on any of them.
- * @deprecated use {@link TermsQueryBuilder} instead.
+ * A filer for a field based on several terms matching on any of them.
  */
-@Deprecated
-public class TermsLookupQueryBuilder extends TermsQueryBuilder {
+public class TermsLookupQueryBuilder extends QueryBuilder {
+
+    private final String name;
+    private String lookupIndex;
+    private String lookupType;
+    private String lookupId;
+    private String lookupRouting;
+    private String lookupPath;
+
+    private String queryName;
 
     public TermsLookupQueryBuilder(String name) {
-        super(name, (Object[]) null);
+        this.name = name;
+    }
+
+    /**
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public TermsLookupQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
+    /**
+     * Sets the index name to lookup the terms from.
+     */
+    public TermsLookupQueryBuilder lookupIndex(String lookupIndex) {
+        this.lookupIndex = lookupIndex;
+        return this;
+    }
+
+    /**
+     * Sets the index type to lookup the terms from.
+     */
+    public TermsLookupQueryBuilder lookupType(String lookupType) {
+        this.lookupType = lookupType;
+        return this;
+    }
+
+    /**
+     * Sets the doc id to lookup the terms from.
+     */
+    public TermsLookupQueryBuilder lookupId(String lookupId) {
+        this.lookupId = lookupId;
+        return this;
+    }
+
+    /**
+     * Sets the path within the document to lookup the terms from.
+     */
+    public TermsLookupQueryBuilder lookupPath(String lookupPath) {
+        this.lookupPath = lookupPath;
+        return this;
+    }
+
+    public TermsLookupQueryBuilder lookupRouting(String lookupRouting) {
+        this.lookupRouting = lookupRouting;
+        return this;
     }
 
     @Override
-    public String getWriteableName() {
-        return TermsQueryBuilder.NAME;
-   }
+    public void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(TermsQueryParser.NAME);
+
+        builder.startObject(name);
+        if (lookupIndex != null) {
+            builder.field("index", lookupIndex);
+        }
+        builder.field("type", lookupType);
+        builder.field("id", lookupId);
+        if (lookupRouting != null) {
+            builder.field("routing", lookupRouting);
+        }
+        builder.field("path", lookupPath);
+        builder.endObject();
+
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
+
+        builder.endObject();
+    }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/TermsQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/TermsQueryBuilder.java
index 90731a4..ca54eb3 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TermsQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TermsQueryBuilder.java
@@ -19,153 +19,101 @@
 
 package org.elasticsearch.index.query;
 
-import com.google.common.primitives.Doubles;
-import com.google.common.primitives.Floats;
-import com.google.common.primitives.Ints;
-import com.google.common.primitives.Longs;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.queries.TermsQuery;
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.action.get.GetRequest;
-import org.elasticsearch.action.get.GetResponse;
-import org.elasticsearch.client.Client;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.BytesRefs;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.support.XContentMapValues;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.indices.cache.query.terms.TermsLookup;
-import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
-import java.util.*;
 
 /**
- * A filter for a field based on several terms matching on any of them.
+ * A filer for a field based on several terms matching on any of them.
  */
-public class TermsQueryBuilder extends AbstractQueryBuilder<TermsQueryBuilder> {
+public class TermsQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<TermsQueryBuilder> {
 
-    public static final String NAME = "terms";
+    private final String name;
 
-    static final TermsQueryBuilder PROTOTYPE = new TermsQueryBuilder("");
+    private final Object values;
 
-    public static final boolean DEFAULT_DISABLE_COORD = false;
-
-    private final String fieldName;
-    private final List<Object> values;
-    @Deprecated
     private String minimumShouldMatch;
-    @Deprecated
-    private boolean disableCoord = DEFAULT_DISABLE_COORD;
-    private TermsLookup termsLookup;
 
-    TermsQueryBuilder(String fieldName, List<Object> values, String minimumShouldMatch, boolean disableCoord, TermsLookup termsLookup) {
-        this.fieldName = fieldName;
-        if (values == null && termsLookup == null) {
-            throw new IllegalArgumentException("No value specified for terms query");
-        }
-        this.values = values;
-        this.disableCoord = disableCoord;
-        this.minimumShouldMatch = minimumShouldMatch;
-        this.termsLookup = termsLookup;
-    }
+    private Boolean disableCoord;
+
+    private String queryName;
+
+    private float boost = -1;
 
     /**
-     * A filter for a field based on several terms matching on any of them.
-     *
-     * @param fieldName The field name
-     * @param values The terms
-     */
-    public TermsQueryBuilder(String fieldName, String... values) {
-        this(fieldName, values != null ? Arrays.asList(values) : (Iterable<?>) null);
-    }
-    
-    /**
-     * A filter for a field based on several terms matching on any of them.
+     * A filer for a field based on several terms matching on any of them.
      *
-     * @param fieldName The field name
+     * @param name   The field name
      * @param values The terms
      */
-    public TermsQueryBuilder(String fieldName, int... values) {
-        this(fieldName, values != null ? Ints.asList(values) : (Iterable<?>) null);
+    public TermsQueryBuilder(String name, String... values) {
+        this(name, (Object[]) values);
     }
 
     /**
-     * A filter for a field based on several terms matching on any of them.
+     * A filer for a field based on several terms matching on any of them.
      *
-     * @param fieldName The field name
+     * @param name   The field name
      * @param values The terms
      */
-    public TermsQueryBuilder(String fieldName, long... values) {
-        this(fieldName, values != null ? Longs.asList(values) : (Iterable<?>) null);
+    public TermsQueryBuilder(String name, int... values) {
+        this.name = name;
+        this.values = values;
     }
 
     /**
-     * A filter for a field based on several terms matching on any of them.
+     * A filer for a field based on several terms matching on any of them.
      *
-     * @param fieldName The field name
+     * @param name   The field name
      * @param values The terms
      */
-    public TermsQueryBuilder(String fieldName, float... values) {
-        this(fieldName, values != null ? Floats.asList(values) : (Iterable<?>) null);
+    public TermsQueryBuilder(String name, long... values) {
+        this.name = name;
+        this.values = values;
     }
 
     /**
-     * A filter for a field based on several terms matching on any of them.
+     * A filer for a field based on several terms matching on any of them.
      *
-     * @param fieldName The field name
+     * @param name   The field name
      * @param values The terms
      */
-    public TermsQueryBuilder(String fieldName, double... values) {
-        this(fieldName, values != null ? Doubles.asList(values) : (Iterable<?>) null);
+    public TermsQueryBuilder(String name, float... values) {
+        this.name = name;
+        this.values = values;
     }
 
     /**
-     * A filter for a field based on several terms matching on any of them.
+     * A filer for a field based on several terms matching on any of them.
      *
-     * @param fieldName The field name
+     * @param name   The field name
      * @param values The terms
      */
-    public TermsQueryBuilder(String fieldName, Object... values) {
-        this(fieldName, values != null ? Arrays.asList(values) : (Iterable<?>) null);
+    public TermsQueryBuilder(String name, double... values) {
+        this.name = name;
+        this.values = values;
     }
 
     /**
-     * Constructor used for terms query lookup.
+     * A filer for a field based on several terms matching on any of them.
      *
-     * @param fieldName The field name
+     * @param name   The field name
+     * @param values The terms
      */
-    public TermsQueryBuilder(String fieldName) {
-        this.fieldName = fieldName;
-        this.values = null;
+    public TermsQueryBuilder(String name, Object... values) {
+        this.name = name;
+        this.values = values;
     }
 
     /**
-     * A filter for a field based on several terms matching on any of them.
+     * A filer for a field based on several terms matching on any of them.
      *
-     * @param fieldName The field name
+     * @param name   The field name
      * @param values The terms
      */
-    public TermsQueryBuilder(String fieldName, Iterable<?> values) {
-        if (values == null) {
-            throw new IllegalArgumentException("No value specified for terms query");
-        }
-        this.fieldName = fieldName;
-        this.values = convertToBytesRefListIfStringList(values);
-    }
-
-    public String fieldName() {
-        return this.fieldName;
-    }
-
-    public List<Object> values() {
-        return convertToStringListIfBytesRefList(this.values);
+    public TermsQueryBuilder(String name, Iterable values) {
+        this.name = name;
+        this.values = values;
     }
 
     /**
@@ -178,10 +126,6 @@ public class TermsQueryBuilder extends AbstractQueryBuilder<TermsQueryBuilder> {
         return this;
     }
 
-    public String minimumShouldMatch() {
-        return this.minimumShouldMatch;
-    }
-
     /**
      * Disables <tt>Similarity#coord(int,int)</tt> in scoring. Defaults to <tt>false</tt>.
      * @deprecated use [bool] query instead
@@ -192,271 +136,41 @@ public class TermsQueryBuilder extends AbstractQueryBuilder<TermsQueryBuilder> {
         return this;
     }
 
-    boolean disableCoord() {
-        return this.disableCoord;
-    }
-
-    private boolean isTermsLookupQuery() {
-        return this.termsLookup != null;
-    }
-
-    public TermsQueryBuilder termsLookup(TermsLookup termsLookup) {
-        this.termsLookup = termsLookup;
-        return this;
-    }
-
-    public TermsLookup termsLookup() {
-        return this.termsLookup;
-    }
-
-    /**
-     * Sets the index name to lookup the terms from.
-     */
-    public TermsQueryBuilder lookupIndex(String lookupIndex) {
-        if (lookupIndex == null) {
-            throw new IllegalArgumentException("Lookup index cannot be set to null");
-        }
-        if (this.termsLookup == null) {
-            this.termsLookup = new TermsLookup();
-        }
-        this.termsLookup.index(lookupIndex);
-        return this;
-    }
-
-    /**
-     * Sets the type name to lookup the terms from.
-     */
-    public TermsQueryBuilder lookupType(String lookupType) {
-        if (lookupType == null) {
-            throw new IllegalArgumentException("Lookup type cannot be set to null");
-        }
-        if (this.termsLookup == null) {
-            this.termsLookup = new TermsLookup();
-        }
-        this.termsLookup.type(lookupType);
-        return this;
-    }
-
-    /**
-     * Sets the document id to lookup the terms from.
-     */
-    public TermsQueryBuilder lookupId(String lookupId) {
-        if (lookupId == null) {
-            throw new IllegalArgumentException("Lookup id cannot be set to null");
-        }
-        if (this.termsLookup == null) {
-            this.termsLookup = new TermsLookup();
-        }
-        this.termsLookup.id(lookupId);
-        return this;
-    }
-
     /**
-     * Sets the path name to lookup the terms from.
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
      */
-    public TermsQueryBuilder lookupPath(String lookupPath) {
-        if (lookupPath == null) {
-            throw new IllegalArgumentException("Lookup path cannot be set to null");
-        }
-        if (this.termsLookup == null) {
-            this.termsLookup = new TermsLookup();
-        }
-        this.termsLookup.path(lookupPath);
+    public TermsQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
         return this;
     }
 
-    /**
-     * Sets the routing to lookup the terms from.
-     */
-    public TermsQueryBuilder lookupRouting(String lookupRouting) {
-        if (lookupRouting == null) {
-            throw new IllegalArgumentException("Lookup routing cannot be set to null");
-        }
-        if (this.termsLookup == null) {
-            this.termsLookup = new TermsLookup();
-        }
-        this.termsLookup.routing(lookupRouting);
+    @Override
+    public TermsQueryBuilder boost(float boost) {
+        this.boost = boost;
         return this;
     }
 
-    /**
-     * Same as {@link #convertToBytesRefIfString} but on Iterable.
-     * @param objs the Iterable of input object
-     * @return the same input or a list of {@link BytesRef} representation if input was a list of type string
-     */
-    private static List<Object> convertToBytesRefListIfStringList(Iterable<?> objs) {
-        if (objs == null) {
-            return null;
-        }
-        List<Object> newObjs = new ArrayList<>();
-        for (Object obj : objs) {
-            newObjs.add(convertToBytesRefIfString(obj));
-        }
-        return newObjs;
-    }
-
-    /**
-     * Same as {@link #convertToStringIfBytesRef} but on Iterable.
-     * @param objs the Iterable of input object
-     * @return the same input or a list of utf8 string if input was a list of type {@link BytesRef}
-     */
-    private static List<Object> convertToStringListIfBytesRefList(Iterable<?> objs) {
-        if (objs == null) {
-            return null;
-        }
-        List<Object> newObjs = new ArrayList<>();
-        for (Object obj : objs) {
-            newObjs.add(convertToStringIfBytesRef(obj));
-        }
-        return newObjs;
-    }
-
     @Override
     public void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        if (isTermsLookupQuery()) {
-            builder.startObject(fieldName);
-            termsLookup.toXContent(builder, params);
-            builder.endObject();
-        } else {
-            builder.field(fieldName, convertToStringListIfBytesRefList(values));
-        }
+        builder.startObject(TermsQueryParser.NAME);
+        builder.field(name, values);
+
         if (minimumShouldMatch != null) {
             builder.field("minimum_should_match", minimumShouldMatch);
         }
-        if (disableCoord != DEFAULT_DISABLE_COORD) {
-            builder.field("disable_coord", disableCoord);
-        }
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        List<Object> terms;
-        if (isTermsLookupQuery()) {
-            if (termsLookup.index() == null) {
-                termsLookup.index(context.index().name());
-            }
-            Client client = context.getClient();
-            terms = fetch(termsLookup, client);
-        } else {
-            terms = values;
-        }
-        if (terms == null || terms.isEmpty()) {
-            return Queries.newMatchNoDocsQuery();
-        }
-        return handleTermsQuery(terms, fieldName, context, minimumShouldMatch, disableCoord);
-    }
-
-    private List<Object> fetch(TermsLookup termsLookup, Client client) {
-        List<Object> terms = new ArrayList<>();
-        GetRequest getRequest = new GetRequest(termsLookup.index(), termsLookup.type(), termsLookup.id())
-                .preference("_local").routing(termsLookup.routing());
-        getRequest.copyContextAndHeadersFrom(SearchContext.current());
-        final GetResponse getResponse = client.get(getRequest).actionGet();
-        if (getResponse.isExists()) {
-            List<Object> extractedValues = XContentMapValues.extractRawValues(termsLookup.path(), getResponse.getSourceAsMap());
-            terms.addAll(extractedValues);
-        }
-        return terms;
-    }
-
-    private static Query handleTermsQuery(List<Object> terms, String fieldName, QueryShardContext context, String minimumShouldMatch, boolean disableCoord) {
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        String indexFieldName;
-        if (fieldType != null) {
-            indexFieldName = fieldType.names().indexName();
-        } else {
-            indexFieldName = fieldName;
-        }
-
-        Query query;
-        if (context.isFilter()) {
-            if (fieldType != null) {
-                query = fieldType.termsQuery(terms, context);
-            } else {
-                BytesRef[] filterValues = new BytesRef[terms.size()];
-                for (int i = 0; i < filterValues.length; i++) {
-                    filterValues[i] = BytesRefs.toBytesRef(terms.get(i));
-                }
-                query = new TermsQuery(indexFieldName, filterValues);
-            }
-        } else {
-            BooleanQuery.Builder bq = new BooleanQuery.Builder();
-            bq.setDisableCoord(disableCoord);
-            for (Object term : terms) {
-                if (fieldType != null) {
-                    bq.add(fieldType.termQuery(term, context), BooleanClause.Occur.SHOULD);
-                } else {
-                    bq.add(new TermQuery(new Term(indexFieldName, BytesRefs.toBytesRef(term))), BooleanClause.Occur.SHOULD);
-                }
-            }
-            query = Queries.applyMinimumShouldMatch(bq.build(), minimumShouldMatch);
-        }
-        return query;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (this.fieldName == null) {
-            validationException = addValidationError("field name cannot be null.", validationException);
-        }
-        if (isTermsLookupQuery() && this.values != null) {
-            validationException = addValidationError("can't have both a terms query and a lookup query.", validationException);
-        }
-        if (isTermsLookupQuery()) {
-            QueryValidationException exception = termsLookup.validate();
-            if (exception != null) {
-                validationException = QueryValidationException.addValidationErrors(exception.validationErrors(), validationException);
-            }
+        if (disableCoord != null) {
+            builder.field("disable_coord", disableCoord);
         }
-        return validationException;
-    }
 
-    @SuppressWarnings("unchecked")
-    @Override
-    protected TermsQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        String field = in.readString();
-        TermsLookup lookup = null;
-        if (in.readBoolean()) {
-            lookup = TermsLookup.readTermsLookupFrom(in);
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        List<Object> values = (List<Object>) in.readGenericValue();
-        String minimumShouldMatch = in.readOptionalString();
-        boolean disableCoord = in.readBoolean();
-        return new TermsQueryBuilder(field, values, minimumShouldMatch, disableCoord, lookup);
-    }
 
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-        out.writeBoolean(isTermsLookupQuery());
-        if (isTermsLookupQuery()) {
-            termsLookup.writeTo(out);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        out.writeGenericValue(values);
-        out.writeOptionalString(minimumShouldMatch);
-        out.writeBoolean(disableCoord);
-    }
 
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldName, values, minimumShouldMatch, disableCoord, termsLookup);
-    }
-
-    @Override
-    protected boolean doEquals(TermsQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-                Objects.equals(values, other.values) &&
-                Objects.equals(minimumShouldMatch, other.minimumShouldMatch) &&
-                Objects.equals(disableCoord, other.disableCoord) &&
-                Objects.equals(termsLookup, other.termsLookup);
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/TermsQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/TermsQueryParser.java
index b1f949c..b5fbce4 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TermsQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TermsQueryParser.java
@@ -19,29 +19,40 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.queries.TermsQuery;
+import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.TermQuery;
+import org.apache.lucene.util.BytesRef;
+import org.elasticsearch.action.get.GetRequest;
+import org.elasticsearch.action.get.GetResponse;
+import org.elasticsearch.client.Client;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.BytesRefs;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.common.xcontent.support.XContentMapValues;
+import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.indices.cache.query.terms.TermsLookup;
+import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
 
 /**
- * Parser for terms query and terms lookup.
  *
- * Filters documents that have fields that match any of the provided terms (not analyzed)
- *
- * It also supports a terms lookup mechanism which can be used to fetch the term values from
- * a document in an index.
  */
-public class TermsQueryParser extends BaseQueryParser {
+public class TermsQueryParser implements QueryParser {
 
-    private static final ParseField MIN_SHOULD_MATCH_FIELD = new ParseField("min_match", "min_should_match", "minimum_should_match")
-            .withAllDeprecated("Use [bool] query instead");
+    public static final String NAME = "terms";
+    private static final ParseField MIN_SHOULD_MATCH_FIELD = new ParseField("min_match", "min_should_match").withAllDeprecated("Use [bool] query instead");
     private static final ParseField DISABLE_COORD_FIELD = new ParseField("disable_coord").withAllDeprecated("Use [bool] query instead");
     private static final ParseField EXECUTION_FIELD = new ParseField("execution").withAllDeprecated("execution is deprecated and has no effect");
+    private Client client;
 
     @Inject
     public TermsQueryParser() {
@@ -49,24 +60,34 @@ public class TermsQueryParser extends BaseQueryParser {
 
     @Override
     public String[] names() {
-        return new String[]{TermsQueryBuilder.NAME, "in"};
+        return new String[]{NAME, "in"};
+    }
+
+    @Inject(optional = true)
+    public void setClient(Client client) {
+        this.client = client;
     }
 
     @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        String fieldName = null;
-        List<Object> values = null;
+        String queryName = null;
+        String currentFieldName = null;
+
+        String lookupIndex = parseContext.index().name();
+        String lookupType = null;
+        String lookupId = null;
+        String lookupPath = null;
+        String lookupRouting = null;
         String minShouldMatch = null;
-        boolean disableCoord = TermsQueryBuilder.DEFAULT_DISABLE_COORD;
-        TermsLookup termsLookup = null;
 
-        String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        boolean disableCoord = false;
 
         XContentParser.Token token;
-        String currentFieldName = null;
+        List<Object> terms = new ArrayList<>();
+        String fieldName = null;
+        float boost = 1f;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
@@ -77,16 +98,51 @@ public class TermsQueryParser extends BaseQueryParser {
                     throw new QueryParsingException(parseContext, "[terms] query does not support multiple fields");
                 }
                 fieldName = currentFieldName;
-                values = parseValues(parseContext, parser);
+
+                while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
+                    Object value = parser.objectBytes();
+                    if (value == null) {
+                        throw new QueryParsingException(parseContext, "No value specified for terms query");
+                    }
+                    terms.add(value);
+                }
             } else if (token == XContentParser.Token.START_OBJECT) {
                 fieldName = currentFieldName;
-                termsLookup = parseTermsLookup(parseContext, parser);
+                while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
+                    if (token == XContentParser.Token.FIELD_NAME) {
+                        currentFieldName = parser.currentName();
+                    } else if (token.isValue()) {
+                        if ("index".equals(currentFieldName)) {
+                            lookupIndex = parser.text();
+                        } else if ("type".equals(currentFieldName)) {
+                            lookupType = parser.text();
+                        } else if ("id".equals(currentFieldName)) {
+                            lookupId = parser.text();
+                        } else if ("path".equals(currentFieldName)) {
+                            lookupPath = parser.text();
+                        } else if ("routing".equals(currentFieldName)) {
+                            lookupRouting = parser.textOrNull();
+                        } else {
+                            throw new QueryParsingException(parseContext, "[terms] query does not support [" + currentFieldName
+                                    + "] within lookup element");
+                        }
+                    }
+                }
+                if (lookupType == null) {
+                    throw new QueryParsingException(parseContext, "[terms] query lookup element requires specifying the type");
+                }
+                if (lookupId == null) {
+                    throw new QueryParsingException(parseContext, "[terms] query lookup element requires specifying the id");
+                }
+                if (lookupPath == null) {
+                    throw new QueryParsingException(parseContext, "[terms] query lookup element requires specifying the path");
+                }
             } else if (token.isValue()) {
                 if (parseContext.parseFieldMatcher().match(currentFieldName, EXECUTION_FIELD)) {
                     // ignore
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, MIN_SHOULD_MATCH_FIELD)) {
                     if (minShouldMatch != null) {
-                        throw new IllegalArgumentException("[" + currentFieldName + "] is not allowed in a filter context for the [" + TermsQueryBuilder.NAME + "] query");
+                        throw new IllegalArgumentException("[" + currentFieldName + "] is not allowed in a filter context for the [" + NAME + "] query");
                     }
                     minShouldMatch = parser.textOrNull();
                 } else if ("boost".equals(currentFieldName)) {
@@ -102,64 +158,57 @@ public class TermsQueryParser extends BaseQueryParser {
         }
 
         if (fieldName == null) {
-            throw new QueryParsingException(parseContext, "terms query requires a field name, followed by array of terms or a document lookup specification");
+            throw new QueryParsingException(parseContext, "terms query requires a field name, followed by array of terms");
         }
-        return new TermsQueryBuilder(fieldName, values, minShouldMatch, disableCoord, termsLookup)
-                .boost(boost)
-                .queryName(queryName);
-    }
 
-    private static List<Object> parseValues(QueryParseContext parseContext, XContentParser parser) throws IOException {
-        List<Object> values = new ArrayList<>();
-        XContentParser.Token token;
-        while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-            Object value = parser.objectBytes();
-            if (value == null) {
-                throw new QueryParsingException(parseContext, "No value specified for terms query");
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            fieldName = fieldType.names().indexName();
+        }
+
+        if (lookupId != null) {
+            final TermsLookup lookup = new TermsLookup(lookupIndex, lookupType, lookupId, lookupRouting, lookupPath, parseContext);
+            GetRequest getRequest = new GetRequest(lookup.getIndex(), lookup.getType(), lookup.getId()).preference("_local").routing(lookup.getRouting());
+            getRequest.copyContextAndHeadersFrom(SearchContext.current());
+            final GetResponse getResponse = client.get(getRequest).actionGet();
+            if (getResponse.isExists()) {
+                List<Object> values = XContentMapValues.extractRawValues(lookup.getPath(), getResponse.getSourceAsMap());
+                terms.addAll(values);
             }
-            values.add(value);
         }
-        return values;
-    }
 
-    private static TermsLookup parseTermsLookup(QueryParseContext parseContext, XContentParser parser) throws IOException {
-        TermsLookup termsLookup = new TermsLookup();
-        XContentParser.Token token;
-        String currentFieldName = null;
-        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
-            if (token == XContentParser.Token.FIELD_NAME) {
-                currentFieldName = parser.currentName();
-            } else if (token.isValue()) {
-                if ("index".equals(currentFieldName)) {
-                    termsLookup.index(parser.textOrNull());
-                } else if ("type".equals(currentFieldName)) {
-                    termsLookup.type(parser.text());
-                } else if ("id".equals(currentFieldName)) {
-                    termsLookup.id(parser.text());
-                } else if ("routing".equals(currentFieldName)) {
-                    termsLookup.routing(parser.textOrNull());
-                } else if ("path".equals(currentFieldName)) {
-                    termsLookup.path(parser.text());
+        if (terms.isEmpty()) {
+            return Queries.newMatchNoDocsQuery();
+        }
+
+        Query query;
+        if (parseContext.isFilter()) {
+            if (fieldType != null) {
+                query = fieldType.termsQuery(terms, parseContext);
+            } else {
+                BytesRef[] filterValues = new BytesRef[terms.size()];
+                for (int i = 0; i < filterValues.length; i++) {
+                    filterValues[i] = BytesRefs.toBytesRef(terms.get(i));
+                }
+                query = new TermsQuery(fieldName, filterValues);
+            }
+        } else {
+            BooleanQuery.Builder bq = new BooleanQuery.Builder();
+            bq.setDisableCoord(disableCoord);
+            for (Object term : terms) {
+                if (fieldType != null) {
+                    bq.add(fieldType.termQuery(term, parseContext), Occur.SHOULD);
                 } else {
-                    throw new QueryParsingException(parseContext, "[terms] query does not support [" + currentFieldName
-                            + "] within lookup element");
+                    bq.add(new TermQuery(new Term(fieldName, BytesRefs.toBytesRef(term))), Occur.SHOULD);
                 }
             }
+            query = Queries.applyMinimumShouldMatch(bq.build(), minShouldMatch);
         }
-        if (termsLookup.type() == null) {
-            throw new QueryParsingException(parseContext, "[terms] query lookup element requires specifying the type");
-        }
-        if (termsLookup.id() == null) {
-            throw new QueryParsingException(parseContext, "[terms] query lookup element requires specifying the id");
-        }
-        if (termsLookup.path() == null) {
-            throw new QueryParsingException(parseContext, "[terms] query lookup element requires specifying the path");
-        }
-        return termsLookup;
-    }
+        query.setBoost(boost);
 
-    @Override
-    public TermsQueryBuilder getBuilderPrototype() {
-        return TermsQueryBuilder.PROTOTYPE;
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/TypeQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/TypeQueryBuilder.java
index 9f89a94..2a9a6c5 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TypeQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TypeQueryBuilder.java
@@ -19,92 +19,22 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.DocumentMapper;
-import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
 
 import java.io.IOException;
-import java.util.Objects;
 
-public class TypeQueryBuilder extends AbstractQueryBuilder<TypeQueryBuilder> {
+public class TypeQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "type";
-
-    private final BytesRef type;
-
-    static final TypeQueryBuilder PROTOTYPE = new TypeQueryBuilder((BytesRef) null);
+    private final String type;
 
     public TypeQueryBuilder(String type) {
-        this.type = BytesRefs.toBytesRef(type);
-    }
-
-    TypeQueryBuilder(BytesRef type) {
         this.type = type;
     }
 
-    public String type() {
-        return BytesRefs.toString(this.type);
-    }
-
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("value", type.utf8ToString());
-        printBoostAndQueryName(builder);
+        builder.startObject(TypeQueryParser.NAME);
+        builder.field("value", type);
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query filter;
-        //LUCENE 4 UPGRADE document mapper should use bytesref as well?
-        DocumentMapper documentMapper = context.mapperService().documentMapper(type.utf8ToString());
-        if (documentMapper == null) {
-            filter = new TermQuery(new Term(TypeFieldMapper.NAME, type));
-        } else {
-            filter = documentMapper.typeFilter();
-        }
-        return filter;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (type == null) {
-            validationException = addValidationError("[type] cannot be null", validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    protected TypeQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new TypeQueryBuilder(in.readBytesRef());
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeBytesRef(type);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(type);
-    }
-
-    @Override
-    protected boolean doEquals(TypeQueryBuilder other) {
-        return Objects.equals(type, other.type);
-    }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/TypeQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/TypeQueryParser.java
index ee5e772..e4b7889 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TypeQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TypeQueryParser.java
@@ -19,16 +19,20 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.DocumentMapper;
+import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
 
 import java.io.IOException;
 
-/**
- * Parser for type query
- */
-public class TypeQueryParser extends BaseQueryParser<TypeQueryBuilder> {
+public class TypeQueryParser implements QueryParser {
+
+    public static final String NAME = "type";
 
     @Inject
     public TypeQueryParser() {
@@ -36,45 +40,37 @@ public class TypeQueryParser extends BaseQueryParser<TypeQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{TypeQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public TypeQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
-        BytesRef type = null;
 
-        String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-
-        String currentFieldName = null;
-        XContentParser.Token token;
-        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
-            if (token == XContentParser.Token.FIELD_NAME) {
-                currentFieldName = parser.currentName();
-            } else if (token.isValue()) {
-                if ("_name".equals(currentFieldName)) {
-                    queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
-                } else if ("value".equals(currentFieldName)) {
-                    type = parser.utf8Bytes();
-                }
-            } else {
-                throw new QueryParsingException(parseContext, "[type] filter doesn't support [" + currentFieldName + "]");
-            }
+        XContentParser.Token token = parser.nextToken();
+        if (token != XContentParser.Token.FIELD_NAME) {
+            throw new QueryParsingException(parseContext, "[type] filter should have a value field, and the type name");
         }
-
-        if (type == null) {
-            throw new QueryParsingException(parseContext, "[type] filter needs to be provided with a value for the type");
+        String fieldName = parser.currentName();
+        if (!fieldName.equals("value")) {
+            throw new QueryParsingException(parseContext, "[type] filter should have a value field, and the type name");
         }
-        return new TypeQueryBuilder(type)
-                .boost(boost)
-                .queryName(queryName);
-    }
+        token = parser.nextToken();
+        if (token != XContentParser.Token.VALUE_STRING) {
+            throw new QueryParsingException(parseContext, "[type] filter should have a value field, and the type name");
+        }
+        BytesRef type = parser.utf8Bytes();
+        // move to the next token
+        parser.nextToken();
 
-    @Override
-    public TypeQueryBuilder getBuilderPrototype() {
-        return TypeQueryBuilder.PROTOTYPE;
+        Query filter;
+        //LUCENE 4 UPGRADE document mapper should use bytesref as well? 
+        DocumentMapper documentMapper = parseContext.mapperService().documentMapper(type.utf8ToString());
+        if (documentMapper == null) {
+            filter = new TermQuery(new Term(TypeFieldMapper.NAME, type));
+        } else {
+            filter = documentMapper.typeFilter();
+        }
+        return filter;
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/WildcardQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/WildcardQueryBuilder.java
index 89b753e..654f14e 100644
--- a/core/src/main/java/org/elasticsearch/index/query/WildcardQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/WildcardQueryBuilder.java
@@ -19,20 +19,9 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.WildcardQuery;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * Implements the wildcard search query. Supported wildcards are <tt>*</tt>, which
@@ -42,17 +31,17 @@ import java.util.Objects;
  * a Wildcard term should not start with one of the wildcards <tt>*</tt> or
  * <tt>?</tt>.
  */
-public class WildcardQueryBuilder extends AbstractQueryBuilder<WildcardQueryBuilder> implements MultiTermQueryBuilder<WildcardQueryBuilder> {
+public class WildcardQueryBuilder extends MultiTermQueryBuilder implements BoostableQueryBuilder<WildcardQueryBuilder> {
 
-    public static final String NAME = "wildcard";
+    private final String name;
 
-    private final String fieldName;
+    private final String wildcard;
 
-    private final String value;
+    private float boost = -1;
 
     private String rewrite;
 
-    static final WildcardQueryBuilder PROTOTYPE = new WildcardQueryBuilder(null, null);
+    private String queryName;
 
     /**
      * Implements the wildcard search query. Supported wildcards are <tt>*</tt>, which
@@ -62,20 +51,12 @@ public class WildcardQueryBuilder extends AbstractQueryBuilder<WildcardQueryBuil
      * a Wildcard term should not start with one of the wildcards <tt>*</tt> or
      * <tt>?</tt>.
      *
-     * @param fieldName The field name
-     * @param value The wildcard query string
+     * @param name     The field name
+     * @param wildcard The wildcard query string
      */
-    public WildcardQueryBuilder(String fieldName, String value) {
-        this.fieldName = fieldName;
-        this.value = value;
-    }
-
-    public String fieldName() {
-        return fieldName;
-    }
-
-    public String value() {
-        return value;
+    public WildcardQueryBuilder(String name, String wildcard) {
+        this.name = name;
+        this.wildcard = wildcard;
     }
 
     public WildcardQueryBuilder rewrite(String rewrite) {
@@ -83,83 +64,43 @@ public class WildcardQueryBuilder extends AbstractQueryBuilder<WildcardQueryBuil
         return this;
     }
 
-    public String rewrite() {
-        return this.rewrite;
-    }
-
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
     @Override
-    public String getWriteableName() {
-        return NAME;
+    public WildcardQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
-    @Override
-    public void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.startObject(fieldName);
-        builder.field("wildcard", value);
-        if (rewrite != null) {
-            builder.field("rewrite", rewrite);
-        }
-        printBoostAndQueryName(builder);
-        builder.endObject();
-        builder.endObject();
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public WildcardQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        String indexFieldName;
-        BytesRef valueBytes;
-
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType != null) {
-            indexFieldName = fieldType.names().indexName();
-            valueBytes = fieldType.indexedValueForSearch(value);
+    public void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(WildcardQueryParser.NAME);
+        if (boost == -1 && rewrite == null && queryName == null) {
+            builder.field(name, wildcard);
         } else {
-            indexFieldName = fieldName;
-            valueBytes = new BytesRef(value);
+            builder.startObject(name);
+            builder.field("wildcard", wildcard);
+            if (boost != -1) {
+                builder.field("boost", boost);
+            }
+            if (rewrite != null) {
+                builder.field("rewrite", rewrite);
+            }
+            if (queryName != null) {
+                builder.field("_name", queryName);
+            }
+            builder.endObject();
         }
-
-        WildcardQuery query = new WildcardQuery(new Term(indexFieldName, valueBytes));
-        MultiTermQuery.RewriteMethod rewriteMethod = QueryParsers.parseRewriteMethod(context.parseFieldMatcher(), rewrite, null);
-        QueryParsers.setRewriteMethod(query, rewriteMethod);
-        return query;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (Strings.isEmpty(this.fieldName)) {
-            validationException = addValidationError("field name cannot be null or empty.", validationException);
-        }
-        if (this.value == null) {
-            validationException = addValidationError("wildcard cannot be null", validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    protected WildcardQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        WildcardQueryBuilder wildcardQueryBuilder = new WildcardQueryBuilder(in.readString(), in.readString());
-        wildcardQueryBuilder.rewrite = in.readOptionalString();
-        return wildcardQueryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-        out.writeString(value);
-        out.writeOptionalString(rewrite);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldName, value, rewrite);
-    }
-
-    @Override
-    protected boolean doEquals(WildcardQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-                Objects.equals(value, other.value) &&
-                Objects.equals(rewrite, other.rewrite);
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/WildcardQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/WildcardQueryParser.java
index d3b3e26..da92db4 100644
--- a/core/src/main/java/org/elasticsearch/index/query/WildcardQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/WildcardQueryParser.java
@@ -19,15 +19,23 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.WildcardQuery;
+import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
 
 /**
- * Parser for wildcard query
+ *
  */
-public class WildcardQueryParser extends BaseQueryParser<WildcardQueryBuilder> {
+public class WildcardQueryParser implements QueryParser {
+
+    public static final String NAME = "wildcard";
 
     @Inject
     public WildcardQueryParser() {
@@ -35,11 +43,11 @@ public class WildcardQueryParser extends BaseQueryParser<WildcardQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{WildcardQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public WildcardQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         XContentParser.Token token = parser.nextToken();
@@ -47,10 +55,10 @@ public class WildcardQueryParser extends BaseQueryParser<WildcardQueryBuilder> {
             throw new QueryParsingException(parseContext, "[wildcard] query malformed, no field");
         }
         String fieldName = parser.currentName();
-        String rewrite = null;
+        String rewriteMethod = null;
 
         String value = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
         String queryName = null;
         token = parser.nextToken();
         if (token == XContentParser.Token.START_OBJECT) {
@@ -66,7 +74,7 @@ public class WildcardQueryParser extends BaseQueryParser<WildcardQueryBuilder> {
                     } else if ("boost".equals(currentFieldName)) {
                         boost = parser.floatValue();
                     } else if ("rewrite".equals(currentFieldName)) {
-                        rewrite = parser.textOrNull();
+                        rewriteMethod = parser.textOrNull();
                     } else if ("_name".equals(currentFieldName)) {
                         queryName = parser.text();
                     } else {
@@ -83,14 +91,22 @@ public class WildcardQueryParser extends BaseQueryParser<WildcardQueryBuilder> {
         if (value == null) {
             throw new QueryParsingException(parseContext, "No value specified for prefix query");
         }
-        return new WildcardQueryBuilder(fieldName, value)
-                .rewrite(rewrite)
-                .boost(boost)
-                .queryName(queryName);
-    }
 
-    @Override
-    public WildcardQueryBuilder getBuilderPrototype() {
-        return WildcardQueryBuilder.PROTOTYPE;
+        BytesRef valueBytes;
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            fieldName = fieldType.names().indexName();
+            valueBytes = fieldType.indexedValueForSearch(value);
+        } else {
+            valueBytes = new BytesRef(value);
+        }
+
+        WildcardQuery wildcardQuery = new WildcardQuery(new Term(fieldName, valueBytes));
+        QueryParsers.setRewriteMethod(wildcardQuery, parseContext.parseFieldMatcher(), rewriteMethod);
+        wildcardQuery.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, wildcardQuery);
+        }
+        return wildcardQuery;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/WrapperQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/WrapperQueryBuilder.java
index f4a75c7..6fde3c7 100644
--- a/core/src/main/java/org/elasticsearch/index/query/WrapperQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/WrapperQueryBuilder.java
@@ -20,16 +20,10 @@
 package org.elasticsearch.index.query;
 
 import com.google.common.base.Charsets;
-import org.apache.lucene.search.Query;
 import org.elasticsearch.common.bytes.BytesReference;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
-import java.util.Arrays;
 
 /**
  * A Query builder which allows building a query given JSON string or binary data provided as input. This is useful when you want
@@ -45,24 +39,28 @@ import java.util.Arrays;
  * }
  * </pre>
  */
-public class WrapperQueryBuilder extends AbstractQueryBuilder<WrapperQueryBuilder> {
+public class WrapperQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "wrapper";
     private final byte[] source;
-    static final WrapperQueryBuilder PROTOTYPE = new WrapperQueryBuilder((byte[]) null);
+    private final int offset;
+    private final int length;
 
     /**
      * Creates a query builder given a query provided as a string
      */
     public WrapperQueryBuilder(String source) {
         this.source = source.getBytes(Charsets.UTF_8);
+        this.offset = 0;
+        this.length = this.source.length;
     }
 
     /**
      * Creates a query builder given a query provided as a bytes array
      */
-    public WrapperQueryBuilder(byte[] source) {
+    public WrapperQueryBuilder(byte[] source, int offset, int length) {
         this.source = source;
+        this.offset = offset;
+        this.length = length;
     }
 
     /**
@@ -70,71 +68,14 @@ public class WrapperQueryBuilder extends AbstractQueryBuilder<WrapperQueryBuilde
      */
     public WrapperQueryBuilder(BytesReference source) {
         this.source = source.array();
-    }
-
-    public byte[] source() {
-        return this.source;
-    }
-
-    @Override
-    public String getName() {
-        return NAME;
+        this.offset = source.arrayOffset();
+        this.length = source.length();
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("query", source);
+        builder.startObject(WrapperQueryParser.NAME);
+        builder.field("query", source, offset, length);
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        try (XContentParser qSourceParser = XContentFactory.xContent(source).createParser(source)) {
-            final QueryShardContext contextCopy = new QueryShardContext(context.index(), context.indexQueryParserService());
-            contextCopy.reset(qSourceParser);
-            QueryBuilder result = contextCopy.parseContext().parseInnerQueryBuilder();
-            context.combineNamedQueries(contextCopy);
-            return result.toQuery(context);
-        }
-    }
-
-    @Override
-    protected void setFinalBoost(Query query) {
-        //no-op this query doesn't support boost
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (this.source == null || this.source.length == 0) {
-            validationException = addValidationError("query source text cannot be null or empty", validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    protected WrapperQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new WrapperQueryBuilder(in.readByteArray());
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeByteArray(this.source);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Arrays.hashCode(source);
-    }
-
-    @Override
-    protected boolean doEquals(WrapperQueryBuilder other) {
-        return Arrays.equals(source, other.source);   // otherwise we compare pointers
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/WrapperQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/WrapperQueryParser.java
index cd9eb83..331ba78 100644
--- a/core/src/main/java/org/elasticsearch/index/query/WrapperQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/WrapperQueryParser.java
@@ -19,7 +19,9 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
@@ -27,7 +29,9 @@ import java.io.IOException;
 /**
  * Query parser for JSON Queries.
  */
-public class WrapperQueryParser extends BaseQueryParser {
+public class WrapperQueryParser implements QueryParser {
+
+    public static final String NAME = "wrapper";
 
     @Inject
     public WrapperQueryParser() {
@@ -35,11 +39,11 @@ public class WrapperQueryParser extends BaseQueryParser {
 
     @Override
     public String[] names() {
-        return new String[]{WrapperQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         XContentParser.Token token = parser.nextToken();
@@ -52,18 +56,14 @@ public class WrapperQueryParser extends BaseQueryParser {
         }
         parser.nextToken();
 
-        byte[] source = parser.binaryValue();
-
-        parser.nextToken();
-
-        if (source == null) {
-            throw new QueryParsingException(parseContext, "wrapper query has no [query] specified");
+        byte[] querySource = parser.binaryValue();
+        try (XContentParser qSourceParser = XContentFactory.xContent(querySource).createParser(querySource)) {
+            final QueryParseContext context = new QueryParseContext(parseContext.index(), parseContext.indexQueryParserService());
+            context.reset(qSourceParser);
+            Query result = context.parseInnerQuery();
+            parser.nextToken();
+            parseContext.combineNamedQueries(context);
+            return result;
         }
-        return new WrapperQueryBuilder(source);
-    }
-
-    @Override
-    public WrapperQueryBuilder getBuilderPrototype() {
-        return WrapperQueryBuilder.PROTOTYPE;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java
index 7580c84..db16951 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java
@@ -43,7 +43,7 @@ import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.core.DateFieldMapper;
 import org.elasticsearch.index.mapper.core.NumberFieldMapper;
 import org.elasticsearch.index.mapper.geo.GeoPointFieldMapper;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.query.functionscore.gauss.GaussDecayFunctionBuilder;
 import org.elasticsearch.index.query.functionscore.gauss.GaussDecayFunctionParser;
@@ -89,8 +89,7 @@ import java.util.Locale;
  * <p>
  * See {@link GaussDecayFunctionBuilder} and {@link GaussDecayFunctionParser}
  * for an example. The parser furthermore needs to be registered in the
- * {@link org.elasticsearch.index.query.functionscore.FunctionScoreModule
- * FunctionScoreModule}.
+ * {@link org.elasticsearch.search.SearchModule SearchModule}.
  *
  * **/
 
@@ -119,7 +118,7 @@ public abstract class DecayFunctionParser implements ScoreFunctionParser {
      *
      * */
     @Override
-    public ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, QueryParsingException {
+    public ScoreFunction parse(QueryParseContext parseContext, XContentParser parser) throws IOException, QueryParsingException {
         String currentFieldName;
         XContentParser.Token token;
         AbstractDistanceScoreFunction scoreFunction;
@@ -132,7 +131,7 @@ public abstract class DecayFunctionParser implements ScoreFunctionParser {
             if (token == XContentParser.Token.START_OBJECT) {
                 variableContent.copyCurrentStructure(parser);
                 fieldName = currentFieldName;
-            } else if (context.parseFieldMatcher().match(currentFieldName, MULTI_VALUE_MODE)) {
+            } else if (parseContext.parseFieldMatcher().match(currentFieldName, MULTI_VALUE_MODE)) {
                 multiValueMode = parser.text();
             } else {
                 throw new ElasticsearchParseException("malformed score function score parameters.");
@@ -142,34 +141,34 @@ public abstract class DecayFunctionParser implements ScoreFunctionParser {
             throw new ElasticsearchParseException("malformed score function score parameters.");
         }
         XContentParser variableParser = XContentFactory.xContent(variableContent.string()).createParser(variableContent.string());
-        scoreFunction = parseVariable(fieldName, variableParser, context, MultiValueMode.fromString(multiValueMode.toUpperCase(Locale.ROOT)));
+        scoreFunction = parseVariable(fieldName, variableParser, parseContext, MultiValueMode.fromString(multiValueMode.toUpperCase(Locale.ROOT)));
         return scoreFunction;
     }
 
     // parses origin and scale parameter for field "fieldName"
-    private AbstractDistanceScoreFunction parseVariable(String fieldName, XContentParser parser, QueryShardContext context, MultiValueMode mode) throws IOException {
+    private AbstractDistanceScoreFunction parseVariable(String fieldName, XContentParser parser, QueryParseContext parseContext, MultiValueMode mode) throws IOException {
 
         // now, the field must exist, else we cannot read the value for
         // the doc later
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
         if (fieldType == null) {
-            throw new QueryParsingException(context.parseContext(), "unknown field [{}]", fieldName);
+            throw new QueryParsingException(parseContext, "unknown field [{}]", fieldName);
         }
 
         // dates and time need special handling
         parser.nextToken();
         if (fieldType instanceof DateFieldMapper.DateFieldType) {
-            return parseDateVariable(fieldName, parser, context, (DateFieldMapper.DateFieldType) fieldType, mode);
+            return parseDateVariable(fieldName, parser, parseContext, (DateFieldMapper.DateFieldType) fieldType, mode);
         } else if (fieldType instanceof GeoPointFieldMapper.GeoPointFieldType) {
-            return parseGeoVariable(fieldName, parser, context, (GeoPointFieldMapper.GeoPointFieldType) fieldType, mode);
+            return parseGeoVariable(fieldName, parser, parseContext, (GeoPointFieldMapper.GeoPointFieldType) fieldType, mode);
         } else if (fieldType instanceof NumberFieldMapper.NumberFieldType) {
-            return parseNumberVariable(fieldName, parser, context, (NumberFieldMapper.NumberFieldType) fieldType, mode);
+            return parseNumberVariable(fieldName, parser, parseContext, (NumberFieldMapper.NumberFieldType) fieldType, mode);
         } else {
-            throw new QueryParsingException(context.parseContext(), "field [{}] is of type [{}], but only numeric types are supported.", fieldName, fieldType);
+            throw new QueryParsingException(parseContext, "field [{}] is of type [{}], but only numeric types are supported.", fieldName, fieldType);
         }
     }
 
-    private AbstractDistanceScoreFunction parseNumberVariable(String fieldName, XContentParser parser, QueryShardContext context,
+    private AbstractDistanceScoreFunction parseNumberVariable(String fieldName, XContentParser parser, QueryParseContext parseContext,
             NumberFieldMapper.NumberFieldType fieldType, MultiValueMode mode) throws IOException {
         XContentParser.Token token;
         String parameterName = null;
@@ -199,11 +198,11 @@ public abstract class DecayFunctionParser implements ScoreFunctionParser {
         if (!scaleFound || !refFound) {
             throw new ElasticsearchParseException("both [{}] and [{}] must be set for numeric fields.", DecayFunctionBuilder.SCALE, DecayFunctionBuilder.ORIGIN);
         }
-        IndexNumericFieldData numericFieldData = context.getForField(fieldType);
+        IndexNumericFieldData numericFieldData = parseContext.getForField(fieldType);
         return new NumericFieldDataScoreFunction(origin, scale, decay, offset, getDecayFunction(), numericFieldData, mode);
     }
 
-    private AbstractDistanceScoreFunction parseGeoVariable(String fieldName, XContentParser parser, QueryShardContext context,
+    private AbstractDistanceScoreFunction parseGeoVariable(String fieldName, XContentParser parser, QueryParseContext parseContext,
             GeoPointFieldMapper.GeoPointFieldType fieldType, MultiValueMode mode) throws IOException {
         XContentParser.Token token;
         String parameterName = null;
@@ -231,12 +230,12 @@ public abstract class DecayFunctionParser implements ScoreFunctionParser {
         }
         double scale = DistanceUnit.DEFAULT.parse(scaleString, DistanceUnit.DEFAULT);
         double offset = DistanceUnit.DEFAULT.parse(offsetString, DistanceUnit.DEFAULT);
-        IndexGeoPointFieldData indexFieldData = context.getForField(fieldType);
+        IndexGeoPointFieldData indexFieldData = parseContext.getForField(fieldType);
         return new GeoFieldDataScoreFunction(origin, scale, decay, offset, getDecayFunction(), indexFieldData, mode);
 
     }
 
-    private AbstractDistanceScoreFunction parseDateVariable(String fieldName, XContentParser parser, QueryShardContext context,
+    private AbstractDistanceScoreFunction parseDateVariable(String fieldName, XContentParser parser, QueryParseContext parseContext,
             DateFieldMapper.DateFieldType dateFieldType, MultiValueMode mode) throws IOException {
         XContentParser.Token token;
         String parameterName = null;
@@ -271,7 +270,7 @@ public abstract class DecayFunctionParser implements ScoreFunctionParser {
         double scale = val.getMillis();
         val = TimeValue.parseTimeValue(offsetString, TimeValue.timeValueHours(24), getClass().getSimpleName() + ".offset");
         double offset = val.getMillis();
-        IndexNumericFieldData numericFieldData = context.getForField(dateFieldType);
+        IndexNumericFieldData numericFieldData = parseContext.getForField(dateFieldType);
         return new NumericFieldDataScoreFunction(origin, scale, decay, offset, getDecayFunction(), numericFieldData, mode);
     }
 
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilder.java
index 3880592..dec90b1 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilder.java
@@ -21,7 +21,7 @@ package org.elasticsearch.index.query.functionscore;
 
 import org.elasticsearch.common.lucene.search.function.CombineFunction;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.query.AbstractQueryBuilder;
+import org.elasticsearch.index.query.BoostableQueryBuilder;
 import org.elasticsearch.index.query.QueryBuilder;
 
 import java.io.IOException;
@@ -31,11 +31,11 @@ import java.util.ArrayList;
  * A query that uses a filters with a script associated with them to compute the
  * score.
  */
-public class FunctionScoreQueryBuilder extends AbstractQueryBuilder<FunctionScoreQueryBuilder> {
+public class FunctionScoreQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<FunctionScoreQueryBuilder> {
 
     private final QueryBuilder queryBuilder;
 
-    private final QueryBuilder filterBuilder;
+    private Float boost;
 
     private Float maxBoost;
 
@@ -47,8 +47,6 @@ public class FunctionScoreQueryBuilder extends AbstractQueryBuilder<FunctionScor
     private ArrayList<ScoreFunctionBuilder> scoreFunctions = new ArrayList<>();
     private Float minScore = null;
 
-    static final FunctionScoreQueryBuilder PROTOTYPE = new FunctionScoreQueryBuilder();
-
     /**
      * Creates a function_score query that executes on documents that match query a query.
      * Query and filter will be wrapped into a filtered_query.
@@ -57,11 +55,9 @@ public class FunctionScoreQueryBuilder extends AbstractQueryBuilder<FunctionScor
      */
     public FunctionScoreQueryBuilder(QueryBuilder queryBuilder) {
         this.queryBuilder = queryBuilder;
-        this.filterBuilder = null;
     }
 
     public FunctionScoreQueryBuilder() {
-        this.filterBuilder = null;
         this.queryBuilder = null;
     }
 
@@ -75,7 +71,6 @@ public class FunctionScoreQueryBuilder extends AbstractQueryBuilder<FunctionScor
             throw new IllegalArgumentException("function_score: function must not be null");
         }
         queryBuilder = null;
-        filterBuilder = null;
         this.filters.add(null);
         this.scoreFunctions.add(scoreFunctionBuilder);
     }
@@ -143,6 +138,17 @@ public class FunctionScoreQueryBuilder extends AbstractQueryBuilder<FunctionScor
         return this;
     }
 
+    /**
+     * Sets the boost for this query. Documents matching this query will (in
+     * addition to the normal weightings) have their score multiplied by the
+     * boost provided.
+     */
+    @Override
+    public FunctionScoreQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
         builder.startObject(FunctionScoreQueryParser.NAME);
@@ -150,10 +156,6 @@ public class FunctionScoreQueryBuilder extends AbstractQueryBuilder<FunctionScor
             builder.field("query");
             queryBuilder.toXContent(builder, params);
         }
-        if (filterBuilder != null) {
-            builder.field("filter");
-            filterBuilder.toXContent(builder, params);
-        }
         builder.startArray("functions");
         for (int i = 0; i < filters.size(); i++) {
             builder.startObject();
@@ -175,10 +177,13 @@ public class FunctionScoreQueryBuilder extends AbstractQueryBuilder<FunctionScor
         if (maxBoost != null) {
             builder.field("max_boost", maxBoost);
         }
+        if (boost != null) {
+            builder.field("boost", boost);
+        }
         if (minScore != null) {
             builder.field("min_score", minScore);
         }
-        printBoostAndQueryName(builder);
+
         builder.endObject();
     }
 
@@ -186,9 +191,4 @@ public class FunctionScoreQueryBuilder extends AbstractQueryBuilder<FunctionScor
         this.minScore = minScore;
         return this;
     }
-
-    @Override
-    public String getWriteableName() {
-        return FunctionScoreQueryParser.NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryParser.java
index c59be16..879bfea 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryParser.java
@@ -21,7 +21,6 @@ package org.elasticsearch.index.query.functionscore;
 
 import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.ImmutableMap.Builder;
-
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.ConstantScoreQuery;
@@ -31,21 +30,17 @@ import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.lucene.search.Queries;
-import org.elasticsearch.common.lucene.search.function.CombineFunction;
-import org.elasticsearch.common.lucene.search.function.FiltersFunctionScoreQuery;
-import org.elasticsearch.common.lucene.search.function.FunctionScoreQuery;
-import org.elasticsearch.common.lucene.search.function.ScoreFunction;
-import org.elasticsearch.common.lucene.search.function.WeightFactorFunction;
+import org.elasticsearch.common.lucene.search.function.*;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.*;
-import org.elasticsearch.index.query.functionscore.factor.FactorParser;
+import org.elasticsearch.index.query.QueryParseContext;
+import org.elasticsearch.index.query.QueryParser;
+import org.elasticsearch.index.query.QueryParsingException;
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.Arrays;
 
 /**
- * Parser for function_score query
+ *
  */
 public class FunctionScoreQueryParser implements QueryParser {
 
@@ -53,7 +48,6 @@ public class FunctionScoreQueryParser implements QueryParser {
 
     // For better readability of error message
     static final String MISPLACED_FUNCTION_MESSAGE_PREFIX = "you can either define [functions] array or a single function, not both. ";
-    static final String MISPLACED_BOOST_FUNCTION_MESSAGE_SUFFIX = " did you mean [boost] instead?";
 
     public static final ParseField WEIGHT_FIELD = new ParseField("weight");
     private static final ParseField FILTER_FIELD = new ParseField("filter").withAllDeprecated("query");
@@ -82,14 +76,12 @@ public class FunctionScoreQueryParser implements QueryParser {
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         Query query = null;
         Query filter = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        String queryName = null;
+        float boost = 1.0f;
 
         FiltersFunctionScoreQuery.ScoreMode scoreMode = FiltersFunctionScoreQuery.ScoreMode.Multiply;
         ArrayList<FiltersFunctionScoreQuery.FilterFunction> filterFunctions = new ArrayList<>();
@@ -119,16 +111,14 @@ public class FunctionScoreQueryParser implements QueryParser {
                 maxBoost = parser.floatValue();
             } else if ("boost".equals(currentFieldName)) {
                 boost = parser.floatValue();
-            } else if ("_name".equals(currentFieldName)) {
-                queryName = parser.text();
             } else if ("min_score".equals(currentFieldName) || "minScore".equals(currentFieldName)) {
                 minScore = parser.floatValue();
             } else if ("functions".equals(currentFieldName)) {
                 if (singleFunctionFound) {
                     String errorString = "already found [" + singleFunctionName + "], now encountering [functions].";
-                    handleMisplacedFunctionsDeclaration(errorString, singleFunctionName);
+                    handleMisplacedFunctionsDeclaration(errorString);
                 }
-                currentFieldName = parseFiltersAndFunctions(context, parser, filterFunctions, currentFieldName);
+                currentFieldName = parseFiltersAndFunctions(parseContext, parser, filterFunctions, currentFieldName);
                 functionArrayFound = true;
             } else {
                 ScoreFunction scoreFunction;
@@ -139,11 +129,11 @@ public class FunctionScoreQueryParser implements QueryParser {
                     // we try to parse a score function. If there is no score
                     // function for the current field name,
                     // functionParserMapper.get() will throw an Exception.
-                    scoreFunction = functionParserMapper.get(parseContext, currentFieldName).parse(context, parser);
+                    scoreFunction = functionParserMapper.get(parseContext, currentFieldName).parse(parseContext, parser);
                 }
                 if (functionArrayFound) {
                     String errorString = "already found [functions] array, now encountering [" + currentFieldName + "].";
-                    handleMisplacedFunctionsDeclaration(errorString, currentFieldName);
+                    handleMisplacedFunctionsDeclaration(errorString);
                 }
                 if (filterFunctions.size() > 0) {
                     throw new ElasticsearchParseException("failed to parse [{}] query. already found function [{}], now encountering [{}]. use [functions] array if you want to define several functions.", NAME, singleFunctionName, currentFieldName);
@@ -170,7 +160,6 @@ public class FunctionScoreQueryParser implements QueryParser {
         if (maxBoost == null) {
             maxBoost = Float.MAX_VALUE;
         }
-        Query result;
         // handle cases where only one score function and no filter was
         // provided. In this case we create a FunctionScoreQuery.
         if (filterFunctions.size() == 0 || filterFunctions.size() == 1 && (filterFunctions.get(0).filter == null || Queries.isConstantMatchAllQuery(filterFunctions.get(0).filter))) {
@@ -179,8 +168,9 @@ public class FunctionScoreQueryParser implements QueryParser {
             if (combineFunction != null) {
                 theQuery.setCombineFunction(combineFunction);
             }
+            theQuery.setBoost(boost);
             theQuery.setMaxBoost(maxBoost);
-            result = theQuery;
+            return theQuery;
             // in all other cases we create a FiltersFunctionScoreQuery.
         } else {
             FiltersFunctionScoreQuery functionScoreQuery = new FiltersFunctionScoreQuery(query, scoreMode,
@@ -188,26 +178,17 @@ public class FunctionScoreQueryParser implements QueryParser {
             if (combineFunction != null) {
                 functionScoreQuery.setCombineFunction(combineFunction);
             }
-            result = functionScoreQuery;
-        }
-        result.setBoost(boost);
-        if (queryName != null) {
-            context.addNamedQuery(queryName, query);
+            functionScoreQuery.setBoost(boost);
+            return functionScoreQuery;
         }
-        return result;
     }
 
-    private void handleMisplacedFunctionsDeclaration(String errorString, String functionName) {
-        errorString = MISPLACED_FUNCTION_MESSAGE_PREFIX + errorString;
-        if (Arrays.asList(FactorParser.NAMES).contains(functionName)) {
-            errorString = errorString + MISPLACED_BOOST_FUNCTION_MESSAGE_SUFFIX;
-        }
-        throw new ElasticsearchParseException("failed to parse [{}] query. [{}]", NAME, errorString);
+    private void handleMisplacedFunctionsDeclaration(String errorString) {
+        throw new ElasticsearchParseException("failed to parse [{}] query. [{}]", NAME, MISPLACED_FUNCTION_MESSAGE_PREFIX + errorString);
     }
 
-    private String parseFiltersAndFunctions(QueryShardContext context, XContentParser parser,
+    private String parseFiltersAndFunctions(QueryParseContext parseContext, XContentParser parser,
                                             ArrayList<FiltersFunctionScoreQuery.FilterFunction> filterFunctions, String currentFieldName) throws IOException {
-        QueryParseContext parseContext = context.parseContext();
         XContentParser.Token token;
         while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
             Query filter = null;
@@ -229,7 +210,7 @@ public class FunctionScoreQueryParser implements QueryParser {
                             // functionParserMapper throws exception if parser
                             // non-existent
                             ScoreFunctionParser functionParser = functionParserMapper.get(parseContext, currentFieldName);
-                            scoreFunction = functionParser.parse(context, parser);
+                            scoreFunction = functionParser.parse(parseContext, parser);
                         }
                     }
                 }
@@ -276,16 +257,4 @@ public class FunctionScoreQueryParser implements QueryParser {
         }
         return cf;
     }
-
-    //norelease to be removed once all queries are moved over to extend BaseQueryParser
-    @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
-        Query query = parse(parseContext.shardContext());
-        return new QueryWrappingQueryBuilder(query);
-    }
-
-    @Override
-    public FunctionScoreQueryBuilder getBuilderPrototype() {
-        return FunctionScoreQueryBuilder.PROTOTYPE;
-    }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionBuilders.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionBuilders.java
index ea8e255..23c1ca1 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionBuilders.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionBuilders.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.index.query.functionscore;
 
 import org.elasticsearch.index.query.functionscore.exp.ExponentialDecayFunctionBuilder;
-import org.elasticsearch.index.query.functionscore.factor.FactorBuilder;
 import org.elasticsearch.index.query.functionscore.fieldvaluefactor.FieldValueFactorFunctionBuilder;
 import org.elasticsearch.index.query.functionscore.gauss.GaussDecayFunctionBuilder;
 import org.elasticsearch.index.query.functionscore.lin.LinearDecayFunctionBuilder;
@@ -29,8 +28,6 @@ import org.elasticsearch.index.query.functionscore.script.ScriptScoreFunctionBui
 import org.elasticsearch.index.query.functionscore.weight.WeightBuilder;
 import org.elasticsearch.script.Script;
 
-import java.util.Map;
-
 public class ScoreFunctionBuilders {
    
     public static ExponentialDecayFunctionBuilder exponentialDecayFunction(String fieldName, Object origin, Object scale) {
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParser.java
index 4065f08..74c3d08 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParser.java
@@ -21,14 +21,14 @@ package org.elasticsearch.index.query.functionscore;
 
 import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
 
 import java.io.IOException;
 
 public interface ScoreFunctionParser {
 
-    ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, QueryParsingException;
+    ScoreFunction parse(QueryParseContext parseContext, XContentParser parser) throws IOException, QueryParsingException;
 
     /**
      * Returns the name of the function, for example "linear", "gauss" etc. This
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParserMapper.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParserMapper.java
index fe33532..37a6f80 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParserMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParserMapper.java
@@ -23,7 +23,6 @@ import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.query.functionscore.exp.ExponentialDecayFunctionParser;
-import org.elasticsearch.index.query.functionscore.factor.FactorParser;
 import org.elasticsearch.index.query.functionscore.fieldvaluefactor.FieldValueFactorFunctionParser;
 import org.elasticsearch.index.query.functionscore.gauss.GaussDecayFunctionParser;
 import org.elasticsearch.index.query.functionscore.lin.LinearDecayFunctionParser;
@@ -42,8 +41,7 @@ public class ScoreFunctionParserMapper {
     @Inject
     public ScoreFunctionParserMapper(Set<ScoreFunctionParser> parsers) {
         Map<String, ScoreFunctionParser> map = new HashMap<>();
-        // build-in parsers
-        addParser(new FactorParser(), map);
+        // built-in parsers
         addParser(new ScriptScoreFunctionParser(), map);
         addParser(new GaussDecayFunctionParser(), map);
         addParser(new LinearDecayFunctionParser(), map);
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/factor/FactorBuilder.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/factor/FactorBuilder.java
deleted file mode 100644
index 3a176c4..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/factor/FactorBuilder.java
+++ /dev/null
@@ -1,67 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query.functionscore.factor;
-
-import org.elasticsearch.common.lucene.search.function.BoostScoreFunction;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilder;
-
-import java.io.IOException;
-
-/**
- * A query that simply applies the boost factor to another query (multiply it).
- *
- *
- */
-@Deprecated
-public class FactorBuilder extends ScoreFunctionBuilder {
-
-    private Float boostFactor;
-
-    /**
-     * Sets the boost factor for this query.
-     */
-    public FactorBuilder boostFactor(float boost) {
-        this.boostFactor = new Float(boost);
-        return this;
-    }
-
-    @Override
-    public void doXContent(XContentBuilder builder, Params params) throws IOException {
-        if (boostFactor != null) {
-            builder.field("boost_factor", boostFactor.floatValue());
-        }
-    }
-
-    @Override
-    public String getName() {
-        return FactorParser.NAMES[0];
-    }
-
-    @Override
-    public ScoreFunctionBuilder setWeight(float weight) {
-        throw new IllegalArgumentException(BoostScoreFunction.BOOST_WEIGHT_ERROR_MESSAGE);
-    }
-
-    @Override
-    public void buildWeight(XContentBuilder builder) throws IOException {
-        //we do not want the weight to be written for boost_factor as it does not make sense to have it
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/factor/FactorParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/factor/FactorParser.java
deleted file mode 100644
index 2635c2b..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/factor/FactorParser.java
+++ /dev/null
@@ -1,54 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query.functionscore.factor;
-
-import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.lucene.search.function.BoostScoreFunction;
-import org.elasticsearch.common.lucene.search.function.ScoreFunction;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardContext;
-import org.elasticsearch.index.query.QueryParsingException;
-import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
-
-import java.io.IOException;
-
-/**
- *
- */
-@Deprecated
-public class FactorParser implements ScoreFunctionParser {
-
-    public static String[] NAMES = { "boost_factor", "boostFactor" };
-
-    @Inject
-    public FactorParser() {
-    }
-
-    @Override
-    public ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, QueryParsingException {
-        float boostFactor = parser.floatValue();
-        return new BoostScoreFunction(boostFactor);
-    }
-
-    @Override
-    public String[] getNames() {
-        return NAMES;
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/fieldvaluefactor/FieldValueFactorFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/fieldvaluefactor/FieldValueFactorFunctionParser.java
index 140f541..6f68db5 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/fieldvaluefactor/FieldValueFactorFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/fieldvaluefactor/FieldValueFactorFunctionParser.java
@@ -19,13 +19,15 @@
 
 package org.elasticsearch.index.query.functionscore.fieldvaluefactor;
 
+import org.apache.lucene.document.FieldType;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.common.lucene.search.function.FieldValueFactorFunction;
 import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.fielddata.IndexNumericFieldData;
+import org.elasticsearch.index.fielddata.plain.DoubleArrayIndexFieldData;
+import org.elasticsearch.index.mapper.FieldMapper;
 import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
@@ -52,8 +54,7 @@ public class FieldValueFactorFunctionParser implements ScoreFunctionParser {
     public static String[] NAMES = { "field_value_factor", "fieldValueFactor" };
 
     @Override
-    public ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public ScoreFunction parse(QueryParseContext parseContext, XContentParser parser) throws IOException, QueryParsingException {
 
         String currentFieldName = null;
         String field = null;
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionParser.java
index 20c2f55..124336c 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionParser.java
@@ -27,8 +27,8 @@ import org.elasticsearch.common.lucene.search.function.RandomScoreFunction;
 import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.fielddata.IndexFieldData;
+import org.elasticsearch.index.mapper.FieldMapper;
 import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
@@ -51,8 +51,8 @@ public class RandomScoreFunctionParser implements ScoreFunctionParser {
     }
 
     @Override
-    public ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public ScoreFunction parse(QueryParseContext parseContext, XContentParser parser) throws IOException, QueryParsingException {
+
         int seed = -1;
 
         String currentFieldName = null;
@@ -90,7 +90,7 @@ public class RandomScoreFunctionParser implements ScoreFunctionParser {
         }
 
         if (seed == -1) {
-            seed = Longs.hashCode(context.nowInMillis());
+            seed = Longs.hashCode(parseContext.nowInMillis());
         }
         final ShardId shardId = SearchContext.current().indexShard().shardId();
         final int salt = (shardId.index().name().hashCode() << 10) | shardId.id();
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/script/ScriptScoreFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/script/ScriptScoreFunctionParser.java
index 2f38631..2abb7ca 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/script/ScriptScoreFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/script/ScriptScoreFunctionParser.java
@@ -25,7 +25,6 @@ import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.lucene.search.function.ScriptScoreFunction;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
@@ -57,8 +56,7 @@ public class ScriptScoreFunctionParser implements ScoreFunctionParser {
     }
 
     @Override
-    public ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public ScoreFunction parse(QueryParseContext parseContext, XContentParser parser) throws IOException, QueryParsingException {
         ScriptParameterParser scriptParameterParser = new ScriptParameterParser();
         Script script = null;
         Map<String, Object> vars = null;
@@ -100,7 +98,7 @@ public class ScriptScoreFunctionParser implements ScoreFunctionParser {
 
         SearchScript searchScript;
         try {
-            searchScript = context.scriptService().search(context.lookup(), script, ScriptContext.Standard.SEARCH);
+            searchScript = parseContext.scriptService().search(parseContext.lookup(), script, ScriptContext.Standard.SEARCH);
             return new ScriptScoreFunction(script, searchScript);
         } catch (Exception e) {
             throw new QueryParsingException(parseContext, NAMES[0] + " the script could not be loaded", e);
diff --git a/core/src/main/java/org/elasticsearch/index/query/support/BaseInnerHitBuilder.java b/core/src/main/java/org/elasticsearch/index/query/support/BaseInnerHitBuilder.java
new file mode 100644
index 0000000..48a2f59
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/index/query/support/BaseInnerHitBuilder.java
@@ -0,0 +1,376 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.query.support;
+
+import org.elasticsearch.common.Nullable;
+import org.elasticsearch.common.xcontent.ToXContent;
+import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.index.query.QueryBuilder;
+import org.elasticsearch.script.Script;
+import org.elasticsearch.search.builder.SearchSourceBuilder;
+import org.elasticsearch.search.highlight.HighlightBuilder;
+import org.elasticsearch.search.sort.SortBuilder;
+import org.elasticsearch.search.sort.SortOrder;
+
+import java.io.IOException;
+import java.util.Map;
+
+/**
+ */
+@SuppressWarnings("unchecked")
+public abstract class BaseInnerHitBuilder<T extends BaseInnerHitBuilder> implements ToXContent {
+
+    protected SearchSourceBuilder sourceBuilder;
+
+    /**
+     * The index to start to return hits from. Defaults to <tt>0</tt>.
+     */
+    public T setFrom(int from) {
+        sourceBuilder().from(from);
+        return (T) this;
+    }
+
+
+    /**
+     * The number of search hits to return. Defaults to <tt>10</tt>.
+     */
+    public T setSize(int size) {
+        sourceBuilder().size(size);
+        return (T) this;
+    }
+
+    /**
+     * Applies when sorting, and controls if scores will be tracked as well. Defaults to
+     * <tt>false</tt>.
+     */
+    public T setTrackScores(boolean trackScores) {
+        sourceBuilder().trackScores(trackScores);
+        return (T) this;
+    }
+
+    /**
+     * Should each {@link org.elasticsearch.search.SearchHit} be returned with an
+     * explanation of the hit (ranking).
+     */
+    public T setExplain(boolean explain) {
+        sourceBuilder().explain(explain);
+        return (T) this;
+    }
+
+    /**
+     * Should each {@link org.elasticsearch.search.SearchHit} be returned with its
+     * version.
+     */
+    public T setVersion(boolean version) {
+        sourceBuilder().version(version);
+        return (T) this;
+    }
+
+    /**
+     * Add a stored field to be loaded and returned with the inner hit.
+     */
+    public T field(String name) {
+        sourceBuilder().field(name);
+        return (T) this;
+    }
+
+    /**
+     * Sets no fields to be loaded, resulting in only id and type to be returned per field.
+     */
+    public T setNoFields() {
+        sourceBuilder().noFields();
+        return (T) this;
+    }
+
+    /**
+     * Indicates whether the response should contain the stored _source for every hit
+     */
+    public T setFetchSource(boolean fetch) {
+        sourceBuilder().fetchSource(fetch);
+        return (T) this;
+    }
+
+    /**
+     * Indicate that _source should be returned with every hit, with an "include" and/or "exclude" set which can include simple wildcard
+     * elements.
+     *
+     * @param include An optional include (optionally wildcarded) pattern to filter the returned _source
+     * @param exclude An optional exclude (optionally wildcarded) pattern to filter the returned _source
+     */
+    public T setFetchSource(@Nullable String include, @Nullable String exclude) {
+        sourceBuilder().fetchSource(include, exclude);
+        return (T) this;
+    }
+
+    /**
+     * Indicate that _source should be returned with every hit, with an "include" and/or "exclude" set which can include simple wildcard
+     * elements.
+     *
+     * @param includes An optional list of include (optionally wildcarded) pattern to filter the returned _source
+     * @param excludes An optional list of exclude (optionally wildcarded) pattern to filter the returned _source
+     */
+    public T setFetchSource(@Nullable String[] includes, @Nullable String[] excludes) {
+        sourceBuilder().fetchSource(includes, excludes);
+        return (T) this;
+    }
+
+    /**
+     * Adds a field data based field to load and return. The field does not have to be stored,
+     * but its recommended to use non analyzed or numeric fields.
+     *
+     * @param name The field to get from the field data cache
+     */
+    public T addFieldDataField(String name) {
+        sourceBuilder().fieldDataField(name);
+        return (T) this;
+    }
+
+    /**
+     * Adds a script based field to load and return. The field does not have to be stored,
+     * but its recommended to use non analyzed or numeric fields.
+     *
+     * @param name   The name that will represent this value in the return hit
+     * @param script The script to use
+     */
+    public T addScriptField(String name, Script script) {
+        sourceBuilder().scriptField(name, script);
+        return (T) this;
+    }
+
+    /**
+     * Adds a sort against the given field name and the sort ordering.
+     *
+     * @param field The name of the field
+     * @param order The sort ordering
+     */
+    public T addSort(String field, SortOrder order) {
+        sourceBuilder().sort(field, order);
+        return (T) this;
+    }
+
+    /**
+     * Adds a generic sort builder.
+     *
+     * @see org.elasticsearch.search.sort.SortBuilders
+     */
+    public T addSort(SortBuilder sort) {
+        sourceBuilder().sort(sort);
+        return (T) this;
+    }
+
+    public HighlightBuilder highlightBuilder() {
+        return sourceBuilder().highlighter();
+    }
+
+    /**
+     * Adds a field to be highlighted with default fragment size of 100 characters, and
+     * default number of fragments of 5.
+     *
+     * @param name The field to highlight
+     */
+    public T addHighlightedField(String name) {
+        highlightBuilder().field(name);
+        return (T) this;
+    }
+
+
+    /**
+     * Adds a field to be highlighted with a provided fragment size (in characters), and
+     * default number of fragments of 5.
+     *
+     * @param name         The field to highlight
+     * @param fragmentSize The size of a fragment in characters
+     */
+    public T addHighlightedField(String name, int fragmentSize) {
+        highlightBuilder().field(name, fragmentSize);
+        return (T) this;
+    }
+
+    /**
+     * Adds a field to be highlighted with a provided fragment size (in characters), and
+     * a provided (maximum) number of fragments.
+     *
+     * @param name              The field to highlight
+     * @param fragmentSize      The size of a fragment in characters
+     * @param numberOfFragments The (maximum) number of fragments
+     */
+    public T addHighlightedField(String name, int fragmentSize, int numberOfFragments) {
+        highlightBuilder().field(name, fragmentSize, numberOfFragments);
+        return (T) this;
+    }
+
+    /**
+     * Adds a field to be highlighted with a provided fragment size (in characters),
+     * a provided (maximum) number of fragments and an offset for the highlight.
+     *
+     * @param name              The field to highlight
+     * @param fragmentSize      The size of a fragment in characters
+     * @param numberOfFragments The (maximum) number of fragments
+     */
+    public T addHighlightedField(String name, int fragmentSize, int numberOfFragments,
+                                        int fragmentOffset) {
+        highlightBuilder().field(name, fragmentSize, numberOfFragments, fragmentOffset);
+        return (T) this;
+    }
+
+    /**
+     * Adds a highlighted field.
+     */
+    public T addHighlightedField(HighlightBuilder.Field field) {
+        highlightBuilder().field(field);
+        return (T) this;
+    }
+
+    /**
+     * Set a tag scheme that encapsulates a built in pre and post tags. The allows schemes
+     * are <tt>styled</tt> and <tt>default</tt>.
+     *
+     * @param schemaName The tag scheme name
+     */
+    public T setHighlighterTagsSchema(String schemaName) {
+        highlightBuilder().tagsSchema(schemaName);
+        return (T) this;
+    }
+
+    public T setHighlighterFragmentSize(Integer fragmentSize) {
+        highlightBuilder().fragmentSize(fragmentSize);
+        return (T) this;
+    }
+
+    public T setHighlighterNumOfFragments(Integer numOfFragments) {
+        highlightBuilder().numOfFragments(numOfFragments);
+        return (T) this;
+    }
+
+    public T setHighlighterFilter(Boolean highlightFilter) {
+        highlightBuilder().highlightFilter(highlightFilter);
+        return (T) this;
+    }
+
+    /**
+     * The encoder to set for highlighting
+     */
+    public T setHighlighterEncoder(String encoder) {
+        highlightBuilder().encoder(encoder);
+        return (T) this;
+    }
+
+    /**
+     * Explicitly set the pre tags that will be used for highlighting.
+     */
+    public T setHighlighterPreTags(String... preTags) {
+        highlightBuilder().preTags(preTags);
+        return (T) this;
+    }
+
+    /**
+     * Explicitly set the post tags that will be used for highlighting.
+     */
+    public T setHighlighterPostTags(String... postTags) {
+        highlightBuilder().postTags(postTags);
+        return (T) this;
+    }
+
+    /**
+     * The order of fragments per field. By default, ordered by the order in the
+     * highlighted text. Can be <tt>score</tt>, which then it will be ordered
+     * by score of the fragments.
+     */
+    public T setHighlighterOrder(String order) {
+        highlightBuilder().order(order);
+        return (T) this;
+    }
+
+    public T setHighlighterRequireFieldMatch(boolean requireFieldMatch) {
+        highlightBuilder().requireFieldMatch(requireFieldMatch);
+        return (T) this;
+    }
+
+    public T setHighlighterBoundaryMaxScan(Integer boundaryMaxScan) {
+        highlightBuilder().boundaryMaxScan(boundaryMaxScan);
+        return (T) this;
+    }
+
+    public T setHighlighterBoundaryChars(char[] boundaryChars) {
+        highlightBuilder().boundaryChars(boundaryChars);
+        return (T) this;
+    }
+
+    /**
+     * The highlighter type to use.
+     */
+    public T setHighlighterType(String type) {
+        highlightBuilder().highlighterType(type);
+        return (T) this;
+    }
+
+    public T setHighlighterFragmenter(String fragmenter) {
+        highlightBuilder().fragmenter(fragmenter);
+        return (T) this;
+    }
+
+    /**
+     * Sets a query to be used for highlighting all fields instead of the search query.
+     */
+    public T setHighlighterQuery(QueryBuilder highlightQuery) {
+        highlightBuilder().highlightQuery(highlightQuery);
+        return (T) this;
+    }
+
+    /**
+     * Sets the size of the fragment to return from the beginning of the field if there are no matches to
+     * highlight and the field doesn't also define noMatchSize.
+     * @param noMatchSize integer to set or null to leave out of request.  default is null.
+     * @return this builder for chaining
+     */
+    public T setHighlighterNoMatchSize(Integer noMatchSize) {
+        highlightBuilder().noMatchSize(noMatchSize);
+        return (T) this;
+    }
+
+    /**
+     * Sets the maximum number of phrases the fvh will consider if the field doesn't also define phraseLimit.
+     */
+    public T setHighlighterPhraseLimit(Integer phraseLimit) {
+        highlightBuilder().phraseLimit(phraseLimit);
+        return (T) this;
+    }
+
+    public T setHighlighterOptions(Map<String, Object> options) {
+        highlightBuilder().options(options);
+        return (T) this;
+    }
+
+    protected SearchSourceBuilder sourceBuilder() {
+        if (sourceBuilder == null) {
+            sourceBuilder = new SearchSourceBuilder();
+        }
+        return sourceBuilder;
+    }
+
+    @Override
+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
+        if (sourceBuilder != null) {
+            sourceBuilder.innerToXContent(builder, params);
+        }
+        return builder;
+    }
+
+}
diff --git a/core/src/main/java/org/elasticsearch/index/query/support/InnerHitsQueryParserHelper.java b/core/src/main/java/org/elasticsearch/index/query/support/InnerHitsQueryParserHelper.java
index bb581a8..b4d3e63 100644
--- a/core/src/main/java/org/elasticsearch/index/query/support/InnerHitsQueryParserHelper.java
+++ b/core/src/main/java/org/elasticsearch/index/query/support/InnerHitsQueryParserHelper.java
@@ -21,8 +21,6 @@ package org.elasticsearch.index.query.support;
 
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardContext;
-import org.elasticsearch.index.query.QueryShardException;
 import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.search.fetch.fielddata.FieldDataFieldsParseElement;
@@ -53,12 +51,13 @@ public class InnerHitsQueryParserHelper {
         this.fieldDataFieldsParseElement = fieldDataFieldsParseElement;
     }
 
-    public InnerHitsSubSearchContext parse(XContentParser parser) throws IOException {
+    public InnerHitsSubSearchContext parse(QueryParseContext parserContext) throws IOException, QueryParsingException {
         String fieldName = null;
         XContentParser.Token token;
         String innerHitName = null;
         SubSearchContext subSearchContext = new SubSearchContext(SearchContext.current());
         try {
+            XContentParser parser = parserContext.parser();
             while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
                 if (token == XContentParser.Token.FIELD_NAME) {
                     fieldName = parser.currentName();
@@ -73,7 +72,7 @@ public class InnerHitsQueryParserHelper {
                 }
             }
         } catch (Exception e) {
-            throw new IOException("Failed to parse [_inner_hits]");
+            throw new QueryParsingException(parserContext, "Failed to parse [_inner_hits]", e);
         }
         return new InnerHitsSubSearchContext(innerHitName, subSearchContext);
     }
diff --git a/core/src/main/java/org/elasticsearch/index/query/support/NestedInnerQueryParseSupport.java b/core/src/main/java/org/elasticsearch/index/query/support/NestedInnerQueryParseSupport.java
index 717fe3f..49610a7 100644
--- a/core/src/main/java/org/elasticsearch/index/query/support/NestedInnerQueryParseSupport.java
+++ b/core/src/main/java/org/elasticsearch/index/query/support/NestedInnerQueryParseSupport.java
@@ -28,9 +28,8 @@ import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentHelper;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.mapper.object.ObjectMapper;
-import org.elasticsearch.index.query.QueryShardContext;
-import org.elasticsearch.index.query.QueryShardException;
 import org.elasticsearch.index.query.QueryParseContext;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
@@ -42,7 +41,6 @@ import java.io.IOException;
  */
 public class NestedInnerQueryParseSupport {
 
-    protected final QueryShardContext shardContext;
     protected final QueryParseContext parseContext;
 
     private BytesReference source;
@@ -62,15 +60,12 @@ public class NestedInnerQueryParseSupport {
     private ObjectMapper parentObjectMapper;
 
     public NestedInnerQueryParseSupport(XContentParser parser, SearchContext searchContext) {
-        parseContext = searchContext.queryParserService().getShardContext().parseContext();
-        shardContext = searchContext.queryParserService().getShardContext();
-        shardContext.reset(parser);
-
+        parseContext = searchContext.queryParserService().getParseContext();
+        parseContext.reset(parser);
     }
 
-    public NestedInnerQueryParseSupport(QueryShardContext context) {
-        this.parseContext = context.parseContext();
-        this.shardContext = context;
+    public NestedInnerQueryParseSupport(QueryParseContext parseContext) {
+        this.parseContext = parseContext;
     }
 
     public void query() throws IOException {
@@ -108,10 +103,10 @@ public class NestedInnerQueryParseSupport {
             return innerQuery;
         } else {
             if (path == null) {
-                throw new QueryShardException(shardContext, "[nested] requires 'path' field");
+                throw new QueryParsingException(parseContext, "[nested] requires 'path' field");
             }
             if (!queryFound) {
-                throw new QueryShardException(shardContext, "[nested] requires either 'query' or 'filter' field");
+                throw new QueryParsingException(parseContext, "[nested] requires either 'query' or 'filter' field");
             }
 
             XContentParser old = parseContext.parser();
@@ -137,10 +132,10 @@ public class NestedInnerQueryParseSupport {
             return innerFilter;
         } else {
             if (path == null) {
-                throw new QueryShardException(shardContext, "[nested] requires 'path' field");
+                throw new QueryParsingException(parseContext, "[nested] requires 'path' field");
             }
             if (!filterFound) {
-                throw new QueryShardException(shardContext, "[nested] requires either 'query' or 'filter' field");
+                throw new QueryParsingException(parseContext, "[nested] requires either 'query' or 'filter' field");
             }
 
             setPathLevel();
@@ -160,12 +155,12 @@ public class NestedInnerQueryParseSupport {
 
     public void setPath(String path) {
         this.path = path;
-        nestedObjectMapper = shardContext.getObjectMapper(path);
+        nestedObjectMapper = parseContext.getObjectMapper(path);
         if (nestedObjectMapper == null) {
-            throw new QueryShardException(shardContext, "[nested] failed to find nested object under path [" + path + "]");
+            throw new QueryParsingException(parseContext, "[nested] failed to find nested object under path [" + path + "]");
         }
         if (!nestedObjectMapper.nested().isNested()) {
-            throw new QueryShardException(shardContext, "[nested] nested object under path [" + path + "] is not of nested type");
+            throw new QueryParsingException(parseContext, "[nested] nested object under path [" + path + "] is not of nested type");
         }
     }
 
@@ -190,18 +185,18 @@ public class NestedInnerQueryParseSupport {
     }
 
     private void setPathLevel() {
-        ObjectMapper objectMapper = shardContext.nestedScope().getObjectMapper();
+        ObjectMapper objectMapper = parseContext.nestedScope().getObjectMapper();
         if (objectMapper == null) {
-            parentFilter = shardContext.bitsetFilter(Queries.newNonNestedFilter());
+            parentFilter = parseContext.bitsetFilter(Queries.newNonNestedFilter());
         } else {
-            parentFilter = shardContext.bitsetFilter(objectMapper.nestedTypeFilter());
+            parentFilter = parseContext.bitsetFilter(objectMapper.nestedTypeFilter());
         }
         childFilter = nestedObjectMapper.nestedTypeFilter();
-        parentObjectMapper = shardContext.nestedScope().nextLevel(nestedObjectMapper);
+        parentObjectMapper = parseContext.nestedScope().nextLevel(nestedObjectMapper);
     }
 
     private void resetPathLevel() {
-        shardContext.nestedScope().previousLevel();
+        parseContext.nestedScope().previousLevel();
     }
 
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/support/QueryInnerHitBuilder.java b/core/src/main/java/org/elasticsearch/index/query/support/QueryInnerHitBuilder.java
new file mode 100644
index 0000000..71229ab
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/index/query/support/QueryInnerHitBuilder.java
@@ -0,0 +1,51 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.query.support;
+
+import org.elasticsearch.common.xcontent.XContentBuilder;
+
+import java.io.IOException;
+
+/**
+ */
+public class QueryInnerHitBuilder extends BaseInnerHitBuilder<QueryInnerHitBuilder> {
+
+    private String name;
+
+    /**
+     * Set the key name to be used in the response.
+     *
+     * Defaults to the path if used in nested query, child type if used in has_child query and parent type if used in has_parent.
+     */
+    public QueryInnerHitBuilder setName(String name) {
+        this.name = name;
+        return this;
+    }
+
+    @Override
+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
+        super.toXContent(builder, params);
+        if (name != null) {
+            builder.field("name", name);
+        }
+        return builder;
+    }
+
+}
diff --git a/core/src/main/java/org/elasticsearch/index/query/support/QueryInnerHits.java b/core/src/main/java/org/elasticsearch/index/query/support/QueryInnerHits.java
deleted file mode 100644
index fc9b154..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/support/QueryInnerHits.java
+++ /dev/null
@@ -1,110 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.query.support;
-
-import org.elasticsearch.ElasticsearchException;
-import org.elasticsearch.action.support.ToXContentToBytes;
-import org.elasticsearch.common.bytes.BytesReference;
-import org.elasticsearch.common.io.stream.BytesStreamOutput;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.io.stream.Writeable;
-import org.elasticsearch.common.xcontent.*;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsBuilder;
-
-import java.io.IOException;
-
-/**
- */
-public class QueryInnerHits extends ToXContentToBytes implements Writeable<QueryInnerHits> {
-    private final BytesReference queryInnerHitsSearchSource;
-
-    public QueryInnerHits(StreamInput input) throws IOException {
-        queryInnerHitsSearchSource = input.readBytesReference();
-    }
-
-    public QueryInnerHits(XContentParser parser) throws IOException {
-        BytesStreamOutput out = new BytesStreamOutput();
-        try (XContentBuilder builder = XContentFactory.cborBuilder(out)) {
-            builder.copyCurrentStructure(parser);
-            queryInnerHitsSearchSource = builder.bytes();
-        }
-    }
-
-    public QueryInnerHits() {
-        this(null, null);
-    }
-
-    public QueryInnerHits(String name, InnerHitsBuilder.InnerHit innerHit) {
-        BytesStreamOutput out = new BytesStreamOutput();
-        try (XContentBuilder builder = XContentFactory.cborBuilder(out)) {
-            builder.startObject();
-            if (name != null) {
-                builder.field("name", name);
-            }
-            if (innerHit != null) {
-                innerHit.toXContent(builder, ToXContent.EMPTY_PARAMS);
-            }
-            builder.endObject();
-            this.queryInnerHitsSearchSource = builder.bytes();
-        } catch (IOException e) {
-            throw new ElasticsearchException("failed to build xcontent", e);
-        }
-    }
-
-    @Override
-    public QueryInnerHits readFrom(StreamInput in) throws IOException {
-        return new QueryInnerHits(in);
-    }
-
-    @Override
-    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.field("inner_hits");
-        try (XContentParser parser = XContentType.CBOR.xContent().createParser(queryInnerHitsSearchSource)) {
-            builder.copyCurrentStructure(parser);
-        }
-        return builder;
-    }
-
-    @Override
-    public void writeTo(StreamOutput out) throws IOException {
-        out.writeBytesReference(queryInnerHitsSearchSource);
-    }
-
-    public XContentParser getXcontentParser() throws IOException {
-        return XContentType.CBOR.xContent().createParser(queryInnerHitsSearchSource);
-    }
-
-    @Override
-    public boolean equals(Object o) {
-        if (this == o) return true;
-        if (o == null || getClass() != o.getClass()) return false;
-
-        QueryInnerHits that = (QueryInnerHits) o;
-
-        return queryInnerHitsSearchSource.equals(that.queryInnerHitsSearchSource);
-
-    }
-
-    @Override
-    public int hashCode() {
-        return queryInnerHitsSearchSource.hashCode();
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/support/QueryParsers.java b/core/src/main/java/org/elasticsearch/index/query/support/QueryParsers.java
index a500393..1a12c74 100644
--- a/core/src/main/java/org/elasticsearch/index/query/support/QueryParsers.java
+++ b/core/src/main/java/org/elasticsearch/index/query/support/QueryParsers.java
@@ -29,12 +29,12 @@ import org.elasticsearch.common.ParseFieldMatcher;
  */
 public final class QueryParsers {
 
-    public static final ParseField CONSTANT_SCORE = new ParseField("constant_score", "constant_score_auto", "constant_score_filter");
-    public static final ParseField SCORING_BOOLEAN = new ParseField("scoring_boolean");
-    public static final ParseField CONSTANT_SCORE_BOOLEAN = new ParseField("constant_score_boolean");
-    public static final ParseField TOP_TERMS = new ParseField("top_terms_");
-    public static final ParseField TOP_TERMS_BOOST = new ParseField("top_terms_boost_");
-    public static final ParseField TOP_TERMS_BLENDED_FREQS = new ParseField("top_terms_blended_freqs_");
+    private static final ParseField CONSTANT_SCORE = new ParseField("constant_score", "constant_score_auto", "constant_score_filter");
+    private static final ParseField SCORING_BOOLEAN = new ParseField("scoring_boolean");
+    private static final ParseField CONSTANT_SCORE_BOOLEAN = new ParseField("constant_score_boolean");
+    private static final ParseField TOP_TERMS = new ParseField("top_terms_");
+    private static final ParseField TOP_TERMS_BOOST = new ParseField("top_terms_boost_");
+    private static final ParseField TOP_TERMS_BLENDED_FREQS = new ParseField("top_terms_blended_freqs_");
 
     private QueryParsers() {
 
diff --git a/core/src/main/java/org/elasticsearch/index/query/support/XContentStructure.java b/core/src/main/java/org/elasticsearch/index/query/support/XContentStructure.java
new file mode 100644
index 0000000..37716d1
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/index/query/support/XContentStructure.java
@@ -0,0 +1,136 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.query.support;
+
+import org.apache.lucene.search.Query;
+import org.elasticsearch.common.Nullable;
+import org.elasticsearch.common.bytes.BytesReference;
+import org.elasticsearch.common.xcontent.XContentFactory;
+import org.elasticsearch.common.xcontent.XContentHelper;
+import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.query.QueryParseContext;
+
+import java.io.IOException;
+
+/**
+ * XContentStructure is a class used to capture a subset of query, to be parsed
+ * at a later time when more information (in this case, types) is available.
+ * Note that using this class requires copying the parser's data, which will
+ * result in additional overhead versus parsing the inner query/filter
+ * immediately, however, the extra overhead means that the type not be
+ * extracted prior to query parsing (in the case of unordered JSON).
+ */
+public abstract class XContentStructure {
+
+    private final QueryParseContext parseContext;
+    private BytesReference innerBytes;
+
+    /**
+     * Create a new XContentStructure for the current parsing context.
+     */
+    public XContentStructure(QueryParseContext queryParseContext) {
+        this.parseContext = queryParseContext;
+    }
+
+    /**
+     * "Freeze" the parsing content, which means copying the current parser's
+     * structure into an internal {@link BytesReference} to be parsed later.
+     * @return the original XContentStructure object
+     */
+    public XContentStructure freeze() throws IOException {
+        this.bytes(XContentFactory.smileBuilder().copyCurrentStructure(parseContext.parser()).bytes());
+        return this;
+    }
+
+    /**
+     * Set the bytes to be used for parsing
+     */
+    public void bytes(BytesReference innerBytes) {
+        this.innerBytes = innerBytes;
+    }
+
+    /**
+     * Return the bytes that are going to be used for parsing
+     */
+    public BytesReference bytes() {
+        return this.innerBytes;
+    }
+
+    /**
+     * Use the captured bytes to parse the inner query using the specified
+     * types. The original QueryParseContext's parser is switched during this
+     * parsing, so this method is NOT thread-safe.
+     * @param types types to be used during the inner query parsing
+     * @return {@link Query} parsed from the bytes captured in {@code freeze()}
+     */
+    public Query asQuery(String... types) throws IOException {
+        BytesReference br = this.bytes();
+        assert br != null : "innerBytes must be set with .bytes(bytes) or .freeze() before parsing";
+        XContentParser innerParser = XContentHelper.createParser(br);
+        String[] origTypes = QueryParseContext.setTypesWithPrevious(types);
+        XContentParser old = parseContext.parser();
+        parseContext.parser(innerParser);
+        try {
+            return parseContext.parseInnerQuery();
+        } finally {
+            parseContext.parser(old);
+            QueryParseContext.setTypes(origTypes);
+        }
+    }
+
+    /**
+     * InnerQuery is an extension of {@code XContentStructure} that eagerly
+     * parses the query in a streaming manner if the types are available at
+     * construction time.
+     */
+    public static class InnerQuery extends XContentStructure {
+        private Query query = null;
+        private boolean queryParsed = false;
+        public InnerQuery(QueryParseContext parseContext1, @Nullable String... types) throws IOException {
+            super(parseContext1);
+            if (types != null) {
+                String[] origTypes = QueryParseContext.setTypesWithPrevious(types);
+                try {
+                    query = parseContext1.parseInnerQuery();
+                    queryParsed = true;
+                } finally {
+                    QueryParseContext.setTypes(origTypes);
+                }
+            } else {
+                BytesReference innerBytes = XContentFactory.smileBuilder().copyCurrentStructure(parseContext1.parser()).bytes();
+                super.bytes(innerBytes);
+            }
+        }
+
+        /**
+         * Return the query represented by the XContentStructure object,
+         * returning the cached Query if it has already been parsed.
+         * @param types types to be used during the inner query parsing
+         */
+        @Override
+        public Query asQuery(String... types) throws IOException {
+            if (!queryParsed) { // query can be null
+                this.query = super.asQuery(types);
+            }
+            return this.query;
+        }
+    }
+
+}
diff --git a/core/src/main/java/org/elasticsearch/index/search/MatchQuery.java b/core/src/main/java/org/elasticsearch/index/search/MatchQuery.java
index f0cb1d4..fb5fff8 100644
--- a/core/src/main/java/org/elasticsearch/index/search/MatchQuery.java
+++ b/core/src/main/java/org/elasticsearch/index/search/MatchQuery.java
@@ -25,16 +25,12 @@ import org.apache.lucene.queries.ExtendedCommonTermsQuery;
 import org.apache.lucene.search.*;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.util.QueryBuilder;
-import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.common.Nullable;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.io.stream.Writeable;
 import org.elasticsearch.common.lucene.search.MultiPhrasePrefixQuery;
 import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.unit.Fuzziness;
 import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
@@ -42,92 +38,18 @@ import java.util.List;
 
 public class MatchQuery {
 
-    public static enum Type implements Writeable<Type> {
-        /**
-         * The text is analyzed and terms are added to a boolean query.
-         */
-        BOOLEAN(0),
-        /**
-         * The text is analyzed and used as a phrase query.
-         */
-        PHRASE(1),
-        /**
-         * The text is analyzed and used in a phrase query, with the last term acting as a prefix.
-         */
-        PHRASE_PREFIX(2);
-
-        private final int ordinal;
-
-        private static final Type PROTOTYPE = BOOLEAN;
-
-        private Type(int ordinal) {
-            this.ordinal = ordinal;
-        }
-
-        @Override
-        public Type readFrom(StreamInput in) throws IOException {
-            int ord = in.readVInt();
-            for (Type type : Type.values()) {
-                if (type.ordinal == ord) {
-                    return type;
-                }
-            }
-            throw new ElasticsearchException("unknown serialized type [" + ord + "]");
-        }
-
-        public static Type readTypeFrom(StreamInput in) throws IOException {
-            return PROTOTYPE.readFrom(in);
-        }
-
-        @Override
-        public void writeTo(StreamOutput out) throws IOException {
-            out.writeVInt(this.ordinal);
-        }
+    public static enum Type {
+        BOOLEAN,
+        PHRASE,
+        PHRASE_PREFIX
     }
 
-    public static enum ZeroTermsQuery implements Writeable<ZeroTermsQuery> {
-        NONE(0),
-        ALL(1);
-
-        private final int ordinal;
-
-        private static final ZeroTermsQuery PROTOTYPE = NONE;
-
-        private ZeroTermsQuery(int ordinal) {
-            this.ordinal = ordinal;
-        }
-
-        @Override
-        public ZeroTermsQuery readFrom(StreamInput in) throws IOException {
-            int ord = in.readVInt();
-            for (ZeroTermsQuery zeroTermsQuery : ZeroTermsQuery.values()) {
-                if (zeroTermsQuery.ordinal == ord) {
-                    return zeroTermsQuery;
-                }
-            }
-            throw new ElasticsearchException("unknown serialized type [" + ord + "]");
-        }
-
-        public static ZeroTermsQuery readZeroTermsQueryFrom(StreamInput in) throws IOException {
-            return PROTOTYPE.readFrom(in);
-        }
-
-        @Override
-        public void writeTo(StreamOutput out) throws IOException {
-            out.writeVInt(this.ordinal);
-        }
+    public static enum ZeroTermsQuery {
+        NONE,
+        ALL
     }
 
-    /** the default phrase slop */
-    public static final int DEFAULT_PHRASE_SLOP = 0;
-
-    /** the default leniency setting */
-    public static final boolean DEFAULT_LENIENCY = false;
-
-    /** the default zero terms query */
-    public static final ZeroTermsQuery DEFAULT_ZERO_TERMS_QUERY = ZeroTermsQuery.NONE;
-
-    protected final QueryShardContext context;
+    protected final QueryParseContext parseContext;
 
     protected String analyzer;
 
@@ -135,26 +57,26 @@ public class MatchQuery {
 
     protected boolean enablePositionIncrements = true;
 
-    protected int phraseSlop = DEFAULT_PHRASE_SLOP;
+    protected int phraseSlop = 0;
 
     protected Fuzziness fuzziness = null;
-
+    
     protected int fuzzyPrefixLength = FuzzyQuery.defaultPrefixLength;
-
+    
     protected int maxExpansions = FuzzyQuery.defaultMaxExpansions;
 
     protected boolean transpositions = FuzzyQuery.defaultTranspositions;
 
     protected MultiTermQuery.RewriteMethod fuzzyRewriteMethod;
 
-    protected boolean lenient = DEFAULT_LENIENCY;
-
-    protected ZeroTermsQuery zeroTermsQuery = DEFAULT_ZERO_TERMS_QUERY;
+    protected boolean lenient;
 
+    protected ZeroTermsQuery zeroTermsQuery = ZeroTermsQuery.NONE;
+    
     protected Float commonTermsCutoff = null;
-
-    public MatchQuery(QueryShardContext context) {
-        this.context = context;
+    
+    public MatchQuery(QueryParseContext parseContext) {
+        this.parseContext = parseContext;
     }
 
     public void setAnalyzer(String analyzer) {
@@ -164,9 +86,9 @@ public class MatchQuery {
     public void setOccur(BooleanClause.Occur occur) {
         this.occur = occur;
     }
-
-    public void setCommonTermsCutoff(Float cutoff) {
-        this.commonTermsCutoff = cutoff;
+    
+    public void setCommonTermsCutoff(float cutoff) {
+        this.commonTermsCutoff = Float.valueOf(cutoff);
     }
 
     public void setEnablePositionIncrements(boolean enablePositionIncrements) {
@@ -212,11 +134,11 @@ public class MatchQuery {
     protected Analyzer getAnalyzer(MappedFieldType fieldType) {
         if (this.analyzer == null) {
             if (fieldType != null) {
-                return context.getSearchAnalyzer(fieldType);
+                return parseContext.getSearchAnalyzer(fieldType);
             }
-            return context.mapperService().searchAnalyzer();
+            return parseContext.mapperService().searchAnalyzer();
         } else {
-            Analyzer analyzer = context.mapperService().analysisService().analyzer(this.analyzer);
+            Analyzer analyzer = parseContext.mapperService().analysisService().analyzer(this.analyzer);
             if (analyzer == null) {
                 throw new IllegalArgumentException("No analyzer found for [" + this.analyzer + "]");
             }
@@ -226,7 +148,7 @@ public class MatchQuery {
 
     public Query parse(Type type, String fieldName, Object value) throws IOException {
         final String field;
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
         if (fieldType != null) {
             field = fieldType.names().indexName();
         } else {
@@ -235,14 +157,14 @@ public class MatchQuery {
 
         if (fieldType != null && fieldType.useTermQueryWithQueryString() && !forceAnalyzeQueryString()) {
             try {
-                return fieldType.termQuery(value, context);
+                return fieldType.termQuery(value, parseContext);
             } catch (RuntimeException e) {
                 if (lenient) {
                     return null;
                 }
                 throw e;
             }
-
+            
         }
         Analyzer analyzer = getAnalyzer(fieldType);
         assert analyzer != null;
@@ -276,7 +198,7 @@ public class MatchQuery {
     }
 
     protected Query zeroTermsQuery() {
-        return zeroTermsQuery == DEFAULT_ZERO_TERMS_QUERY ? Queries.newMatchNoDocsQuery() : Queries.newMatchAllQuery();
+        return zeroTermsQuery == ZeroTermsQuery.NONE ? Queries.newMatchNoDocsQuery() : Queries.newMatchAllQuery();
     }
 
     private class MatchQueryBuilder extends QueryBuilder {
diff --git a/core/src/main/java/org/elasticsearch/index/search/MultiMatchQuery.java b/core/src/main/java/org/elasticsearch/index/search/MultiMatchQuery.java
index 5fb2db0..08cc55f 100644
--- a/core/src/main/java/org/elasticsearch/index/search/MultiMatchQuery.java
+++ b/core/src/main/java/org/elasticsearch/index/search/MultiMatchQuery.java
@@ -31,7 +31,7 @@ import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.query.MultiMatchQueryBuilder;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -47,10 +47,10 @@ public class MultiMatchQuery extends MatchQuery {
         this.groupTieBreaker = tieBreaker;
     }
 
-    public MultiMatchQuery(QueryShardContext context) {
-        super(context);
+    public MultiMatchQuery(QueryParseContext parseContext) {
+        super(parseContext);
     }
-
+    
     private Query parseAndApply(Type type, String fieldName, Object value, String minimumShouldMatch, Float boostValue) throws IOException {
         Query query = parse(type, fieldName, value);
         if (query instanceof BooleanQuery) {
@@ -162,7 +162,7 @@ public class MultiMatchQuery extends MatchQuery {
             List<Tuple<String, Float>> missing = new ArrayList<>();
             for (Map.Entry<String, Float> entry : fieldNames.entrySet()) {
                 String name = entry.getKey();
-                MappedFieldType fieldType = context.fieldMapper(name);
+                MappedFieldType fieldType = parseContext.fieldMapper(name);
                 if (fieldType != null) {
                     Analyzer actualAnalyzer = getAnalyzer(fieldType);
                     name = fieldType.names().indexName();
diff --git a/core/src/main/java/org/elasticsearch/index/search/morelikethis/MoreLikeThisFetchService.java b/core/src/main/java/org/elasticsearch/index/search/morelikethis/MoreLikeThisFetchService.java
new file mode 100644
index 0000000..49643aa
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/index/search/morelikethis/MoreLikeThisFetchService.java
@@ -0,0 +1,100 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.search.morelikethis;
+
+import org.apache.lucene.index.Fields;
+import org.elasticsearch.action.termvectors.MultiTermVectorsItemResponse;
+import org.elasticsearch.action.termvectors.MultiTermVectorsRequest;
+import org.elasticsearch.action.termvectors.MultiTermVectorsResponse;
+import org.elasticsearch.action.termvectors.TermVectorsResponse;
+import org.elasticsearch.client.Client;
+import org.elasticsearch.common.Nullable;
+import org.elasticsearch.common.component.AbstractComponent;
+import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.index.query.MoreLikeThisQueryBuilder.Item;
+import org.elasticsearch.search.internal.SearchContext;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+
+/**
+ *
+ */
+public class MoreLikeThisFetchService extends AbstractComponent {
+
+    private final Client client;
+
+    @Inject
+    public MoreLikeThisFetchService(Client client, Settings settings) {
+        super(settings);
+        this.client = client;
+    }
+
+    public Fields[] fetch(List<Item> items) throws IOException {
+        return getFieldsFor(fetchResponse(items, null, SearchContext.current()), items);
+    }
+
+    public MultiTermVectorsResponse fetchResponse(List<Item> likeItems, @Nullable List<Item> unlikeItems,
+                                                  SearchContext searchContext) throws IOException {
+        MultiTermVectorsRequest request = new MultiTermVectorsRequest();
+        for (Item item : likeItems) {
+            request.add(item.toTermVectorsRequest());
+        }
+        if (unlikeItems != null) {
+            for (Item item : unlikeItems) {
+                request.add(item.toTermVectorsRequest());
+            }
+        }
+        request.copyContextAndHeadersFrom(searchContext);
+        return client.multiTermVectors(request).actionGet();
+    }
+
+    public static Fields[] getFieldsFor(MultiTermVectorsResponse responses, List<Item> items) throws IOException {
+        List<Fields> likeFields = new ArrayList<>();
+
+        Set<Item> selectedItems = new HashSet<>();
+        for (Item request : items) {
+            selectedItems.add(new Item(request.index(), request.type(), request.id()));
+        }
+
+        for (MultiTermVectorsItemResponse response : responses) {
+            if (!hasResponseFromRequest(response, selectedItems)) {
+                continue;
+            }
+            if (response.isFailed()) {
+                continue;
+            }
+            TermVectorsResponse getResponse = response.getResponse();
+            if (!getResponse.isExists()) {
+                continue;
+            }
+            likeFields.add(getResponse.getFields());
+        }
+        return likeFields.toArray(Fields.EMPTY_ARRAY);
+    }
+
+    private static boolean hasResponseFromRequest(MultiTermVectorsItemResponse response, Set<Item> selectedItems) {
+        return selectedItems.contains(new Item(response.getIndex(), response.getType(), response.getId()));
+    }
+}
diff --git a/core/src/main/java/org/elasticsearch/index/search/shape/ShapeFetchService.java b/core/src/main/java/org/elasticsearch/index/search/shape/ShapeFetchService.java
new file mode 100644
index 0000000..97d0804
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/index/search/shape/ShapeFetchService.java
@@ -0,0 +1,91 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.search.shape;
+
+import org.elasticsearch.action.get.GetRequest;
+import org.elasticsearch.action.get.GetResponse;
+import org.elasticsearch.client.Client;
+import org.elasticsearch.common.Strings;
+import org.elasticsearch.common.component.AbstractComponent;
+import org.elasticsearch.common.geo.builders.ShapeBuilder;
+import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.xcontent.XContentHelper;
+import org.elasticsearch.common.xcontent.XContentParser;
+
+import java.io.IOException;
+
+/**
+ * Service which retrieves pre-indexed Shapes from another index
+ */
+public class ShapeFetchService extends AbstractComponent {
+
+    private final Client client;
+
+    @Inject
+    public ShapeFetchService(Client client, Settings settings) {
+        super(settings);
+        this.client = client;
+    }
+
+    /**
+     * Fetches the Shape with the given ID in the given type and index.
+     *
+     * @param getRequest GetRequest containing index, type and id
+     * @param path      Name or path of the field in the Shape Document where the Shape itself is located
+     * @return Shape with the given ID
+     * @throws IOException Can be thrown while parsing the Shape Document and extracting the Shape
+     */
+    public ShapeBuilder fetch(GetRequest getRequest,String path) throws IOException {
+        getRequest.preference("_local");
+        getRequest.operationThreaded(false);
+        GetResponse response = client.get(getRequest).actionGet();
+        if (!response.isExists()) {
+            throw new IllegalArgumentException("Shape with ID [" + getRequest.id() + "] in type [" + getRequest.type() + "] not found");
+        }
+
+        String[] pathElements = Strings.splitStringToArray(path, '.');
+        int currentPathSlot = 0;
+
+        XContentParser parser = null;
+        try {
+            parser = XContentHelper.createParser(response.getSourceAsBytesRef());
+            XContentParser.Token currentToken;
+            while ((currentToken = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
+                if (currentToken == XContentParser.Token.FIELD_NAME) {
+                    if (pathElements[currentPathSlot].equals(parser.currentName())) {
+                        parser.nextToken();
+                        if (++currentPathSlot == pathElements.length) {
+                            return ShapeBuilder.parse(parser);
+                        }
+                    } else {
+                        parser.nextToken();
+                        parser.skipChildren();
+                    }
+                }
+            }
+            throw new IllegalStateException("Shape with name [" + getRequest.id() + "] found but missing " + path + " field");
+        } finally {
+            if (parser != null) {
+                parser.close();
+            }
+        }
+    }
+}
diff --git a/core/src/main/java/org/elasticsearch/index/search/shape/ShapeModule.java b/core/src/main/java/org/elasticsearch/index/search/shape/ShapeModule.java
new file mode 100644
index 0000000..510d04f
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/index/search/shape/ShapeModule.java
@@ -0,0 +1,34 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.search.shape;
+
+import org.elasticsearch.common.geo.ShapesAvailability;
+import org.elasticsearch.common.inject.AbstractModule;
+
+public class ShapeModule extends AbstractModule {
+
+    @Override
+    protected void configure() {
+        // TODO: We could wrap this entire module in a JTS_AVAILABILITY check
+        if (ShapesAvailability.JTS_AVAILABLE) {
+            bind(ShapeFetchService.class).asEagerSingleton();
+        }
+    }
+}
diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
index 8d8c3d9..bf463db 100644
--- a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
+++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
@@ -20,11 +20,10 @@
 package org.elasticsearch.index.shard;
 
 import com.google.common.base.Charsets;
-import com.google.common.base.Preconditions;
 import org.apache.lucene.codecs.PostingsFormat;
 import org.apache.lucene.index.CheckIndex;
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.search.*;
+import org.apache.lucene.search.QueryCachingPolicy;
+import org.apache.lucene.search.UsageTrackingQueryCachingPolicy;
 import org.apache.lucene.store.AlreadyClosedException;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.ThreadInterruptedException;
@@ -66,7 +65,6 @@ import org.elasticsearch.index.deletionpolicy.SnapshotDeletionPolicy;
 import org.elasticsearch.index.deletionpolicy.SnapshotIndexCommit;
 import org.elasticsearch.index.engine.*;
 import org.elasticsearch.index.fielddata.FieldDataStats;
-import org.elasticsearch.index.fielddata.IndexFieldDataCache;
 import org.elasticsearch.index.fielddata.IndexFieldDataService;
 import org.elasticsearch.index.fielddata.ShardFieldData;
 import org.elasticsearch.index.flush.FlushStats;
@@ -111,10 +109,7 @@ import org.elasticsearch.threadpool.ThreadPool;
 import java.io.IOException;
 import java.io.PrintStream;
 import java.nio.channels.ClosedByInterruptException;
-import java.util.Arrays;
-import java.util.EnumSet;
-import java.util.Locale;
-import java.util.Map;
+import java.util.*;
 import java.util.concurrent.CopyOnWriteArrayList;
 import java.util.concurrent.ScheduledFuture;
 import java.util.concurrent.TimeUnit;
@@ -208,8 +203,8 @@ public class IndexShard extends AbstractIndexShardComponent {
         this.deletionPolicy = deletionPolicy;
         this.similarityService = similarityService;
         this.wrappingService = wrappingService;
-        Preconditions.checkNotNull(store, "Store must be provided to the index shard");
-        Preconditions.checkNotNull(deletionPolicy, "Snapshot deletion policy must be provided to the index shard");
+        Objects.requireNonNull(store, "Store must be provided to the index shard");
+        Objects.requireNonNull(deletionPolicy, "Snapshot deletion policy must be provided to the index shard");
         this.engineFactory = factory;
         this.indicesLifecycle = (InternalIndicesLifecycle) indicesLifecycle;
         this.indexSettingsService = indexSettingsService;
diff --git a/core/src/main/java/org/elasticsearch/index/store/FsDirectoryService.java b/core/src/main/java/org/elasticsearch/index/store/FsDirectoryService.java
index dfd6cdf..2d12fab 100644
--- a/core/src/main/java/org/elasticsearch/index/store/FsDirectoryService.java
+++ b/core/src/main/java/org/elasticsearch/index/store/FsDirectoryService.java
@@ -19,12 +19,22 @@
 
 package org.elasticsearch.index.store;
 
-import com.google.common.collect.Sets;
-import org.apache.lucene.store.*;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.FSDirectory;
+import org.apache.lucene.store.FileSwitchDirectory;
+import org.apache.lucene.store.LockFactory;
+import org.apache.lucene.store.MMapDirectory;
+import org.apache.lucene.store.NIOFSDirectory;
+import org.apache.lucene.store.NativeFSLockFactory;
+import org.apache.lucene.store.RateLimitedFSDirectory;
+import org.apache.lucene.store.SimpleFSDirectory;
+import org.apache.lucene.store.SimpleFSLockFactory;
+import org.apache.lucene.store.StoreRateLimiting;
 import org.apache.lucene.util.Constants;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.metrics.CounterMetric;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.util.set.Sets;
 import org.elasticsearch.index.settings.IndexSettings;
 import org.elasticsearch.index.shard.ShardPath;
 
@@ -32,7 +42,6 @@ import java.io.IOException;
 import java.nio.file.Files;
 import java.nio.file.Path;
 import java.util.Collections;
-import java.util.Locale;
 import java.util.Set;
 
 /**
diff --git a/core/src/main/java/org/elasticsearch/indices/IndicesModule.java b/core/src/main/java/org/elasticsearch/indices/IndicesModule.java
index ff248fc..32c7bc8 100644
--- a/core/src/main/java/org/elasticsearch/indices/IndicesModule.java
+++ b/core/src/main/java/org/elasticsearch/indices/IndicesModule.java
@@ -110,7 +110,6 @@ public class IndicesModule extends AbstractModule {
         registerQueryParser(NotQueryParser.class);
         registerQueryParser(ExistsQueryParser.class);
         registerQueryParser(MissingQueryParser.class);
-        registerQueryParser(MatchNoneQueryParser.class);
 
         if (ShapesAvailability.JTS_AVAILABLE) {
             registerQueryParser(GeoShapeQueryParser.class);
diff --git a/core/src/main/java/org/elasticsearch/indices/cache/query/terms/TermsLookup.java b/core/src/main/java/org/elasticsearch/indices/cache/query/terms/TermsLookup.java
index 8da06ea..28ab04b 100644
--- a/core/src/main/java/org/elasticsearch/indices/cache/query/terms/TermsLookup.java
+++ b/core/src/main/java/org/elasticsearch/indices/cache/query/terms/TermsLookup.java
@@ -19,162 +19,58 @@
 
 package org.elasticsearch.indices.cache.query.terms;
 
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.io.stream.Writeable;
-import org.elasticsearch.common.xcontent.ToXContent;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.query.QueryValidationException;
-
-import java.io.IOException;
-import java.util.Objects;
+import org.elasticsearch.common.Nullable;
+import org.elasticsearch.index.query.QueryParseContext;
 
 /**
- * Encapsulates the parameters needed to fetch terms.
  */
-public class TermsLookup implements Writeable<TermsLookup>, ToXContent {
-    static final TermsLookup PROTOTYPE = new TermsLookup();
+public class TermsLookup {
 
-    private String index;
-    private String type;
-    private String id;
-    private String path;
-    private String routing;
+    private final String index;
+    private final String type;
+    private final String id;
+    private final String routing;
+    private final String path;
 
-    public TermsLookup() {
-    }
+    @Nullable
+    private final QueryParseContext queryParseContext;
 
-    public TermsLookup(String index, String type, String id, String path) {
+    public TermsLookup(String index, String type, String id, String routing, String path, @Nullable QueryParseContext queryParseContext) {
         this.index = index;
         this.type = type;
         this.id = id;
+        this.routing = routing;
         this.path = path;
+        this.queryParseContext = queryParseContext;
     }
 
-    public String index() {
+    public String getIndex() {
         return index;
     }
 
-    public TermsLookup index(String index) {
-        this.index = index;
-        return this;
-    }
-
-    public String type() {
+    public String getType() {
         return type;
     }
 
-    public TermsLookup type(String type) {
-        this.type = type;
-        return this;
-    }
-
-    public String id() {
+    public String getId() {
         return id;
     }
 
-    public TermsLookup id(String id) {
-        this.id = id;
-        return this;
+    public String getRouting() {
+        return this.routing;
     }
 
-    public String path() {
+    public String getPath() {
         return path;
     }
 
-    public TermsLookup path(String path) {
-        this.path = path;
-        return this;
-    }
-
-    public String routing() {
-        return routing;
-    }
-
-    public TermsLookup routing(String routing) {
-        this.routing = routing;
-        return this;
+    @Nullable
+    public QueryParseContext getQueryParseContext() {
+        return queryParseContext;
     }
 
     @Override
     public String toString() {
         return index + "/" + type + "/" + id + "/" + path;
     }
-
-    @Override
-    public TermsLookup readFrom(StreamInput in) throws IOException {
-        TermsLookup termsLookup = new TermsLookup();
-        termsLookup.index = in.readOptionalString();
-        termsLookup.type = in.readString();
-        termsLookup.id = in.readString();
-        termsLookup.path = in.readString();
-        termsLookup.routing = in.readOptionalString();
-        return termsLookup;
-    }
-
-    public static TermsLookup readTermsLookupFrom(StreamInput in) throws IOException {
-        return PROTOTYPE.readFrom(in);
-    }
-
-    @Override
-    public void writeTo(StreamOutput out) throws IOException {
-        out.writeOptionalString(index);
-        out.writeString(type);
-        out.writeString(id);
-        out.writeString(path);
-        out.writeOptionalString(routing);
-    }
-
-    @Override
-    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-        if (index != null) {
-            builder.field("index", index);
-        }
-        builder.field("type", type);
-        builder.field("id", id);
-        builder.field("path", path);
-        if (routing != null) {
-            builder.field("routing", routing);
-        }
-        return builder;
-    }
-
-    @Override
-    public int hashCode() {
-        return Objects.hash(index, type, id, path, routing);
-    }
-
-    @Override
-    public boolean equals(Object obj) {
-        if (this == obj) {
-            return true;
-        }
-        if (obj == null || getClass() != obj.getClass()) {
-            return false;
-        }
-        TermsLookup other = (TermsLookup) obj;
-        return Objects.equals(index, other.index) &&
-                Objects.equals(type, other.type) &&
-                Objects.equals(id, other.id) &&
-                Objects.equals(path, other.path) &&
-                Objects.equals(routing, other.routing);
-    }
-
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (id == null) {
-            validationException = addValidationError("[terms] query lookup element requires specifying the id.", validationException);
-        }
-        if (type == null) {
-            validationException = addValidationError("[terms] query lookup element requires specifying the type.", validationException);
-        }
-        if (path == null) {
-            validationException = addValidationError("[terms] query lookup element requires specifying the path.", validationException);
-        }
-        return validationException;
-    }
-
-    private static QueryValidationException addValidationError(String validationError, QueryValidationException validationException) {
-        return QueryValidationException.addValidationError("terms_lookup", validationError, validationException);
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/indices/query/IndicesQueriesRegistry.java b/core/src/main/java/org/elasticsearch/indices/query/IndicesQueriesRegistry.java
index b453503..9a7454b 100644
--- a/core/src/main/java/org/elasticsearch/indices/query/IndicesQueriesRegistry.java
+++ b/core/src/main/java/org/elasticsearch/indices/query/IndicesQueriesRegistry.java
@@ -22,10 +22,7 @@ package org.elasticsearch.indices.query;
 import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.io.stream.NamedWriteableRegistry;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.index.query.EmptyQueryBuilder;
-import org.elasticsearch.index.query.QueryBuilder;
 import org.elasticsearch.index.query.QueryParser;
 
 import java.util.HashMap;
@@ -34,28 +31,24 @@ import java.util.Set;
 
 public class IndicesQueriesRegistry extends AbstractComponent {
 
-    private ImmutableMap<String, QueryParser<?>> queryParsers;
+    private ImmutableMap<String, QueryParser> queryParsers;
 
     @Inject
-    public IndicesQueriesRegistry(Settings settings, Set<QueryParser> injectedQueryParsers, NamedWriteableRegistry namedWriteableRegistry) {
+    public IndicesQueriesRegistry(Settings settings, Set<QueryParser> injectedQueryParsers) {
         super(settings);
-        Map<String, QueryParser<?>> queryParsers = new HashMap<>();
-        for (QueryParser<?> queryParser : injectedQueryParsers) {
+        Map<String, QueryParser> queryParsers = new HashMap<>();
+        for (QueryParser queryParser : injectedQueryParsers) {
             for (String name : queryParser.names()) {
                 queryParsers.put(name, queryParser);
             }
-            namedWriteableRegistry.registerPrototype(QueryBuilder.class, queryParser.getBuilderPrototype());
         }
-        // EmptyQueryBuilder is not registered as query parser but used internally.
-        // We need to register it with the NamedWriteableRegistry in order to serialize it
-        namedWriteableRegistry.registerPrototype(QueryBuilder.class, EmptyQueryBuilder.PROTOTYPE);
         this.queryParsers = ImmutableMap.copyOf(queryParsers);
     }
 
     /**
      * Returns all the registered query parsers
      */
-    public ImmutableMap<String, QueryParser<?>> queryParsers() {
+    public ImmutableMap<String, QueryParser> queryParsers() {
         return queryParsers;
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/monitor/jvm/JvmInfo.java b/core/src/main/java/org/elasticsearch/monitor/jvm/JvmInfo.java
index a2b12ea..599c860 100644
--- a/core/src/main/java/org/elasticsearch/monitor/jvm/JvmInfo.java
+++ b/core/src/main/java/org/elasticsearch/monitor/jvm/JvmInfo.java
@@ -73,7 +73,16 @@ public class JvmInfo implements Streamable, ToXContent {
             // ignore
         }
         info.inputArguments = runtimeMXBean.getInputArguments().toArray(new String[runtimeMXBean.getInputArguments().size()]);
-        info.bootClassPath = runtimeMXBean.getBootClassPath();
+        try {
+            info.bootClassPath = runtimeMXBean.getBootClassPath();
+        } catch (UnsupportedOperationException e) {
+            // oracle java 9
+            info.bootClassPath = System.getProperty("sun.boot.class.path");
+            if (info.bootClassPath == null) {
+                // something else
+                info.bootClassPath = "<unknown>";
+            }
+        }
         info.classPath = runtimeMXBean.getClassPath();
         info.systemProperties = runtimeMXBean.getSystemProperties();
 
diff --git a/core/src/main/java/org/elasticsearch/monitor/os/OsStats.java b/core/src/main/java/org/elasticsearch/monitor/os/OsStats.java
index 03f262f..0e8a737 100644
--- a/core/src/main/java/org/elasticsearch/monitor/os/OsStats.java
+++ b/core/src/main/java/org/elasticsearch/monitor/os/OsStats.java
@@ -227,6 +227,7 @@ public class OsStats implements Streamable, ToXContent {
         }
     }
 
+    // TODO: if values are -1, this should return -1 to show its unsupported?
     private static short calculatePercentage(long used, long max) {
         return max <= 0 ? 0 : (short) (Math.round((100d * used) / max));
     }
diff --git a/core/src/main/java/org/elasticsearch/node/Node.java b/core/src/main/java/org/elasticsearch/node/Node.java
index 3331c7b..e0532ed 100644
--- a/core/src/main/java/org/elasticsearch/node/Node.java
+++ b/core/src/main/java/org/elasticsearch/node/Node.java
@@ -31,6 +31,7 @@ import org.elasticsearch.cluster.ClusterService;
 import org.elasticsearch.cluster.action.index.MappingUpdatedAction;
 import org.elasticsearch.cluster.routing.RoutingService;
 import org.elasticsearch.common.StopWatch;
+import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.component.Lifecycle;
 import org.elasticsearch.common.component.LifecycleComponent;
 import org.elasticsearch.common.inject.Injector;
@@ -55,6 +56,7 @@ import org.elasticsearch.gateway.GatewayModule;
 import org.elasticsearch.gateway.GatewayService;
 import org.elasticsearch.http.HttpServer;
 import org.elasticsearch.http.HttpServerModule;
+import org.elasticsearch.index.search.shape.ShapeModule;
 import org.elasticsearch.indices.IndicesModule;
 import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.indices.breaker.CircuitBreakerModule;
@@ -188,6 +190,7 @@ public class Node implements Releasable {
             modules.add(new MonitorModule(settings));
             modules.add(new GatewayModule(settings));
             modules.add(new NodeClientModule());
+            modules.add(new ShapeModule());
             modules.add(new PercolatorModule());
             modules.add(new ResourceWatcherModule());
             modules.add(new RepositoriesModule());
diff --git a/core/src/main/java/org/elasticsearch/node/internal/InternalSettingsPreparer.java b/core/src/main/java/org/elasticsearch/node/internal/InternalSettingsPreparer.java
index 1515617..c155f93 100644
--- a/core/src/main/java/org/elasticsearch/node/internal/InternalSettingsPreparer.java
+++ b/core/src/main/java/org/elasticsearch/node/internal/InternalSettingsPreparer.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.node.internal;
 
 import com.google.common.base.Charsets;
-import com.google.common.collect.Sets;
 import org.elasticsearch.cluster.ClusterName;
 import org.elasticsearch.common.Booleans;
 import org.elasticsearch.common.Strings;
@@ -37,6 +36,7 @@ import java.io.InputStreamReader;
 import java.nio.file.Files;
 import java.nio.file.Path;
 import java.util.ArrayList;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
@@ -105,7 +105,7 @@ public class InternalSettingsPreparer {
         }
         if (loadFromEnv) {
             boolean settingsFileFound = false;
-            Set<String> foundSuffixes = Sets.newHashSet();
+            Set<String> foundSuffixes = new HashSet<>();
             for (String allowedSuffix : ALLOWED_SUFFIXES) {
                 Path path = environment.configFile().resolve("elasticsearch" + allowedSuffix);
                 if (Files.exists(path)) {
diff --git a/core/src/main/java/org/elasticsearch/plugins/PluginManager.java b/core/src/main/java/org/elasticsearch/plugins/PluginManager.java
index ee9e6b3..3eded07 100644
--- a/core/src/main/java/org/elasticsearch/plugins/PluginManager.java
+++ b/core/src/main/java/org/elasticsearch/plugins/PluginManager.java
@@ -41,7 +41,6 @@ import java.io.IOException;
 import java.io.OutputStream;
 import java.net.MalformedURLException;
 import java.net.URL;
-import java.net.URLClassLoader;
 import java.nio.file.*;
 import java.nio.file.attribute.BasicFileAttributes;
 import java.nio.file.attribute.PosixFileAttributeView;
@@ -315,10 +314,7 @@ public class PluginManager {
     private void jarHellCheck(Path candidate, boolean isolated) throws IOException {
         // create list of current jars in classpath
         final List<URL> jars = new ArrayList<>();
-        ClassLoader loader = PluginManager.class.getClassLoader();
-        if (loader instanceof URLClassLoader) {
-            Collections.addAll(jars, ((URLClassLoader) loader).getURLs());
-        }
+        jars.addAll(Arrays.asList(JarHell.parseClassPath()));
 
         // read existing bundles. this does some checks on the installation too.
         List<Bundle> bundles = PluginsService.getPluginBundles(environment.pluginsFile());
diff --git a/core/src/main/java/org/elasticsearch/plugins/PluginManagerCliParser.java b/core/src/main/java/org/elasticsearch/plugins/PluginManagerCliParser.java
index c24b823..db6afd1 100644
--- a/core/src/main/java/org/elasticsearch/plugins/PluginManagerCliParser.java
+++ b/core/src/main/java/org/elasticsearch/plugins/PluginManagerCliParser.java
@@ -34,6 +34,7 @@ import org.elasticsearch.plugins.PluginManager.OutputMode;
 
 import java.net.MalformedURLException;
 import java.net.URL;
+import java.net.URLDecoder;
 import java.util.Locale;
 
 import static org.elasticsearch.common.cli.CliToolConfig.Builder.cmd;
@@ -221,7 +222,7 @@ public class PluginManagerCliParser extends CliTool {
             if (name != null) {
                 terminal.println("-> Installing " + Strings.coalesceToEmpty(name) + "...");
             } else {
-                terminal.println("-> Installing from " + url + "...");
+                terminal.println("-> Installing from " + URLDecoder.decode(url.toString(), "UTF-8") + "...");
             }
             pluginManager.downloadAndExtract(name, terminal);
             return ExitStatus.OK;
diff --git a/core/src/main/java/org/elasticsearch/plugins/PluginsService.java b/core/src/main/java/org/elasticsearch/plugins/PluginsService.java
index c70349f..5834efc 100644
--- a/core/src/main/java/org/elasticsearch/plugins/PluginsService.java
+++ b/core/src/main/java/org/elasticsearch/plugins/PluginsService.java
@@ -47,6 +47,7 @@ import java.nio.file.DirectoryStream;
 import java.nio.file.Files;
 import java.nio.file.Path;
 import java.util.ArrayList;
+import java.util.Arrays;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.HashMap;
@@ -331,12 +332,7 @@ public class PluginsService extends AbstractComponent {
             // pluginmanager does it, but we do it again, in case lusers mess with jar files manually
             try {
                 final List<URL> jars = new ArrayList<>();
-                ClassLoader parentLoader = getClass().getClassLoader();
-                if (parentLoader instanceof URLClassLoader) {
-                    for (URL url : ((URLClassLoader) parentLoader).getURLs()) {
-                        jars.add(url);
-                    }
-                }
+                jars.addAll(Arrays.asList(JarHell.parseClassPath()));
                 jars.addAll(bundle.urls);
                 JarHell.checkJarHell(jars.toArray(new URL[0]));
             } catch (Exception e) {
diff --git a/core/src/main/java/org/elasticsearch/rest/action/admin/cluster/node/info/RestNodesInfoAction.java b/core/src/main/java/org/elasticsearch/rest/action/admin/cluster/node/info/RestNodesInfoAction.java
index 06c5a22..aed9514 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/admin/cluster/node/info/RestNodesInfoAction.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/admin/cluster/node/info/RestNodesInfoAction.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.rest.action.admin.cluster.node.info;
 
-import com.google.common.collect.Sets;
 import org.elasticsearch.action.admin.cluster.node.info.NodesInfoRequest;
 import org.elasticsearch.action.admin.cluster.node.info.NodesInfoResponse;
 import org.elasticsearch.client.Client;
@@ -27,8 +26,15 @@ import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.settings.SettingsFilter;
+import org.elasticsearch.common.util.set.Sets;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.rest.*;
+import org.elasticsearch.rest.BaseRestHandler;
+import org.elasticsearch.rest.BytesRestResponse;
+import org.elasticsearch.rest.RestChannel;
+import org.elasticsearch.rest.RestController;
+import org.elasticsearch.rest.RestRequest;
+import org.elasticsearch.rest.RestResponse;
+import org.elasticsearch.rest.RestStatus;
 import org.elasticsearch.rest.action.support.RestBuilderListener;
 
 import java.util.Set;
diff --git a/core/src/main/java/org/elasticsearch/rest/action/cat/RestIndicesAction.java b/core/src/main/java/org/elasticsearch/rest/action/cat/RestIndicesAction.java
index 3530e88..09edd81f 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/cat/RestIndicesAction.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/cat/RestIndicesAction.java
@@ -192,6 +192,9 @@ public class RestIndicesAction extends AbstractCatAction {
         table.addCell("indexing.index_total", "sibling:pri;alias:iito,indexingIndexTotal;default:false;text-align:right;desc:number of indexing ops");
         table.addCell("pri.indexing.index_total", "default:false;text-align:right;desc:number of indexing ops");
 
+        table.addCell("indexing.index_failed", "sibling:pri;alias:iif,indexingIndexFailed;default:false;text-align:right;desc:number of failed indexing ops");
+        table.addCell("pri.indexing.index_failed", "default:false;text-align:right;desc:number of failed indexing ops");
+
         table.addCell("merges.current", "sibling:pri;alias:mc,mergesCurrent;default:false;text-align:right;desc:number of current merges");
         table.addCell("pri.merges.current", "default:false;text-align:right;desc:number of current merges");
 
@@ -403,6 +406,9 @@ public class RestIndicesAction extends AbstractCatAction {
             table.addCell(indexStats == null ? null : indexStats.getTotal().getIndexing().getTotal().getIndexCount());
             table.addCell(indexStats == null ? null : indexStats.getPrimaries().getIndexing().getTotal().getIndexCount());
 
+            table.addCell(indexStats == null ? null : indexStats.getTotal().getIndexing().getTotal().getIndexFailedCount());
+            table.addCell(indexStats == null ? null : indexStats.getPrimaries().getIndexing().getTotal().getIndexFailedCount());
+
             table.addCell(indexStats == null ? null : indexStats.getTotal().getMerge().getCurrent());
             table.addCell(indexStats == null ? null : indexStats.getPrimaries().getMerge().getCurrentSize());
 
diff --git a/core/src/main/java/org/elasticsearch/rest/action/cat/RestNodesAction.java b/core/src/main/java/org/elasticsearch/rest/action/cat/RestNodesAction.java
index 1bc43b4..f29b352 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/cat/RestNodesAction.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/cat/RestNodesAction.java
@@ -166,6 +166,7 @@ public class RestNodesAction extends AbstractCatAction {
         table.addCell("indexing.index_current", "alias:iic,indexingIndexCurrent;default:false;text-align:right;desc:number of current indexing ops");
         table.addCell("indexing.index_time", "alias:iiti,indexingIndexTime;default:false;text-align:right;desc:time spent in indexing");
         table.addCell("indexing.index_total", "alias:iito,indexingIndexTotal;default:false;text-align:right;desc:number of indexing ops");
+        table.addCell("indexing.index_failed", "alias:iif,indexingIndexFailed;default:false;text-align:right;desc:number of failed indexing ops");
 
         table.addCell("merges.current", "alias:mc,mergesCurrent;default:false;text-align:right;desc:number of current merges");
         table.addCell("merges.current_docs", "alias:mcd,mergesCurrentDocs;default:false;text-align:right;desc:number of current merging docs");
@@ -300,6 +301,7 @@ public class RestNodesAction extends AbstractCatAction {
             table.addCell(indexingStats == null ? null : indexingStats.getTotal().getIndexCurrent());
             table.addCell(indexingStats == null ? null : indexingStats.getTotal().getIndexTime());
             table.addCell(indexingStats == null ? null : indexingStats.getTotal().getIndexCount());
+            table.addCell(indexingStats == null ? null : indexingStats.getTotal().getIndexFailedCount());
 
             MergeStats mergeStats = indicesStats == null ? null : indicesStats.getMerge();
             table.addCell(mergeStats == null ? null : mergeStats.getCurrent());
diff --git a/core/src/main/java/org/elasticsearch/rest/action/cat/RestShardsAction.java b/core/src/main/java/org/elasticsearch/rest/action/cat/RestShardsAction.java
index c6df5ee..5ec23c9 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/cat/RestShardsAction.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/cat/RestShardsAction.java
@@ -121,6 +121,7 @@ public class RestShardsAction extends AbstractCatAction {
         table.addCell("indexing.index_current", "alias:iic,indexingIndexCurrent;default:false;text-align:right;desc:number of current indexing ops");
         table.addCell("indexing.index_time", "alias:iiti,indexingIndexTime;default:false;text-align:right;desc:time spent in indexing");
         table.addCell("indexing.index_total", "alias:iito,indexingIndexTotal;default:false;text-align:right;desc:number of indexing ops");
+        table.addCell("indexing.index_failed", "alias:iif,indexingIndexFailed;default:false;text-align:right;desc:number of failed indexing ops");
 
         table.addCell("merges.current", "alias:mc,mergesCurrent;default:false;text-align:right;desc:number of current merges");
         table.addCell("merges.current_docs", "alias:mcd,mergesCurrentDocs;default:false;text-align:right;desc:number of current merging docs");
@@ -255,6 +256,7 @@ public class RestShardsAction extends AbstractCatAction {
             table.addCell(shardStats == null ? null : shardStats.getIndexing().getTotal().getIndexCurrent());
             table.addCell(shardStats == null ? null : shardStats.getIndexing().getTotal().getIndexTime());
             table.addCell(shardStats == null ? null : shardStats.getIndexing().getTotal().getIndexCount());
+            table.addCell(shardStats == null ? null : shardStats.getIndexing().getTotal().getIndexFailedCount());
 
             table.addCell(shardStats == null ? null : shardStats.getMerge().getCurrent());
             table.addCell(shardStats == null ? null : shardStats.getMerge().getCurrentNumDocs());
diff --git a/core/src/main/java/org/elasticsearch/rest/action/explain/RestExplainAction.java b/core/src/main/java/org/elasticsearch/rest/action/explain/RestExplainAction.java
index 7c01fdd..ce306c6 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/explain/RestExplainAction.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/explain/RestExplainAction.java
@@ -30,7 +30,6 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentBuilderString;
 import org.elasticsearch.index.get.GetResult;
-import org.elasticsearch.index.query.Operator;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.index.query.QueryStringQueryBuilder;
 import org.elasticsearch.rest.*;
@@ -75,7 +74,13 @@ public class RestExplainAction extends BaseRestHandler {
             queryStringBuilder.lenient(request.paramAsBoolean("lenient", null));
             String defaultOperator = request.param("default_operator");
             if (defaultOperator != null) {
-                queryStringBuilder.defaultOperator(Operator.fromString(defaultOperator));
+                if ("OR".equals(defaultOperator)) {
+                    queryStringBuilder.defaultOperator(QueryStringQueryBuilder.Operator.OR);
+                } else if ("AND".equals(defaultOperator)) {
+                    queryStringBuilder.defaultOperator(QueryStringQueryBuilder.Operator.AND);
+                } else {
+                    throw new IllegalArgumentException("Unsupported defaultOperator [" + defaultOperator + "], can either be [OR] or [AND]");
+                }
             }
 
             QuerySourceBuilder querySourceBuilder = new QuerySourceBuilder();
diff --git a/core/src/main/java/org/elasticsearch/rest/action/support/RestActions.java b/core/src/main/java/org/elasticsearch/rest/action/support/RestActions.java
index 674aa69..bd17c1d 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/support/RestActions.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/support/RestActions.java
@@ -27,7 +27,6 @@ import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.lucene.uid.Versions;
 import org.elasticsearch.common.xcontent.*;
-import org.elasticsearch.index.query.Operator;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.index.query.QueryStringQueryBuilder;
 import org.elasticsearch.rest.RestRequest;
@@ -98,7 +97,13 @@ public class RestActions {
         queryBuilder.lenient(request.paramAsBoolean("lenient", null));
         String defaultOperator = request.param("default_operator");
         if (defaultOperator != null) {
-            queryBuilder.defaultOperator(Operator.fromString(defaultOperator));
+            if ("OR".equals(defaultOperator)) {
+                queryBuilder.defaultOperator(QueryStringQueryBuilder.Operator.OR);
+            } else if ("AND".equals(defaultOperator)) {
+                queryBuilder.defaultOperator(QueryStringQueryBuilder.Operator.AND);
+            } else {
+                throw new IllegalArgumentException("Unsupported defaultOperator [" + defaultOperator + "], can either be [OR] or [AND]");
+            }
         }
         return new QuerySourceBuilder().setQuery(queryBuilder);
     }
diff --git a/core/src/main/java/org/elasticsearch/search/SearchModule.java b/core/src/main/java/org/elasticsearch/search/SearchModule.java
index fec2a48..419f6ec 100644
--- a/core/src/main/java/org/elasticsearch/search/SearchModule.java
+++ b/core/src/main/java/org/elasticsearch/search/SearchModule.java
@@ -24,6 +24,7 @@ import org.elasticsearch.common.inject.multibindings.Multibinder;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionParserMapper;
+import org.elasticsearch.index.search.morelikethis.MoreLikeThisFetchService;
 import org.elasticsearch.search.action.SearchServiceTransportAction;
 import org.elasticsearch.search.aggregations.AggregationParseElement;
 import org.elasticsearch.search.aggregations.AggregationPhase;
@@ -338,6 +339,8 @@ public class SearchModule extends AbstractModule {
         bind(SearchPhaseController.class).asEagerSingleton();
         bind(FetchPhase.class).asEagerSingleton();
         bind(SearchServiceTransportAction.class).asEagerSingleton();
+        bind(MoreLikeThisFetchService.class).asEagerSingleton();
+
         if (searchServiceImpl == SearchService.class) {
             bind(SearchService.class).asEagerSingleton();
         } else {
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/AggregatorFactories.java b/core/src/main/java/org/elasticsearch/search/aggregations/AggregatorFactories.java
index 0a76f1f..6a1cd27 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/AggregatorFactories.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/AggregatorFactories.java
@@ -244,5 +244,13 @@ public class AggregatorFactories {
                 orderedPipelineAggregators.add(factory);
             }
         }
+
+        AggregatorFactory[] getAggregatorFactories() {
+            return this.factories.toArray(new AggregatorFactory[this.factories.size()]);
+        }
+
+        List<PipelineAggregatorFactory> getPipelineAggregatorFactories() {
+            return this.pipelineAggregatorFactories;
+        }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/AggregatorParsers.java b/core/src/main/java/org/elasticsearch/search/aggregations/AggregatorParsers.java
index bba7be2..257fef8 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/AggregatorParsers.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/AggregatorParsers.java
@@ -80,7 +80,7 @@ public class AggregatorParsers {
     /**
      * Returns the parser that is registered under the given pipeline aggregator
      * type.
-     * 
+     *
      * @param type
      *            The pipeline aggregator type
      * @return The parser associated with the given pipeline aggregator type.
@@ -228,6 +228,10 @@ public class AggregatorParsers {
                     throw new SearchParseException(context, "Aggregation [" + aggregationName + "] cannot define sub-aggregations",
                             parser.getTokenLocation());
                 }
+                if (level == 0) {
+                    pipelineAggregatorFactory
+                            .validate(null, factories.getAggregatorFactories(), factories.getPipelineAggregatorFactories());
+                }
                 factories.addPipelineAggregator(pipelineAggregatorFactory);
             }
         }
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/GND.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/GND.java
index 99ee7c7..00d12a8 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/GND.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/GND.java
@@ -28,7 +28,7 @@ import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardException;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
@@ -117,7 +117,7 @@ public class GND extends NXYSignificanceHeuristic {
 
         @Override
         public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher, SearchContext context)
-                throws IOException, QueryShardException {
+                throws IOException, QueryParsingException {
             String givenName = parser.currentName();
             boolean backgroundIsSuperset = true;
             XContentParser.Token token = parser.nextToken();
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/JLHScore.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/JLHScore.java
index 97264e7..d5bfc5c 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/JLHScore.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/JLHScore.java
@@ -27,7 +27,7 @@ import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardException;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
@@ -110,7 +110,7 @@ public class JLHScore extends SignificanceHeuristic {
 
         @Override
         public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher, SearchContext context)
-                throws IOException, QueryShardException {
+                throws IOException, QueryParsingException {
             // move to the closing bracket
             if (!parser.nextToken().equals(XContentParser.Token.END_OBJECT)) {
                 throw new ElasticsearchParseException("failed to parse [jhl] significance heuristic. expected an empty object, but found [{}] instead", parser.currentToken());
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/NXYSignificanceHeuristic.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/NXYSignificanceHeuristic.java
index c6a6924..4d86661 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/NXYSignificanceHeuristic.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/NXYSignificanceHeuristic.java
@@ -27,7 +27,7 @@ import org.elasticsearch.common.ParseFieldMatcher;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardException;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
@@ -140,7 +140,7 @@ public abstract class NXYSignificanceHeuristic extends SignificanceHeuristic {
 
         @Override
         public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher, SearchContext context)
-                throws IOException, QueryShardException {
+                throws IOException, QueryParsingException {
             String givenName = parser.currentName();
             boolean includeNegatives = false;
             boolean backgroundIsSuperset = true;
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/PercentageScore.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/PercentageScore.java
index aceae8c..d613ef2 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/PercentageScore.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/PercentageScore.java
@@ -27,7 +27,7 @@ import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardException;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
@@ -79,7 +79,7 @@ public class PercentageScore extends SignificanceHeuristic {
 
         @Override
         public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher, SearchContext context)
-                throws IOException, QueryShardException {
+                throws IOException, QueryParsingException {
             // move to the closing bracket
             if (!parser.nextToken().equals(XContentParser.Token.END_OBJECT)) {
                 throw new ElasticsearchParseException("failed to parse [percentage] significance heuristic. expected an empty object, but got [{}] instead", parser.currentToken());
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/ScriptHeuristic.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/ScriptHeuristic.java
index 046ca71..632827c 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/ScriptHeuristic.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/ScriptHeuristic.java
@@ -29,10 +29,14 @@ import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.logging.ESLoggerFactory;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardException;
-import org.elasticsearch.script.*;
+import org.elasticsearch.index.query.QueryParsingException;
+import org.elasticsearch.script.ExecutableScript;
+import org.elasticsearch.script.Script;
 import org.elasticsearch.script.Script.ScriptField;
+import org.elasticsearch.script.ScriptContext;
+import org.elasticsearch.script.ScriptParameterParser;
 import org.elasticsearch.script.ScriptParameterParser.ScriptParameterValue;
+import org.elasticsearch.script.ScriptService;
 import org.elasticsearch.search.aggregations.InternalAggregation;
 import org.elasticsearch.search.internal.SearchContext;
 
@@ -130,7 +134,7 @@ public class ScriptHeuristic extends SignificanceHeuristic {
 
         @Override
         public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher, SearchContext context)
-                throws IOException, QueryShardException {
+                throws IOException, QueryParsingException {
             String heuristicName = parser.currentName();
             Script script = null;
             XContentParser.Token token;
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsBuilder.java b/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsBuilder.java
index a14fdfe..125f635 100644
--- a/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsBuilder.java
+++ b/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsBuilder.java
@@ -19,15 +19,10 @@
 
 package org.elasticsearch.search.fetch.innerhits;
 
-import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.index.query.QueryBuilder;
-import org.elasticsearch.script.Script;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
-import org.elasticsearch.search.highlight.HighlightBuilder;
-import org.elasticsearch.search.sort.SortBuilder;
-import org.elasticsearch.search.sort.SortOrder;
+import org.elasticsearch.index.query.support.BaseInnerHitBuilder;
 
 import java.io.IOException;
 import java.util.HashMap;
@@ -37,12 +32,12 @@ import java.util.Map;
  */
 public class InnerHitsBuilder implements ToXContent {
 
-    private final Map<String, InnerHitsHolder> innerHits = new HashMap<>();
+    private Map<String, InnerHit> innerHits = new HashMap<>();
 
     @Override
     public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
         builder.startObject("inner_hits");
-        for (Map.Entry<String, InnerHitsHolder> entry : innerHits.entrySet()) {
+        for (Map.Entry<String, InnerHit> entry : innerHits.entrySet()) {
             builder.startObject(entry.getKey());
             entry.getValue().toXContent(builder, params);
             builder.endObject();
@@ -50,425 +45,36 @@ public class InnerHitsBuilder implements ToXContent {
         return builder.endObject();
     }
 
-    /**
-     * For nested inner hits the path to collect child nested docs for.
-     * @param name the name / key of the inner hits in the response
-     * @param path the path into the nested to collect inner hits for
-     * @param innerHit the inner hits definition
-     */
-    public void addNestedInnerHits(String name, String path, InnerHit innerHit) {
-        if (innerHits.containsKey(name)) {
-            throw new IllegalArgumentException("inner hits for name: [" + name +"] is already registered");
-        }
-        innerHits.put(name, new NestedInnerHitsHolder(path, innerHit));
-    }
-
-    /**
-     * For parent/child inner hits the type to collect inner hits for.
-     * @param name the name / key of the inner hits in the response
-     * @param type the document type to collect inner hits for
-     * @param innerHit the inner hits definition
-     */
-    public void addParentChildInnerHits(String name, String type, InnerHit innerHit) {
-        innerHits.put(name, new ParentChildInnerHitsHolder(type, innerHit));
-    }
-
-    private static class InnerHitsHolder implements ToXContent{
-        private final InnerHit hits;
-
-        private InnerHitsHolder(InnerHit hits) {
-            this.hits = hits;
-        }
-
-        @Override
-        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-            return hits.toXContent(builder, params);
-        }
-    }
-
-    private static class ParentChildInnerHitsHolder extends InnerHitsHolder {
-
-        private final String type;
-
-        private ParentChildInnerHitsHolder(String type, InnerHit hits) {
-            super(hits);
-            this.type = type;
-        }
-
-        @Override
-        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-            builder.startObject("type").startObject(type);
-            super.toXContent(builder, params);
-            return builder.endObject().endObject();
-        }
-    }
-
-    private static class NestedInnerHitsHolder extends InnerHitsHolder {
-
-        private final String path;
-
-        private NestedInnerHitsHolder(String path, InnerHit hits) {
-            super(hits);
-            this.path = path;
-        }
-
-        @Override
-        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-            builder.startObject("path").startObject(path);
-            super.toXContent(builder, params);
-            return builder.endObject().endObject();
-        }
+    public void addInnerHit(String name, InnerHit innerHit) {
+        innerHits.put(name, innerHit);
     }
 
-    public static class InnerHit implements ToXContent {
+    public static class InnerHit extends BaseInnerHitBuilder<InnerHit> {
 
-        private SearchSourceBuilder sourceBuilder;
         private String path;
         private String type;
 
         /**
-         * The index to start to return hits from. Defaults to <tt>0</tt>.
-         */
-        public InnerHit setFrom(int from) {
-            sourceBuilder().from(from);
-            return this;
-        }
-
-        /**
-         * The number of search hits to return. Defaults to <tt>10</tt>.
-         */
-        public InnerHit setSize(int size) {
-            sourceBuilder().size(size);
-            return this;
-        }
-
-        /**
-         * Applies when sorting, and controls if scores will be tracked as well. Defaults to
-         * <tt>false</tt>.
-         */
-        public InnerHit setTrackScores(boolean trackScores) {
-            sourceBuilder().trackScores(trackScores);
-            return this;
-        }
-
-        /**
-         * Should each {@link org.elasticsearch.search.SearchHit} be returned with an
-         * explanation of the hit (ranking).
-         */
-        public InnerHit setExplain(boolean explain) {
-            sourceBuilder().explain(explain);
-            return this;
-        }
-
-        /**
-         * Should each {@link org.elasticsearch.search.SearchHit} be returned with its
-         * version.
-         */
-        public InnerHit setVersion(boolean version) {
-            sourceBuilder().version(version);
-            return this;
-        }
-
-        /**
-         * Add a stored field to be loaded and returned with the inner hit.
-         */
-        public InnerHit field(String name) {
-            sourceBuilder().field(name);
-            return this;
-        }
-
-        /**
-         * Sets no fields to be loaded, resulting in only id and type to be returned per field.
-         */
-        public InnerHit setNoFields() {
-            sourceBuilder().noFields();
-            return this;
-        }
-
-        /**
-         * Indicates whether the response should contain the stored _source for every hit
-         */
-        public InnerHit setFetchSource(boolean fetch) {
-            sourceBuilder().fetchSource(fetch);
-            return this;
-        }
-
-        /**
-         * Indicate that _source should be returned with every hit, with an "include" and/or "exclude" set which can include simple wildcard
-         * elements.
-         *
-         * @param include An optional include (optionally wildcarded) pattern to filter the returned _source
-         * @param exclude An optional exclude (optionally wildcarded) pattern to filter the returned _source
-         */
-        public InnerHit setFetchSource(@Nullable String include, @Nullable String exclude) {
-            sourceBuilder().fetchSource(include, exclude);
-            return this;
-        }
-
-        /**
-         * Indicate that _source should be returned with every hit, with an "include" and/or "exclude" set which can include simple wildcard
-         * elements.
-         *
-         * @param includes An optional list of include (optionally wildcarded) pattern to filter the returned _source
-         * @param excludes An optional list of exclude (optionally wildcarded) pattern to filter the returned _source
-         */
-        public InnerHit setFetchSource(@Nullable String[] includes, @Nullable String[] excludes) {
-            sourceBuilder().fetchSource(includes, excludes);
-            return this;
-        }
-
-        /**
-         * Adds a field data based field to load and return. The field does not have to be stored,
-         * but its recommended to use non analyzed or numeric fields.
-         *
-         * @param name The field to get from the field data cache
-         */
-        public InnerHit addFieldDataField(String name) {
-            sourceBuilder().fieldDataField(name);
-            return this;
-        }
-
-        /**
-         * Adds a script based field to load and return. The field does not have to be stored,
-         * but its recommended to use non analyzed or numeric fields.
-         *
-         * @param name   The name that will represent this value in the return hit
-         * @param script The script to use
-         */
-        public InnerHit addScriptField(String name, Script script) {
-            sourceBuilder().scriptField(name, script);
-            return this;
-        }
-
-        /**
-         * Adds a sort against the given field name and the sort ordering.
-         *
-         * @param field The name of the field
-         * @param order The sort ordering
-         */
-        public InnerHit addSort(String field, SortOrder order) {
-            sourceBuilder().sort(field, order);
-            return this;
-        }
-
-        /**
-         * Adds a generic sort builder.
-         *
-         * @see org.elasticsearch.search.sort.SortBuilders
-         */
-        public InnerHit addSort(SortBuilder sort) {
-            sourceBuilder().sort(sort);
-            return this;
-        }
-
-        public HighlightBuilder highlightBuilder() {
-            return sourceBuilder().highlighter();
-        }
-
-        /**
-         * Adds a field to be highlighted with default fragment size of 100 characters, and
-         * default number of fragments of 5.
-         *
-         * @param name The field to highlight
-         */
-        public InnerHit addHighlightedField(String name) {
-            highlightBuilder().field(name);
-            return this;
-        }
-
-
-        /**
-         * Adds a field to be highlighted with a provided fragment size (in characters), and
-         * default number of fragments of 5.
-         *
-         * @param name         The field to highlight
-         * @param fragmentSize The size of a fragment in characters
-         */
-        public InnerHit addHighlightedField(String name, int fragmentSize) {
-            highlightBuilder().field(name, fragmentSize);
-            return this;
-        }
-
-        /**
-         * Adds a field to be highlighted with a provided fragment size (in characters), and
-         * a provided (maximum) number of fragments.
-         *
-         * @param name              The field to highlight
-         * @param fragmentSize      The size of a fragment in characters
-         * @param numberOfFragments The (maximum) number of fragments
-         */
-        public InnerHit addHighlightedField(String name, int fragmentSize, int numberOfFragments) {
-            highlightBuilder().field(name, fragmentSize, numberOfFragments);
-            return this;
-        }
-
-        /**
-         * Adds a field to be highlighted with a provided fragment size (in characters),
-         * a provided (maximum) number of fragments and an offset for the highlight.
-         *
-         * @param name              The field to highlight
-         * @param fragmentSize      The size of a fragment in characters
-         * @param numberOfFragments The (maximum) number of fragments
-         */
-        public InnerHit addHighlightedField(String name, int fragmentSize, int numberOfFragments,
-                                            int fragmentOffset) {
-            highlightBuilder().field(name, fragmentSize, numberOfFragments, fragmentOffset);
-            return this;
-        }
-
-        /**
-         * Adds a highlighted field.
-         */
-        public InnerHit addHighlightedField(HighlightBuilder.Field field) {
-            highlightBuilder().field(field);
-            return this;
-        }
-
-        /**
-         * Set a tag scheme that encapsulates a built in pre and post tags. The allows schemes
-         * are <tt>styled</tt> and <tt>default</tt>.
-         *
-         * @param schemaName The tag scheme name
-         */
-        public InnerHit setHighlighterTagsSchema(String schemaName) {
-            highlightBuilder().tagsSchema(schemaName);
-            return this;
-        }
-
-        public InnerHit setHighlighterFragmentSize(Integer fragmentSize) {
-            highlightBuilder().fragmentSize(fragmentSize);
-            return this;
-        }
-
-        public InnerHit setHighlighterNumOfFragments(Integer numOfFragments) {
-            highlightBuilder().numOfFragments(numOfFragments);
-            return this;
-        }
-
-        public InnerHit setHighlighterFilter(Boolean highlightFilter) {
-            highlightBuilder().highlightFilter(highlightFilter);
-            return this;
-        }
-
-        /**
-         * The encoder to set for highlighting
-         */
-        public InnerHit setHighlighterEncoder(String encoder) {
-            highlightBuilder().encoder(encoder);
-            return this;
-        }
-
-        /**
-         * Explicitly set the pre tags that will be used for highlighting.
-         */
-        public InnerHit setHighlighterPreTags(String... preTags) {
-            highlightBuilder().preTags(preTags);
-            return this;
-        }
-
-        /**
-         * Explicitly set the post tags that will be used for highlighting.
-         */
-        public InnerHit setHighlighterPostTags(String... postTags) {
-            highlightBuilder().postTags(postTags);
-            return this;
-        }
-
-        /**
-         * The order of fragments per field. By default, ordered by the order in the
-         * highlighted text. Can be <tt>score</tt>, which then it will be ordered
-         * by score of the fragments.
-         */
-        public InnerHit setHighlighterOrder(String order) {
-            highlightBuilder().order(order);
-            return this;
-        }
-
-        public InnerHit setHighlighterRequireFieldMatch(boolean requireFieldMatch) {
-            highlightBuilder().requireFieldMatch(requireFieldMatch);
-            return this;
-        }
-
-        public InnerHit setHighlighterBoundaryMaxScan(Integer boundaryMaxScan) {
-            highlightBuilder().boundaryMaxScan(boundaryMaxScan);
-            return this;
-        }
-
-        public InnerHit setHighlighterBoundaryChars(char[] boundaryChars) {
-            highlightBuilder().boundaryChars(boundaryChars);
-            return this;
-        }
-
-        /**
-         * The highlighter type to use.
-         */
-        public InnerHit setHighlighterType(String type) {
-            highlightBuilder().highlighterType(type);
-            return this;
-        }
-
-        public InnerHit setHighlighterFragmenter(String fragmenter) {
-            highlightBuilder().fragmenter(fragmenter);
-            return this;
-        }
-
-        /**
-         * Sets a query to be used for highlighting all fields instead of the search query.
-         */
-        public InnerHit setHighlighterQuery(QueryBuilder highlightQuery) {
-            highlightBuilder().highlightQuery(highlightQuery);
-            return this;
-        }
-
-        /**
-         * Sets the size of the fragment to return from the beginning of the field if there are no matches to
-         * highlight and the field doesn't also define noMatchSize.
-         *
-         * @param noMatchSize integer to set or null to leave out of request.  default is null.
-         * @return this builder for chaining
+         * Sets the query to run for collecting the inner hits.
          */
-        public InnerHit setHighlighterNoMatchSize(Integer noMatchSize) {
-            highlightBuilder().noMatchSize(noMatchSize);
+        public InnerHit setQuery(QueryBuilder query) {
+            sourceBuilder().query(query);
             return this;
         }
 
         /**
-         * Sets the maximum number of phrases the fvh will consider if the field doesn't also define phraseLimit.
+         * For parent/child inner hits the type to collect inner hits for.
          */
-        public InnerHit setHighlighterPhraseLimit(Integer phraseLimit) {
-            highlightBuilder().phraseLimit(phraseLimit);
-            return this;
-        }
-
-        public InnerHit setHighlighterOptions(Map<String, Object> options) {
-            highlightBuilder().options(options);
-            return this;
-        }
-
-        protected SearchSourceBuilder sourceBuilder() {
-            if (sourceBuilder == null) {
-                sourceBuilder = new SearchSourceBuilder();
-            }
-            return sourceBuilder;
-        }
-
-        /**
-         * Sets the query to run for collecting the inner hits.
-         */
-        public InnerHit setQuery(QueryBuilder query) {
-            sourceBuilder().query(query);
+        public InnerHit setPath(String path) {
+            this.path = path;
             return this;
         }
 
-
-
-
         /**
-         * Adds a nested inner hit definition that collects inner hits for hits
-         * on this inner hit level.
+         * For nested inner hits the path to collect child nested docs for.
          */
-        public InnerHit addNestedInnerHits(String name, String path, InnerHit innerHit) {
-            sourceBuilder().innerHitsBuilder().addNestedInnerHits(name, path, innerHit);
+        public InnerHit setType(String type) {
+            this.type = type;
             return this;
         }
 
@@ -476,17 +82,21 @@ public class InnerHitsBuilder implements ToXContent {
          * Adds a nested inner hit definition that collects inner hits for hits
          * on this inner hit level.
          */
-        public InnerHit addParentChildInnerHits(String name, String type, InnerHit innerHit) {
-            sourceBuilder().innerHitsBuilder().addParentChildInnerHits(name, type, innerHit);
+        public InnerHit addInnerHit(String name, InnerHit innerHit) {
+            sourceBuilder().innerHitsBuilder().addInnerHit(name, innerHit);
             return this;
         }
 
         @Override
         public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-            if (sourceBuilder != null) {
-                sourceBuilder.innerToXContent(builder, params);
+            if (path != null) {
+                builder.startObject("path").startObject(path);
+            } else {
+                builder.startObject("type").startObject(type);
             }
-            return builder;
+            super.toXContent(builder, params);
+            return builder.endObject().endObject();
         }
     }
+
 }
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsParseElement.java b/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsParseElement.java
index ac6dc18..c02e2c6 100644
--- a/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsParseElement.java
+++ b/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsParseElement.java
@@ -24,7 +24,7 @@ import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.mapper.DocumentMapper;
 import org.elasticsearch.index.mapper.object.ObjectMapper;
 import org.elasticsearch.index.query.ParsedQuery;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.search.SearchParseElement;
 import org.elasticsearch.search.fetch.fielddata.FieldDataFieldsParseElement;
 import org.elasticsearch.search.fetch.script.ScriptFieldsParseElement;
@@ -59,15 +59,15 @@ public class InnerHitsParseElement implements SearchParseElement {
 
     @Override
     public void parse(XContentParser parser, SearchContext searchContext) throws Exception {
-        QueryShardContext context = searchContext.queryParserService().getShardContext();
-        context.reset(parser);
-        Map<String, InnerHitsContext.BaseInnerHits> innerHitsMap = parseInnerHits(parser, context, searchContext);
+        QueryParseContext parseContext = searchContext.queryParserService().getParseContext();
+        parseContext.reset(parser);
+        Map<String, InnerHitsContext.BaseInnerHits> innerHitsMap = parseInnerHits(parser, parseContext, searchContext);
         if (innerHitsMap != null) {
             searchContext.innerHits(new InnerHitsContext(innerHitsMap));
         }
     }
 
-    private Map<String, InnerHitsContext.BaseInnerHits> parseInnerHits(XContentParser parser, QueryShardContext context, SearchContext searchContext) throws Exception {
+    private Map<String, InnerHitsContext.BaseInnerHits> parseInnerHits(XContentParser parser, QueryParseContext parseContext, SearchContext searchContext) throws Exception {
         XContentParser.Token token;
         Map<String, InnerHitsContext.BaseInnerHits> innerHitsMap = null;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -79,7 +79,7 @@ public class InnerHitsParseElement implements SearchParseElement {
             if (token != XContentParser.Token.START_OBJECT) {
                 throw new IllegalArgumentException("Inner hit definition for [" + innerHitName + " starts with a [" + token + "], expected a [" + XContentParser.Token.START_OBJECT + "].");
             }
-            InnerHitsContext.BaseInnerHits innerHits = parseInnerHit(parser, context, searchContext, innerHitName);
+            InnerHitsContext.BaseInnerHits innerHits = parseInnerHit(parser, parseContext, searchContext, innerHitName);
             if (innerHitsMap == null) {
                 innerHitsMap = new HashMap<>();
             }
@@ -88,7 +88,7 @@ public class InnerHitsParseElement implements SearchParseElement {
         return innerHitsMap;
     }
 
-    private InnerHitsContext.BaseInnerHits parseInnerHit(XContentParser parser, QueryShardContext context, SearchContext searchContext, String innerHitName) throws Exception {
+    private InnerHitsContext.BaseInnerHits parseInnerHit(XContentParser parser, QueryParseContext parseContext, SearchContext searchContext, String innerHitName) throws Exception {
         XContentParser.Token token = parser.nextToken();
         if (token != XContentParser.Token.FIELD_NAME) {
             throw new IllegalArgumentException("Unexpected token " + token + " inside inner hit definition. Either specify [path] or [type] object");
@@ -123,9 +123,9 @@ public class InnerHitsParseElement implements SearchParseElement {
 
         final InnerHitsContext.BaseInnerHits innerHits;
         if (nestedPath != null) {
-            innerHits = parseNested(parser, context, searchContext, fieldName);
+            innerHits = parseNested(parser, parseContext, searchContext, fieldName);
         } else if (type != null) {
-            innerHits = parseParentChild(parser, context, searchContext, fieldName);
+            innerHits = parseParentChild(parser, parseContext, searchContext, fieldName);
         } else {
             throw new IllegalArgumentException("Either [path] or [type] must be defined");
         }
@@ -143,16 +143,16 @@ public class InnerHitsParseElement implements SearchParseElement {
         return innerHits;
     }
 
-    private InnerHitsContext.ParentChildInnerHits parseParentChild(XContentParser parser, QueryShardContext context, SearchContext searchContext, String type) throws Exception {
-        ParseResult parseResult = parseSubSearchContext(searchContext, context, parser);
+    private InnerHitsContext.ParentChildInnerHits parseParentChild(XContentParser parser, QueryParseContext parseContext, SearchContext searchContext, String type) throws Exception {
+        ParseResult parseResult = parseSubSearchContext(searchContext, parseContext, parser);
         DocumentMapper documentMapper = searchContext.mapperService().documentMapper(type);
         if (documentMapper == null) {
             throw new IllegalArgumentException("type [" + type + "] doesn't exist");
         }
-        return new InnerHitsContext.ParentChildInnerHits(parseResult.context(), parseResult.query(), parseResult.childInnerHits(), context.mapperService(), documentMapper);
+        return new InnerHitsContext.ParentChildInnerHits(parseResult.context(), parseResult.query(), parseResult.childInnerHits(), parseContext.mapperService(), documentMapper);
     }
 
-    private InnerHitsContext.NestedInnerHits parseNested(XContentParser parser, QueryShardContext context, SearchContext searchContext, String nestedPath) throws Exception {
+    private InnerHitsContext.NestedInnerHits parseNested(XContentParser parser, QueryParseContext parseContext, SearchContext searchContext, String nestedPath) throws Exception {
         ObjectMapper objectMapper = searchContext.getObjectMapper(nestedPath);
         if (objectMapper == null) {
             throw new IllegalArgumentException("path [" + nestedPath +"] doesn't exist");
@@ -160,14 +160,14 @@ public class InnerHitsParseElement implements SearchParseElement {
         if (objectMapper.nested().isNested() == false) {
             throw new IllegalArgumentException("path [" + nestedPath +"] isn't nested");
         }
-        ObjectMapper parentObjectMapper = context.nestedScope().nextLevel(objectMapper);
-        ParseResult parseResult = parseSubSearchContext(searchContext, context, parser);
-        context.nestedScope().previousLevel();
+        ObjectMapper parentObjectMapper = parseContext.nestedScope().nextLevel(objectMapper);
+        ParseResult parseResult = parseSubSearchContext(searchContext, parseContext, parser);
+        parseContext.nestedScope().previousLevel();
 
         return new InnerHitsContext.NestedInnerHits(parseResult.context(), parseResult.query(), parseResult.childInnerHits(), parentObjectMapper, objectMapper);
     }
 
-    private ParseResult parseSubSearchContext(SearchContext searchContext, QueryShardContext context, XContentParser parser) throws Exception {
+    private ParseResult parseSubSearchContext(SearchContext searchContext, QueryParseContext parseContext, XContentParser parser) throws Exception {
         ParsedQuery query = null;
         Map<String, InnerHitsContext.BaseInnerHits> childInnerHits = null;
         SubSearchContext subSearchContext = new SubSearchContext(searchContext);
@@ -178,10 +178,10 @@ public class InnerHitsParseElement implements SearchParseElement {
                 fieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("query".equals(fieldName)) {
-                    Query q = searchContext.queryParserService().parseInnerQuery(context);
-                    query = new ParsedQuery(q, context.copyNamedQueries());
+                    Query q = searchContext.queryParserService().parseInnerQuery(parseContext);
+                    query = new ParsedQuery(q, parseContext.copyNamedQueries());
                 } else if ("inner_hits".equals(fieldName)) {
-                    childInnerHits = parseInnerHits(parser, context, searchContext);
+                    childInnerHits = parseInnerHits(parser, parseContext, searchContext);
                 } else {
                     parseCommonInnerHitOptions(parser, token, fieldName, subSearchContext, sortParseElement, sourceParseElement, highlighterParseElement, scriptFieldsParseElement, fieldDataFieldsParseElement);
                 }
diff --git a/core/src/main/java/org/elasticsearch/search/highlight/CustomQueryScorer.java b/core/src/main/java/org/elasticsearch/search/highlight/CustomQueryScorer.java
index a2d7624..6914d85 100644
--- a/core/src/main/java/org/elasticsearch/search/highlight/CustomQueryScorer.java
+++ b/core/src/main/java/org/elasticsearch/search/highlight/CustomQueryScorer.java
@@ -79,15 +79,15 @@ public final class CustomQueryScorer extends QueryScorer {
                                            Map<String, WeightedSpanTerm> terms) throws IOException {
             if (query instanceof FunctionScoreQuery) {
                 query = ((FunctionScoreQuery) query).getSubQuery();
-                extract(query, terms);
+                extract(query, query.getBoost(), terms);
             } else if (query instanceof FiltersFunctionScoreQuery) {
                 query = ((FiltersFunctionScoreQuery) query).getSubQuery();
-                extract(query, terms);
+                extract(query, query.getBoost(), terms);
             } else if (query instanceof FilteredQuery) {
                 query = ((FilteredQuery) query).getQuery();
-                extract(query, terms);
+                extract(query, 1F, terms);
             } else {
-                extractWeightedTerms(terms, query);
+                extractWeightedTerms(terms, query, query.getBoost());
             }
         }
 
diff --git a/core/src/main/java/org/elasticsearch/search/highlight/HighlighterParseElement.java b/core/src/main/java/org/elasticsearch/search/highlight/HighlighterParseElement.java
index 74723c7..12f376f 100644
--- a/core/src/main/java/org/elasticsearch/search/highlight/HighlighterParseElement.java
+++ b/core/src/main/java/org/elasticsearch/search/highlight/HighlighterParseElement.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.search.highlight;
 
-import com.google.common.collect.Sets;
 import org.apache.lucene.search.vectorhighlight.SimpleBoundaryScanner;
 import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.xcontent.XContentParser;
@@ -30,6 +29,7 @@ import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
 import java.util.ArrayList;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
 
@@ -211,7 +211,7 @@ public class HighlighterParseElement implements SearchParseElement {
                     }
                     fieldOptionsBuilder.postTags(postTagsList.toArray(new String[postTagsList.size()]));
                 } else if ("matched_fields".equals(fieldName) || "matchedFields".equals(fieldName)) {
-                    Set<String> matchedFields = Sets.newHashSet();
+                    Set<String> matchedFields = new HashSet<>();
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                         matchedFields.add(parser.text());
                     }
diff --git a/core/src/main/java/org/elasticsearch/search/internal/DefaultSearchContext.java b/core/src/main/java/org/elasticsearch/search/internal/DefaultSearchContext.java
index d3ea19e..981c277 100644
--- a/core/src/main/java/org/elasticsearch/search/internal/DefaultSearchContext.java
+++ b/core/src/main/java/org/elasticsearch/search/internal/DefaultSearchContext.java
@@ -20,12 +20,7 @@
 package org.elasticsearch.search.internal;
 
 import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Collector;
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.ScoreDoc;
-import org.apache.lucene.search.Sort;
+import org.apache.lucene.search.*;
 import org.apache.lucene.util.Counter;
 import org.elasticsearch.action.search.SearchType;
 import org.elasticsearch.cache.recycler.PageCacheRecycler;
@@ -33,8 +28,8 @@ import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.ParseFieldMatcher;
 import org.elasticsearch.common.lease.Releasables;
 import org.elasticsearch.common.lucene.search.Queries;
-import org.elasticsearch.common.lucene.search.function.BoostScoreFunction;
 import org.elasticsearch.common.lucene.search.function.FunctionScoreQuery;
+import org.elasticsearch.common.lucene.search.function.WeightFactorFunction;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.index.IndexService;
@@ -67,16 +62,26 @@ import org.elasticsearch.search.rescore.RescoreSearchContext;
 import org.elasticsearch.search.suggest.SuggestionSearchContext;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
+import java.util.*;
 
 /**
  *
  */
 public class DefaultSearchContext extends SearchContext {
+    /**
+     * Index setting describing the maximum value of from + size on a query.
+     */
+    public static final String MAX_RESULT_WINDOW = "index.max_result_window";
+    public static class Defaults {
+        /**
+         * Default maximum value of from + size on a query. 10,000 was chosen as
+         * a conservative default as it is sure to not cause trouble. Users can
+         * certainly profile their cluster and decide to set it to 100,000
+         * safely. 1,000,000 is probably way to high for any cluster to set
+         * safely.
+         */
+        public static final int MAX_RESULT_WINDOW = 10000;
+    }
 
     private final long id;
     private final ShardSearchRequest request;
@@ -168,12 +173,20 @@ public class DefaultSearchContext extends SearchContext {
      */
     @Override
     public void preProcess() {
-        if (!(from() == -1 && size() == -1)) {
-            // from and size have been set.
-            int numHits = from() + size();
-            if (numHits < 0) {
-                String msg = "Result window is too large, from + size must be less than or equal to: [" + Integer.MAX_VALUE + "] but was [" + (((long) from()) + ((long) size())) + "]";
-                throw new QueryPhaseExecutionException(this, msg);
+        if (scrollContext == null) {
+            long from = from() == -1 ? 0 : from();
+            long size = size() == -1 ? 10 : size();
+            long resultWindow = from + size;
+            // We need settingsService's view of the settings because its dynamic.
+            // indexService's isn't.
+            int maxResultWindow = indexService.settingsService().getSettings().getAsInt(MAX_RESULT_WINDOW, Defaults.MAX_RESULT_WINDOW);
+
+            if (resultWindow > maxResultWindow) {
+                throw new QueryPhaseExecutionException(this,
+                        "Result window is too large, from + size must be less than or equal to: [" + maxResultWindow + "] but was ["
+                                + resultWindow + "]. See the scroll api for a more efficient way to request large data sets. "
+                                + "This limit can be set by changing the [" + DefaultSearchContext.MAX_RESULT_WINDOW
+                                + "] index level parameter.");
             }
         }
 
@@ -184,7 +197,7 @@ public class DefaultSearchContext extends SearchContext {
             parsedQuery(ParsedQuery.parsedMatchAllQuery());
         }
         if (queryBoost() != 1.0f) {
-            parsedQuery(new ParsedQuery(new FunctionScoreQuery(query(), new BoostScoreFunction(queryBoost)), parsedQuery()));
+            parsedQuery(new ParsedQuery(new FunctionScoreQuery(query(), new WeightFactorFunction(queryBoost)), parsedQuery()));
         }
         Query searchFilter = searchFilter(types());
         if (searchFilter != null) {
diff --git a/core/src/main/java/org/elasticsearch/search/internal/SearchContext.java b/core/src/main/java/org/elasticsearch/search/internal/SearchContext.java
index d73e3a7..234a841 100644
--- a/core/src/main/java/org/elasticsearch/search/internal/SearchContext.java
+++ b/core/src/main/java/org/elasticsearch/search/internal/SearchContext.java
@@ -43,7 +43,7 @@ import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.mapper.object.ObjectMapper;
 import org.elasticsearch.index.query.IndexQueryParserService;
 import org.elasticsearch.index.query.ParsedQuery;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.shard.IndexShard;
 import org.elasticsearch.index.similarity.SimilarityService;
 import org.elasticsearch.script.ScriptService;
@@ -75,12 +75,12 @@ public abstract class SearchContext extends DelegatingHasContextAndHeaders imple
 
     public static void setCurrent(SearchContext value) {
         current.set(value);
-        QueryShardContext.setTypes(value.types());
+        QueryParseContext.setTypes(value.types());
     }
 
     public static void removeCurrent() {
         current.remove();
-        QueryShardContext.removeTypes();
+        QueryParseContext.removeTypes();
     }
 
     public static SearchContext current() {
diff --git a/core/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortParser.java b/core/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortParser.java
index 405e2cc..f10db63 100644
--- a/core/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortParser.java
+++ b/core/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortParser.java
@@ -170,6 +170,7 @@ public class GeoDistanceSortParser implements SortParser {
 
         final Nested nested;
         if (nestedHelper != null && nestedHelper.getPath() != null) {
+            
             BitSetProducer rootDocumentsFilter = context.bitsetFilterCache().getBitSetProducer(Queries.newNonNestedFilter());
             Filter innerDocumentsFilter;
             if (nestedHelper.filterFound()) {
diff --git a/core/src/main/java/org/elasticsearch/snapshots/RestoreService.java b/core/src/main/java/org/elasticsearch/snapshots/RestoreService.java
index 443e723..3616725 100644
--- a/core/src/main/java/org/elasticsearch/snapshots/RestoreService.java
+++ b/core/src/main/java/org/elasticsearch/snapshots/RestoreService.java
@@ -81,6 +81,7 @@ import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
@@ -89,7 +90,6 @@ import java.util.Set;
 import java.util.concurrent.BlockingQueue;
 import java.util.concurrent.CopyOnWriteArrayList;
 
-import static com.google.common.collect.Sets.newHashSet;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_AUTO_EXPAND_REPLICAS;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_CREATION_DATE;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_INDEX_UUID;
@@ -229,7 +229,7 @@ public class RestoreService extends AbstractComponent implements ClusterStateLis
                     ClusterBlocks.Builder blocks = ClusterBlocks.builder().blocks(currentState.blocks());
                     RoutingTable.Builder rtBuilder = RoutingTable.builder(currentState.routingTable());
                     final ImmutableMap<ShardId, RestoreInProgress.ShardRestoreStatus> shards;
-                    Set<String> aliases = newHashSet();
+                    Set<String> aliases = new HashSet<>();
                     if (!renamedIndices.isEmpty()) {
                         // We have some indices to restore
                         ImmutableMap.Builder<ShardId, RestoreInProgress.ShardRestoreStatus> shardsBuilder = ImmutableMap.builder();
diff --git a/core/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java b/core/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java
index 1e19633..76485a0 100644
--- a/core/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java
+++ b/core/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java
@@ -64,13 +64,13 @@ import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Locale;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.CopyOnWriteArrayList;
 
-import static com.google.common.collect.Sets.newHashSet;
 import static org.elasticsearch.cluster.SnapshotsInProgress.completed;
 
 /**
@@ -139,7 +139,7 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
      * @return list of snapshots
      */
     public List<Snapshot> snapshots(String repositoryName) {
-        Set<Snapshot> snapshotSet = newHashSet();
+        Set<Snapshot> snapshotSet = new HashSet<>();
         List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, null);
         for (SnapshotsInProgress.Entry entry : entries) {
             snapshotSet.add(inProgressSnapshot(entry));
@@ -736,8 +736,8 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
      * @return list of failed and closed indices
      */
     private Tuple<Set<String>, Set<String>> indicesWithMissingShards(ImmutableMap<ShardId, SnapshotsInProgress.ShardSnapshotStatus> shards, MetaData metaData) {
-        Set<String> missing = newHashSet();
-        Set<String> closed = newHashSet();
+        Set<String> missing = new HashSet<>();
+        Set<String> closed = new HashSet<>();
         for (ImmutableMap.Entry<ShardId, SnapshotsInProgress.ShardSnapshotStatus> entry : shards.entrySet()) {
             if (entry.getValue().state() == State.MISSING) {
                 if (metaData.hasIndex(entry.getKey().getIndex()) && metaData.index(entry.getKey().getIndex()).getState() == IndexMetaData.State.CLOSE) {
diff --git a/core/src/main/java/org/elasticsearch/transport/TransportModule.java b/core/src/main/java/org/elasticsearch/transport/TransportModule.java
index 6926401..abf90de 100644
--- a/core/src/main/java/org/elasticsearch/transport/TransportModule.java
+++ b/core/src/main/java/org/elasticsearch/transport/TransportModule.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.transport;
 
-import com.google.common.base.Preconditions;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.common.inject.AbstractModule;
 import org.elasticsearch.common.io.stream.NamedWriteableRegistry;
@@ -31,6 +30,7 @@ import org.elasticsearch.transport.netty.NettyTransport;
 
 import java.util.HashMap;
 import java.util.Map;
+import java.util.Objects;
 
 /**
  *
@@ -107,15 +107,15 @@ public class TransportModule extends AbstractModule {
     }
 
     public void setTransportService(Class<? extends TransportService> transportService, String source) {
-        Preconditions.checkNotNull(transportService, "Configured transport service may not be null");
-        Preconditions.checkNotNull(source, "Plugin, that changes transport service may not be null");
+        Objects.requireNonNull(transportService, "Configured transport service may not be null");
+        Objects.requireNonNull(source, "Plugin, that changes transport service may not be null");
         this.configuredTransportService = transportService;
         this.configuredTransportServiceSource = source;
     }
 
     public void setTransport(Class<? extends Transport> transport, String source) {
-        Preconditions.checkNotNull(transport, "Configured transport may not be null");
-        Preconditions.checkNotNull(source, "Plugin, that changes transport may not be null");
+        Objects.requireNonNull(transport, "Configured transport may not be null");
+        Objects.requireNonNull(source, "Plugin, that changes transport may not be null");
         this.configuredTransport = transport;
         this.configuredTransportSource = source;
     }
diff --git a/core/src/main/resources/org/elasticsearch/bootstrap/security.policy b/core/src/main/resources/org/elasticsearch/bootstrap/security.policy
index 4f984aa..aa88fba 100644
--- a/core/src/main/resources/org/elasticsearch/bootstrap/security.policy
+++ b/core/src/main/resources/org/elasticsearch/bootstrap/security.policy
@@ -36,6 +36,10 @@ grant codeBase "${es.security.jar.lucene.core}" {
   permission java.lang.RuntimePermission "accessClassInPackage.sun.misc";
 };
 
+//// test framework permissions.
+//// These are mock objects and test management that we allow test framework libs
+//// to provide on our behalf. But tests themselves cannot do this stuff!
+
 grant codeBase "${es.security.jar.elasticsearch.securemock}" {
   // needed to support creation of mocks
   permission java.lang.RuntimePermission "reflectionFactoryAccess";
@@ -80,8 +84,6 @@ grant {
   permission java.lang.RuntimePermission "getProtectionDomain";
 
   // reflection hacks:
-  // needed for mock filesystems in tests (to capture implCloseChannel)
-  permission java.lang.RuntimePermission "accessClassInPackage.sun.nio.ch";
   // needed by groovy engine
   permission java.lang.RuntimePermission "accessClassInPackage.sun.reflect";
   // needed by aws core sdk (TODO: look into this)
diff --git a/core/src/test/java/org/elasticsearch/ESExceptionTests.java b/core/src/test/java/org/elasticsearch/ESExceptionTests.java
index eb3d870..a43352f 100644
--- a/core/src/test/java/org/elasticsearch/ESExceptionTests.java
+++ b/core/src/test/java/org/elasticsearch/ESExceptionTests.java
@@ -24,6 +24,7 @@ import org.apache.lucene.index.IndexFormatTooNewException;
 import org.apache.lucene.index.IndexFormatTooOldException;
 import org.apache.lucene.store.AlreadyClosedException;
 import org.apache.lucene.store.LockObtainFailedException;
+import org.apache.lucene.util.Constants;
 import org.elasticsearch.action.search.SearchPhaseExecutionException;
 import org.elasticsearch.action.search.ShardSearchFailure;
 import org.elasticsearch.common.io.stream.BytesStreamOutput;
@@ -35,7 +36,8 @@ import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentLocation;
 import org.elasticsearch.index.Index;
 import org.elasticsearch.index.IndexNotFoundException;
-import org.elasticsearch.index.query.*;
+import org.elasticsearch.index.query.QueryParsingException;
+import org.elasticsearch.index.query.TestQueryParsingException;
 import org.elasticsearch.rest.RestStatus;
 import org.elasticsearch.search.SearchParseException;
 import org.elasticsearch.search.SearchShardTarget;
@@ -51,6 +53,7 @@ import java.io.EOFException;
 import java.io.FileNotFoundException;
 import java.io.IOException;
 import java.nio.file.NoSuchFileException;
+import java.util.Collections;
 
 import static org.hamcrest.Matchers.equalTo;
 
@@ -307,7 +310,7 @@ public class ESExceptionTests extends ESTestCase {
                 new OutOfMemoryError("no memory left"),
                 new AlreadyClosedException("closed!!", new NullPointerException()),
                 new LockObtainFailedException("can't lock directory", new NullPointerException()),
-                new Throwable("this exception is unknown", new QueryShardException(new Index("foo"), "foobar", null) ), // somethin unknown
+                new Throwable("this exception is unknown", new QueryParsingException(new Index("foo"), 1, 2, "foobar", null) ), // somethin unknown
         };
         for (Throwable t : causes) {
             BytesStreamOutput out = new BytesStreamOutput();
@@ -322,7 +325,12 @@ public class ESExceptionTests extends ESTestCase {
             } else {
                 assertEquals(e.getCause().getClass(), NotSerializableExceptionWrapper.class);
             }
-            assertArrayEquals(e.getStackTrace(), ex.getStackTrace());
+            // TODO: fix this test
+            // on java 9, expected:<sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)> 
+            //            but was:<sun.reflect.NativeMethodAccessorImpl.invoke0(java.base@9.0/Native Method)>
+            if (!Constants.JRE_IS_MINIMUM_JAVA9) {
+                assertArrayEquals(e.getStackTrace(), ex.getStackTrace());
+            }
             assertTrue(e.getStackTrace().length > 1);
             ElasticsearchAssertions.assertVersionSerializable(VersionUtils.randomVersion(getRandom()), t);
             ElasticsearchAssertions.assertVersionSerializable(VersionUtils.randomVersion(getRandom()), ex);
diff --git a/core/src/test/java/org/elasticsearch/ExceptionSerializationTests.java b/core/src/test/java/org/elasticsearch/ExceptionSerializationTests.java
index eaa5ad0..32e30cf 100644
--- a/core/src/test/java/org/elasticsearch/ExceptionSerializationTests.java
+++ b/core/src/test/java/org/elasticsearch/ExceptionSerializationTests.java
@@ -21,7 +21,8 @@ package org.elasticsearch;
 import com.fasterxml.jackson.core.JsonLocation;
 import com.fasterxml.jackson.core.JsonParseException;
 import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Sets;
+
+import org.apache.lucene.util.Constants;
 import org.codehaus.groovy.runtime.typehandling.GroovyCastException;
 import org.elasticsearch.action.FailedNodeException;
 import org.elasticsearch.action.RoutingMissingException;
@@ -32,7 +33,12 @@ import org.elasticsearch.client.AbstractClientHeadersTestCase;
 import org.elasticsearch.cluster.block.ClusterBlockException;
 import org.elasticsearch.cluster.metadata.SnapshotId;
 import org.elasticsearch.cluster.node.DiscoveryNode;
-import org.elasticsearch.cluster.routing.*;
+import org.elasticsearch.cluster.routing.IllegalShardRoutingStateException;
+import org.elasticsearch.cluster.routing.RoutingTableValidation;
+import org.elasticsearch.cluster.routing.RoutingValidationException;
+import org.elasticsearch.cluster.routing.ShardRouting;
+import org.elasticsearch.cluster.routing.ShardRoutingState;
+import org.elasticsearch.cluster.routing.TestShardRouting;
 import org.elasticsearch.common.breaker.CircuitBreakingException;
 import org.elasticsearch.common.io.PathUtils;
 import org.elasticsearch.common.io.stream.BytesStreamOutput;
@@ -41,11 +47,12 @@ import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.transport.LocalTransportAddress;
 import org.elasticsearch.common.unit.ByteSizeValue;
+import org.elasticsearch.common.util.CancellableThreadsTests;
+import org.elasticsearch.common.util.set.Sets;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentLocation;
-import org.elasticsearch.common.util.CancellableThreadsTests;
 import org.elasticsearch.discovery.DiscoverySettings;
 import org.elasticsearch.index.AlreadyExpiredException;
 import org.elasticsearch.index.Index;
@@ -54,7 +61,6 @@ import org.elasticsearch.index.engine.IndexFailedEngineException;
 import org.elasticsearch.index.engine.RecoveryEngineException;
 import org.elasticsearch.index.mapper.MergeMappingException;
 import org.elasticsearch.index.query.QueryParsingException;
-import org.elasticsearch.index.query.QueryShardException;
 import org.elasticsearch.index.shard.IllegalIndexShardStateException;
 import org.elasticsearch.index.shard.IndexShardState;
 import org.elasticsearch.index.shard.ShardId;
@@ -233,16 +239,6 @@ public class ExceptionSerializationTests extends ESTestCase {
         assertEquals(ex.getColumnNumber(), 2);
     }
 
-    public void testQueryShardException() throws IOException {
-        QueryShardException ex = serialize(new QueryShardException(new Index("foo"), "fobar", null));
-        assertEquals(ex.getIndex(), "foo");
-        assertEquals(ex.getMessage(), "fobar");
-
-        ex = serialize(new QueryShardException((Index)null, null, null));
-        assertNull(ex.getIndex());
-        assertNull(ex.getMessage());
-    }
-
     public void testSearchException() throws IOException {
         SearchShardTarget target = new SearchShardTarget("foo", "bar", 1);
         SearchException ex = serialize(new SearchException(target, "hello world"));
@@ -573,12 +569,15 @@ public class ExceptionSerializationTests extends ESTestCase {
             }
             Throwable deserialized = serialize(t);
             assertTrue(deserialized instanceof NotSerializableExceptionWrapper);
-            assertArrayEquals(t.getStackTrace(), deserialized.getStackTrace());
-            assertEquals(t.getSuppressed().length, deserialized.getSuppressed().length);
-            if (t.getSuppressed().length > 0) {
-                assertTrue(deserialized.getSuppressed()[0] instanceof NotSerializableExceptionWrapper);
-                assertArrayEquals(t.getSuppressed()[0].getStackTrace(), deserialized.getSuppressed()[0].getStackTrace());
-                assertTrue(deserialized.getSuppressed()[1] instanceof NullPointerException);
+            // TODO: fix this test for more java 9 differences
+            if (!Constants.JRE_IS_MINIMUM_JAVA9) {
+                assertArrayEquals(t.getStackTrace(), deserialized.getStackTrace());
+                assertEquals(t.getSuppressed().length, deserialized.getSuppressed().length);
+                if (t.getSuppressed().length > 0) {
+                    assertTrue(deserialized.getSuppressed()[0] instanceof NotSerializableExceptionWrapper);
+                    assertArrayEquals(t.getSuppressed()[0].getStackTrace(), deserialized.getSuppressed()[0].getStackTrace());
+                    assertTrue(deserialized.getSuppressed()[1] instanceof NullPointerException);
+                }
             }
         }
     }
diff --git a/core/src/test/java/org/elasticsearch/action/admin/indices/template/put/MetaDataIndexTemplateServiceTests.java b/core/src/test/java/org/elasticsearch/action/admin/indices/template/put/MetaDataIndexTemplateServiceTests.java
index 53f3a14..86a9bbc 100644
--- a/core/src/test/java/org/elasticsearch/action/admin/indices/template/put/MetaDataIndexTemplateServiceTests.java
+++ b/core/src/test/java/org/elasticsearch/action/admin/indices/template/put/MetaDataIndexTemplateServiceTests.java
@@ -19,10 +19,8 @@
 
 package org.elasticsearch.action.admin.indices.template.put;
 
-import com.google.common.collect.Sets;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
-import org.elasticsearch.cluster.metadata.IndexTemplateFilter;
 import org.elasticsearch.cluster.metadata.MetaDataCreateIndexService;
 import org.elasticsearch.cluster.metadata.MetaDataIndexTemplateService;
 import org.elasticsearch.cluster.metadata.MetaDataIndexTemplateService.PutRequest;
@@ -33,6 +31,7 @@ import org.junit.Test;
 
 import java.util.ArrayList;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 
@@ -82,7 +81,7 @@ public class MetaDataIndexTemplateServiceTests extends ESTestCase {
                 null,
                 Version.CURRENT,
                 null,
-                Sets.<IndexTemplateFilter>newHashSet(),
+                new HashSet<>(),
                 null,
                 null
         );
diff --git a/core/src/test/java/org/elasticsearch/aliases/IndexAliasesIT.java b/core/src/test/java/org/elasticsearch/aliases/IndexAliasesIT.java
index 05037eb..ccde0fa 100644
--- a/core/src/test/java/org/elasticsearch/aliases/IndexAliasesIT.java
+++ b/core/src/test/java/org/elasticsearch/aliases/IndexAliasesIT.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.aliases;
 
-import org.elasticsearch.Version;
 import org.elasticsearch.action.ActionRequestValidationException;
 import org.elasticsearch.action.admin.indices.alias.Alias;
 import org.elasticsearch.action.admin.indices.alias.IndicesAliasesRequestBuilder;
@@ -34,7 +33,6 @@ import org.elasticsearch.cluster.metadata.AliasMetaData;
 import org.elasticsearch.cluster.metadata.AliasOrIndex;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.StopWatch;
-import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.index.query.QueryBuilder;
 import org.elasticsearch.index.query.QueryBuilders;
@@ -49,12 +47,12 @@ import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
 
 import java.util.Arrays;
+import java.util.HashSet;
 import java.util.Set;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
 import java.util.concurrent.TimeUnit;
 
-import static com.google.common.collect.Sets.newHashSet;
 import static org.elasticsearch.client.Requests.createIndexRequest;
 import static org.elasticsearch.client.Requests.indexRequest;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.INDEX_METADATA_BLOCK;
@@ -151,7 +149,7 @@ public class IndexAliasesIT extends ESIntegTestCase {
         logger.info("--> making sure that filter was stored with alias [alias1] and filter [user:kimchy]");
         ClusterState clusterState = admin().cluster().prepareState().get().getState();
         IndexMetaData indexMd = clusterState.metaData().index("test");
-        assertThat(indexMd.aliases().get("alias1").filter().string(), equalTo("{\"term\":{\"user\":{\"value\":\"kimchy\",\"boost\":1.0}}}"));
+        assertThat(indexMd.aliases().get("alias1").filter().string(), equalTo("{\"term\":{\"user\":\"kimchy\"}}"));
 
     }
 
@@ -413,8 +411,8 @@ public class IndexAliasesIT extends ESIntegTestCase {
         assertThat(client().prepareCount("bars").setQuery(QueryBuilders.matchAllQuery()).get().getCount(), equalTo(1L));
     }
 
-
-
+    
+    
     @Test
     public void testDeleteAliases() throws Exception {
         logger.info("--> creating index [test1] and [test2]");
@@ -434,17 +432,17 @@ public class IndexAliasesIT extends ESIntegTestCase {
                 .addAlias("test2", "aliasToTests")
                 .addAlias("test2", "foos", termQuery("name", "foo"))
                 .addAlias("test2", "tests", termQuery("name", "test")));
-
-        String[] indices = {"test1", "test2"};
+        
+        String[] indices = {"test1", "test2"}; 
         String[] aliases = {"aliasToTest1", "foos", "bars", "tests", "aliasToTest2", "aliasToTests"};
-
+        
         admin().indices().prepareAliases().removeAlias(indices, aliases).get();
-
+        
         AliasesExistResponse response = admin().indices().prepareAliasesExist(aliases).get();
         assertThat(response.exists(), equalTo(false));
     }
 
-
+    
     @Test
     public void testWaitForAliasCreationMultipleShards() throws Exception {
         logger.info("--> creating index [test]");
@@ -532,16 +530,16 @@ public class IndexAliasesIT extends ESIntegTestCase {
 
         logger.info("--> verify that filter was updated");
         AliasMetaData aliasMetaData = ((AliasOrIndex.Alias) internalCluster().clusterService().state().metaData().getAliasAndIndexLookup().get("alias1")).getFirstAliasMetaData();
-        assertThat(aliasMetaData.getFilter().toString(), equalTo("{\"term\":{\"name\":{\"value\":\"bar\",\"boost\":1.0}}}"));
+        assertThat(aliasMetaData.getFilter().toString(), equalTo("{\"term\":{\"name\":\"bar\"}}"));
 
         logger.info("--> deleting alias1");
         stopWatch.start();
         assertAcked((admin().indices().prepareAliases().removeAlias("test", "alias1").setTimeout(timeout)));
         assertThat(stopWatch.stop().lastTaskTime().millis(), lessThan(timeout.millis()));
 
-
+        
     }
-
+    
     @Test(expected = AliasesNotFoundException.class)
     public void testIndicesRemoveNonExistingAliasResponds404() throws Exception {
         logger.info("--> creating index [test]");
@@ -1050,7 +1048,7 @@ public class IndexAliasesIT extends ESIntegTestCase {
 
     private void assertHits(SearchHits hits, String... ids) {
         assertThat(hits.totalHits(), equalTo((long) ids.length));
-        Set<String> hitIds = newHashSet();
+        Set<String> hitIds = new HashSet<>();
         for (SearchHit hit : hits.getHits()) {
             hitIds.add(hit.id());
         }
diff --git a/core/src/test/java/org/elasticsearch/benchmark/search/child/ChildSearchBenchmark.java b/core/src/test/java/org/elasticsearch/benchmark/search/child/ChildSearchBenchmark.java
index cdc3d63..bc0d188 100644
--- a/core/src/test/java/org/elasticsearch/benchmark/search/child/ChildSearchBenchmark.java
+++ b/core/src/test/java/org/elasticsearch/benchmark/search/child/ChildSearchBenchmark.java
@@ -26,7 +26,6 @@ import org.elasticsearch.client.Client;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.SizeValue;
 import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.query.ScoreType;
 import org.elasticsearch.indices.IndexAlreadyExistsException;
 import org.elasticsearch.node.Node;
 import org.elasticsearch.search.aggregations.AggregationBuilders;
@@ -282,12 +281,12 @@ public class ChildSearchBenchmark {
         System.out.println("--> Running has_child query with score type");
         // run parent child score query
         for (int j = 0; j < QUERY_WARMUP; j++) {
-            client.prepareSearch(indexName).setQuery(hasChildQuery("child", termQuery("field2", parentChildIndexGenerator.getQueryValue())).scoreType(ScoreType.MAX)).execute().actionGet();
+            client.prepareSearch(indexName).setQuery(hasChildQuery("child", termQuery("field2", parentChildIndexGenerator.getQueryValue())).scoreMode("max")).execute().actionGet();
         }
 
         totalQueryTime = 0;
         for (int j = 0; j < QUERY_COUNT; j++) {
-            SearchResponse searchResponse = client.prepareSearch(indexName).setQuery(hasChildQuery("child", termQuery("field2", parentChildIndexGenerator.getQueryValue())).scoreType(ScoreType.MAX)).execute().actionGet();
+            SearchResponse searchResponse = client.prepareSearch(indexName).setQuery(hasChildQuery("child", termQuery("field2", parentChildIndexGenerator.getQueryValue())).scoreMode("max")).execute().actionGet();
             if (j % 10 == 0) {
                 System.out.println("--> hits [" + j + "], got [" + searchResponse.getHits().totalHits() + "]");
             }
@@ -297,7 +296,7 @@ public class ChildSearchBenchmark {
         
         totalQueryTime = 0;
         for (int j = 0; j < QUERY_COUNT; j++) {
-            SearchResponse searchResponse = client.prepareSearch(indexName).setQuery(hasChildQuery("child", matchAllQuery()).scoreType(ScoreType.MAX)).execute().actionGet();
+            SearchResponse searchResponse = client.prepareSearch(indexName).setQuery(hasChildQuery("child", matchAllQuery()).scoreMode("max")).execute().actionGet();
             if (j % 10 == 0) {
                 System.out.println("--> hits [" + j + "], got [" + searchResponse.getHits().totalHits() + "]");
             }
@@ -308,12 +307,12 @@ public class ChildSearchBenchmark {
         System.out.println("--> Running has_parent query with score type");
         // run parent child score query
         for (int j = 0; j < QUERY_WARMUP; j++) {
-            client.prepareSearch(indexName).setQuery(hasParentQuery("parent", termQuery("field1", parentChildIndexGenerator.getQueryValue())).score(true)).execute().actionGet();
+            client.prepareSearch(indexName).setQuery(hasParentQuery("parent", termQuery("field1", parentChildIndexGenerator.getQueryValue())).scoreMode("score")).execute().actionGet();
         }
 
         totalQueryTime = 0;
         for (int j = 1; j < QUERY_COUNT; j++) {
-            SearchResponse searchResponse = client.prepareSearch(indexName).setQuery(hasParentQuery("parent", termQuery("field1", parentChildIndexGenerator.getQueryValue())).score(true)).execute().actionGet();
+            SearchResponse searchResponse = client.prepareSearch(indexName).setQuery(hasParentQuery("parent", termQuery("field1", parentChildIndexGenerator.getQueryValue())).scoreMode("score")).execute().actionGet();
             if (j % 10 == 0) {
                 System.out.println("--> hits [" + j + "], got [" + searchResponse.getHits().totalHits() + "]");
             }
@@ -323,7 +322,7 @@ public class ChildSearchBenchmark {
 
         totalQueryTime = 0;
         for (int j = 1; j < QUERY_COUNT; j++) {
-            SearchResponse searchResponse = client.prepareSearch(indexName).setQuery(hasParentQuery("parent", matchAllQuery()).score(true)).execute().actionGet();
+            SearchResponse searchResponse = client.prepareSearch(indexName).setQuery(hasParentQuery("parent", matchAllQuery()).scoreMode("score")).execute().actionGet();
             if (j % 10 == 0) {
                 System.out.println("--> hits [" + j + "], got [" + searchResponse.getHits().totalHits() + "]");
             }
diff --git a/core/src/test/java/org/elasticsearch/benchmark/search/child/ChildSearchShortCircuitBenchmark.java b/core/src/test/java/org/elasticsearch/benchmark/search/child/ChildSearchShortCircuitBenchmark.java
index c44977b..f7eaa74 100644
--- a/core/src/test/java/org/elasticsearch/benchmark/search/child/ChildSearchShortCircuitBenchmark.java
+++ b/core/src/test/java/org/elasticsearch/benchmark/search/child/ChildSearchShortCircuitBenchmark.java
@@ -30,7 +30,6 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.SizeValue;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.query.ScoreType;
 import org.elasticsearch.node.Node;
 
 import java.io.IOException;
@@ -179,7 +178,7 @@ public class ChildSearchShortCircuitBenchmark {
         for (int i = 1; i < PARENT_COUNT; i *= 2) {
             for (int j = 0; j < QUERY_COUNT; j++) {
                 SearchResponse searchResponse = client.prepareSearch(indexName)
-                        .setQuery(hasChildQuery("child", matchQuery("field2", i)).scoreType(ScoreType.MAX))
+                        .setQuery(hasChildQuery("child", matchQuery("field2", i)).scoreMode("max"))
                         .execute().actionGet();
                 if (searchResponse.getHits().totalHits() != i) {
                     System.err.println("--> mismatch on hits");
diff --git a/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java b/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java
index a779db2..e31fc7d 100644
--- a/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java
+++ b/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java
@@ -86,7 +86,7 @@ public class BootstrapForTesting {
                 // initialize paths the same exact way as bootstrap.
                 Permissions perms = new Permissions();
                 // add permissions to everything in classpath
-                for (URL url : ((URLClassLoader)BootstrapForTesting.class.getClassLoader()).getURLs()) {
+                for (URL url : JarHell.parseClassPath()) {
                     Path path = PathUtils.get(url.toURI());
                     // resource itself
                     perms.add(new FilePermission(path.toString(), "read,readlink"));
@@ -97,6 +97,7 @@ public class BootstrapForTesting {
                     String filename = path.getFileName().toString();
                     if (filename.contains("jython") && filename.endsWith(".jar")) {
                         // just enough so it won't fail when it does not exist
+                        perms.add(new FilePermission(path.getParent().toString(), "read,readlink"));
                         perms.add(new FilePermission(path.getParent().resolve("Lib").toString(), "read,readlink"));
                     }
                 }
@@ -114,7 +115,7 @@ public class BootstrapForTesting {
                     perms.add(new FilePermission(coverageDir.resolve("jacoco-it.exec").toString(), "read,write"));
                 }
                 Policy.setPolicy(new ESPolicy(perms));
-                System.setSecurityManager(new XTestSecurityManager());
+                System.setSecurityManager(new TestSecurityManager());
                 Security.selfTest();
             } catch (Exception e) {
                 throw new RuntimeException("unable to install test security manager", e);
diff --git a/core/src/test/java/org/elasticsearch/bootstrap/XTestSecurityManager.java b/core/src/test/java/org/elasticsearch/bootstrap/XTestSecurityManager.java
deleted file mode 100644
index c626274..0000000
--- a/core/src/test/java/org/elasticsearch/bootstrap/XTestSecurityManager.java
+++ /dev/null
@@ -1,113 +0,0 @@
-package org.elasticsearch.bootstrap;
-
-import java.security.AccessController;
-import java.security.PrivilegedAction;
-
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-// the above license header is a lie, here is the real one.
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * A {@link SecurityManager} that prevents tests calling {@link System#exit(int)}.
- * Only the test runner itself is allowed to exit the JVM.
- * All other security checks are handled by the default security policy.
- * <p>
- * Use this with {@code -Djava.security.manager=org.apache.lucene.util.TestSecurityManager}.
- */ 
-// TODO: remove me when https://issues.apache.org/jira/browse/LUCENE-6794 is committed
-public final class XTestSecurityManager extends SecurityManager {
-  
-  static final String JUNIT4_TEST_RUNNER_PACKAGE = "com.carrotsearch.ant.tasks.junit4.";
-  static final String ECLIPSE_TEST_RUNNER_PACKAGE = "org.eclipse.jdt.internal.junit.runner.";
-  static final String IDEA_TEST_RUNNER_PACKAGE = "com.intellij.rt.execution.junit.";
-
-  /**
-   * Creates a new TestSecurityManager. This ctor is called on JVM startup,
-   * when {@code -Djava.security.manager=org.apache.lucene.util.TestSecurityManager}
-   * is passed to JVM.
-   */
-  public XTestSecurityManager() {
-    super();
-  }
-
-  /**
-   * {@inheritDoc}
-   * <p>This method inspects the stack trace and checks who is calling
-   * {@link System#exit(int)} and similar methods
-   * @throws SecurityException if the caller of this method is not the test runner itself.
-   */
-  @Override
-  public void checkExit(final int status) {
-    AccessController.doPrivileged((PrivilegedAction<Void>) () -> {
-        final String systemClassName = System.class.getName(),
-                runtimeClassName = Runtime.class.getName();
-        String exitMethodHit = null;
-        for (final StackTraceElement se : Thread.currentThread().getStackTrace()) {
-          final String className = se.getClassName(), methodName = se.getMethodName();
-          if (
-                  ("exit".equals(methodName) || "halt".equals(methodName)) &&
-                          (systemClassName.equals(className) || runtimeClassName.equals(className))
-                  ) {
-            exitMethodHit = className + '#' + methodName + '(' + status + ')';
-            continue;
-          }
-
-          if (exitMethodHit != null) {
-            if (className.startsWith(JUNIT4_TEST_RUNNER_PACKAGE) ||
-                    className.startsWith(ECLIPSE_TEST_RUNNER_PACKAGE) ||
-                    className.startsWith(IDEA_TEST_RUNNER_PACKAGE)) {
-              // this exit point is allowed, we return normally from closure:
-              return /*void*/ null;
-            } else {
-              // anything else in stack trace is not allowed, break and throw SecurityException below:
-              break;
-            }
-          }
-        }
-
-        if (exitMethodHit == null) {
-          // should never happen, only if JVM hides stack trace - replace by generic:
-          exitMethodHit = "JVM exit method";
-        }
-        throw new SecurityException(exitMethodHit + " calls are not allowed because they terminate the test runner's JVM.");
-    });
-    
-    // we passed the stack check, delegate to super, so default policy can still deny permission:
-    super.checkExit(status);
-  }
-
-}
diff --git a/core/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityIT.java b/core/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityIT.java
index cca46cf..8151876 100644
--- a/core/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityIT.java
+++ b/core/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityIT.java
@@ -98,8 +98,7 @@ public class OldIndexBackwardsCompatibilityIT extends ESIntegTestCase {
 
     private List<String> loadIndexesList(String prefix) throws IOException {
         List<String> indexes = new ArrayList<>();
-        Path dir = getDataPath(".");
-        try (DirectoryStream<Path> stream = Files.newDirectoryStream(dir, prefix + "-*.zip")) {
+        try (DirectoryStream<Path> stream = Files.newDirectoryStream(getBwcIndicesPath(), prefix + "-*.zip")) {
             for (Path path : stream) {
                 indexes.add(path.getFileName().toString());
             }
@@ -166,7 +165,7 @@ public class OldIndexBackwardsCompatibilityIT extends ESIntegTestCase {
         String indexName = indexFile.replace(".zip", "").toLowerCase(Locale.ROOT).replace("unsupported-", "index-");
 
         // decompress the index
-        Path backwardsIndex = getDataPath(indexFile);
+        Path backwardsIndex = getBwcIndicesPath().resolve(indexFile);
         try (InputStream stream = Files.newInputStream(backwardsIndex)) {
             TestUtil.unzip(stream, unzipDir);
         }
diff --git a/core/src/test/java/org/elasticsearch/bwcompat/RecoveryWithUnsupportedIndicesIT.java b/core/src/test/java/org/elasticsearch/bwcompat/RecoveryWithUnsupportedIndicesIT.java
index d598ba9..486267b 100644
--- a/core/src/test/java/org/elasticsearch/bwcompat/RecoveryWithUnsupportedIndicesIT.java
+++ b/core/src/test/java/org/elasticsearch/bwcompat/RecoveryWithUnsupportedIndicesIT.java
@@ -31,7 +31,7 @@ public class RecoveryWithUnsupportedIndicesIT extends StaticIndexBackwardCompati
         String indexName = "unsupported-0.20.6";
 
         logger.info("Checking static index " + indexName);
-        Settings nodeSettings = prepareBackwardsDataDir(getDataPath(indexName + ".zip"), Node.HTTP_ENABLED, true);
+        Settings nodeSettings = prepareBackwardsDataDir(getBwcIndicesPath().resolve(indexName + ".zip"), Node.HTTP_ENABLED, true);
         try {
             internalCluster().startNode(nodeSettings);
             fail();
diff --git a/core/src/test/java/org/elasticsearch/bwcompat/RestoreBackwardsCompatIT.java b/core/src/test/java/org/elasticsearch/bwcompat/RestoreBackwardsCompatIT.java
index 14bcfc7..9ef4238 100644
--- a/core/src/test/java/org/elasticsearch/bwcompat/RestoreBackwardsCompatIT.java
+++ b/core/src/test/java/org/elasticsearch/bwcompat/RestoreBackwardsCompatIT.java
@@ -62,12 +62,12 @@ public class RestoreBackwardsCompatIT extends AbstractSnapshotIntegTestCase {
             // Configure using path.repo
             return settingsBuilder()
                     .put(super.nodeSettings(nodeOrdinal))
-                    .put("path.repo", reposRoot())
+                    .put("path.repo", getBwcIndicesPath())
                     .build();
         } else {
             // Configure using url white list
             try {
-                URI repoJarPatternUri = new URI("jar:" + reposRoot().toUri().toString() + "*.zip!/repo/");
+                URI repoJarPatternUri = new URI("jar:" + getBwcIndicesPath().toUri().toString() + "*.zip!/repo/");
                 return settingsBuilder()
                         .put(super.nodeSettings(nodeOrdinal))
                         .putArray("repositories.url.allowed_urls", repoJarPatternUri.toString())
@@ -128,10 +128,6 @@ public class RestoreBackwardsCompatIT extends AbstractSnapshotIntegTestCase {
         }
     }
 
-    private Path reposRoot() {
-        return getDataPath(".");
-    }
-
     private List<String> repoVersions() throws Exception {
         return listRepoVersions("repo");
     }
@@ -142,7 +138,7 @@ public class RestoreBackwardsCompatIT extends AbstractSnapshotIntegTestCase {
 
     private List<String> listRepoVersions(String prefix) throws Exception {
         List<String> repoVersions = new ArrayList<>();
-        Path repoFiles = reposRoot();
+        Path repoFiles = getBwcIndicesPath();
         try (DirectoryStream<Path> stream = Files.newDirectoryStream(repoFiles, prefix + "-*.zip")) {
             for (Path entry : stream) {
                 String fileName = entry.getFileName().toString();
@@ -155,8 +151,8 @@ public class RestoreBackwardsCompatIT extends AbstractSnapshotIntegTestCase {
     }
 
     private void createRepo(String prefix, String version, String repo) throws Exception {
-        String repoFile = prefix + "-" + version + ".zip";
-        URI repoFileUri = getDataPath(repoFile).toUri();
+        Path repoFile = getBwcIndicesPath().resolve(prefix + "-" + version + ".zip");
+        URI repoFileUri = repoFile.toUri();
         URI repoJarUri = new URI("jar:" + repoFileUri.toString() + "!/repo/");
         logger.info("-->  creating repository [{}] for version [{}]", repo, version);
         assertAcked(client().admin().cluster().preparePutRepository(repo)
diff --git a/core/src/test/java/org/elasticsearch/cache/recycler/MockPageCacheRecycler.java b/core/src/test/java/org/elasticsearch/cache/recycler/MockPageCacheRecycler.java
index 37927ef..99cd417 100644
--- a/core/src/test/java/org/elasticsearch/cache/recycler/MockPageCacheRecycler.java
+++ b/core/src/test/java/org/elasticsearch/cache/recycler/MockPageCacheRecycler.java
@@ -19,10 +19,10 @@
 
 package org.elasticsearch.cache.recycler;
 
-import com.google.common.collect.Sets;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.recycler.Recycler.V;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.util.set.Sets;
 import org.elasticsearch.test.ESTestCase;
 import org.elasticsearch.test.InternalTestCluster;
 import org.elasticsearch.threadpool.ThreadPool;
@@ -46,7 +46,7 @@ public class MockPageCacheRecycler extends PageCacheRecycler {
             // and releasing pages, lets make sure that after a reasonable timeout, all master
             // copy (snapshot) have been released
             boolean success =
-                    ESTestCase.awaitBusy(() -> Sets.intersection(masterCopy.keySet(), ACQUIRED_PAGES.keySet()).isEmpty());
+                    ESTestCase.awaitBusy(() -> Sets.haveEmptyIntersection(masterCopy.keySet(), ACQUIRED_PAGES.keySet()));
             if (!success) {
                 masterCopy.keySet().retainAll(ACQUIRED_PAGES.keySet());
                 ACQUIRED_PAGES.keySet().removeAll(masterCopy.keySet()); // remove all existing master copy we will report on
diff --git a/core/src/test/java/org/elasticsearch/cluster/MockInternalClusterInfoService.java b/core/src/test/java/org/elasticsearch/cluster/MockInternalClusterInfoService.java
index f3cfe2e..eff22c8 100644
--- a/core/src/test/java/org/elasticsearch/cluster/MockInternalClusterInfoService.java
+++ b/core/src/test/java/org/elasticsearch/cluster/MockInternalClusterInfoService.java
@@ -18,20 +18,27 @@
  */
 package org.elasticsearch.cluster;
 
+import org.elasticsearch.Version;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.admin.cluster.node.stats.NodeStats;
 import org.elasticsearch.action.admin.cluster.node.stats.NodesStatsResponse;
 import org.elasticsearch.action.admin.cluster.node.stats.TransportNodesStatsAction;
 import org.elasticsearch.action.admin.indices.stats.IndicesStatsResponse;
 import org.elasticsearch.action.admin.indices.stats.TransportIndicesStatsAction;
-import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDeciderTests;
-import org.elasticsearch.cluster.routing.allocation.decider.MockDiskUsagesIT;
+import org.elasticsearch.cluster.node.DiscoveryNode;
+import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.transport.DummyTransportAddress;
+import org.elasticsearch.monitor.fs.FsInfo;
 import org.elasticsearch.node.settings.NodeSettingsService;
 import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.threadpool.ThreadPool;
 
+import java.util.AbstractMap;
+import java.util.Collections;
+import java.util.Map;
+import java.util.Set;
 import java.util.concurrent.CountDownLatch;
 
 /**
@@ -57,6 +64,21 @@ public class MockInternalClusterInfoService extends InternalClusterInfoService {
     private final ClusterName clusterName;
     private volatile NodeStats[] stats = new NodeStats[3];
 
+    /** Create a fake NodeStats for the given node and usage */
+    public static NodeStats makeStats(String nodeName, DiskUsage usage) {
+        FsInfo.Path[] paths = new FsInfo.Path[1];
+        FsInfo.Path path = new FsInfo.Path("/dev/null", null,
+            usage.getTotalBytes(), usage.getFreeBytes(), usage.getFreeBytes());
+        paths[0] = path;
+        FsInfo fsInfo = new FsInfo(System.currentTimeMillis(), paths);
+        return new NodeStats(new DiscoveryNode(nodeName, DummyTransportAddress.INSTANCE, Version.CURRENT),
+            System.currentTimeMillis(),
+            null, null, null, null, null,
+            fsInfo,
+            null, null, null,
+            null);
+    }
+
     @Inject
     public MockInternalClusterInfoService(Settings settings, NodeSettingsService nodeSettingsService,
                                           TransportNodesStatsAction transportNodesStatsAction,
@@ -64,21 +86,21 @@ public class MockInternalClusterInfoService extends InternalClusterInfoService {
                                           ClusterService clusterService, ThreadPool threadPool) {
         super(settings, nodeSettingsService, transportNodesStatsAction, transportIndicesStatsAction, clusterService, threadPool);
         this.clusterName = ClusterName.clusterNameFromSettings(settings);
-        stats[0] = MockDiskUsagesIT.makeStats("node_t1", new DiskUsage("node_t1", "n1", "/dev/null", 100, 100));
-        stats[1] = MockDiskUsagesIT.makeStats("node_t2", new DiskUsage("node_t2", "n2", "/dev/null", 100, 100));
-        stats[2] = MockDiskUsagesIT.makeStats("node_t3", new DiskUsage("node_t3", "n3", "/dev/null", 100, 100));
+        stats[0] = makeStats("node_t1", new DiskUsage("node_t1", "n1", "/dev/null", 100, 100));
+        stats[1] = makeStats("node_t2", new DiskUsage("node_t2", "n2", "/dev/null", 100, 100));
+        stats[2] = makeStats("node_t3", new DiskUsage("node_t3", "n3", "/dev/null", 100, 100));
     }
 
     public void setN1Usage(String nodeName, DiskUsage newUsage) {
-        stats[0] = MockDiskUsagesIT.makeStats(nodeName, newUsage);
+        stats[0] = makeStats(nodeName, newUsage);
     }
 
     public void setN2Usage(String nodeName, DiskUsage newUsage) {
-        stats[1] = MockDiskUsagesIT.makeStats(nodeName, newUsage);
+        stats[1] = makeStats(nodeName, newUsage);
     }
 
     public void setN3Usage(String nodeName, DiskUsage newUsage) {
-        stats[2] = MockDiskUsagesIT.makeStats(nodeName, newUsage);
+        stats[2] = makeStats(nodeName, newUsage);
     }
 
     @Override
@@ -96,6 +118,28 @@ public class MockInternalClusterInfoService extends InternalClusterInfoService {
 
     public ClusterInfo getClusterInfo() {
         ClusterInfo clusterInfo = super.getClusterInfo();
-        return new ClusterInfo(clusterInfo.getNodeLeastAvailableDiskUsages(), clusterInfo.getNodeMostAvailableDiskUsages(), clusterInfo.shardSizes, DiskThresholdDeciderTests.DEV_NULL_MAP);
+        return new ClusterInfo(clusterInfo.getNodeLeastAvailableDiskUsages(), clusterInfo.getNodeMostAvailableDiskUsages(), clusterInfo.shardSizes, DEV_NULL_MAP);
+    }
+
+    public static final Map<ShardRouting, String> DEV_NULL_MAP = Collections.unmodifiableMap(new StaticValueMap("/dev/null"));
+
+    // a test only map that always returns the same value no matter what key is passed
+    private static final class StaticValueMap extends AbstractMap<ShardRouting, String> {
+
+        private final String value;
+
+        private StaticValueMap(String value) {
+            this.value = value;
+        }
+
+        @Override
+        public String get(Object key) {
+            return value;
+        }
+
+        @Override
+        public Set<Entry<ShardRouting, String>> entrySet() {
+            throw new UnsupportedOperationException("this is a test-only map that only supports #get(Object key)");
+        }
     }
 }
diff --git a/core/src/test/java/org/elasticsearch/cluster/metadata/HumanReadableIndexSettingsTests.java b/core/src/test/java/org/elasticsearch/cluster/metadata/HumanReadableIndexSettingsTests.java
index 8e906ae..4163ad0 100644
--- a/core/src/test/java/org/elasticsearch/cluster/metadata/HumanReadableIndexSettingsTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/metadata/HumanReadableIndexSettingsTests.java
@@ -26,7 +26,6 @@ import org.joda.time.DateTime;
 import org.joda.time.DateTimeZone;
 import org.junit.Test;
 
-import static com.google.common.collect.Sets.newHashSet;
 import static org.elasticsearch.test.VersionUtils.randomVersion;
 
 public class HumanReadableIndexSettingsTests extends ESTestCase {
diff --git a/core/src/test/java/org/elasticsearch/cluster/metadata/IndexNameExpressionResolverTests.java b/core/src/test/java/org/elasticsearch/cluster/metadata/IndexNameExpressionResolverTests.java
index 1a0e998..3bae8e1 100644
--- a/core/src/test/java/org/elasticsearch/cluster/metadata/IndexNameExpressionResolverTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/metadata/IndexNameExpressionResolverTests.java
@@ -19,15 +19,14 @@
 
 package org.elasticsearch.cluster.metadata;
 
-import com.google.common.collect.Sets;
 import org.elasticsearch.Version;
 import org.elasticsearch.action.support.IndicesOptions;
 import org.elasticsearch.cluster.ClusterName;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.metadata.IndexMetaData.State;
 import org.elasticsearch.common.Strings;
-import org.elasticsearch.index.IndexNotFoundException;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.index.IndexNotFoundException;
 import org.elasticsearch.indices.IndexClosedException;
 import org.elasticsearch.test.ESTestCase;
 import org.junit.Test;
@@ -36,8 +35,14 @@ import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashSet;
 
-import static com.google.common.collect.Sets.newHashSet;
-import static org.hamcrest.Matchers.*;
+import static org.elasticsearch.common.util.set.Sets.newHashSet;
+import static org.hamcrest.Matchers.arrayContaining;
+import static org.hamcrest.Matchers.arrayContainingInAnyOrder;
+import static org.hamcrest.Matchers.arrayWithSize;
+import static org.hamcrest.Matchers.containsString;
+import static org.hamcrest.Matchers.emptyArray;
+import static org.hamcrest.Matchers.equalTo;
+import static org.hamcrest.Matchers.notNullValue;
 
 /**
  */
@@ -562,7 +567,7 @@ public class IndexNameExpressionResolverTests extends ESTestCase {
                 .put(indexBuilder("kuku"));
         ClusterState state = ClusterState.builder(new ClusterName("_name")).metaData(mdBuilder).build();
         IndexNameExpressionResolver.Context context = new IndexNameExpressionResolver.Context(state, IndicesOptions.lenientExpandOpen());
-        assertThat(newHashSet(indexNameExpressionResolver.concreteIndices(context, new String[]{})), equalTo(Sets.newHashSet("kuku", "testXXX")));
+        assertThat(newHashSet(indexNameExpressionResolver.concreteIndices(context, new String[]{})), equalTo(newHashSet("kuku", "testXXX")));
     }
 
     @Test
diff --git a/core/src/test/java/org/elasticsearch/cluster/metadata/WildcardExpressionResolverTests.java b/core/src/test/java/org/elasticsearch/cluster/metadata/WildcardExpressionResolverTests.java
index d2f55fc..4c36415 100644
--- a/core/src/test/java/org/elasticsearch/cluster/metadata/WildcardExpressionResolverTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/metadata/WildcardExpressionResolverTests.java
@@ -28,7 +28,7 @@ import org.junit.Test;
 
 import java.util.Arrays;
 
-import static com.google.common.collect.Sets.newHashSet;
+import static org.elasticsearch.common.util.set.Sets.newHashSet;
 import static org.hamcrest.Matchers.equalTo;
 
 public class WildcardExpressionResolverTests extends ESTestCase {
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/RoutingServiceTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/RoutingServiceTests.java
index 6b2e972..960ccc5 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/RoutingServiceTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/RoutingServiceTests.java
@@ -30,6 +30,7 @@ import org.elasticsearch.cluster.routing.allocation.AllocationService;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.test.ESAllocationTestCase;
+import org.elasticsearch.test.junit.annotations.TestLogging;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.junit.After;
 import org.junit.Before;
@@ -93,6 +94,7 @@ public class RoutingServiceTests extends ESAllocationTestCase {
     }
 
     @Test
+    @TestLogging("_root:DEBUG")
     public void testDelayedUnassignedScheduleReroute() throws Exception {
         AllocationService allocation = createAllocationService();
         MetaData metaData = MetaData.builder()
@@ -108,7 +110,7 @@ public class RoutingServiceTests extends ESAllocationTestCase {
         clusterState = ClusterState.builder(clusterState).routingResult(allocation.applyStartedShards(clusterState, clusterState.getRoutingNodes().shardsWithState(INITIALIZING))).build();
         // starting replicas
         clusterState = ClusterState.builder(clusterState).routingResult(allocation.applyStartedShards(clusterState, clusterState.getRoutingNodes().shardsWithState(INITIALIZING))).build();
-        assertThat(clusterState.getRoutingNodes().hasUnassigned(), equalTo(false));
+        assertFalse("no shards should be unassigned", clusterState.getRoutingNodes().hasUnassigned());
         // remove node2 and reroute
         ClusterState prevState = clusterState;
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).remove("node2")).build();
@@ -123,7 +125,7 @@ public class RoutingServiceTests extends ESAllocationTestCase {
         assertBusy(new Runnable() {
             @Override
             public void run() {
-                assertThat(routingService.hasReroutedAndClear(), equalTo(true));
+                assertTrue("routing service should have run a reroute", routingService.hasReroutedAndClear());
             }
         });
         // verify the registration has been reset
@@ -186,6 +188,7 @@ public class RoutingServiceTests extends ESAllocationTestCase {
 
         @Override
         protected void performReroute(String reason) {
+            logger.info("--> performing fake reroute [{}]", reason);
             rerouted.set(true);
         }
     }
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AwarenessAllocationTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AwarenessAllocationTests.java
index f1f29d5..7498905 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AwarenessAllocationTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AwarenessAllocationTests.java
@@ -785,7 +785,7 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();
 
-        logger.info("--> adding two nodes on same rack and do rerouting");
+        logger.info("--> adding two nodes in different zones and do rerouting");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
                 .put(newNode("A-0", ImmutableMap.of("zone", "a")))
                 .put(newNode("B-0", ImmutableMap.of("zone", "b")))
@@ -826,4 +826,45 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
         assertThat(clusterState.getRoutingNodes().node("A-0").size(), equalTo(3));
         assertThat(clusterState.getRoutingNodes().node("B-0").size(), equalTo(5));
     }
+
+    @Test
+    public void testUnassignedShardsWithUnbalancedZones() {
+        AllocationService strategy = createAllocationService(settingsBuilder()
+                .put("cluster.routing.allocation.concurrent_recoveries", 10)
+                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE, "always")
+                .put("cluster.routing.allocation.awareness.attributes", "zone")
+                .build());
+
+        logger.info("Building initial routing table for 'testUnassignedShardsWithUnbalancedZones'");
+
+        MetaData metaData = MetaData.builder()
+                .put(IndexMetaData.builder("test").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(4))
+                .build();
+
+        RoutingTable routingTable = RoutingTable.builder()
+                .addAsNew(metaData.index("test"))
+                .build();
+
+        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();
+
+        logger.info("--> adding 5 nodes in different zones and do rerouting");
+        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
+                        .put(newNode("A-0", ImmutableMap.of("zone", "a")))
+                        .put(newNode("A-1", ImmutableMap.of("zone", "a")))
+                        .put(newNode("A-2", ImmutableMap.of("zone", "a")))
+                        .put(newNode("A-3", ImmutableMap.of("zone", "a")))
+                        .put(newNode("B-0", ImmutableMap.of("zone", "b")))
+        ).build();
+        routingTable = strategy.reroute(clusterState).routingTable();
+        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
+        assertThat(clusterState.getRoutingNodes().shardsWithState(STARTED).size(), equalTo(0));
+        assertThat(clusterState.getRoutingNodes().shardsWithState(INITIALIZING).size(), equalTo(1));
+
+        logger.info("--> start the shard (primary)");
+        routingTable = strategy.applyStartedShards(clusterState, clusterState.getRoutingNodes().shardsWithState(INITIALIZING)).routingTable();
+        clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
+        assertThat(clusterState.getRoutingNodes().shardsWithState(STARTED).size(), equalTo(1));
+        assertThat(clusterState.getRoutingNodes().shardsWithState(INITIALIZING).size(), equalTo(3));
+        assertThat(clusterState.getRoutingNodes().shardsWithState(UNASSIGNED).size(), equalTo(1)); // Unassigned shard is expected.
+    }
 }
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/SingleShardNoReplicasRoutingTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/SingleShardNoReplicasRoutingTests.java
index a6b0e41..e197dbd 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/SingleShardNoReplicasRoutingTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/SingleShardNoReplicasRoutingTests.java
@@ -36,14 +36,22 @@ import org.elasticsearch.test.ESAllocationTestCase;
 import org.junit.Test;
 
 import java.util.ArrayList;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
 
-import static com.google.common.collect.Sets.newHashSet;
-import static org.elasticsearch.cluster.routing.ShardRoutingState.*;
+import static org.elasticsearch.cluster.routing.ShardRoutingState.INITIALIZING;
+import static org.elasticsearch.cluster.routing.ShardRoutingState.RELOCATING;
+import static org.elasticsearch.cluster.routing.ShardRoutingState.STARTED;
+import static org.elasticsearch.cluster.routing.ShardRoutingState.UNASSIGNED;
 import static org.elasticsearch.cluster.routing.allocation.RoutingNodesUtils.numberOfShardsOfType;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
-import static org.hamcrest.Matchers.*;
+import static org.hamcrest.Matchers.anyOf;
+import static org.hamcrest.Matchers.equalTo;
+import static org.hamcrest.Matchers.hasItem;
+import static org.hamcrest.Matchers.lessThan;
+import static org.hamcrest.Matchers.not;
+import static org.hamcrest.Matchers.nullValue;
 
 /**
  *
@@ -262,7 +270,7 @@ public class SingleShardNoReplicasRoutingTests extends ESAllocationTestCase {
             assertThat(nodeIndex, lessThan(25));
         }
         RoutingNodes routingNodes = clusterState.getRoutingNodes();
-        Set<String> encounteredIndices = newHashSet();
+        Set<String> encounteredIndices = new HashSet<>();
         for (RoutingNode routingNode : routingNodes) {
             assertThat(routingNode.numberOfShardsWithState(STARTED), equalTo(0));
             assertThat(routingNode.size(), equalTo(2));
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderTests.java
index fbecc86..dfdd9ba 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderTests.java
@@ -24,6 +24,7 @@ import org.elasticsearch.cluster.ClusterInfo;
 import org.elasticsearch.cluster.ClusterInfoService;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.DiskUsage;
+import org.elasticsearch.cluster.MockInternalClusterInfoService;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.cluster.node.DiscoveryNode;
@@ -88,7 +89,7 @@ public class DiskThresholdDeciderTests extends ESAllocationTestCase {
         Map<String, Long> shardSizes = new HashMap<>();
         shardSizes.put("[test][0][p]", 10L); // 10 bytes
         shardSizes.put("[test][0][r]", 10L);
-        final ClusterInfo clusterInfo = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), DEV_NULL_MAP);
+        final ClusterInfo clusterInfo = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), MockInternalClusterInfoService.DEV_NULL_MAP);
 
         AllocationDeciders deciders = new AllocationDeciders(Settings.EMPTY,
                 new HashSet<>(Arrays.asList(
@@ -282,7 +283,7 @@ public class DiskThresholdDeciderTests extends ESAllocationTestCase {
         Map<String, Long> shardSizes = new HashMap<>();
         shardSizes.put("[test][0][p]", 10L); // 10 bytes
         shardSizes.put("[test][0][r]", 10L);
-        final ClusterInfo clusterInfo = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), DEV_NULL_MAP);
+        final ClusterInfo clusterInfo = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), MockInternalClusterInfoService.DEV_NULL_MAP);
 
         AllocationDeciders deciders = new AllocationDeciders(Settings.EMPTY,
                 new HashSet<>(Arrays.asList(
@@ -344,7 +345,7 @@ public class DiskThresholdDeciderTests extends ESAllocationTestCase {
 
         // Make node without the primary now habitable to replicas
         usages.put(nodeWithoutPrimary, new DiskUsage(nodeWithoutPrimary, "", "/dev/null", 100, 35)); // 65% used
-        final ClusterInfo clusterInfo2 = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), DEV_NULL_MAP);
+        final ClusterInfo clusterInfo2 = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), MockInternalClusterInfoService.DEV_NULL_MAP);
         cis = new ClusterInfoService() {
             @Override
             public ClusterInfo getClusterInfo() {
@@ -543,7 +544,7 @@ public class DiskThresholdDeciderTests extends ESAllocationTestCase {
 
         Map<String, Long> shardSizes = new HashMap<>();
         shardSizes.put("[test][0][p]", 10L); // 10 bytes
-        final ClusterInfo clusterInfo = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), DEV_NULL_MAP);
+        final ClusterInfo clusterInfo = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), MockInternalClusterInfoService.DEV_NULL_MAP);
 
         AllocationDeciders deciders = new AllocationDeciders(Settings.EMPTY,
                 new HashSet<>(Arrays.asList(
@@ -610,7 +611,7 @@ public class DiskThresholdDeciderTests extends ESAllocationTestCase {
         Map<String, Long> shardSizes = new HashMap<>();
         shardSizes.put("[test][0][p]", 10L); // 10 bytes
         shardSizes.put("[test][0][r]", 10L); // 10 bytes
-        final ClusterInfo clusterInfo = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), DEV_NULL_MAP);
+        final ClusterInfo clusterInfo = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), MockInternalClusterInfoService.DEV_NULL_MAP);
 
         AllocationDeciders deciders = new AllocationDeciders(Settings.EMPTY,
                 new HashSet<>(Arrays.asList(
@@ -714,7 +715,7 @@ public class DiskThresholdDeciderTests extends ESAllocationTestCase {
         shardSizes.put("[test][0][r]", 14L);
         shardSizes.put("[test2][0][p]", 1L); // 1 bytes
         shardSizes.put("[test2][0][r]", 1L);
-        final ClusterInfo clusterInfo = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), DEV_NULL_MAP);
+        final ClusterInfo clusterInfo = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), MockInternalClusterInfoService.DEV_NULL_MAP);
 
         AllocationDeciders deciders = new AllocationDeciders(Settings.EMPTY,
                 new HashSet<>(Arrays.asList(
@@ -817,7 +818,7 @@ public class DiskThresholdDeciderTests extends ESAllocationTestCase {
         Map<String, Long> shardSizes = new HashMap<>();
         shardSizes.put("[test][0][p]", 40L);
         shardSizes.put("[test][1][p]", 40L);
-        final ClusterInfo clusterInfo = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), DEV_NULL_MAP);
+        final ClusterInfo clusterInfo = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), MockInternalClusterInfoService.DEV_NULL_MAP);
 
         DiskThresholdDecider diskThresholdDecider = new DiskThresholdDecider(diskSettings);
         MetaData metaData = MetaData.builder()
@@ -925,26 +926,4 @@ public class DiskThresholdDeciderTests extends ESAllocationTestCase {
                 rn.shardsWithState(RELOCATING),
                 rn.shardsWithState(STARTED));
     }
-
-    public static final Map<ShardRouting, String> DEV_NULL_MAP = Collections.unmodifiableMap(new StaticValueMap("/dev/null"));
-
-    // a test only map that always returns the same value no matter what key is passed
-    private static final class StaticValueMap extends AbstractMap<ShardRouting, String> {
-
-        private final String value;
-
-        private StaticValueMap(String value) {
-            this.value = value;
-        }
-
-        @Override
-        public String get(Object key) {
-            return value;
-        }
-
-        @Override
-        public Set<Entry<ShardRouting, String>> entrySet() {
-            throw new UnsupportedOperationException("this is a test-only map that only supports #get(Object key)");
-        }
-    }
 }
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderUnitTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderUnitTests.java
index 853f669..6460664 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderUnitTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderUnitTests.java
@@ -20,12 +20,21 @@
 package org.elasticsearch.cluster.routing.allocation.decider;
 
 import org.elasticsearch.Version;
-import org.elasticsearch.cluster.*;
+import org.elasticsearch.cluster.ClusterInfo;
+import org.elasticsearch.cluster.ClusterInfoService;
+import org.elasticsearch.cluster.ClusterState;
+import org.elasticsearch.cluster.DiskUsage;
+import org.elasticsearch.cluster.EmptyClusterInfoService;
+import org.elasticsearch.cluster.MockInternalClusterInfoService;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
-import org.elasticsearch.cluster.routing.*;
+import org.elasticsearch.cluster.routing.RoutingNode;
+import org.elasticsearch.cluster.routing.RoutingTable;
+import org.elasticsearch.cluster.routing.ShardRouting;
+import org.elasticsearch.cluster.routing.ShardRoutingHelper;
+import org.elasticsearch.cluster.routing.UnassignedInfo;
 import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.transport.DummyTransportAddress;
@@ -215,7 +224,7 @@ public class DiskThresholdDeciderUnitTests extends ESTestCase {
         shardSizes.put("[test][1][r]", 100L);
         shardSizes.put("[test][2][r]", 1000L);
         shardSizes.put("[other][0][p]", 10000L);
-        ClusterInfo info = new ClusterInfo(Collections.EMPTY_MAP, Collections.EMPTY_MAP, shardSizes, DiskThresholdDeciderTests.DEV_NULL_MAP);
+        ClusterInfo info = new ClusterInfo(Collections.EMPTY_MAP, Collections.EMPTY_MAP, shardSizes, MockInternalClusterInfoService.DEV_NULL_MAP);
         ShardRouting test_0 = ShardRouting.newUnassigned("test", 0, null, false, new UnassignedInfo(UnassignedInfo.Reason.INDEX_CREATED, "foo"));
         ShardRoutingHelper.initialize(test_0, "node1");
         ShardRoutingHelper.moveToStarted(test_0);
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/MockDiskUsagesIT.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/MockDiskUsagesIT.java
index 121c477..8396f61 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/MockDiskUsagesIT.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/MockDiskUsagesIT.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.cluster.routing.allocation.decider;
 
-import org.elasticsearch.Version;
-import org.elasticsearch.action.admin.cluster.node.stats.NodeStats;
 import org.elasticsearch.action.admin.cluster.node.stats.NodesStatsResponse;
 import org.elasticsearch.action.admin.cluster.state.ClusterStateResponse;
 import org.elasticsearch.cluster.ClusterInfo;
@@ -28,11 +26,8 @@ import org.elasticsearch.cluster.ClusterInfoService;
 import org.elasticsearch.cluster.DiskUsage;
 import org.elasticsearch.cluster.InternalClusterInfoService;
 import org.elasticsearch.cluster.MockInternalClusterInfoService;
-import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.routing.RoutingNode;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.transport.DummyTransportAddress;
-import org.elasticsearch.monitor.fs.FsInfo;
 import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
@@ -170,20 +165,4 @@ public class MockDiskUsagesIT extends ESIntegTestCase {
             }
         });
     }
-
-    /** Create a fake NodeStats for the given node and usage */
-    public static NodeStats makeStats(String nodeName, DiskUsage usage) {
-        FsInfo.Path[] paths = new FsInfo.Path[1];
-        FsInfo.Path path = new FsInfo.Path("/dev/null", null,
-                usage.getTotalBytes(), usage.getFreeBytes(), usage.getFreeBytes());
-        paths[0] = path;
-        FsInfo fsInfo = new FsInfo(System.currentTimeMillis(), paths);
-        return new NodeStats(new DiscoveryNode(nodeName, DummyTransportAddress.INSTANCE, Version.CURRENT),
-                System.currentTimeMillis(),
-                null, null, null, null, null,
-                fsInfo,
-                null, null, null,
-                null);
-    }
-
 }
diff --git a/core/src/test/java/org/elasticsearch/common/cli/CheckFileCommandTests.java b/core/src/test/java/org/elasticsearch/common/cli/CheckFileCommandTests.java
index bb9cad1..02d822d 100644
--- a/core/src/test/java/org/elasticsearch/common/cli/CheckFileCommandTests.java
+++ b/core/src/test/java/org/elasticsearch/common/cli/CheckFileCommandTests.java
@@ -20,10 +20,10 @@
 package org.elasticsearch.common.cli;
 
 import com.google.common.base.Charsets;
-import com.google.common.collect.Sets;
 import com.google.common.jimfs.Configuration;
 import com.google.common.jimfs.Jimfs;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.util.set.Sets;
 import org.elasticsearch.env.Environment;
 import org.elasticsearch.test.ESTestCase;
 import org.junit.Test;
@@ -32,10 +32,18 @@ import java.io.IOException;
 import java.nio.file.FileSystem;
 import java.nio.file.Files;
 import java.nio.file.Path;
-import java.nio.file.attribute.*;
+import java.nio.file.attribute.GroupPrincipal;
+import java.nio.file.attribute.PosixFileAttributeView;
+import java.nio.file.attribute.PosixFileAttributes;
+import java.nio.file.attribute.PosixFilePermission;
+import java.nio.file.attribute.UserPrincipal;
 import java.util.Set;
 
-import static org.hamcrest.Matchers.*;
+import static org.hamcrest.Matchers.allOf;
+import static org.hamcrest.Matchers.containsString;
+import static org.hamcrest.Matchers.hasItem;
+import static org.hamcrest.Matchers.hasSize;
+import static org.hamcrest.Matchers.is;
 
 /**
  *
diff --git a/core/src/test/java/org/elasticsearch/common/geo/ShapeRelationTests.java b/core/src/test/java/org/elasticsearch/common/geo/ShapeRelationTests.java
deleted file mode 100644
index 83b6671..0000000
--- a/core/src/test/java/org/elasticsearch/common/geo/ShapeRelationTests.java
+++ /dev/null
@@ -1,92 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.common.geo;
-
-import org.elasticsearch.common.io.stream.BytesStreamOutput;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.test.ESTestCase;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.equalTo;
-
-public class ShapeRelationTests extends ESTestCase {
-
-    public void testValidOrdinals() {
-        assertThat(ShapeRelation.INTERSECTS.ordinal(), equalTo(0));
-        assertThat(ShapeRelation.DISJOINT.ordinal(), equalTo(1));
-        assertThat(ShapeRelation.WITHIN.ordinal(), equalTo(2));
-    }
-
-    public void testwriteTo() throws Exception {
-        try (BytesStreamOutput out = new BytesStreamOutput()) {
-            ShapeRelation.INTERSECTS.writeTo(out);
-            try (StreamInput in = StreamInput.wrap(out.bytes())) {
-                assertThat(in.readVInt(), equalTo(0));
-            }
-        }
-
-        try (BytesStreamOutput out = new BytesStreamOutput()) {
-            ShapeRelation.DISJOINT.writeTo(out);
-            try (StreamInput in = StreamInput.wrap(out.bytes())) {
-                assertThat(in.readVInt(), equalTo(1));
-            }
-        }
-
-        try (BytesStreamOutput out = new BytesStreamOutput()) {
-            ShapeRelation.WITHIN.writeTo(out);
-            try (StreamInput in = StreamInput.wrap(out.bytes())) {
-                assertThat(in.readVInt(), equalTo(2));
-            }
-        }
-    }
-
-    public void testReadFrom() throws Exception {
-        try (BytesStreamOutput out = new BytesStreamOutput()) {
-            out.writeVInt(0);
-            try (StreamInput in = StreamInput.wrap(out.bytes())) {
-                assertThat(ShapeRelation.DISJOINT.readFrom(in), equalTo(ShapeRelation.INTERSECTS));
-            }
-        }
-        try (BytesStreamOutput out = new BytesStreamOutput()) {
-            out.writeVInt(1);
-            try (StreamInput in = StreamInput.wrap(out.bytes())) {
-                assertThat(ShapeRelation.DISJOINT.readFrom(in), equalTo(ShapeRelation.DISJOINT));
-            }
-        }
-        try (BytesStreamOutput out = new BytesStreamOutput()) {
-            out.writeVInt(2);
-            try (StreamInput in = StreamInput.wrap(out.bytes())) {
-                assertThat(ShapeRelation.DISJOINT.readFrom(in), equalTo(ShapeRelation.WITHIN));
-            }
-        }
-    }
-
-    @Test(expected = IOException.class)
-    public void testInvalidReadFrom() throws Exception {
-        try (BytesStreamOutput out = new BytesStreamOutput()) {
-            out.writeVInt(randomIntBetween(3, Integer.MAX_VALUE));
-            try (StreamInput in = StreamInput.wrap(out.bytes())) {
-                ShapeRelation.DISJOINT.readFrom(in);
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/common/geo/SpatialStrategyTests.java b/core/src/test/java/org/elasticsearch/common/geo/SpatialStrategyTests.java
deleted file mode 100644
index c53a3fb..0000000
--- a/core/src/test/java/org/elasticsearch/common/geo/SpatialStrategyTests.java
+++ /dev/null
@@ -1,78 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.common.geo;
-
-import org.elasticsearch.common.io.stream.BytesStreamOutput;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.test.ESTestCase;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.equalTo;
-
-public class SpatialStrategyTests extends ESTestCase {
-
-    public void testValidOrdinals() {
-        assertThat(SpatialStrategy.TERM.ordinal(), equalTo(0));
-        assertThat(SpatialStrategy.RECURSIVE.ordinal(), equalTo(1));
-    }
-
-    public void testwriteTo() throws Exception {
-        try (BytesStreamOutput out = new BytesStreamOutput()) {
-            SpatialStrategy.TERM.writeTo(out);
-            try (StreamInput in = StreamInput.wrap(out.bytes())) {
-                assertThat(in.readVInt(), equalTo(0));
-            }
-        }
-
-        try (BytesStreamOutput out = new BytesStreamOutput()) {
-            SpatialStrategy.RECURSIVE.writeTo(out);
-            try (StreamInput in = StreamInput.wrap(out.bytes())) {
-                assertThat(in.readVInt(), equalTo(1));
-            }
-        }
-    }
-
-    public void testReadFrom() throws Exception {
-        try (BytesStreamOutput out = new BytesStreamOutput()) {
-            out.writeVInt(0);
-            try (StreamInput in = StreamInput.wrap(out.bytes())) {
-                assertThat(SpatialStrategy.TERM.readFrom(in), equalTo(SpatialStrategy.TERM));
-            }
-        }
-        try (BytesStreamOutput out = new BytesStreamOutput()) {
-            out.writeVInt(1);
-            try (StreamInput in = StreamInput.wrap(out.bytes())) {
-                assertThat(SpatialStrategy.TERM.readFrom(in), equalTo(SpatialStrategy.RECURSIVE));
-            }
-        }
-    }
-
-    @Test(expected = IOException.class)
-    public void testInvalidReadFrom() throws Exception {
-        try (BytesStreamOutput out = new BytesStreamOutput()) {
-            out.writeVInt(randomIntBetween(2, Integer.MAX_VALUE));
-            try (StreamInput in = StreamInput.wrap(out.bytes())) {
-                SpatialStrategy.TERM.readFrom(in);
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/common/io/stream/BytesStreamsTests.java b/core/src/test/java/org/elasticsearch/common/io/stream/BytesStreamsTests.java
index afc17ce..d313dd7 100644
--- a/core/src/test/java/org/elasticsearch/common/io/stream/BytesStreamsTests.java
+++ b/core/src/test/java/org/elasticsearch/common/io/stream/BytesStreamsTests.java
@@ -26,7 +26,6 @@ import org.elasticsearch.test.ESTestCase;
 import org.junit.Test;
 
 import java.io.IOException;
-
 import java.util.Objects;
 
 import static org.hamcrest.Matchers.closeTo;
diff --git a/core/src/test/java/org/elasticsearch/common/lucene/index/FreqTermsEnumTests.java b/core/src/test/java/org/elasticsearch/common/lucene/index/FreqTermsEnumTests.java
index aff6e7a..1c7a6ab 100644
--- a/core/src/test/java/org/elasticsearch/common/lucene/index/FreqTermsEnumTests.java
+++ b/core/src/test/java/org/elasticsearch/common/lucene/index/FreqTermsEnumTests.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.common.lucene.index;
 
-import com.google.common.collect.Sets;
 import org.apache.lucene.analysis.core.KeywordAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -50,6 +49,7 @@ import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
@@ -123,7 +123,7 @@ public class FreqTermsEnumTests extends ESTestCase {
             }
         }
 
-        Set<String> deletedIds = Sets.newHashSet();
+        Set<String> deletedIds = new HashSet<>();
         for (int i = 0; i < docs.length; i++) {
             Document doc = docs[i];
             if (randomInt(5) == 2) {
@@ -157,7 +157,7 @@ public class FreqTermsEnumTests extends ESTestCase {
     }
 
     private void addFreqs(Document doc, Map<String, FreqHolder> reference) {
-        Set<String> addedDocFreq = Sets.newHashSet();
+        Set<String> addedDocFreq = new HashSet<>();
         for (IndexableField field : doc.getFields("field")) {
             String term = field.stringValue();
             FreqHolder freqHolder = reference.get(term);
diff --git a/core/src/test/java/org/elasticsearch/common/unit/FuzzinessTests.java b/core/src/test/java/org/elasticsearch/common/unit/FuzzinessTests.java
index 807b4a7..234e341 100644
--- a/core/src/test/java/org/elasticsearch/common/unit/FuzzinessTests.java
+++ b/core/src/test/java/org/elasticsearch/common/unit/FuzzinessTests.java
@@ -18,8 +18,6 @@
  */
 package org.elasticsearch.common.unit;
 
-import org.elasticsearch.common.io.stream.BytesStreamOutput;
-import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.xcontent.XContent;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.common.xcontent.XContentType;
@@ -164,29 +162,4 @@ public class FuzzinessTests extends ESTestCase {
         }
     }
 
-    @Test
-    public void testSerialization() throws IOException {
-        Fuzziness fuzziness = Fuzziness.AUTO;
-        Fuzziness deserializedFuzziness = doSerializeRoundtrip(fuzziness);
-        assertEquals(fuzziness, deserializedFuzziness);
-
-        fuzziness = Fuzziness.fromEdits(randomIntBetween(0, 2));
-        deserializedFuzziness = doSerializeRoundtrip(fuzziness);
-        assertEquals(fuzziness, deserializedFuzziness);
-    }
-
-    @Test
-    public void testSerializationAuto() throws IOException {
-        Fuzziness fuzziness = Fuzziness.AUTO;
-        Fuzziness deserializedFuzziness = doSerializeRoundtrip(fuzziness);
-        assertEquals(fuzziness, deserializedFuzziness);
-        assertEquals(fuzziness.asInt(), deserializedFuzziness.asInt());
-    }
-
-    private static Fuzziness doSerializeRoundtrip(Fuzziness in) throws IOException {
-        BytesStreamOutput output = new BytesStreamOutput();
-        in.writeTo(output);
-        StreamInput streamInput = StreamInput.wrap(output.bytes());
-        return Fuzziness.readFuzzinessFrom(streamInput);
-    }
 }
diff --git a/core/src/test/java/org/elasticsearch/common/util/MockBigArrays.java b/core/src/test/java/org/elasticsearch/common/util/MockBigArrays.java
index de5a8bb..50f1886 100644
--- a/core/src/test/java/org/elasticsearch/common/util/MockBigArrays.java
+++ b/core/src/test/java/org/elasticsearch/common/util/MockBigArrays.java
@@ -21,12 +21,12 @@ package org.elasticsearch.common.util;
 
 import com.carrotsearch.randomizedtesting.RandomizedContext;
 import com.carrotsearch.randomizedtesting.SeedUtils;
-import com.google.common.collect.Sets;
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.Accountables;
 import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.cache.recycler.PageCacheRecycler;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.util.set.Sets;
 import org.elasticsearch.indices.breaker.CircuitBreakerService;
 import org.elasticsearch.test.ESTestCase;
 
@@ -58,7 +58,7 @@ public class MockBigArrays extends BigArrays {
             // not empty, we might be executing on a shared cluster that keeps on obtaining
             // and releasing arrays, lets make sure that after a reasonable timeout, all master
             // copy (snapshot) have been released
-            boolean success = ESTestCase.awaitBusy(() -> Sets.intersection(masterCopy.keySet(), ACQUIRED_ARRAYS.keySet()).isEmpty());
+            boolean success = ESTestCase.awaitBusy(() -> Sets.haveEmptyIntersection(masterCopy.keySet(), ACQUIRED_ARRAYS.keySet()));
             if (!success) {
                 masterCopy.keySet().retainAll(ACQUIRED_ARRAYS.keySet());
                 ACQUIRED_ARRAYS.keySet().removeAll(masterCopy.keySet()); // remove all existing master copy we will report on
diff --git a/core/src/test/java/org/elasticsearch/common/util/MultiDataPathUpgraderTests.java b/core/src/test/java/org/elasticsearch/common/util/MultiDataPathUpgraderTests.java
index fe3051b..8d495a0 100644
--- a/core/src/test/java/org/elasticsearch/common/util/MultiDataPathUpgraderTests.java
+++ b/core/src/test/java/org/elasticsearch/common/util/MultiDataPathUpgraderTests.java
@@ -19,7 +19,6 @@
 package org.elasticsearch.common.util;
 
 import com.google.common.base.Charsets;
-import com.google.common.collect.Sets;
 import org.apache.lucene.util.CollectionUtil;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.TestUtil;
@@ -28,6 +27,7 @@ import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.io.FileSystemUtils;
+import org.elasticsearch.common.util.set.Sets;
 import org.elasticsearch.env.NodeEnvironment;
 import org.elasticsearch.gateway.MetaDataStateFormat;
 import org.elasticsearch.index.shard.ShardId;
@@ -39,8 +39,16 @@ import java.io.BufferedWriter;
 import java.io.IOException;
 import java.io.InputStream;
 import java.net.URISyntaxException;
-import java.nio.file.*;
-import java.util.*;
+import java.nio.file.DirectoryStream;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.util.ArrayList;
+import java.util.Comparator;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Locale;
+import java.util.Map;
 
 /**
  */
@@ -133,8 +141,7 @@ public class MultiDataPathUpgraderTests extends ESTestCase {
      */
     public void testUpgradeRealIndex() throws IOException, URISyntaxException {
         List<Path> indexes = new ArrayList<>();
-        Path dir = getDataPath("/" + OldIndexBackwardsCompatibilityIT.class.getPackage().getName().replace('.', '/')); // the files are in the same pkg as the OldIndexBackwardsCompatibilityTests test
-        try (DirectoryStream<Path> stream = Files.newDirectoryStream(dir, "index-*.zip")) {
+        try (DirectoryStream<Path> stream = Files.newDirectoryStream(getBwcIndicesPath(), "index-*.zip")) {
             for (Path path : stream) {
                 indexes.add(path);
             }
diff --git a/core/src/test/java/org/elasticsearch/index/deletionpolicy/SnapshotIndexCommitExistsMatcher.java b/core/src/test/java/org/elasticsearch/index/deletionpolicy/SnapshotIndexCommitExistsMatcher.java
index 6ef7974..26f723b 100644
--- a/core/src/test/java/org/elasticsearch/index/deletionpolicy/SnapshotIndexCommitExistsMatcher.java
+++ b/core/src/test/java/org/elasticsearch/index/deletionpolicy/SnapshotIndexCommitExistsMatcher.java
@@ -19,15 +19,13 @@
 
 package org.elasticsearch.index.deletionpolicy;
 
-import com.google.common.collect.Sets;
+import org.elasticsearch.common.util.set.Sets;
 import org.hamcrest.Description;
 import org.hamcrest.Matcher;
 import org.hamcrest.TypeSafeMatcher;
 
 import java.io.IOException;
-import java.util.Arrays;
 import java.util.HashSet;
-import java.util.List;
 
 /**
  *
diff --git a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
index 5a1efd1..35939d3 100644
--- a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
+++ b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
@@ -1786,8 +1786,7 @@ public class InternalEngineTests extends ESTestCase {
 
     public void testUpgradeOldIndex() throws IOException {
         List<Path> indexes = new ArrayList<>();
-        Path dir = getDataPath("/" + OldIndexBackwardsCompatibilityIT.class.getPackage().getName().replace('.', '/')); // the files are in the same pkg as the OldIndexBackwardsCompatibilityTests test
-        try (DirectoryStream<Path> stream = Files.newDirectoryStream(dir, "index-*.zip")) {
+        try (DirectoryStream<Path> stream = Files.newDirectoryStream(getBwcIndicesPath(), "index-*.zip")) {
             for (Path path : stream) {
                 indexes.add(path);
             }
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/externalvalues/ExternalValuesMapperIntegrationIT.java b/core/src/test/java/org/elasticsearch/index/mapper/externalvalues/ExternalValuesMapperIntegrationIT.java
index 35449d0..42a9df6 100644
--- a/core/src/test/java/org/elasticsearch/index/mapper/externalvalues/ExternalValuesMapperIntegrationIT.java
+++ b/core/src/test/java/org/elasticsearch/index/mapper/externalvalues/ExternalValuesMapperIntegrationIT.java
@@ -22,12 +22,14 @@ package org.elasticsearch.index.mapper.externalvalues;
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.common.geo.ShapeRelation;
 import org.elasticsearch.common.geo.builders.ShapeBuilder;
+import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
 
+import java.util.Arrays;
 import java.util.Collection;
 
 import static org.hamcrest.Matchers.equalTo;
@@ -72,7 +74,7 @@ public class ExternalValuesMapperIntegrationIT extends ESIntegTestCase {
         assertThat(response.getHits().totalHits(), equalTo((long) 1));
 
         response = client().prepareSearch("test-idx")
-                .setPostFilter(QueryBuilders.geoShapeQuery("field.shape", ShapeBuilder.newPoint(-100, 45)).relation(ShapeRelation.WITHIN))
+                .setPostFilter(QueryBuilders.geoShapeQuery("field.shape", ShapeBuilder.newPoint(-100, 45), ShapeRelation.WITHIN))
                         .execute().actionGet();
 
         assertThat(response.getHits().totalHits(), equalTo((long) 1));
diff --git a/core/src/test/java/org/elasticsearch/index/query/AbstractQueryTestCase.java b/core/src/test/java/org/elasticsearch/index/query/AbstractQueryTestCase.java
deleted file mode 100644
index 23a729e..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/AbstractQueryTestCase.java
+++ /dev/null
@@ -1,670 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import com.carrotsearch.randomizedtesting.generators.CodepointSetGenerator;
-
-import org.apache.lucene.search.Query;
-import org.elasticsearch.Version;
-import org.elasticsearch.action.ActionFuture;
-import org.elasticsearch.action.admin.indices.mapping.put.PutMappingRequest;
-import org.elasticsearch.action.get.GetRequest;
-import org.elasticsearch.action.get.GetResponse;
-import org.elasticsearch.action.support.PlainActionFuture;
-import org.elasticsearch.action.termvectors.MultiTermVectorsRequest;
-import org.elasticsearch.action.termvectors.MultiTermVectorsResponse;
-import org.elasticsearch.client.Client;
-import org.elasticsearch.cluster.ClusterService;
-import org.elasticsearch.cluster.ClusterState;
-import org.elasticsearch.cluster.metadata.IndexMetaData;
-import org.elasticsearch.cluster.metadata.MetaData;
-import org.elasticsearch.common.ParseFieldMatcher;
-import org.elasticsearch.common.collect.Tuple;
-import org.elasticsearch.common.compress.CompressedXContent;
-import org.elasticsearch.common.inject.AbstractModule;
-import org.elasticsearch.common.inject.Injector;
-import org.elasticsearch.common.inject.ModulesBuilder;
-import org.elasticsearch.common.inject.multibindings.Multibinder;
-import org.elasticsearch.common.inject.util.Providers;
-import org.elasticsearch.common.io.stream.BytesStreamOutput;
-import org.elasticsearch.common.io.stream.NamedWriteableAwareStreamInput;
-import org.elasticsearch.common.io.stream.NamedWriteableRegistry;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.settings.SettingsModule;
-import org.elasticsearch.common.unit.Fuzziness;
-import org.elasticsearch.common.xcontent.ToXContent;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.env.Environment;
-import org.elasticsearch.env.EnvironmentModule;
-import org.elasticsearch.index.Index;
-import org.elasticsearch.index.IndexNameModule;
-import org.elasticsearch.index.analysis.AnalysisModule;
-import org.elasticsearch.index.cache.IndexCacheModule;
-import org.elasticsearch.index.mapper.MapperService;
-import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
-import org.elasticsearch.index.query.support.QueryParsers;
-import org.elasticsearch.index.settings.IndexSettingsModule;
-import org.elasticsearch.index.similarity.SimilarityModule;
-import org.elasticsearch.indices.IndicesModule;
-import org.elasticsearch.indices.analysis.IndicesAnalysisService;
-import org.elasticsearch.indices.breaker.CircuitBreakerService;
-import org.elasticsearch.indices.breaker.NoneCircuitBreakerService;
-import org.elasticsearch.script.ScriptModule;
-import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.test.ESTestCase;
-import org.elasticsearch.test.TestSearchContext;
-import org.elasticsearch.test.VersionUtils;
-import org.elasticsearch.test.cluster.TestClusterService;
-import org.elasticsearch.threadpool.ThreadPool;
-import org.elasticsearch.threadpool.ThreadPoolModule;
-import org.joda.time.DateTime;
-import org.joda.time.DateTimeZone;
-import org.junit.After;
-import org.junit.AfterClass;
-import org.junit.Before;
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.lang.reflect.InvocationHandler;
-import java.lang.reflect.Method;
-import java.lang.reflect.Proxy;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.List;
-import java.util.Map;
-import java.util.concurrent.ExecutionException;
-
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.not;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.nullValue;
-
-public abstract class AbstractQueryTestCase<QB extends AbstractQueryBuilder<QB>> extends ESTestCase {
-
-    private static final GeohashGenerator geohashGenerator = new GeohashGenerator();
-    protected static final String STRING_FIELD_NAME = "mapped_string";
-    protected static final String STRING_FIELD_NAME_2 = "mapped_string_2";
-    protected static final String INT_FIELD_NAME = "mapped_int";
-    protected static final String DOUBLE_FIELD_NAME = "mapped_double";
-    protected static final String BOOLEAN_FIELD_NAME = "mapped_boolean";
-    protected static final String DATE_FIELD_NAME = "mapped_date";
-    protected static final String OBJECT_FIELD_NAME = "mapped_object";
-    protected static final String GEO_POINT_FIELD_NAME = "mapped_geo_point";
-    protected static final String GEO_SHAPE_FIELD_NAME = "mapped_geo_shape";
-    protected static final String[] MAPPED_FIELD_NAMES = new String[] { STRING_FIELD_NAME, INT_FIELD_NAME, DOUBLE_FIELD_NAME,
-            BOOLEAN_FIELD_NAME, DATE_FIELD_NAME, OBJECT_FIELD_NAME, GEO_POINT_FIELD_NAME, GEO_SHAPE_FIELD_NAME };
-    protected static final String[] MAPPED_LEAF_FIELD_NAMES = new String[] { STRING_FIELD_NAME, INT_FIELD_NAME, DOUBLE_FIELD_NAME,
-            BOOLEAN_FIELD_NAME, DATE_FIELD_NAME, GEO_POINT_FIELD_NAME };
-
-    private static Injector injector;
-    private static IndexQueryParserService queryParserService;
-
-    protected static IndexQueryParserService queryParserService() {
-        return queryParserService;
-    }
-
-    private static Index index;
-
-    protected static Index getIndex() {
-        return index;
-    }
-
-    private static String[] currentTypes;
-
-    protected static String[] getCurrentTypes() {
-        return currentTypes;
-    }
-
-    private static NamedWriteableRegistry namedWriteableRegistry;
-
-    private static String[] randomTypes;
-    private static ClientInvocationHandler clientInvocationHandler = new ClientInvocationHandler();
-
-    /**
-     * Setup for the whole base test class.
-     * @throws IOException
-     */
-    @BeforeClass
-    public static void init() throws IOException {
-        // we have to prefer CURRENT since with the range of versions we support it's rather unlikely to get the current actually.
-        Version version = randomBoolean() ? Version.CURRENT : VersionUtils.randomVersionBetween(random(), Version.V_2_0_0_beta1, Version.CURRENT);
-        Settings settings = Settings.settingsBuilder()
-                .put("name", AbstractQueryTestCase.class.toString())
-                .put("path.home", createTempDir())
-                .build();
-        Settings indexSettings = Settings.settingsBuilder()
-                .put(IndexMetaData.SETTING_VERSION_CREATED, version).build();
-        index = new Index(randomAsciiOfLengthBetween(1, 10));
-        final TestClusterService clusterService = new TestClusterService();
-        clusterService.setState(new ClusterState.Builder(clusterService.state()).metaData(new MetaData.Builder().put(
-                new IndexMetaData.Builder(index.name()).settings(indexSettings).numberOfShards(1).numberOfReplicas(0))));
-        final Client proxy = (Client) Proxy.newProxyInstance(
-                Client.class.getClassLoader(),
-                new Class[]{Client.class},
-                clientInvocationHandler);
-        injector = new ModulesBuilder().add(
-                new EnvironmentModule(new Environment(settings)),
-                new SettingsModule(settings),
-                new ThreadPoolModule(new ThreadPool(settings)),
-                new IndicesModule(settings) {
-                    @Override
-                    public void configure() {
-                        // skip services
-                        bindQueryParsersExtension();
-                    }
-                },
-                new ScriptModule(settings),
-                new IndexSettingsModule(index, indexSettings),
-                new IndexCacheModule(indexSettings),
-                new AnalysisModule(indexSettings, new IndicesAnalysisService(indexSettings)),
-                new SimilarityModule(indexSettings),
-                new IndexNameModule(index),
-        new AbstractModule() {
-                    @Override
-                    protected void configure() {
-                        bind(Client.class).toInstance(proxy);
-                        Multibinder.newSetBinder(binder(), ScoreFunctionParser.class);
-                        bind(ClusterService.class).toProvider(Providers.of(clusterService));
-                        bind(CircuitBreakerService.class).to(NoneCircuitBreakerService.class);
-                        bind(NamedWriteableRegistry.class).asEagerSingleton();
-                    }
-                }
-        ).createInjector();
-        queryParserService = injector.getInstance(IndexQueryParserService.class);
-        MapperService mapperService = queryParserService.mapperService;
-        //create some random type with some default field, those types will stick around for all of the subclasses
-        currentTypes = new String[randomIntBetween(0, 5)];
-        for (int i = 0; i < currentTypes.length; i++) {
-            String type = randomAsciiOfLengthBetween(1, 10);
-            mapperService.merge(type, new CompressedXContent(PutMappingRequest.buildFromSimplifiedDef(type,
-                    STRING_FIELD_NAME, "type=string",
-                    STRING_FIELD_NAME_2, "type=string",
-                    INT_FIELD_NAME, "type=integer",
-                    DOUBLE_FIELD_NAME, "type=double",
-                    BOOLEAN_FIELD_NAME, "type=boolean",
-                    DATE_FIELD_NAME, "type=date",
-                    OBJECT_FIELD_NAME, "type=object",
-                    GEO_POINT_FIELD_NAME, "type=geo_point,lat_lon=true,geohash=true,geohash_prefix=true",
-                    GEO_SHAPE_FIELD_NAME, "type=geo_shape"
-            ).string()), false, false);
-            // also add mappings for two inner field in the object field
-            mapperService.merge(type, new CompressedXContent("{\"properties\":{\""+OBJECT_FIELD_NAME+"\":{\"type\":\"object\","
-                    + "\"properties\":{\""+DATE_FIELD_NAME+"\":{\"type\":\"date\"},\""+INT_FIELD_NAME+"\":{\"type\":\"integer\"}}}}}"), false, false);
-            currentTypes[i] = type;
-        }
-        namedWriteableRegistry = injector.getInstance(NamedWriteableRegistry.class);
-    }
-
-    @AfterClass
-    public static void afterClass() throws Exception {
-        terminate(injector.getInstance(ThreadPool.class));
-        injector = null;
-        index = null;
-        queryParserService = null;
-        currentTypes = null;
-        namedWriteableRegistry = null;
-        randomTypes = null;
-    }
-
-    @Before
-    public void beforeTest() {
-        clientInvocationHandler.delegate = this;
-        //set some random types to be queried as part the search request, before each test
-        randomTypes = getRandomTypes();
-    }
-
-    protected void setSearchContext(String[] types) {
-        TestSearchContext testSearchContext = new TestSearchContext();
-        testSearchContext.setTypes(types);
-        SearchContext.setCurrent(testSearchContext);
-    }
-
-    @After
-    public void afterTest() {
-        clientInvocationHandler.delegate = null;
-        QueryShardContext.removeTypes();
-        SearchContext.removeCurrent();
-    }
-
-    protected final QB createTestQueryBuilder() {
-        QB query = doCreateTestQueryBuilder();
-        //we should not set boost and query name for queries that don't parse it
-        if (supportsBoostAndQueryName()) {
-            if (randomBoolean()) {
-                query.boost(2.0f / randomIntBetween(1, 20));
-            }
-            if (randomBoolean()) {
-                query.queryName(randomAsciiOfLengthBetween(1, 10));
-            }
-        }
-        return query;
-    }
-
-    /**
-     * Create the query that is being tested
-     */
-    protected abstract QB doCreateTestQueryBuilder();
-
-    /**
-     * Generic test that creates new query from the test query and checks both for equality
-     * and asserts equality on the two queries.
-     */
-    @Test
-    public void testFromXContent() throws IOException {
-        QB testQuery = createTestQueryBuilder();
-        assertParsedQuery(testQuery.toString(), testQuery);
-        for (Map.Entry<String, QB> alternateVersion : getAlternateVersions().entrySet()) {
-            assertParsedQuery(alternateVersion.getKey(), alternateVersion.getValue());
-        }
-    }
-
-    /**
-     * Returns alternate string representation of the query that need to be tested as they are never used as output
-     * of {@link QueryBuilder#toXContent(XContentBuilder, ToXContent.Params)}. By default there are no alternate versions.
-     */
-    protected Map<String, QB> getAlternateVersions() {
-        return Collections.emptyMap();
-    }
-
-    /**
-     * Parses the query provided as string argument and compares it with the expected result provided as argument as a {@link QueryBuilder}
-     */
-    protected void assertParsedQuery(String queryAsString, QueryBuilder<?> expectedQuery) throws IOException {
-        assertParsedQuery(queryAsString, expectedQuery, ParseFieldMatcher.STRICT);
-    }
-
-    protected void assertParsedQuery(String queryAsString, QueryBuilder<?> expectedQuery, ParseFieldMatcher matcher) throws IOException {
-        QueryBuilder<?> newQuery = parseQuery(queryAsString, matcher);
-        assertNotSame(newQuery, expectedQuery);
-        assertEquals(expectedQuery, newQuery);
-        assertEquals(expectedQuery.hashCode(), newQuery.hashCode());
-    }
-
-    protected QueryBuilder<?> parseQuery(String queryAsString) throws IOException {
-        return parseQuery(queryAsString, ParseFieldMatcher.STRICT);
-    }
-
-    protected QueryBuilder<?> parseQuery(String queryAsString, ParseFieldMatcher matcher) throws IOException {
-        XContentParser parser = XContentFactory.xContent(queryAsString).createParser(queryAsString);
-        QueryParseContext context = createParseContext();
-        context.reset(parser);
-        context.parseFieldMatcher(matcher);
-        return context.parseInnerQueryBuilder();
-    }
-
-    /**
-     * Test creates the {@link Query} from the {@link QueryBuilder} under test and delegates the
-     * assertions being made on the result to the implementing subclass.
-     */
-    @Test
-    public void testToQuery() throws IOException {
-        QueryShardContext context = createShardContext();
-        context.setAllowUnmappedFields(true);
-
-        QB firstQuery = createTestQueryBuilder();
-        setSearchContext(randomTypes); // only set search context for toQuery to be more realistic
-        Query firstLuceneQuery = firstQuery.toQuery(context);
-        assertLuceneQuery(firstQuery, firstLuceneQuery, context);
-        SearchContext.removeCurrent(); // remove after assertLuceneQuery since the assertLuceneQuery impl might access the context as well
-
-
-        QB secondQuery = copyQuery(firstQuery);
-        //query _name never should affect the result of toQuery, we randomly set it to make sure
-        if (randomBoolean()) {
-            secondQuery.queryName(secondQuery.queryName() == null ? randomAsciiOfLengthBetween(1, 30) : secondQuery.queryName() + randomAsciiOfLengthBetween(1, 10));
-        }
-        setSearchContext(randomTypes); // only set search context for toQuery to be more realistic
-        Query secondLuceneQuery = secondQuery.toQuery(context);
-        assertLuceneQuery(secondQuery, secondLuceneQuery, context);
-        SearchContext.removeCurrent(); // remove after assertLuceneQuery since the assertLuceneQuery impl might access the context as well
-
-        assertThat("two equivalent query builders lead to different lucene queries", secondLuceneQuery, equalTo(firstLuceneQuery));
-
-        //if the initial lucene query is null, changing its boost won't have any effect, we shouldn't test that
-        if (firstLuceneQuery != null && supportsBoostAndQueryName()) {
-            secondQuery.boost(firstQuery.boost() + 1f + randomFloat());
-            setSearchContext(randomTypes); // only set search context for toQuery to be more realistic
-            Query thirdLuceneQuery = secondQuery.toQuery(context);
-            SearchContext.removeCurrent();
-            assertThat("modifying the boost doesn't affect the corresponding lucene query", firstLuceneQuery, not(equalTo(thirdLuceneQuery)));
-        }
-    }
-
-    /**
-     * Few queries allow you to set the boost and queryName on the java api, although the corresponding parser doesn't parse them as they are not supported.
-     * This method allows to disable boost and queryName related tests for those queries. Those queries are easy to identify: their parsers
-     * don't parse `boost` and `_name` as they don't apply to the specific query: filter query, wrapper query and match_none
-     */
-    protected boolean supportsBoostAndQueryName() {
-        return true;
-    }
-
-    /**
-     * Checks the result of {@link QueryBuilder#toQuery(QueryShardContext)} given the original {@link QueryBuilder} and {@link QueryShardContext}.
-     * Verifies that named queries and boost are properly handled and delegates to {@link #doAssertLuceneQuery(AbstractQueryBuilder, Query, QueryShardContext)}
-     * for query specific checks.
-     */
-    protected final void assertLuceneQuery(QB queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if (queryBuilder.queryName() != null) {
-            Query namedQuery = context.copyNamedQueries().get(queryBuilder.queryName());
-            assertThat(namedQuery, equalTo(query));
-        }
-        if (query != null) {
-            assertBoost(queryBuilder, query);
-        }
-        doAssertLuceneQuery(queryBuilder, query, context);
-    }
-
-    /**
-     * Allows to override boost assertions for queries that don't have the default behaviour
-     */
-    protected void assertBoost(QB queryBuilder, Query query) throws IOException {
-        assertThat(query.getBoost(), equalTo(queryBuilder.boost()));
-    }
-
-    /**
-     * Checks the result of {@link QueryBuilder#toQuery(QueryShardContext)} given the original {@link QueryBuilder} and {@link QueryShardContext}.
-     * Contains the query specific checks to be implemented by subclasses.
-     */
-    protected abstract void doAssertLuceneQuery(QB queryBuilder, Query query, QueryShardContext context) throws IOException;
-
-    /**
-     * Test serialization and deserialization of the test query.
-     */
-    @Test
-    public void testSerialization() throws IOException {
-        QB testQuery = createTestQueryBuilder();
-        assertSerialization(testQuery);
-    }
-
-    /**
-     * Serialize the given query builder and asserts that both are equal
-     */
-    protected QB assertSerialization(QB testQuery) throws IOException {
-        try (BytesStreamOutput output = new BytesStreamOutput()) {
-            testQuery.writeTo(output);
-            try (StreamInput in = new NamedWriteableAwareStreamInput(StreamInput.wrap(output.bytes()), namedWriteableRegistry)) {
-                QueryBuilder<?> prototype = queryParser(testQuery.getName()).getBuilderPrototype();
-                QueryBuilder deserializedQuery = prototype.readFrom(in);
-                assertEquals(deserializedQuery, testQuery);
-                assertEquals(deserializedQuery.hashCode(), testQuery.hashCode());
-                assertNotSame(deserializedQuery, testQuery);
-                return (QB) deserializedQuery;
-            }
-        }
-    }
-
-    @Test
-    public void testEqualsAndHashcode() throws IOException {
-        QB firstQuery = createTestQueryBuilder();
-        assertFalse("query is equal to null", firstQuery.equals(null));
-        assertFalse("query is equal to incompatible type", firstQuery.equals(""));
-        assertTrue("query is not equal to self", firstQuery.equals(firstQuery));
-        assertThat("same query's hashcode returns different values if called multiple times", firstQuery.hashCode(), equalTo(firstQuery.hashCode()));
-
-        QB secondQuery = copyQuery(firstQuery);
-        assertTrue("query is not equal to self", secondQuery.equals(secondQuery));
-        assertTrue("query is not equal to its copy", firstQuery.equals(secondQuery));
-        assertTrue("equals is not symmetric", secondQuery.equals(firstQuery));
-        assertThat("query copy's hashcode is different from original hashcode", secondQuery.hashCode(), equalTo(firstQuery.hashCode()));
-
-        QB thirdQuery = copyQuery(secondQuery);
-        assertTrue("query is not equal to self", thirdQuery.equals(thirdQuery));
-        assertTrue("query is not equal to its copy", secondQuery.equals(thirdQuery));
-        assertThat("query copy's hashcode is different from original hashcode", secondQuery.hashCode(), equalTo(thirdQuery.hashCode()));
-        assertTrue("equals is not transitive", firstQuery.equals(thirdQuery));
-        assertThat("query copy's hashcode is different from original hashcode", firstQuery.hashCode(), equalTo(thirdQuery.hashCode()));
-        assertTrue("equals is not symmetric", thirdQuery.equals(secondQuery));
-        assertTrue("equals is not symmetric", thirdQuery.equals(firstQuery));
-
-        if (randomBoolean()) {
-            secondQuery.queryName(secondQuery.queryName() == null ? randomAsciiOfLengthBetween(1, 30) : secondQuery.queryName() + randomAsciiOfLengthBetween(1, 10));
-        } else {
-            secondQuery.boost(firstQuery.boost() + 1f + randomFloat());
-        }
-        assertThat("different queries should not be equal", secondQuery, not(equalTo(firstQuery)));
-        assertThat("different queries should have different hashcode", secondQuery.hashCode(), not(equalTo(firstQuery.hashCode())));
-    }
-
-    private QueryParser<?> queryParser(String queryId) {
-        return queryParserService.indicesQueriesRegistry().queryParsers().get(queryId);
-    }
-
-    //we use the streaming infra to create a copy of the query provided as argument
-    protected QB copyQuery(QB query) throws IOException {
-        try (BytesStreamOutput output = new BytesStreamOutput()) {
-            query.writeTo(output);
-            try (StreamInput in = new NamedWriteableAwareStreamInput(StreamInput.wrap(output.bytes()), namedWriteableRegistry)) {
-                QueryBuilder<?> prototype = queryParser(query.getName()).getBuilderPrototype();
-                @SuppressWarnings("unchecked")
-                QB secondQuery = (QB)prototype.readFrom(in);
-                return secondQuery;
-            }
-        }
-    }
-
-    /**
-     * @return a new {@link QueryShardContext} based on the base test index and queryParserService
-     */
-    protected static QueryShardContext createShardContext() {
-        QueryShardContext queryCreationContext = new QueryShardContext(index, queryParserService);
-        queryCreationContext.reset();
-        queryCreationContext.parseFieldMatcher(ParseFieldMatcher.EMPTY);
-        return queryCreationContext;
-    }
-
-    /**
-     * @return a new {@link QueryParseContext} based on the base test index and queryParserService
-     */
-    protected static QueryParseContext createParseContext() {
-        return createShardContext().parseContext();
-    }
-
-    protected static void assertValidate(QueryBuilder queryBuilder, int totalExpectedErrors) {
-        QueryValidationException queryValidationException = queryBuilder.validate();
-        if (totalExpectedErrors > 0) {
-            assertThat(queryValidationException, notNullValue());
-            assertThat(queryValidationException.validationErrors().size(), equalTo(totalExpectedErrors));
-        } else {
-            assertThat(queryValidationException, nullValue());
-        }
-    }
-
-    /**
-     * create a random value for either {@link AbstractQueryTestCase#BOOLEAN_FIELD_NAME}, {@link AbstractQueryTestCase#INT_FIELD_NAME},
-     * {@link AbstractQueryTestCase#DOUBLE_FIELD_NAME}, {@link AbstractQueryTestCase#STRING_FIELD_NAME} or
-     * {@link AbstractQueryTestCase#DATE_FIELD_NAME}, or a String value by default
-     */
-    protected static Object getRandomValueForFieldName(String fieldName) {
-        Object value;
-        switch (fieldName) {
-            case STRING_FIELD_NAME:
-                value = rarely() ? randomUnicodeOfLength(10) : randomAsciiOfLengthBetween(1, 10); // unicode in 10% cases
-                break;
-            case INT_FIELD_NAME:
-                value = randomIntBetween(0, 10);
-                break;
-            case DOUBLE_FIELD_NAME:
-                value = randomDouble() * 10;
-                break;
-            case BOOLEAN_FIELD_NAME:
-                value = randomBoolean();
-                break;
-            case DATE_FIELD_NAME:
-                value = new DateTime(System.currentTimeMillis(), DateTimeZone.UTC).toString();
-                break;
-            default:
-                value = randomAsciiOfLengthBetween(1, 10);
-        }
-        return value;
-    }
-
-    /**
-     * Helper method to return a mapped or a random field
-     */
-    protected String getRandomFieldName() {
-        // if no type is set then return a random field name
-        if (currentTypes == null || currentTypes.length == 0 || randomBoolean()) {
-            return randomAsciiOfLengthBetween(1, 10);
-        }
-        return randomFrom(MAPPED_LEAF_FIELD_NAMES);
-    }
-
-    /**
-     * Helper method to return a random field (mapped or unmapped) and a value
-     */
-    protected Tuple<String, Object> getRandomFieldNameAndValue() {
-        String fieldName = getRandomFieldName();
-        return new Tuple<>(fieldName, getRandomValueForFieldName(fieldName));
-    }
-
-    /**
-     * Helper method to return a random rewrite method
-     */
-    protected static String getRandomRewriteMethod() {
-        String rewrite;
-        if (randomBoolean()) {
-            rewrite = randomFrom(QueryParsers.CONSTANT_SCORE,
-                    QueryParsers.SCORING_BOOLEAN,
-                    QueryParsers.CONSTANT_SCORE_BOOLEAN).getPreferredName();
-        } else {
-            rewrite = randomFrom(QueryParsers.TOP_TERMS,
-                    QueryParsers.TOP_TERMS_BOOST,
-                    QueryParsers.TOP_TERMS_BLENDED_FREQS).getPreferredName() + "1";
-        }
-        return rewrite;
-    }
-
-    protected String[] getRandomTypes() {
-        String[] types;
-        if (currentTypes.length > 0 && randomBoolean()) {
-            int numberOfQueryTypes = randomIntBetween(1, currentTypes.length);
-            types = new String[numberOfQueryTypes];
-            for (int i = 0; i < numberOfQueryTypes; i++) {
-                types[i] = randomFrom(currentTypes);
-            }
-        } else {
-            if (randomBoolean()) {
-                types = new String[] { MetaData.ALL };
-            } else {
-                types = new String[0];
-            }
-        }
-        return types;
-    }
-
-    protected String getRandomType() {
-        return (currentTypes.length == 0) ? MetaData.ALL : randomFrom(currentTypes);
-    }
-
-    public static String randomGeohash(int minPrecision, int maxPrecision) {
-        return geohashGenerator.ofStringLength(getRandom(), minPrecision, maxPrecision);
-    }
-
-    public static class GeohashGenerator extends CodepointSetGenerator {
-        private final static char[] ASCII_SET = "0123456789bcdefghjkmnpqrstuvwxyz".toCharArray();
-
-        public GeohashGenerator() {
-            super(ASCII_SET);
-        }
-    }
-
-    protected static Fuzziness randomFuzziness(String fieldName) {
-        if (randomBoolean()) {
-            return Fuzziness.fromEdits(randomIntBetween(0, 2));
-        }
-        if (randomBoolean()) {
-            return Fuzziness.AUTO;
-        }
-        switch (fieldName) {
-            case INT_FIELD_NAME:
-                return Fuzziness.build(randomIntBetween(3, 100));
-            case DOUBLE_FIELD_NAME:
-                return Fuzziness.build(1 + randomFloat() * 10);
-            case DATE_FIELD_NAME:
-                return Fuzziness.build(randomTimeValue());
-            default:
-                return Fuzziness.AUTO;
-        }
-    }
-
-    protected static boolean isNumericFieldName(String fieldName) {
-        return INT_FIELD_NAME.equals(fieldName) || DOUBLE_FIELD_NAME.equals(fieldName);
-    }
-
-    protected static String randomAnalyzer() {
-        return randomFrom("simple", "standard", "keyword", "whitespace");
-    }
-
-    protected static String randomMinimumShouldMatch() {
-        return randomFrom("1", "-1", "75%", "-25%", "2<75%", "2<-25%");
-    }
-
-    protected static String randomTimeZone() {
-        return randomFrom(TIMEZONE_IDS);
-    }
-
-    private static final List<String> TIMEZONE_IDS = new ArrayList<>(DateTimeZone.getAvailableIDs());
-
-    private static class ClientInvocationHandler implements InvocationHandler {
-        AbstractQueryTestCase delegate;
-        @Override
-        public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
-            if (method.equals(Client.class.getDeclaredMethod("get", GetRequest.class))) {
-                return new PlainActionFuture<GetResponse>() {
-                    @Override
-                    public GetResponse get() throws InterruptedException, ExecutionException {
-                        return delegate.executeGet((GetRequest) args[0]);
-                    }
-                };
-            } else if (method.equals(Client.class.getDeclaredMethod("multiTermVectors", MultiTermVectorsRequest.class))) {
-                    return new PlainActionFuture<MultiTermVectorsResponse>() {
-                        @Override
-                        public MultiTermVectorsResponse get() throws InterruptedException, ExecutionException {
-                            return delegate.executeMultiTermVectors((MultiTermVectorsRequest) args[0]);
-                        }
-                    };
-            } else if (method.equals(Object.class.getDeclaredMethod("toString"))) {
-                return "MockClient";
-            }
-            throw new UnsupportedOperationException("this test can't handle calls to: " + method);
-        }
-
-    }
-
-    /**
-     * Override this to handle {@link Client#get(GetRequest)} calls from parsers / builders
-     */
-    protected GetResponse executeGet(GetRequest getRequest) {
-        throw new UnsupportedOperationException("this test can't handle GET requests");
-    }
-
-    /**
-     * Override this to handle {@link Client#get(GetRequest)} calls from parsers / builders
-     */
-    protected MultiTermVectorsResponse executeMultiTermVectors(MultiTermVectorsRequest mtvRequest) {
-        throw new UnsupportedOperationException("this test can't handle MultiTermVector requests");
-    }
-
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/AbstractTermQueryTestCase.java b/core/src/test/java/org/elasticsearch/index/query/AbstractTermQueryTestCase.java
deleted file mode 100644
index 3c63fdf..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/AbstractTermQueryTestCase.java
+++ /dev/null
@@ -1,110 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.junit.Test;
-
-import java.util.HashMap;
-import java.util.Map;
-
-import static org.hamcrest.Matchers.is;
-
-public abstract class AbstractTermQueryTestCase<QB extends BaseTermQueryBuilder<QB>> extends AbstractQueryTestCase<QB> {
-
-    @Override
-    protected final QB doCreateTestQueryBuilder() {
-        String fieldName = null;
-        Object value;
-        switch (randomIntBetween(0, 3)) {
-            case 0:
-                if (randomBoolean()) {
-                    fieldName = BOOLEAN_FIELD_NAME;
-                }
-                value = randomBoolean();
-                break;
-            case 1:
-                if (randomBoolean()) {
-                    fieldName = STRING_FIELD_NAME;
-                }
-                if (frequently()) {
-                    value = randomAsciiOfLengthBetween(1, 10);
-                } else {
-                    // generate unicode string in 10% of cases
-                    value = randomUnicodeOfLength(10);
-                }
-                break;
-            case 2:
-                if (randomBoolean()) {
-                    fieldName = INT_FIELD_NAME;
-                }
-                value = randomInt(10000);
-                break;
-            case 3:
-                if (randomBoolean()) {
-                    fieldName = DOUBLE_FIELD_NAME;
-                }
-                value = randomDouble();
-                break;
-            default:
-                throw new UnsupportedOperationException();
-        }
-
-        if (fieldName == null) {
-            fieldName = randomAsciiOfLengthBetween(1, 10);
-        }
-        return createQueryBuilder(fieldName, value);
-    }
-
-    protected abstract QB createQueryBuilder(String fieldName, Object value);
-
-    @Test
-    public void testValidate() throws QueryShardException {
-        QB queryBuilder = createQueryBuilder(randomAsciiOfLengthBetween(1, 30), randomAsciiOfLengthBetween(1, 30));
-        assertNull(queryBuilder.validate());
-
-        queryBuilder = createQueryBuilder(null, randomAsciiOfLengthBetween(1, 30));
-        assertNotNull(queryBuilder.validate());
-        assertThat(queryBuilder.validate().validationErrors().size(), is(1));
-
-        queryBuilder = createQueryBuilder("", randomAsciiOfLengthBetween(1, 30));
-        assertNotNull(queryBuilder.validate());
-        assertThat(queryBuilder.validate().validationErrors().size(), is(1));
-
-        queryBuilder = createQueryBuilder("", null);
-        assertNotNull(queryBuilder.validate());
-        assertThat(queryBuilder.validate().validationErrors().size(), is(2));
-    }
-
-    @Override
-    protected Map<String, QB> getAlternateVersions() {
-        HashMap<String, QB> alternateVersions = new HashMap<>();
-        QB tempQuery = createTestQueryBuilder();
-        QB testQuery = createQueryBuilder(tempQuery.fieldName(), tempQuery.value());
-        boolean isString = testQuery.value() instanceof String;
-        String value = (isString ? "\"" : "") + testQuery.value() + (isString ? "\"" : "");
-        String contentString = "{\n" +
-                "    \"" + testQuery.getName() + "\" : {\n" +
-                "        \"" + testQuery.fieldName() + "\" : " + value + "\n" +
-                "    }\n" +
-                "}";
-        alternateVersions.put(contentString, testQuery);
-        return alternateVersions;
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/BoolQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/BoolQueryBuilderTests.java
deleted file mode 100644
index 59c305c..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/BoolQueryBuilderTests.java
+++ /dev/null
@@ -1,206 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.*;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class BoolQueryBuilderTests extends AbstractQueryTestCase<BoolQueryBuilder> {
-
-    @Override
-    protected BoolQueryBuilder doCreateTestQueryBuilder() {
-        BoolQueryBuilder query = new BoolQueryBuilder();
-        if (randomBoolean()) {
-            query.adjustPureNegative(randomBoolean());
-        }
-        if (randomBoolean()) {
-            query.disableCoord(randomBoolean());
-        }
-        if (randomBoolean()) {
-            query.minimumNumberShouldMatch(randomMinimumShouldMatch());
-        }
-        int mustClauses = randomIntBetween(0, 3);
-        for (int i = 0; i < mustClauses; i++) {
-            query.must(RandomQueryBuilder.createQuery(random()));
-        }
-        int mustNotClauses = randomIntBetween(0, 3);
-        for (int i = 0; i < mustNotClauses; i++) {
-            query.mustNot(RandomQueryBuilder.createQuery(random()));
-        }
-        int shouldClauses = randomIntBetween(0, 3);
-        for (int i = 0; i < shouldClauses; i++) {
-            query.should(RandomQueryBuilder.createQuery(random()));
-        }
-        int filterClauses = randomIntBetween(0, 3);
-        for (int i = 0; i < filterClauses; i++) {
-            query.filter(RandomQueryBuilder.createQuery(random()));
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(BoolQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if (!queryBuilder.hasClauses()) {
-            assertThat(query, instanceOf(MatchAllDocsQuery.class));
-        } else {
-            List<BooleanClause> clauses = new ArrayList<>();
-            clauses.addAll(getBooleanClauses(queryBuilder.must(), BooleanClause.Occur.MUST, context));
-            clauses.addAll(getBooleanClauses(queryBuilder.mustNot(), BooleanClause.Occur.MUST_NOT, context));
-            clauses.addAll(getBooleanClauses(queryBuilder.should(), BooleanClause.Occur.SHOULD, context));
-            clauses.addAll(getBooleanClauses(queryBuilder.filter(), BooleanClause.Occur.FILTER, context));
-
-            if (clauses.isEmpty()) {
-                assertThat(query, instanceOf(MatchAllDocsQuery.class));
-            } else {
-                assertThat(query, instanceOf(BooleanQuery.class));
-                BooleanQuery booleanQuery = (BooleanQuery) query;
-                if (queryBuilder.adjustPureNegative()) {
-                    boolean isNegative = true;
-                    for (BooleanClause clause : clauses) {
-                        if (clause.isProhibited() == false) {
-                            isNegative = false;
-                            break;
-                        }
-                    }
-                    if (isNegative) {
-                        clauses.add(new BooleanClause(new MatchAllDocsQuery(), BooleanClause.Occur.MUST));
-                    }
-                }
-                assertThat(booleanQuery.clauses().size(), equalTo(clauses.size()));
-                Iterator<BooleanClause> clauseIterator = clauses.iterator();
-                for (BooleanClause booleanClause : booleanQuery.getClauses()) {
-                    assertThat(booleanClause, equalTo(clauseIterator.next()));
-                }
-            }
-        }
-    }
-
-    private static List<BooleanClause> getBooleanClauses(List<QueryBuilder> queryBuilders, BooleanClause.Occur occur, QueryShardContext context) throws IOException {
-        List<BooleanClause> clauses = new ArrayList<>();
-        for (QueryBuilder query : queryBuilders) {
-            Query innerQuery = query.toQuery(context);
-            if (innerQuery != null) {
-                clauses.add(new BooleanClause(innerQuery, occur));
-            }
-        }
-        return clauses;
-    }
-
-    @Override
-    protected Map<String, BoolQueryBuilder> getAlternateVersions() {
-        Map<String, BoolQueryBuilder> alternateVersions = new HashMap<>();
-        BoolQueryBuilder tempQueryBuilder = createTestQueryBuilder();
-        BoolQueryBuilder expectedQuery = new BoolQueryBuilder();
-        String contentString = "{\n" +
-                "    \"bool\" : {\n";
-        if (tempQueryBuilder.must().size() > 0) {
-            QueryBuilder must = tempQueryBuilder.must().get(0);
-            contentString += "must: " + must.toString() + ",";
-            expectedQuery.must(must);
-        }
-        if (tempQueryBuilder.mustNot().size() > 0) {
-            QueryBuilder mustNot = tempQueryBuilder.mustNot().get(0);
-            contentString += (randomBoolean() ? "must_not: " : "mustNot: ") + mustNot.toString() + ",";
-            expectedQuery.mustNot(mustNot);
-        }
-        if (tempQueryBuilder.should().size() > 0) {
-            QueryBuilder should = tempQueryBuilder.should().get(0);
-            contentString += "should: " + should.toString() + ",";
-            expectedQuery.should(should);
-        }
-        if (tempQueryBuilder.filter().size() > 0) {
-            QueryBuilder filter = tempQueryBuilder.filter().get(0);
-            contentString += "filter: " + filter.toString() + ",";
-            expectedQuery.filter(filter);
-        }
-        contentString = contentString.substring(0, contentString.length() - 1);
-        contentString += "    }    \n" + "}";
-        alternateVersions.put(contentString, expectedQuery);
-        return alternateVersions;
-    }
-
-    @Test
-    public void testValidate() {
-        BoolQueryBuilder booleanQuery = new BoolQueryBuilder();
-        int iters = randomIntBetween(0, 3);
-        int totalExpectedErrors = 0;
-        for (int i = 0; i < iters; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    booleanQuery.must(RandomQueryBuilder.createInvalidQuery(random()));
-                } else {
-                    booleanQuery.must(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                booleanQuery.must(RandomQueryBuilder.createQuery(random()));
-            }
-        }
-        iters = randomIntBetween(0, 3);
-        for (int i = 0; i < iters; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    booleanQuery.should(RandomQueryBuilder.createInvalidQuery(random()));
-                } else {
-                    booleanQuery.should(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                booleanQuery.should(RandomQueryBuilder.createQuery(random()));
-            }
-        }
-        iters = randomIntBetween(0, 3);
-        for (int i = 0; i < iters; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    booleanQuery.mustNot(RandomQueryBuilder.createInvalidQuery(random()));
-                } else {
-                    booleanQuery.mustNot(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                booleanQuery.mustNot(RandomQueryBuilder.createQuery(random()));
-            }
-        }
-        iters = randomIntBetween(0, 3);
-        for (int i = 0; i < iters; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    booleanQuery.filter(RandomQueryBuilder.createInvalidQuery(random()));
-                } else {
-                    booleanQuery.filter(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                booleanQuery.filter(RandomQueryBuilder.createQuery(random()));
-            }
-        }
-        assertValidate(booleanQuery, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/BoostingQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/BoostingQueryBuilderTests.java
deleted file mode 100644
index 6bb895c..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/BoostingQueryBuilderTests.java
+++ /dev/null
@@ -1,81 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.queries.BoostingQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.instanceOf;
-import static org.hamcrest.CoreMatchers.nullValue;
-
-public class BoostingQueryBuilderTests extends AbstractQueryTestCase<BoostingQueryBuilder> {
-
-    @Override
-    protected BoostingQueryBuilder doCreateTestQueryBuilder() {
-        BoostingQueryBuilder query = new BoostingQueryBuilder(RandomQueryBuilder.createQuery(random()), RandomQueryBuilder.createQuery(random()));
-        query.negativeBoost(2.0f / randomIntBetween(1, 20));
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(BoostingQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        Query positive = queryBuilder.positiveQuery().toQuery(context);
-        Query negative = queryBuilder.negativeQuery().toQuery(context);
-        if (positive == null || negative == null) {
-            assertThat(query, nullValue());
-        } else {
-            assertThat(query, instanceOf(BoostingQuery.class));
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        int totalExpectedErrors = 0;
-        QueryBuilder positive = null;
-        QueryBuilder negative = null;
-        if (frequently()) {
-            if (randomBoolean()) {
-                negative = RandomQueryBuilder.createInvalidQuery(random());
-            }
-            totalExpectedErrors++;
-        } else {
-            negative = RandomQueryBuilder.createQuery(random());
-        }
-        if (frequently()) {
-            if (randomBoolean()) {
-                positive = RandomQueryBuilder.createInvalidQuery(random());
-            }
-            totalExpectedErrors++;
-        } else {
-            positive = RandomQueryBuilder.createQuery(random());
-        }
-        BoostingQueryBuilder boostingQuery = new BoostingQueryBuilder(positive, negative);
-        if (frequently()) {
-            boostingQuery.negativeBoost(0.5f);
-        } else {
-            boostingQuery.negativeBoost(-0.5f);
-            totalExpectedErrors++;
-        }
-        assertValidate(boostingQuery, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/CommonTermsQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/CommonTermsQueryBuilderTests.java
deleted file mode 100644
index 44b5fd9..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/CommonTermsQueryBuilderTests.java
+++ /dev/null
@@ -1,105 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.queries.ExtendedCommonTermsQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-
-public class CommonTermsQueryBuilderTests extends AbstractQueryTestCase<CommonTermsQueryBuilder> {
-
-    @Override
-    protected CommonTermsQueryBuilder doCreateTestQueryBuilder() {
-        CommonTermsQueryBuilder query;
-
-        // mapped or unmapped field
-        String text = randomAsciiOfLengthBetween(1, 10);
-        if (randomBoolean()) {
-            query = new CommonTermsQueryBuilder(STRING_FIELD_NAME, text);
-        } else {
-            query = new CommonTermsQueryBuilder(randomAsciiOfLengthBetween(1, 10), text);
-        }
-
-        if (randomBoolean()) {
-            query.cutoffFrequency((float) randomIntBetween(1, 10));
-        }
-
-        if (randomBoolean()) {
-            query.lowFreqOperator(randomFrom(Operator.values()));
-        }
-
-        // number of low frequency terms that must match
-        if (randomBoolean()) {
-            query.lowFreqMinimumShouldMatch("" + randomIntBetween(1, 5));
-        }
-
-        if (randomBoolean()) {
-            query.highFreqOperator(randomFrom(Operator.values()));
-        }
-
-        // number of high frequency terms that must match
-        if (randomBoolean()) {
-            query.highFreqMinimumShouldMatch("" + randomIntBetween(1, 5));
-        }
-
-        if (randomBoolean()) {
-            query.analyzer(randomAnalyzer());
-        }
-
-        if (randomBoolean()) {
-            query.disableCoord(randomBoolean());
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(CommonTermsQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(ExtendedCommonTermsQuery.class));
-        ExtendedCommonTermsQuery extendedCommonTermsQuery = (ExtendedCommonTermsQuery) query;
-        assertThat(extendedCommonTermsQuery.getHighFreqMinimumNumberShouldMatchSpec(), equalTo(queryBuilder.highFreqMinimumShouldMatch()));
-        assertThat(extendedCommonTermsQuery.getLowFreqMinimumNumberShouldMatchSpec(), equalTo(queryBuilder.lowFreqMinimumShouldMatch()));
-    }
-
-    @Test
-    public void testValidate() {
-        CommonTermsQueryBuilder commonTermsQueryBuilder = new CommonTermsQueryBuilder("", "text");
-        assertThat(commonTermsQueryBuilder.validate().validationErrors().size(), is(1));
-
-        commonTermsQueryBuilder = new CommonTermsQueryBuilder("field", null);
-        assertThat(commonTermsQueryBuilder.validate().validationErrors().size(), is(1));
-
-        commonTermsQueryBuilder = new CommonTermsQueryBuilder("field", "text");
-        assertNull(commonTermsQueryBuilder.validate());
-    }
-
-    @Test
-    public void testNoTermsFromQueryString() throws IOException {
-        CommonTermsQueryBuilder builder = new CommonTermsQueryBuilder(STRING_FIELD_NAME, "");
-        QueryShardContext context = createShardContext();
-        context.setAllowUnmappedFields(true);
-        assertNull(builder.toQuery(context));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/ConstantScoreQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/ConstantScoreQueryBuilderTests.java
deleted file mode 100644
index fedfce3..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/ConstantScoreQueryBuilderTests.java
+++ /dev/null
@@ -1,76 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.*;
-
-public class ConstantScoreQueryBuilderTests extends AbstractQueryTestCase<ConstantScoreQueryBuilder> {
-
-    /**
-     * @return a {@link ConstantScoreQueryBuilder} with random boost between 0.1f and 2.0f
-     */
-    @Override
-    protected ConstantScoreQueryBuilder doCreateTestQueryBuilder() {
-        return new ConstantScoreQueryBuilder(RandomQueryBuilder.createQuery(random()));
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(ConstantScoreQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        Query innerQuery = queryBuilder.innerQuery().toQuery(context);
-        if (innerQuery == null) {
-            assertThat(query, nullValue());
-        } else {
-            assertThat(query, instanceOf(ConstantScoreQuery.class));
-            ConstantScoreQuery constantScoreQuery = (ConstantScoreQuery) query;
-            assertThat(constantScoreQuery.getQuery(), equalTo(innerQuery));
-        }
-    }
-
-    /**
-     * test that missing "filter" element causes {@link QueryParsingException}
-     */
-    @Test(expected=QueryParsingException.class)
-    public void testFilterElement() throws IOException {
-        String queryString = "{ \"" + ConstantScoreQueryBuilder.NAME + "\" : {}";
-        parseQuery(queryString);
-    }
-
-    @Test
-    public void testValidate() {
-        QueryBuilder innerQuery = null;
-        int totalExpectedErrors = 0;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                innerQuery = RandomQueryBuilder.createInvalidQuery(random());
-            }
-            totalExpectedErrors++;
-        } else {
-            innerQuery = RandomQueryBuilder.createQuery(random());
-        }
-        ConstantScoreQueryBuilder constantScoreQuery = new ConstantScoreQueryBuilder(innerQuery);
-        assertValidate(constantScoreQuery, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/DisMaxQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/DisMaxQueryBuilderTests.java
deleted file mode 100644
index ee32963..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/DisMaxQueryBuilderTests.java
+++ /dev/null
@@ -1,128 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.DisjunctionMaxQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.Map;
-
-import static org.hamcrest.CoreMatchers.*;
-
-public class DisMaxQueryBuilderTests extends AbstractQueryTestCase<DisMaxQueryBuilder> {
-
-    /**
-     * @return a {@link DisMaxQueryBuilder} with random inner queries
-     */
-    @Override
-    protected DisMaxQueryBuilder doCreateTestQueryBuilder() {
-        DisMaxQueryBuilder dismax = new DisMaxQueryBuilder();
-        int clauses = randomIntBetween(1, 5);
-        for (int i = 0; i < clauses; i++) {
-            dismax.add(RandomQueryBuilder.createQuery(random()));
-        }
-        if (randomBoolean()) {
-            dismax.tieBreaker(2.0f / randomIntBetween(1, 20));
-        }
-        return dismax;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(DisMaxQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        Collection<Query> queries = AbstractQueryBuilder.toQueries(queryBuilder.innerQueries(), context);
-        if (queries.isEmpty()) {
-            assertThat(query, nullValue());
-        } else {
-            assertThat(query, instanceOf(DisjunctionMaxQuery.class));
-            DisjunctionMaxQuery disjunctionMaxQuery = (DisjunctionMaxQuery) query;
-            assertThat(disjunctionMaxQuery.getTieBreakerMultiplier(), equalTo(queryBuilder.tieBreaker()));
-            assertThat(disjunctionMaxQuery.getDisjuncts().size(), equalTo(queries.size()));
-            Iterator<Query> queryIterator = queries.iterator();
-            for (int i = 0; i < disjunctionMaxQuery.getDisjuncts().size(); i++) {
-                assertThat(disjunctionMaxQuery.getDisjuncts().get(i), equalTo(queryIterator.next()));
-            }
-        }
-    }
-
-    @Override
-    protected Map<String, DisMaxQueryBuilder> getAlternateVersions() {
-        Map<String, DisMaxQueryBuilder> alternateVersions = new HashMap<>();
-        QueryBuilder innerQuery = createTestQueryBuilder().innerQueries().get(0);
-        DisMaxQueryBuilder expectedQuery = new DisMaxQueryBuilder();
-        expectedQuery.add(innerQuery);
-        String contentString = "{\n" +
-                "    \"dis_max\" : {\n" +
-                "        \"queries\" : " + innerQuery.toString() +
-                "    }\n" +
-                "}";
-        alternateVersions.put(contentString, expectedQuery);
-        return alternateVersions;
-    }
-
-    /**
-     * test `null`return value for missing inner queries
-     * @throws IOException
-     * @throws QueryParsingException
-     */
-    @Test
-    public void testNoInnerQueries() throws QueryParsingException, IOException {
-        DisMaxQueryBuilder disMaxBuilder = new DisMaxQueryBuilder();
-        assertNull(disMaxBuilder.toQuery(createShardContext()));
-        assertNull(disMaxBuilder.validate());
-    }
-
-    /**
-     * Test inner query parsing to null. Current DSL allows inner filter element to parse to <tt>null</tt>.
-     * Those should be ignored upstream. To test this, we use inner {@link ConstantScoreQueryBuilder}
-     * with empty inner filter.
-     */
-    @Test
-    public void testInnerQueryReturnsNull() throws IOException {
-        String queryString = "{ \"" + ConstantScoreQueryBuilder.NAME + "\" : { \"filter\" : { } } }";
-        QueryBuilder<?> innerQueryBuilder = parseQuery(queryString);
-        DisMaxQueryBuilder disMaxBuilder = new DisMaxQueryBuilder().add(innerQueryBuilder);
-        assertNull(disMaxBuilder.toQuery(createShardContext()));
-    }
-
-    @Test
-    public void testValidate() {
-        DisMaxQueryBuilder disMaxQuery = new DisMaxQueryBuilder();
-        int iters = randomIntBetween(0, 5);
-        int totalExpectedErrors = 0;
-        for (int i = 0; i < iters; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    disMaxQuery.add(RandomQueryBuilder.createInvalidQuery(random()));
-                } else {
-                    disMaxQuery.add(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                disMaxQuery.add(RandomQueryBuilder.createQuery(random()));
-            }
-        }
-        assertValidate(disMaxQuery, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/ExistsQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/ExistsQueryBuilderTests.java
deleted file mode 100644
index ed5f012..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/ExistsQueryBuilderTests.java
+++ /dev/null
@@ -1,81 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.cluster.metadata.MetaData;
-import org.elasticsearch.index.mapper.object.ObjectMapper;
-
-import java.io.IOException;
-import java.util.Collection;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class ExistsQueryBuilderTests extends AbstractQueryTestCase<ExistsQueryBuilder> {
-
-    @Override
-    protected ExistsQueryBuilder doCreateTestQueryBuilder() {
-        String fieldPattern;
-        if (randomBoolean()) {
-            fieldPattern = randomFrom(MAPPED_FIELD_NAMES);
-        } else {
-            fieldPattern = randomAsciiOfLengthBetween(1, 10);
-        }
-        // also sometimes test wildcard patterns
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                fieldPattern = fieldPattern + "*";
-            } else {
-                fieldPattern = MetaData.ALL;
-            }
-        }
-        return new ExistsQueryBuilder(fieldPattern);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(ExistsQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        String fieldPattern = queryBuilder.fieldName();
-        ObjectMapper objectMapper = context.getObjectMapper(fieldPattern);
-        if (objectMapper != null) {
-            // automatic make the object mapper pattern
-            fieldPattern = fieldPattern + ".*";
-        }
-        Collection<String> fields = context.simpleMatchToIndexNames(fieldPattern);
-        if (getCurrentTypes().length == 0 || fields.size() == 0) {
-            assertThat(query, instanceOf(BooleanQuery.class));
-            BooleanQuery booleanQuery = (BooleanQuery) query;
-            assertThat(booleanQuery.clauses().size(), equalTo(0));
-        } else {
-            assertThat(query, instanceOf(ConstantScoreQuery.class));
-            ConstantScoreQuery constantScoreQuery = (ConstantScoreQuery) query;
-            assertThat(constantScoreQuery.getQuery(), instanceOf(BooleanQuery.class));
-            BooleanQuery booleanQuery = (BooleanQuery) constantScoreQuery.getQuery();
-            assertThat(booleanQuery.clauses().size(), equalTo(fields.size()));
-            for (int i = 0; i < fields.size(); i++) {
-                BooleanClause booleanClause = booleanQuery.clauses().get(i);
-                assertThat(booleanClause.getOccur(), equalTo(BooleanClause.Occur.SHOULD));
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/FieldMaskingSpanQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/FieldMaskingSpanQueryBuilderTests.java
deleted file mode 100644
index 60b139f..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/FieldMaskingSpanQueryBuilderTests.java
+++ /dev/null
@@ -1,83 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.FieldMaskingSpanQuery;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class FieldMaskingSpanQueryBuilderTests extends AbstractQueryTestCase<FieldMaskingSpanQueryBuilder> {
-
-    @Override
-    protected FieldMaskingSpanQueryBuilder doCreateTestQueryBuilder() {
-        String fieldName;
-        if (randomBoolean()) {
-            fieldName = randomFrom(MAPPED_FIELD_NAMES);
-        } else {
-            fieldName = randomAsciiOfLengthBetween(1, 10);
-        }
-        SpanTermQueryBuilder innerQuery = new SpanTermQueryBuilderTests().createTestQueryBuilder();
-        return new FieldMaskingSpanQueryBuilder(innerQuery, fieldName);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(FieldMaskingSpanQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        String fieldInQuery = queryBuilder.fieldName();
-        MappedFieldType fieldType = context.fieldMapper(fieldInQuery);
-        if (fieldType != null) {
-            fieldInQuery = fieldType.names().indexName();
-        }
-        assertThat(query, instanceOf(FieldMaskingSpanQuery.class));
-        FieldMaskingSpanQuery fieldMaskingSpanQuery = (FieldMaskingSpanQuery) query;
-        assertThat(fieldMaskingSpanQuery.getField(), equalTo(fieldInQuery));
-        assertThat(fieldMaskingSpanQuery.getMaskedQuery(), equalTo(queryBuilder.innerQuery().toQuery(context)));
-    }
-
-    @Test
-    public void testValidate() {
-        String fieldName = null;
-        SpanQueryBuilder spanQueryBuilder = null;
-        int totalExpectedErrors = 0;
-        if (randomBoolean()) {
-            fieldName = "fieldName";
-        } else {
-            if (randomBoolean()) {
-                fieldName = "";
-            }
-            totalExpectedErrors++;
-        }
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                spanQueryBuilder = new SpanTermQueryBuilder("", "test");
-            }
-            totalExpectedErrors++;
-        } else {
-            spanQueryBuilder = new SpanTermQueryBuilder("name", "value");
-        }
-        FieldMaskingSpanQueryBuilder queryBuilder = new FieldMaskingSpanQueryBuilder(spanQueryBuilder, fieldName);
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/FuzzyQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/FuzzyQueryBuilderTests.java
deleted file mode 100644
index 3f772fd..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/FuzzyQueryBuilderTests.java
+++ /dev/null
@@ -1,98 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.FuzzyQuery;
-import org.apache.lucene.search.NumericRangeQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.collect.Tuple;
-import org.elasticsearch.common.unit.Fuzziness;
-import org.hamcrest.Matchers;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-
-public class FuzzyQueryBuilderTests extends AbstractQueryTestCase<FuzzyQueryBuilder> {
-
-    @Override
-    protected FuzzyQueryBuilder doCreateTestQueryBuilder() {
-        Tuple<String, Object> fieldAndValue = getRandomFieldNameAndValue();
-        FuzzyQueryBuilder query = new FuzzyQueryBuilder(fieldAndValue.v1(), fieldAndValue.v2());
-        if (randomBoolean()) {
-            query.fuzziness(randomFuzziness(query.fieldName()));
-        }
-        if (randomBoolean()) {
-            query.prefixLength(randomIntBetween(0, 10));
-        }
-        if (randomBoolean()) {
-            query.maxExpansions(randomIntBetween(1, 10));
-        }
-        if (randomBoolean()) {
-            query.transpositions(randomBoolean());
-        }
-        if (randomBoolean()) {
-            query.rewrite(getRandomRewriteMethod());
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(FuzzyQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if (isNumericFieldName(queryBuilder.fieldName()) || queryBuilder.fieldName().equals(DATE_FIELD_NAME)) {
-            assertThat(query, instanceOf(NumericRangeQuery.class));
-        } else {
-            assertThat(query, instanceOf(FuzzyQuery.class));
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        FuzzyQueryBuilder fuzzyQueryBuilder = new FuzzyQueryBuilder("", "text");
-        assertThat(fuzzyQueryBuilder.validate().validationErrors().size(), is(1));
-
-        fuzzyQueryBuilder = new FuzzyQueryBuilder("field", null);
-        assertThat(fuzzyQueryBuilder.validate().validationErrors().size(), is(1));
-
-        fuzzyQueryBuilder = new FuzzyQueryBuilder("field", "text");
-        assertNull(fuzzyQueryBuilder.validate());
-
-        fuzzyQueryBuilder = new FuzzyQueryBuilder(null, null);
-        assertThat(fuzzyQueryBuilder.validate().validationErrors().size(), is(2));
-    }
-    
-    @Test
-    public void testUnsupportedFuzzinessForStringType() throws IOException {
-        QueryShardContext context = createShardContext();
-        context.setAllowUnmappedFields(true);
-        
-        FuzzyQueryBuilder fuzzyQueryBuilder = new FuzzyQueryBuilder(STRING_FIELD_NAME, "text");
-        fuzzyQueryBuilder.fuzziness(Fuzziness.build(randomFrom("a string which is not auto", "3h", "200s")));
-
-        try {
-            fuzzyQueryBuilder.toQuery(context);
-            fail("should have failed with NumberFormatException");
-        } catch (NumberFormatException e) {
-            assertThat(e.getMessage(), Matchers.containsString("For input string"));
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/GeoDistanceRangeQueryTests.java b/core/src/test/java/org/elasticsearch/index/query/GeoDistanceRangeQueryTests.java
deleted file mode 100644
index f3da698..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/GeoDistanceRangeQueryTests.java
+++ /dev/null
@@ -1,246 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.geo.GeoDistance;
-import org.elasticsearch.common.geo.GeoPoint;
-import org.elasticsearch.common.unit.DistanceUnit;
-import org.elasticsearch.index.search.geo.GeoDistanceRangeQuery;
-import org.joda.time.DateTime;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.closeTo;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.notNullValue;
-
-public class GeoDistanceRangeQueryTests extends AbstractQueryTestCase<GeoDistanceRangeQueryBuilder> {
-
-    @Override
-    protected GeoDistanceRangeQueryBuilder doCreateTestQueryBuilder() {
-        GeoDistanceRangeQueryBuilder builder = new GeoDistanceRangeQueryBuilder(GEO_POINT_FIELD_NAME);
-        if (randomBoolean()) {
-            builder.geohash(randomGeohash(1, 12));
-        } else {
-            double lat = randomDouble() * 180 - 90;
-            double lon = randomDouble() * 360 - 180;
-            if (randomBoolean()) {
-                builder.point(lat, lon);
-            } else {
-                builder.point(new GeoPoint(lat, lon));
-            }
-        }
-        int fromValue = randomInt(1000000);
-        int toValue = randomIntBetween(fromValue, 1000000);
-        String fromToUnits = randomFrom(DistanceUnit.values()).toString();
-        if (randomBoolean()) {
-            int branch = randomInt(2);
-            switch (branch) {
-            case 0:
-                builder.from(fromValue);
-                break;
-            case 1:
-                builder.to(toValue);
-                break;
-            case 2:
-                builder.from(fromValue);
-                builder.to(toValue);
-                break;
-            }
-        } else {
-            int branch = randomInt(2);
-            switch (branch) {
-            case 0:
-                builder.from(fromValue + fromToUnits);
-                break;
-            case 1:
-                builder.to(toValue + fromToUnits);
-                break;
-            case 2:
-                builder.from(fromValue + fromToUnits);
-                builder.to(toValue + fromToUnits);
-                break;
-            }
-        }
-        if (randomBoolean()) {
-            builder.includeLower(randomBoolean());
-        }
-        if (randomBoolean()) {
-            builder.includeUpper(randomBoolean());
-        }
-        if (randomBoolean()) {
-            builder.geoDistance(randomFrom(GeoDistance.values()));
-        }
-        if (randomBoolean()) {
-            builder.unit(randomFrom(DistanceUnit.values()));
-        }
-        if (randomBoolean()) {
-            builder.optimizeBbox(randomFrom("none", "memory", "indexed"));
-        }
-        if (randomBoolean()) {
-            builder.coerce(randomBoolean());
-        }
-        if (randomBoolean()) {
-            builder.ignoreMalformed(randomBoolean());
-        }
-        return builder;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(GeoDistanceRangeQueryBuilder queryBuilder, Query query, QueryShardContext context)
-            throws IOException {
-        assertThat(query, instanceOf(GeoDistanceRangeQuery.class));
-        GeoDistanceRangeQuery geoQuery = (GeoDistanceRangeQuery) query;
-        assertThat(geoQuery.fieldName(), equalTo(queryBuilder.fieldName()));
-        if (queryBuilder.point() != null) {
-            assertThat(geoQuery.lat(), equalTo(queryBuilder.point().lat()));
-            assertThat(geoQuery.lon(), equalTo(queryBuilder.point().lon()));
-        }
-        assertThat(geoQuery.geoDistance(), equalTo(queryBuilder.geoDistance()));
-        if (queryBuilder.from() != null && queryBuilder.from() instanceof Number) {
-            double fromValue = ((Number) queryBuilder.from()).doubleValue();
-            if (queryBuilder.unit() != null) {
-                fromValue = queryBuilder.unit().toMeters(fromValue);
-            }
-            if (queryBuilder.geoDistance() != null) {
-                fromValue = queryBuilder.geoDistance().normalize(fromValue, DistanceUnit.DEFAULT);
-            }
-            assertThat(geoQuery.minInclusiveDistance(), closeTo(fromValue, Math.abs(fromValue) / 1000));
-        }
-        if (queryBuilder.to() != null && queryBuilder.to() instanceof Number) {
-            double toValue = ((Number) queryBuilder.to()).doubleValue();
-            if (queryBuilder.unit() != null) {
-                toValue = queryBuilder.unit().toMeters(toValue);
-            }
-            if (queryBuilder.geoDistance() != null) {
-                toValue = queryBuilder.geoDistance().normalize(toValue, DistanceUnit.DEFAULT);
-            }
-            assertThat(geoQuery.maxInclusiveDistance(), closeTo(toValue, Math.abs(toValue) / 1000));
-        }
-    }
-
-    /**
-     * Overridden here to ensure the test is only run if at least one type is
-     * present in the mappings. Geo queries do not execute if the field is not
-     * explicitly mapped
-     */
-    @Override
-    public void testToQuery() throws IOException {
-        assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
-        super.testToQuery();
-    }
-
-    @Test
-    public void testNullFieldName() {
-        GeoDistanceRangeQueryBuilder builder = new GeoDistanceRangeQueryBuilder(null);
-        builder.geohash(randomGeohash(1, 20));
-        builder.from(10);
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(1));
-        assertThat(exception.validationErrors().get(0), equalTo("[" + GeoDistanceRangeQueryBuilder.NAME + "] fieldName must not be null"));
-    }
-
-    @Test
-    public void testNoPoint() {
-        GeoDistanceRangeQueryBuilder builder = new GeoDistanceRangeQueryBuilder(GEO_POINT_FIELD_NAME);
-        builder.from(10);
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(1));
-        assertThat(exception.validationErrors().get(0), equalTo("[" + GeoDistanceRangeQueryBuilder.NAME + "] point must not be null"));
-    }
-
-    @Test
-    public void testNoFromOrTo() {
-        GeoDistanceRangeQueryBuilder builder = new GeoDistanceRangeQueryBuilder(GEO_POINT_FIELD_NAME);
-        String geohash = randomGeohash(1, 20);
-        builder.geohash(geohash);
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(1));
-        assertThat(exception.validationErrors().get(0), equalTo("[" + GeoDistanceRangeQueryBuilder.NAME
-                + "] Must define at least one parameter from [from, to]"));
-    }
-
-    @Test
-    public void testInvalidFrom() {
-        GeoDistanceRangeQueryBuilder builder = new GeoDistanceRangeQueryBuilder(GEO_POINT_FIELD_NAME);
-        String geohash = randomGeohash(1, 20);
-        builder.geohash(geohash);
-        builder.from(new DateTime());
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(1));
-        assertThat(exception.validationErrors().get(0), equalTo("[" + GeoDistanceRangeQueryBuilder.NAME
-                + "] from must either be a number or a string. Found [" + DateTime.class.getName() + "]"));
-    }
-
-    @Test
-    public void testInvalidTo() {
-        GeoDistanceRangeQueryBuilder builder = new GeoDistanceRangeQueryBuilder(GEO_POINT_FIELD_NAME);
-        String geohash = randomGeohash(1, 20);
-        builder.geohash(geohash);
-        builder.to(new DateTime());
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(1));
-        assertThat(exception.validationErrors().get(0), equalTo("[" + GeoDistanceRangeQueryBuilder.NAME
-                + "] to must either be a number or a string. Found [" + DateTime.class.getName() + "]"));
-    }
-
-    @Test
-    public void testInvalidOptimizeBBox() {
-        GeoDistanceRangeQueryBuilder builder = new GeoDistanceRangeQueryBuilder(GEO_POINT_FIELD_NAME);
-        String geohash = randomGeohash(1, 20);
-        builder.geohash(geohash);
-        builder.from(10);
-        builder.optimizeBbox("foo");
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(1));
-        assertThat(exception.validationErrors().get(0), equalTo("[" + GeoDistanceRangeQueryBuilder.NAME
-                + "] optimizeBbox must be one of [none, memory, indexed]"));
-    }
-
-    @Test
-    public void testMultipleValidationErrors() {
-        GeoDistanceRangeQueryBuilder builder = new GeoDistanceRangeQueryBuilder(GEO_POINT_FIELD_NAME);
-        double lat = randomDouble() * 360 - 180;
-        double lon = randomDouble() * 360 - 180;
-        builder.point(lat, lon);
-        builder.from(new DateTime());
-        builder.to(new DateTime());
-        builder.optimizeBbox("foo");
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(3));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/GeoPolygonQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/GeoPolygonQueryBuilderTests.java
deleted file mode 100644
index 297b1ac..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/GeoPolygonQueryBuilderTests.java
+++ /dev/null
@@ -1,189 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import com.spatial4j.core.shape.jts.JtsGeometry;
-import com.vividsolutions.jts.geom.Coordinate;
-
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.geo.GeoPoint;
-import org.elasticsearch.common.geo.GeoUtils;
-import org.elasticsearch.common.geo.builders.ShapeBuilder;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.search.geo.GeoPolygonQuery;
-import org.elasticsearch.test.geo.RandomShapeGenerator;
-import org.elasticsearch.test.geo.RandomShapeGenerator.ShapeType;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.notNullValue;
-
-public class GeoPolygonQueryBuilderTests extends AbstractQueryTestCase<GeoPolygonQueryBuilder> {
-
-    @Override
-    protected GeoPolygonQueryBuilder doCreateTestQueryBuilder() {
-        GeoPolygonQueryBuilder builder;
-        List<GeoPoint> polygon = randomPolygon(randomIntBetween(4, 50));
-        if (randomBoolean()) {
-            builder = new GeoPolygonQueryBuilder(GEO_POINT_FIELD_NAME, polygon);
-        } else {
-            builder = new GeoPolygonQueryBuilder(GEO_POINT_FIELD_NAME);
-            for (GeoPoint point : polygon) {
-                int method = randomInt(2);
-                switch (method) {
-                case 0:
-                    builder.addPoint(point);
-                    break;
-                case 1:
-                    builder.addPoint(point.geohash());
-                    break;
-                case 2:
-                    builder.addPoint(point.lat(), point.lon());
-                    break;
-                }
-            }
-        }
-        builder.coerce(randomBoolean());
-        builder.ignoreMalformed(randomBoolean());
-        return builder;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(GeoPolygonQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(GeoPolygonQuery.class));
-        GeoPolygonQuery geoQuery = (GeoPolygonQuery) query;
-        assertThat(geoQuery.fieldName(), equalTo(queryBuilder.fieldName()));
-        List<GeoPoint> queryBuilderPoints = queryBuilder.points();
-        GeoPoint[] queryPoints = geoQuery.points();
-        assertThat(queryPoints.length, equalTo(queryBuilderPoints.size()));
-        if (queryBuilder.coerce()) {
-            for (int i = 0; i < queryBuilderPoints.size(); i++) {
-                GeoPoint queryBuilderPoint = queryBuilderPoints.get(i);
-                GeoUtils.normalizePoint(queryBuilderPoint, true, true);
-                assertThat(queryPoints[i], equalTo(queryBuilderPoint));
-            }
-        } else {
-            for (int i = 0; i < queryBuilderPoints.size(); i++) {
-                assertThat(queryPoints[i], equalTo(queryBuilderPoints.get(i)));
-            }
-        }
-
-    }
-
-    /**
-     * Overridden here to ensure the test is only run if at least one type is
-     * present in the mappings. Geo queries do not execute if the field is not
-     * explicitly mapped
-     */
-    @Override
-    public void testToQuery() throws IOException {
-        assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
-        super.testToQuery();
-    }
-
-    public List<GeoPoint> randomPolygon(int numPoints) {
-        ShapeBuilder shapeBuilder = null;
-        // This is a temporary fix because sometimes the RandomShapeGenerator
-        // returns null. This is if there is an error generating the polygon. So
-        // in this case keep trying until we successfully generate one
-        while (shapeBuilder == null) {
-            shapeBuilder = RandomShapeGenerator.createShapeWithin(getRandom(), null, ShapeType.POLYGON);
-        }
-        JtsGeometry shape = (JtsGeometry) shapeBuilder.build();
-        Coordinate[] coordinates = shape.getGeom().getCoordinates();
-        ArrayList<GeoPoint> polygonPoints = new ArrayList<>();
-        for (Coordinate coord : coordinates) {
-            polygonPoints.add(new GeoPoint(coord.y, coord.x));
-        }
-        return polygonPoints;
-    }
-
-    @Test(expected = IllegalArgumentException.class)
-    public void testNullFieldName() {
-        new GeoPolygonQueryBuilder(null);
-    }
-
-    @Test
-    public void testEmptyPolygon() {
-        GeoPolygonQueryBuilder builder = new GeoPolygonQueryBuilder(GEO_POINT_FIELD_NAME);
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(1));
-        assertThat(exception.validationErrors().get(0), equalTo("[" + GeoPolygonQueryBuilder.NAME
-                + "] no points defined for geo_polygon query"));
-    }
-
-    @Test
-    public void testInvalidClosedPolygon() {
-        GeoPolygonQueryBuilder builder = new GeoPolygonQueryBuilder(GEO_POINT_FIELD_NAME);
-        builder.addPoint(new GeoPoint(0, 90));
-        builder.addPoint(new GeoPoint(90, 90));
-        builder.addPoint(new GeoPoint(0, 90));
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(1));
-        assertThat(exception.validationErrors().get(0), equalTo("[" + GeoPolygonQueryBuilder.NAME
-                + "] too few points defined for geo_polygon query"));
-    }
-
-    @Test
-    public void testInvalidOpenPolygon() {
-        GeoPolygonQueryBuilder builder = new GeoPolygonQueryBuilder(GEO_POINT_FIELD_NAME);
-        builder.addPoint(new GeoPoint(0, 90));
-        builder.addPoint(new GeoPoint(90, 90));
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(1));
-        assertThat(exception.validationErrors().get(0), equalTo("[" + GeoPolygonQueryBuilder.NAME
-                + "] too few points defined for geo_polygon query"));
-    }
-
-    public void testDeprecatedXContent() throws IOException {
-        XContentBuilder builder = XContentFactory.jsonBuilder().prettyPrint();
-        builder.startObject();
-        builder.startObject("geo_polygon");
-        builder.startObject(GEO_POINT_FIELD_NAME);
-        builder.startArray("points");
-        builder.value("0,0");
-        builder.value("0,90");
-        builder.value("90,90");
-        builder.value("90,0");
-        builder.endArray();
-        builder.endObject();
-        builder.field("normalize", true); // deprecated
-        builder.endObject();
-        builder.endObject();
-        try {
-            parseQuery(builder.string());
-            fail("normalize is deprecated");
-        } catch (IllegalArgumentException ex) {
-            assertEquals("Deprecated field [normalize] used, expected [coerce] instead", ex.getMessage());
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/GeoShapeQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/GeoShapeQueryBuilderTests.java
index 37cb3b0..7a4d1d9 100644
--- a/core/src/test/java/org/elasticsearch/index/query/GeoShapeQueryBuilderTests.java
+++ b/core/src/test/java/org/elasticsearch/index/query/GeoShapeQueryBuilderTests.java
@@ -19,193 +19,13 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.ElasticsearchException;
-import org.elasticsearch.action.get.GetRequest;
-import org.elasticsearch.action.get.GetResponse;
-import org.elasticsearch.common.bytes.BytesArray;
-import org.elasticsearch.common.geo.ShapeRelation;
-import org.elasticsearch.common.geo.SpatialStrategy;
 import org.elasticsearch.common.geo.builders.EnvelopeBuilder;
 import org.elasticsearch.common.geo.builders.ShapeBuilder;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.json.JsonXContent;
-import org.elasticsearch.index.get.GetResult;
-import org.elasticsearch.test.geo.RandomShapeGenerator;
-import org.junit.After;
+import org.elasticsearch.test.ESTestCase;
 import org.junit.Test;
 
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.anyOf;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.notNullValue;
-
-public class GeoShapeQueryBuilderTests extends AbstractQueryTestCase<GeoShapeQueryBuilder> {
-
-    private static String indexedShapeId;
-    private static String indexedShapeType;
-    private static String indexedShapePath;
-    private static String indexedShapeIndex;
-    private static ShapeBuilder indexedShapeToReturn;
-
-    @Override
-    protected GeoShapeQueryBuilder doCreateTestQueryBuilder() {
-        ShapeBuilder shape = RandomShapeGenerator.createShapeWithin(getRandom(), null);
-        GeoShapeQueryBuilder builder;
-        if (randomBoolean()) {
-            try {
-                builder = new GeoShapeQueryBuilder(GEO_SHAPE_FIELD_NAME, shape);
-            } catch (IOException e) {
-                throw new RuntimeException(e);
-            }
-        } else {
-            indexedShapeToReturn = shape;
-            indexedShapeId = randomAsciiOfLengthBetween(3, 20);
-            indexedShapeType = randomAsciiOfLengthBetween(3, 20);
-            builder = new GeoShapeQueryBuilder(GEO_SHAPE_FIELD_NAME, indexedShapeId, indexedShapeType);
-            if (randomBoolean()) {
-                indexedShapeIndex = randomAsciiOfLengthBetween(3, 20);
-                builder.indexedShapeIndex(indexedShapeIndex);
-            }
-            if (randomBoolean()) {
-                indexedShapePath = randomAsciiOfLengthBetween(3, 20);
-                builder.indexedShapePath(indexedShapePath);
-            }
-        }
-        SpatialStrategy strategy = randomFrom(SpatialStrategy.values());
-        builder.strategy(strategy);
-        if (strategy != SpatialStrategy.TERM) {
-            builder.relation(randomFrom(ShapeRelation.values()));
-        }
-        return builder;
-    }
-
-    @Override
-    protected GetResponse executeGet(GetRequest getRequest) {
-        assertThat(indexedShapeToReturn, notNullValue());
-        assertThat(indexedShapeId, notNullValue());
-        assertThat(indexedShapeType, notNullValue());
-        assertThat(getRequest.id(), equalTo(indexedShapeId));
-        assertThat(getRequest.type(), equalTo(indexedShapeType));
-        String expectedShapeIndex = indexedShapeIndex == null ? GeoShapeQueryBuilder.DEFAULT_SHAPE_INDEX_NAME : indexedShapeIndex;
-        assertThat(getRequest.index(), equalTo(expectedShapeIndex));
-        String expectedShapePath = indexedShapePath == null ? GeoShapeQueryBuilder.DEFAULT_SHAPE_FIELD_NAME : indexedShapePath;
-        String json;
-        try {
-            XContentBuilder builder = XContentFactory.jsonBuilder().prettyPrint();
-            builder.startObject();
-            builder.field(expectedShapePath, indexedShapeToReturn);
-            builder.endObject();
-            json = builder.string();
-        } catch (IOException ex) {
-            throw new ElasticsearchException("boom", ex);
-        }
-        GetResponse response = new GetResponse(new GetResult(indexedShapeIndex, indexedShapeType, indexedShapeId, 0, true, new BytesArray(
-                json), null));
-        return response;
-    }
-
-    @After
-    public void clearShapeFields() {
-        indexedShapeToReturn = null;
-        indexedShapeId = null;
-        indexedShapeType = null;
-        indexedShapePath = null;
-        indexedShapeIndex = null;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(GeoShapeQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        // Logic for doToQuery is complex and is hard to test here. Need to rely
-        // on Integration tests to determine if created query is correct
-        // TODO improve GeoShapeQueryBuilder.doToQuery() method to make it
-        // easier to test here
-        assertThat(query, anyOf(instanceOf(BooleanQuery.class), instanceOf(ConstantScoreQuery.class)));
-    }
-
-    /**
-     * Overridden here to ensure the test is only run if at least one type is
-     * present in the mappings. Geo queries do not execute if the field is not
-     * explicitly mapped
-     */
-    @Override
-    public void testToQuery() throws IOException {
-        assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
-        super.testToQuery();
-    }
-
-    @Test(expected = IllegalArgumentException.class)
-    public void testNoFieldName() throws Exception {
-        ShapeBuilder shape = RandomShapeGenerator.createShapeWithin(getRandom(), null);
-        new GeoShapeQueryBuilder(null, shape);
-    }
-
-    @Test
-    public void testNoShape() throws IOException {
-        try {
-            GeoShapeQueryBuilder builder = new GeoShapeQueryBuilder(GEO_SHAPE_FIELD_NAME, (ShapeBuilder) null);
-            QueryValidationException exception = builder.validate();
-            assertThat(exception, notNullValue());
-            assertThat(exception.validationErrors(), notNullValue());
-            assertThat(exception.validationErrors().size(), equalTo(1));
-            assertThat(exception.validationErrors().get(0), equalTo("[" + GeoShapeQueryBuilder.NAME + "] No Shape defined"));
-        } catch (IOException e) {
-            throw new RuntimeException(e);
-        }
-    }
-
-    @Test(expected = IllegalArgumentException.class)
-    public void testNoIndexedShape() throws IOException {
-        new GeoShapeQueryBuilder(GEO_SHAPE_FIELD_NAME, (String) null, "type");
-    }
-
-    @Test(expected = IllegalArgumentException.class)
-    public void testNoIndexedShapeType() throws IOException {
-        new GeoShapeQueryBuilder(GEO_SHAPE_FIELD_NAME, "id", (String) null);
-    }
-
-    @Test
-    public void testNoRelation() {
-        ShapeBuilder shape = RandomShapeGenerator.createShapeWithin(getRandom(), null);
-        try {
-            GeoShapeQueryBuilder builder = new GeoShapeQueryBuilder(GEO_SHAPE_FIELD_NAME, shape);
-            builder.relation(null);
-            QueryValidationException exception = builder.validate();
-            assertThat(exception, notNullValue());
-            assertThat(exception.validationErrors(), notNullValue());
-            assertThat(exception.validationErrors().size(), equalTo(1));
-            assertThat(exception.validationErrors().get(0), equalTo("[" + GeoShapeQueryBuilder.NAME + "] No Shape Relation defined"));
-        } catch (IOException e) {
-            throw new RuntimeException(e);
-        }
-    }
-
-    @Test
-    public void testInvalidRelation() {
-        ShapeBuilder shape = RandomShapeGenerator.createShapeWithin(getRandom(), null);
-        try {
-            GeoShapeQueryBuilder builder = new GeoShapeQueryBuilder(GEO_SHAPE_FIELD_NAME, shape);
-            builder.strategy(SpatialStrategy.TERM);
-            ShapeRelation relation = randomFrom(ShapeRelation.DISJOINT, ShapeRelation.WITHIN);
-            builder.relation(relation);
-            QueryValidationException exception = builder.validate();
-            assertThat(exception, notNullValue());
-            assertThat(exception.validationErrors(), notNullValue());
-            assertThat(exception.validationErrors().size(), equalTo(1));
-            assertThat(
-                    exception.validationErrors().get(0),
-                    equalTo("[" + GeoShapeQueryBuilder.NAME + "] strategy [" + SpatialStrategy.TERM.getStrategyName()
-                            + "] only supports relation [" + ShapeRelation.INTERSECTS.getRelationName() + "] found relation ["
-                            + relation.getRelationName() + "]"));
-        } catch (IOException e) {
-            throw new RuntimeException(e);
-        }
-    }
+public class GeoShapeQueryBuilderTests extends ESTestCase {
 
     @Test // see #3878
     public void testThatXContentSerializationInsideOfArrayWorks() throws Exception {
diff --git a/core/src/test/java/org/elasticsearch/index/query/GeohashCellQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/GeohashCellQueryBuilderTests.java
deleted file mode 100644
index 020f82bd..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/GeohashCellQueryBuilderTests.java
+++ /dev/null
@@ -1,119 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.index.Term;
-import org.apache.lucene.queries.TermsQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.elasticsearch.common.unit.DistanceUnit;
-import org.elasticsearch.index.mapper.geo.GeoPointFieldMapper;
-import org.elasticsearch.index.query.GeohashCellQuery.Builder;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.notNullValue;
-
-public class GeohashCellQueryBuilderTests extends AbstractQueryTestCase<Builder> {
-
-    @Override
-    protected Builder doCreateTestQueryBuilder() {
-        GeohashCellQuery.Builder builder = new Builder(GEO_POINT_FIELD_NAME);
-        builder.geohash(randomGeohash(1, 12));
-        if (randomBoolean()) {
-            builder.neighbors(randomBoolean());
-        }
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                builder.precision(randomIntBetween(1, 12));
-            } else {
-                builder.precision(randomIntBetween(1, 1000000) + randomFrom(DistanceUnit.values()).toString());
-            }
-        }
-        return builder;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(Builder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if (queryBuilder.neighbors()) {
-            assertThat(query, instanceOf(TermsQuery.class));
-        } else {
-            assertThat(query, instanceOf(TermQuery.class));
-            TermQuery termQuery = (TermQuery) query;
-            Term term = termQuery.getTerm();
-            assertThat(term.field(), equalTo(queryBuilder.fieldName() + GeoPointFieldMapper.Names.GEOHASH_SUFFIX));
-            String geohash = queryBuilder.geohash();
-            if (queryBuilder.precision() != null) {
-                int len = Math.min(queryBuilder.precision(), geohash.length());
-                geohash = geohash.substring(0, len);
-            }
-            assertThat(term.text(), equalTo(geohash));
-        }
-    }
-
-    /**
-     * Overridden here to ensure the test is only run if at least one type is
-     * present in the mappings. Geo queries do not execute if the field is not
-     * explicitly mapped
-     */
-    @Override
-    public void testToQuery() throws IOException {
-        assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
-        super.testToQuery();
-    }
-
-    @Test
-    public void testNullField() {
-        GeohashCellQuery.Builder builder = new Builder(null);
-        builder.geohash(randomGeohash(1, 12));
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(1));
-        assertThat(exception.validationErrors().get(0), equalTo("[" + GeohashCellQuery.NAME + "] fieldName must not be null"));
-    }
-
-    @Test
-    public void testNullGeohash() {
-        GeohashCellQuery.Builder builder = new Builder(GEO_POINT_FIELD_NAME);
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(1));
-        assertThat(exception.validationErrors().get(0), equalTo("[" + GeohashCellQuery.NAME + "] geohash or point must be defined"));
-    }
-
-    @Test
-    public void testInvalidPrecision() {
-        GeohashCellQuery.Builder builder = new Builder(GEO_POINT_FIELD_NAME);
-        builder.geohash(randomGeohash(1, 12));
-        builder.precision(-1);
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(1));
-        assertThat(exception.validationErrors().get(0), equalTo("[" + GeohashCellQuery.NAME + "] precision must be greater than 0. Found ["
-                + -1 + "]"));
-    }
-
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/HasChildQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/HasChildQueryBuilderTests.java
deleted file mode 100644
index b6ff913..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/HasChildQueryBuilderTests.java
+++ /dev/null
@@ -1,201 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import com.carrotsearch.randomizedtesting.generators.RandomPicks;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.action.admin.indices.mapping.put.PutMappingRequest;
-import org.elasticsearch.common.compress.CompressedXContent;
-import org.elasticsearch.common.xcontent.ToXContent;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.fielddata.IndexFieldDataService;
-import org.elasticsearch.index.mapper.MapperService;
-import org.elasticsearch.index.query.support.QueryInnerHits;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsBuilder;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
-import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.search.sort.SortOrder;
-import org.elasticsearch.test.TestSearchContext;
-
-import java.io.IOException;
-
-import static org.elasticsearch.test.StreamsUtils.copyToStringFromClasspath;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class HasChildQueryBuilderTests extends AbstractQueryTestCase<HasChildQueryBuilder> {
-    protected static final String PARENT_TYPE = "parent";
-    protected static final String CHILD_TYPE = "child";
-
-    public void setUp() throws Exception {
-        super.setUp();
-        MapperService mapperService = queryParserService().mapperService;
-        mapperService.merge(PARENT_TYPE, new CompressedXContent(PutMappingRequest.buildFromSimplifiedDef(PARENT_TYPE,
-                STRING_FIELD_NAME, "type=string",
-                INT_FIELD_NAME, "type=integer",
-                DOUBLE_FIELD_NAME, "type=double",
-                BOOLEAN_FIELD_NAME, "type=boolean",
-                DATE_FIELD_NAME, "type=date",
-                OBJECT_FIELD_NAME, "type=object"
-        ).string()), false, false);
-        mapperService.merge(CHILD_TYPE, new CompressedXContent(PutMappingRequest.buildFromSimplifiedDef(CHILD_TYPE,
-                "_parent", "type=" + PARENT_TYPE,
-                STRING_FIELD_NAME, "type=string",
-                INT_FIELD_NAME, "type=integer",
-                DOUBLE_FIELD_NAME, "type=double",
-                BOOLEAN_FIELD_NAME, "type=boolean",
-                DATE_FIELD_NAME, "type=date",
-                OBJECT_FIELD_NAME, "type=object"
-        ).string()), false, false);
-    }
-
-    protected void setSearchContext(String[] types) {
-        final MapperService mapperService = queryParserService().mapperService;
-        final IndexFieldDataService fieldData = queryParserService().fieldDataService;
-        TestSearchContext testSearchContext = new TestSearchContext() {
-            private InnerHitsContext context;
-
-
-            @Override
-            public void innerHits(InnerHitsContext innerHitsContext) {
-                context = innerHitsContext;
-            }
-
-            @Override
-            public InnerHitsContext innerHits() {
-                return context;
-            }
-
-            @Override
-            public MapperService mapperService() {
-                return mapperService; // need to build / parse inner hits sort fields
-            }
-
-            @Override
-            public IndexFieldDataService fieldData() {
-                return fieldData; // need to build / parse inner hits sort fields
-            }
-        };
-        testSearchContext.setTypes(types);
-        SearchContext.setCurrent(testSearchContext);
-    }
-
-    /**
-     * @return a {@link HasChildQueryBuilder} with random values all over the place
-     */
-    @Override
-    protected HasChildQueryBuilder doCreateTestQueryBuilder() {
-        int min = randomIntBetween(0, Integer.MAX_VALUE / 2);
-        int max = randomIntBetween(min, Integer.MAX_VALUE);
-        InnerHitsBuilder.InnerHit innerHit = new InnerHitsBuilder.InnerHit().setSize(100).addSort(STRING_FIELD_NAME, SortOrder.ASC);
-        return new HasChildQueryBuilder(CHILD_TYPE,
-                RandomQueryBuilder.createQuery(random()), max, min,
-                RandomPicks.randomFrom(random(), ScoreType.values()),
-                randomBoolean()  ? null : new QueryInnerHits("inner_hits_name", innerHit));
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(HasChildQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        QueryBuilder innerQueryBuilder = queryBuilder.query();
-        if (innerQueryBuilder instanceof EmptyQueryBuilder) {
-            assertNull(query);
-        } else {
-            assertThat(query, instanceOf(HasChildQueryBuilder.LateParsingQuery.class));
-            HasChildQueryBuilder.LateParsingQuery lpq = (HasChildQueryBuilder.LateParsingQuery) query;
-            assertEquals(queryBuilder.minChildren(), lpq.getMinChildren());
-            assertEquals(queryBuilder.maxChildren(), lpq.getMaxChildren());
-            assertEquals(HasChildQueryBuilder.scoreTypeToScoreMode(queryBuilder.scoreType()), lpq.getScoreMode()); // WTF is this why do we have two?
-        }
-        if (queryBuilder.innerHit() != null) {
-            assertNotNull(SearchContext.current());
-            if (query != null) {
-                assertNotNull(SearchContext.current().innerHits());
-                assertEquals(1, SearchContext.current().innerHits().getInnerHits().size());
-                assertTrue(SearchContext.current().innerHits().getInnerHits().containsKey("inner_hits_name"));
-                InnerHitsContext.BaseInnerHits innerHits = SearchContext.current().innerHits().getInnerHits().get("inner_hits_name");
-                assertEquals(innerHits.size(), 100);
-                assertEquals(innerHits.sort().getSort().length, 1);
-                assertEquals(innerHits.sort().getSort()[0].getField(), STRING_FIELD_NAME);
-            } else {
-                assertNull(SearchContext.current().innerHits());
-            }
-        }
-    }
-
-    public void testIllegalValues() {
-        QueryBuilder query = RandomQueryBuilder.createQuery(random());
-        try {
-            new HasChildQueryBuilder(null, query);
-            fail("must not be null");
-        } catch (IllegalArgumentException ex) {
-
-        }
-
-        try {
-            new HasChildQueryBuilder("foo", null);
-            fail("must not be null");
-        } catch (IllegalArgumentException ex) {
-
-        }
-        HasChildQueryBuilder foo = new HasChildQueryBuilder("foo", query);// all good
-        try {
-            foo.scoreType(null);
-            fail("must not be null");
-        } catch (IllegalArgumentException ex) {
-
-        }
-        final int positiveValue = randomIntBetween(0, Integer.MAX_VALUE);
-        try {
-            foo.minChildren(randomIntBetween(Integer.MIN_VALUE, -1));
-            fail("must not be negative");
-        } catch (IllegalArgumentException ex) {
-
-        }
-        foo.minChildren(positiveValue);
-        assertEquals(positiveValue, foo.minChildren());
-        try {
-            foo.maxChildren(randomIntBetween(Integer.MIN_VALUE, -1));
-            fail("must not be negative");
-        } catch (IllegalArgumentException ex) {
-
-        }
-
-        foo.maxChildren(positiveValue);
-        assertEquals(positiveValue, foo.maxChildren());
-    }
-
-    public void testParseFromJSON() throws IOException {
-        String query = copyToStringFromClasspath("/org/elasticsearch/index/query/has-child-with-inner-hits.json").trim();
-        HasChildQueryBuilder queryBuilder = (HasChildQueryBuilder) parseQuery(query);
-        assertEquals(query, queryBuilder.maxChildren(), 1217235442);
-        assertEquals(query, queryBuilder.minChildren(), 883170873);
-        assertEquals(query, queryBuilder.boost(), 2.0f, 0.0f);
-        assertEquals(query, queryBuilder.queryName(), "WNzYMJKRwePuRBh");
-        assertEquals(query, queryBuilder.childType(), "child");
-        assertEquals(query, queryBuilder.scoreType(), ScoreType.AVG);
-        assertNotNull(query, queryBuilder.innerHit());
-        assertEquals(query, queryBuilder.innerHit(), new QueryInnerHits("inner_hits_name", new InnerHitsBuilder.InnerHit().setSize(100).addSort("mapped_string", SortOrder.ASC)));
-        // now assert that we actually generate the same JSON
-        XContentBuilder builder = XContentFactory.jsonBuilder().prettyPrint();
-        queryBuilder.toXContent(builder, ToXContent.EMPTY_PARAMS);
-        assertEquals(query, builder.string());
-    }
-
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/HasChildQueryParserTests.java b/core/src/test/java/org/elasticsearch/index/query/HasChildQueryParserTests.java
new file mode 100644
index 0000000..bdf7efb
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/index/query/HasChildQueryParserTests.java
@@ -0,0 +1,70 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.elasticsearch.index.query;
+
+import org.apache.lucene.search.join.ScoreMode;
+import org.elasticsearch.test.ESTestCase;
+import org.junit.Test;
+
+import static org.hamcrest.MatcherAssert.assertThat;
+import static org.hamcrest.Matchers.equalTo;
+
+public class HasChildQueryParserTests extends ESTestCase {
+
+    @Test
+    public void minFromString() {
+        assertThat("fromString(min) != MIN", ScoreMode.Min, equalTo(HasChildQueryParser.parseScoreMode("min")));
+    }
+
+    @Test
+    public void maxFromString() {
+        assertThat("fromString(max) != MAX", ScoreMode.Max, equalTo(HasChildQueryParser.parseScoreMode("max")));
+    }
+
+    @Test
+    public void avgFromString() {
+        assertThat("fromString(avg) != AVG", ScoreMode.Avg, equalTo(HasChildQueryParser.parseScoreMode("avg")));
+    }
+
+    @Test
+    public void sumFromString() {
+        assertThat("fromString(total) != SUM", ScoreMode.Total, equalTo(HasChildQueryParser.parseScoreMode("total")));
+    }
+
+    @Test
+    public void noneFromString() {
+        assertThat("fromString(none) != NONE", ScoreMode.None, equalTo(HasChildQueryParser.parseScoreMode("none")));
+    }
+
+    /**
+     * Should throw {@link IllegalArgumentException} instead of NPE.
+     */
+    @Test(expected = IllegalArgumentException.class)
+    public void nullFromString_throwsException() {
+        HasChildQueryParser.parseScoreMode(null);
+    }
+
+    /**
+     * Failure should not change (and the value should never match anything...).
+     */
+    @Test(expected = IllegalArgumentException.class)
+    public void unrecognizedFromString_throwsException() {
+        HasChildQueryParser.parseScoreMode("unrecognized value");
+    }
+}
diff --git a/core/src/test/java/org/elasticsearch/index/query/HasParentQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/HasParentQueryBuilderTests.java
deleted file mode 100644
index 1236c78..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/HasParentQueryBuilderTests.java
+++ /dev/null
@@ -1,194 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import com.carrotsearch.randomizedtesting.generators.RandomPicks;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.join.ScoreMode;
-import org.elasticsearch.action.admin.indices.mapping.put.PutMappingRequest;
-import org.elasticsearch.common.ParseFieldMatcher;
-import org.elasticsearch.common.compress.CompressedXContent;
-import org.elasticsearch.common.xcontent.*;
-import org.elasticsearch.index.fielddata.IndexFieldDataService;
-import org.elasticsearch.index.mapper.MapperService;
-import org.elasticsearch.index.query.support.QueryInnerHits;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsBuilder;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
-import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.search.sort.SortOrder;
-import org.elasticsearch.test.TestSearchContext;
-
-import java.io.IOException;
-import java.util.Arrays;
-
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class HasParentQueryBuilderTests extends AbstractQueryTestCase<HasParentQueryBuilder> {
-    protected static final String PARENT_TYPE = "parent";
-    protected static final String CHILD_TYPE = "child";
-
-    public void setUp() throws Exception {
-        super.setUp();
-        MapperService mapperService = queryParserService().mapperService;
-        mapperService.merge(PARENT_TYPE, new CompressedXContent(PutMappingRequest.buildFromSimplifiedDef(PARENT_TYPE,
-                STRING_FIELD_NAME, "type=string",
-                INT_FIELD_NAME, "type=integer",
-                DOUBLE_FIELD_NAME, "type=double",
-                BOOLEAN_FIELD_NAME, "type=boolean",
-                DATE_FIELD_NAME, "type=date",
-                OBJECT_FIELD_NAME, "type=object"
-        ).string()), false, false);
-        mapperService.merge(CHILD_TYPE, new CompressedXContent(PutMappingRequest.buildFromSimplifiedDef(CHILD_TYPE,
-                "_parent", "type=" + PARENT_TYPE,
-                STRING_FIELD_NAME, "type=string",
-                INT_FIELD_NAME, "type=integer",
-                DOUBLE_FIELD_NAME, "type=double",
-                BOOLEAN_FIELD_NAME, "type=boolean",
-                DATE_FIELD_NAME, "type=date",
-                OBJECT_FIELD_NAME, "type=object"
-        ).string()), false, false);
-    }
-
-    protected void setSearchContext(String[] types) {
-        final MapperService mapperService = queryParserService().mapperService;
-        final IndexFieldDataService fieldData = queryParserService().fieldDataService;
-        TestSearchContext testSearchContext = new TestSearchContext() {
-            private InnerHitsContext context;
-
-
-            @Override
-            public void innerHits(InnerHitsContext innerHitsContext) {
-                context = innerHitsContext;
-            }
-
-            @Override
-            public InnerHitsContext innerHits() {
-                return context;
-            }
-
-            @Override
-            public MapperService mapperService() {
-                return mapperService; // need to build / parse inner hits sort fields
-            }
-
-            @Override
-            public IndexFieldDataService fieldData() {
-                return fieldData; // need to build / parse inner hits sort fields
-            }
-        };
-        testSearchContext.setTypes(types);
-        SearchContext.setCurrent(testSearchContext);
-    }
-
-    /**
-     * @return a {@link HasChildQueryBuilder} with random values all over the place
-     */
-    @Override
-    protected HasParentQueryBuilder doCreateTestQueryBuilder() {
-        InnerHitsBuilder.InnerHit innerHit = new InnerHitsBuilder.InnerHit().setSize(100).addSort(STRING_FIELD_NAME, SortOrder.ASC);
-        return new HasParentQueryBuilder(PARENT_TYPE,
-                RandomQueryBuilder.createQuery(random()),randomBoolean(),
-                randomBoolean() ? null : new QueryInnerHits("inner_hits_name", innerHit));
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(HasParentQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        QueryBuilder innerQueryBuilder = queryBuilder.query();
-        if (innerQueryBuilder instanceof EmptyQueryBuilder) {
-            assertNull(query);
-        } else {
-            assertThat(query, instanceOf(HasChildQueryBuilder.LateParsingQuery.class));
-            HasChildQueryBuilder.LateParsingQuery lpq = (HasChildQueryBuilder.LateParsingQuery) query;
-            assertEquals(queryBuilder.score() ? ScoreMode.Max : ScoreMode.None, lpq.getScoreMode());
-        }
-        if (queryBuilder.innerHit() != null) {
-            assertNotNull(SearchContext.current());
-            if (query != null) {
-                assertNotNull(SearchContext.current().innerHits());
-                assertEquals(1, SearchContext.current().innerHits().getInnerHits().size());
-                assertTrue(SearchContext.current().innerHits().getInnerHits().containsKey("inner_hits_name"));
-                InnerHitsContext.BaseInnerHits innerHits = SearchContext.current().innerHits().getInnerHits().get("inner_hits_name");
-                assertEquals(innerHits.size(), 100);
-                assertEquals(innerHits.sort().getSort().length, 1);
-                assertEquals(innerHits.sort().getSort()[0].getField(), STRING_FIELD_NAME);
-            } else {
-                assertNull(SearchContext.current().innerHits());
-            }
-        }
-    }
-
-    public void testIllegalValues() {
-        QueryBuilder query = RandomQueryBuilder.createQuery(random());
-        try {
-            new HasParentQueryBuilder(null, query);
-            fail("must not be null");
-        } catch (IllegalArgumentException ex) {
-
-        }
-
-        try {
-            new HasParentQueryBuilder("foo", null);
-            fail("must not be null");
-        } catch (IllegalArgumentException ex) {
-
-        }
-    }
-
-    public void testDeprecatedXContent() throws IOException {
-        XContentBuilder builder = XContentFactory.jsonBuilder().prettyPrint();
-        builder.startObject();
-        builder.startObject("has_parent");
-        builder.field("query");
-        EmptyQueryBuilder.PROTOTYPE.toXContent(builder, ToXContent.EMPTY_PARAMS);
-        builder.field("type", "foo"); // deprecated
-        builder.endObject();
-        builder.endObject();
-        try {
-            parseQuery(builder.string());
-            fail("type is deprecated");
-        } catch (IllegalArgumentException ex) {
-            assertEquals("Deprecated field [type] used, expected [parent_type] instead", ex.getMessage());
-        }
-
-        HasParentQueryBuilder queryBuilder = (HasParentQueryBuilder) parseQuery(builder.string(), ParseFieldMatcher.EMPTY);
-        assertEquals("foo", queryBuilder.type());
-
-        boolean score = randomBoolean();
-        String key = RandomPicks.randomFrom(random(), Arrays.asList("score_mode", "scoreMode", "score_type", "scoreType"));
-        builder = XContentFactory.jsonBuilder().prettyPrint();
-        builder.startObject();
-        builder.startObject("has_parent");
-        builder.field("query");
-        EmptyQueryBuilder.PROTOTYPE.toXContent(builder, ToXContent.EMPTY_PARAMS);
-        builder.field(key, score ? "score": "none");
-        builder.field("parent_type", "foo");
-        builder.endObject();
-        builder.endObject();
-        try {
-            parseQuery(builder.string());
-            fail(key + " is deprecated");
-        } catch (IllegalArgumentException ex) {
-            assertEquals("Deprecated field [" + key + "] used, replaced by [score]", ex.getMessage());
-        }
-
-        queryBuilder = (HasParentQueryBuilder) parseQuery(builder.string(), ParseFieldMatcher.EMPTY);
-        assertEquals(score, queryBuilder.score());
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/IdsQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/IdsQueryBuilderTests.java
deleted file mode 100644
index 41fba87..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/IdsQueryBuilderTests.java
+++ /dev/null
@@ -1,124 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-
-import org.apache.lucene.queries.TermsQuery;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.cluster.metadata.MetaData;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class IdsQueryBuilderTests extends AbstractQueryTestCase<IdsQueryBuilder> {
-
-    /**
-     * check that parser throws exception on missing values field
-     * @throws IOException
-     */
-    @Test(expected=QueryParsingException.class)
-    public void testIdsNotProvided() throws IOException {
-        String noIdsFieldQuery = "{\"ids\" : { \"type\" : \"my_type\"  }";
-        parseQuery(noIdsFieldQuery);
-    }
-
-    @Override
-    protected IdsQueryBuilder doCreateTestQueryBuilder() {
-        String[] types;
-        if (getCurrentTypes().length > 0 && randomBoolean()) {
-            int numberOfTypes = randomIntBetween(1, getCurrentTypes().length);
-            types = new String[numberOfTypes];
-            for (int i = 0; i < numberOfTypes; i++) {
-                if (frequently()) {
-                    types[i] = randomFrom(getCurrentTypes());
-                } else {
-                    types[i] = randomAsciiOfLengthBetween(1, 10);
-                }
-            }
-        } else {
-            if (randomBoolean()) {
-                types = new String[]{MetaData.ALL};
-            } else {
-                types = new String[0];
-            }
-        }
-        int numberOfIds = randomIntBetween(0, 10);
-        String[] ids = new String[numberOfIds];
-        for (int i = 0; i < numberOfIds; i++) {
-            ids[i] = randomAsciiOfLengthBetween(1, 10);
-        }
-        IdsQueryBuilder query;
-        if (types.length > 0 || randomBoolean()) {
-            query = new IdsQueryBuilder(types);
-            query.addIds(ids);
-        } else {
-            query = new IdsQueryBuilder();
-            query.addIds(ids);
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(IdsQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if (queryBuilder.ids().size() == 0) {
-            assertThat(query, instanceOf(BooleanQuery.class));
-            assertThat(((BooleanQuery)query).clauses().size(), equalTo(0));
-        } else {
-            assertThat(query, instanceOf(TermsQuery.class));
-        }
-    }
-
-    @Override
-    protected Map<String, IdsQueryBuilder> getAlternateVersions() {
-        Map<String, IdsQueryBuilder> alternateVersions = new HashMap<>();
-
-        IdsQueryBuilder tempQuery = createTestQueryBuilder();
-        if (tempQuery.types() != null && tempQuery.types().length > 0) {
-            String type = tempQuery.types()[0];
-            IdsQueryBuilder testQuery = new IdsQueryBuilder(type);
-
-            //single value type can also be called _type
-            String contentString1 = "{\n" +
-                        "    \"ids\" : {\n" +
-                        "        \"_type\" : \"" + type + "\",\n" +
-                        "        \"values\" : []\n" +
-                        "    }\n" +
-                        "}";
-            alternateVersions.put(contentString1, testQuery);
-
-            //array of types can also be called type rather than types
-            String contentString2 = "{\n" +
-                        "    \"ids\" : {\n" +
-                        "        \"type\" : [\"" + type + "\"],\n" +
-                        "        \"values\" : []\n" +
-                        "    }\n" +
-                        "}";
-            alternateVersions.put(contentString2, testQuery);
-        }
-
-        return alternateVersions;
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/IndexQueryParserFilterDateRangeTimezoneTests.java b/core/src/test/java/org/elasticsearch/index/query/IndexQueryParserFilterDateRangeTimezoneTests.java
index 6222f3b..d581aa6 100644
--- a/core/src/test/java/org/elasticsearch/index/query/IndexQueryParserFilterDateRangeTimezoneTests.java
+++ b/core/src/test/java/org/elasticsearch/index/query/IndexQueryParserFilterDateRangeTimezoneTests.java
@@ -83,7 +83,7 @@ public class IndexQueryParserFilterDateRangeTimezoneTests extends ESSingleNodeTe
             SearchContext.setCurrent(new TestSearchContext());
             queryParser.parse(query).query();
             fail("A Range Filter on a numeric field with a TimeZone should raise a QueryParsingException");
-        } catch (QueryShardException e) {
+        } catch (QueryParsingException e) {
             // We expect it
         } finally {
             SearchContext.removeCurrent();
@@ -120,7 +120,7 @@ public class IndexQueryParserFilterDateRangeTimezoneTests extends ESSingleNodeTe
             SearchContext.setCurrent(new TestSearchContext());
             queryParser.parse(query).query();
             fail("A Range Query on a numeric field with a TimeZone should raise a QueryParsingException");
-        } catch (QueryShardException e) {
+        } catch (QueryParsingException e) {
             // We expect it
         } finally {
             SearchContext.removeCurrent();
diff --git a/core/src/test/java/org/elasticsearch/index/query/IndicesQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/IndicesQueryBuilderTests.java
deleted file mode 100644
index 9990b51..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/IndicesQueryBuilderTests.java
+++ /dev/null
@@ -1,103 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-public class IndicesQueryBuilderTests extends AbstractQueryTestCase<IndicesQueryBuilder> {
-
-    @Override
-    protected IndicesQueryBuilder doCreateTestQueryBuilder() {
-        String[] indices;
-        if (randomBoolean()) {
-            indices = new String[]{getIndex().getName()};
-        } else {
-            indices = generateRandomStringArray(5, 10, false, false);
-        }
-        IndicesQueryBuilder query = new IndicesQueryBuilder(RandomQueryBuilder.createQuery(random()), indices);
-
-        switch (randomInt(2)) {
-            case 0:
-                query.noMatchQuery(RandomQueryBuilder.createQuery(random()));
-                break;
-            case 1:
-                query.noMatchQuery(randomFrom(QueryBuilders.matchAllQuery(), new MatchNoneQueryBuilder()));
-                break;
-            default:
-                // do not set noMatchQuery
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(IndicesQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        Query expected;
-        if (queryBuilder.indices().length == 1 && getIndex().getName().equals(queryBuilder.indices()[0])) {
-            expected = queryBuilder.innerQuery().toQuery(context);
-        } else {
-            expected = queryBuilder.noMatchQuery().toQuery(context);
-        }
-        if (expected != null && queryBuilder.boost() != AbstractQueryBuilder.DEFAULT_BOOST) {
-            expected.setBoost(queryBuilder.boost());
-        }
-        assertEquals(query, expected);
-    }
-
-    @Override
-    protected void assertBoost(IndicesQueryBuilder queryBuilder, Query query) throws IOException {
-        //nothing to do here, boost check is already included in equality check done as part of doAssertLuceneQuery above
-    }
-
-    @Test
-    public void testValidate() {
-        int expectedErrors = 0;
-
-        // inner query
-        QueryBuilder innerQuery;
-        if (randomBoolean()) {
-            // setting innerQuery to null would be caught in the builder already and make validation fail
-            innerQuery = RandomQueryBuilder.createInvalidQuery(random());
-            expectedErrors++;
-        } else {
-            innerQuery = RandomQueryBuilder.createQuery(random());
-        }
-        // indices
-        String[] indices;
-        if (randomBoolean()) {
-            indices = randomBoolean() ? null : new String[0];
-            expectedErrors++;
-        } else {
-            indices = new String[]{"index"};
-        }
-        // no match query
-        QueryBuilder noMatchQuery;
-        if (randomBoolean()) {
-            noMatchQuery = RandomQueryBuilder.createInvalidQuery(random());
-            expectedErrors++;
-        } else {
-            noMatchQuery = RandomQueryBuilder.createQuery(random());
-        }
-
-        assertValidate(new IndicesQueryBuilder(innerQuery, indices).noMatchQuery(noMatchQuery), expectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/MatchAllQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/MatchAllQueryBuilderTests.java
deleted file mode 100644
index 1603855..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/MatchAllQueryBuilderTests.java
+++ /dev/null
@@ -1,40 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.Query;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class MatchAllQueryBuilderTests extends AbstractQueryTestCase<MatchAllQueryBuilder> {
-
-    @Override
-    protected MatchAllQueryBuilder doCreateTestQueryBuilder() {
-        return new MatchAllQueryBuilder();
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(MatchAllQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(MatchAllDocsQuery.class));
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/MatchNoneQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/MatchNoneQueryBuilderTests.java
deleted file mode 100644
index cb80f31..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/MatchNoneQueryBuilderTests.java
+++ /dev/null
@@ -1,48 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class MatchNoneQueryBuilderTests extends AbstractQueryTestCase {
-
-    @Override
-    protected boolean supportsBoostAndQueryName() {
-        return false;
-    }
-
-    @Override
-    protected AbstractQueryBuilder doCreateTestQueryBuilder() {
-        return new MatchNoneQueryBuilder();
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(AbstractQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(BooleanQuery.class));
-        BooleanQuery booleanQuery = (BooleanQuery) query;
-        assertThat(booleanQuery.clauses().size(), equalTo(0));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java
deleted file mode 100644
index 975b027..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/MatchQueryBuilderTests.java
+++ /dev/null
@@ -1,178 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.index.Term;
-import org.apache.lucene.queries.ExtendedCommonTermsQuery;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.FuzzyQuery;
-import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.PhraseQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.elasticsearch.common.lucene.BytesRefs;
-import org.elasticsearch.common.lucene.search.MultiPhrasePrefixQuery;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.search.MatchQuery;
-import org.elasticsearch.index.search.MatchQuery.ZeroTermsQuery;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.Locale;
-
-import static org.hamcrest.CoreMatchers.either;
-import static org.hamcrest.CoreMatchers.instanceOf;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.notNullValue;
-
-public class MatchQueryBuilderTests extends AbstractQueryTestCase<MatchQueryBuilder> {
-
-    @Override
-    protected MatchQueryBuilder doCreateTestQueryBuilder() {
-        String fieldName = randomFrom(new String[] { STRING_FIELD_NAME, BOOLEAN_FIELD_NAME, INT_FIELD_NAME, DOUBLE_FIELD_NAME });
-        Object value = "";
-        if (fieldName.equals(STRING_FIELD_NAME)) {
-            int terms = randomIntBetween(0, 3);
-            StringBuilder builder = new StringBuilder();
-            for (int i = 0; i < terms; i++) {
-                builder.append(randomAsciiOfLengthBetween(1, 10) + " ");
-            }
-            value = builder.toString().trim();
-        } else {
-            value = getRandomValueForFieldName(fieldName);
-        }
-
-        MatchQueryBuilder matchQuery = new MatchQueryBuilder(fieldName, value);
-        matchQuery.type(randomFrom(MatchQuery.Type.values()));
-        matchQuery.operator(randomFrom(Operator.values()));
-
-        if (randomBoolean()) {
-            matchQuery.analyzer(randomFrom("simple", "keyword", "whitespace"));
-        }
-
-        if (randomBoolean()) {
-            matchQuery.slop(randomIntBetween(0, 10));
-        }
-
-        if (randomBoolean()) {
-            matchQuery.fuzziness(randomFuzziness(fieldName));
-        }
-
-        if (randomBoolean()) {
-            matchQuery.prefixLength(randomIntBetween(0, 10));
-        }
-
-        if (randomBoolean()) {
-            matchQuery.minimumShouldMatch(randomMinimumShouldMatch());
-        }
-
-        if (randomBoolean()) {
-            matchQuery.fuzzyRewrite(getRandomRewriteMethod());
-        }
-
-        if (randomBoolean()) {
-            matchQuery.fuzzyTranspositions(randomBoolean());
-        }
-
-        if (randomBoolean()) {
-            matchQuery.lenient(randomBoolean());
-        }
-
-        if (randomBoolean()) {
-            matchQuery.zeroTermsQuery(randomFrom(MatchQuery.ZeroTermsQuery.values()));
-        }
-
-        if (randomBoolean()) {
-            matchQuery.cutoffFrequency((float) 10 / randomIntBetween(1, 100));
-        }
-        return matchQuery;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(MatchQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, notNullValue());
-
-        if (query instanceof MatchAllDocsQuery) {
-            assertThat(queryBuilder.zeroTermsQuery(), equalTo(ZeroTermsQuery.ALL));
-            return;
-        }
-
-        switch (queryBuilder.type()) {
-        case BOOLEAN:
-            assertThat(query, either(instanceOf(BooleanQuery.class)).or(instanceOf(ExtendedCommonTermsQuery.class))
-                    .or(instanceOf(TermQuery.class)).or(instanceOf(FuzzyQuery.class)));
-            break;
-        case PHRASE:
-            assertThat(query, either(instanceOf(BooleanQuery.class)).or(instanceOf(PhraseQuery.class))
-                    .or(instanceOf(TermQuery.class)).or(instanceOf(FuzzyQuery.class)));
-            break;
-        case PHRASE_PREFIX:
-            assertThat(query, either(instanceOf(BooleanQuery.class)).or(instanceOf(MultiPhrasePrefixQuery.class))
-                    .or(instanceOf(TermQuery.class)).or(instanceOf(FuzzyQuery.class)));
-            break;
-        }
-
-        MappedFieldType fieldType = context.fieldMapper(queryBuilder.fieldName());
-        if (query instanceof TermQuery && fieldType != null) {
-            String queryValue = queryBuilder.value().toString();
-            if (queryBuilder.analyzer() == null || queryBuilder.analyzer().equals("simple")) {
-                queryValue = queryValue.toLowerCase(Locale.ROOT);
-            }
-            Query expectedTermQuery = fieldType.termQuery(queryValue, context);
-            // the real query will have boost applied, so we set it to our expeced as well
-            expectedTermQuery.setBoost(queryBuilder.boost());
-            assertEquals(expectedTermQuery, query);
-        }
-
-        if (query instanceof BooleanQuery) {
-            BooleanQuery bq = (BooleanQuery) query;
-            if (queryBuilder.analyzer() == null && queryBuilder.value().toString().length() > 0) {
-                assertEquals(bq.clauses().size(), queryBuilder.value().toString().split(" ").length);
-            }
-        }
-
-        if (query instanceof ExtendedCommonTermsQuery) {
-            assertTrue(queryBuilder.cutoffFrequency() != null);
-            ExtendedCommonTermsQuery ectq = (ExtendedCommonTermsQuery) query;
-            assertEquals((float) queryBuilder.cutoffFrequency(), ectq.getMaxTermFrequency(), Float.MIN_VALUE);
-        }
-
-        if (query instanceof FuzzyQuery) {
-            assertTrue(queryBuilder.fuzziness() != null);
-            FuzzyQuery fuzzyQuery = (FuzzyQuery) query;
-            fuzzyQuery.getTerm().equals(new Term(STRING_FIELD_NAME, BytesRefs.toBytesRef(queryBuilder.value())));
-            assertThat(queryBuilder.prefixLength(), equalTo(fuzzyQuery.getPrefixLength()));
-            assertThat(queryBuilder.fuzzyTranspositions(), equalTo(fuzzyQuery.getTranspositions()));
-        }
-    }
-
-    @Test(expected = IllegalArgumentException.class)
-    public void testNegativePrefixLengthException() {
-        MatchQueryBuilder matchQuery = new MatchQueryBuilder("fieldName", "text");
-        matchQuery.prefixLength(-1); // not allowed, should trigger expection
-    }
-
-    @Test(expected = QueryShardException.class)
-    public void testBadAnalyzer() throws IOException {
-        MatchQueryBuilder matchQuery = new MatchQueryBuilder("fieldName", "text");
-        matchQuery.analyzer("bogusAnalyzer");
-        matchQuery.doToQuery(createShardContext());
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/MissingQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/MissingQueryBuilderTests.java
deleted file mode 100644
index 7a7fba3..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/MissingQueryBuilderTests.java
+++ /dev/null
@@ -1,73 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.is;
-
-public class MissingQueryBuilderTests extends AbstractQueryTestCase<MissingQueryBuilder> {
-
-    @Override
-    protected MissingQueryBuilder doCreateTestQueryBuilder() {
-        MissingQueryBuilder query  = new MissingQueryBuilder(randomBoolean() ? randomFrom(MAPPED_FIELD_NAMES) : randomAsciiOfLengthBetween(1, 10));
-        if (randomBoolean()) {
-            query.nullValue(randomBoolean());
-        }
-        if (randomBoolean()) {
-            query.existence(randomBoolean());
-        }
-        // cannot set both to false
-        if ((query.nullValue() == false) && (query.existence() == false)) {
-            query.existence(!query.existence());
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(MissingQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        //too many mapping dependent cases to test, we don't want to end up duplication the toQuery method
-    }
-
-    @Test
-    public void testValidate() {
-        MissingQueryBuilder missingQueryBuilder = new MissingQueryBuilder("");
-        assertThat(missingQueryBuilder.validate().validationErrors().size(), is(1));
-
-        missingQueryBuilder = new MissingQueryBuilder(null);
-        assertThat(missingQueryBuilder.validate().validationErrors().size(), is(1));
-
-        missingQueryBuilder = new MissingQueryBuilder("field").existence(false).nullValue(false);
-        assertThat(missingQueryBuilder.validate().validationErrors().size(), is(1));
-
-        missingQueryBuilder = new MissingQueryBuilder("field");
-        assertNull(missingQueryBuilder.validate());
-    }
-
-    @Test(expected = QueryShardException.class)
-    public void testBothNullValueAndExistenceFalse() throws IOException {
-        QueryShardContext context = createShardContext();
-        context.setAllowUnmappedFields(true);
-        MissingQueryBuilder.newFilter(context, "field", false, false);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/NestedQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/NestedQueryBuilderTests.java
deleted file mode 100644
index 538370e..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/NestedQueryBuilderTests.java
+++ /dev/null
@@ -1,159 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import com.carrotsearch.randomizedtesting.generators.RandomPicks;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.join.ScoreMode;
-import org.apache.lucene.search.join.ToParentBlockJoinQuery;
-import org.elasticsearch.action.admin.indices.mapping.put.PutMappingRequest;
-import org.elasticsearch.common.ParseFieldMatcher;
-import org.elasticsearch.common.compress.CompressedXContent;
-import org.elasticsearch.common.xcontent.*;
-import org.elasticsearch.index.fielddata.IndexFieldDataService;
-import org.elasticsearch.index.mapper.MapperService;
-import org.elasticsearch.index.query.support.QueryInnerHits;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsBuilder;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
-import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.search.sort.SortOrder;
-import org.elasticsearch.test.TestSearchContext;
-
-import java.io.IOException;
-import java.util.Arrays;
-
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class NestedQueryBuilderTests extends AbstractQueryTestCase<NestedQueryBuilder> {
-
-    public void setUp() throws Exception {
-        super.setUp();
-        MapperService mapperService = queryParserService().mapperService;
-        mapperService.merge("nested_doc", new CompressedXContent(PutMappingRequest.buildFromSimplifiedDef("nested_doc",
-                STRING_FIELD_NAME, "type=string",
-                INT_FIELD_NAME, "type=integer",
-                DOUBLE_FIELD_NAME, "type=double",
-                BOOLEAN_FIELD_NAME, "type=boolean",
-                DATE_FIELD_NAME, "type=date",
-                OBJECT_FIELD_NAME, "type=object",
-                "nested1", "type=nested"
-        ).string()), false, false);
-    }
-
-    protected void setSearchContext(String[] types) {
-        final MapperService mapperService = queryParserService().mapperService;
-        final IndexFieldDataService fieldData = queryParserService().fieldDataService;
-        TestSearchContext testSearchContext = new TestSearchContext() {
-            private InnerHitsContext context;
-
-
-            @Override
-            public void innerHits(InnerHitsContext innerHitsContext) {
-                context = innerHitsContext;
-            }
-
-            @Override
-            public InnerHitsContext innerHits() {
-                return context;
-            }
-
-            @Override
-            public MapperService mapperService() {
-                return mapperService; // need to build / parse inner hits sort fields
-            }
-
-            @Override
-            public IndexFieldDataService fieldData() {
-                return fieldData; // need to build / parse inner hits sort fields
-            }
-        };
-        testSearchContext.setTypes(types);
-        SearchContext.setCurrent(testSearchContext);
-    }
-
-    /**
-     * @return a {@link HasChildQueryBuilder} with random values all over the place
-     */
-    @Override
-    protected NestedQueryBuilder doCreateTestQueryBuilder() {
-        InnerHitsBuilder.InnerHit innerHit = new InnerHitsBuilder.InnerHit().setSize(100).addSort(STRING_FIELD_NAME, SortOrder.ASC);
-        return new NestedQueryBuilder("nested1", RandomQueryBuilder.createQuery(random()),
-                RandomPicks.randomFrom(random(), ScoreMode.values()),
-                SearchContext.current() == null ? null : new QueryInnerHits("inner_hits_name", innerHit));
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(NestedQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        QueryBuilder innerQueryBuilder = queryBuilder.query();
-        if (innerQueryBuilder instanceof EmptyQueryBuilder) {
-            assertNull(query);
-        } else {
-            assertThat(query, instanceOf(ToParentBlockJoinQuery.class));
-            ToParentBlockJoinQuery parentBlockJoinQuery = (ToParentBlockJoinQuery) query;
-            //TODO how to assert this?
-        }
-        if (queryBuilder.innerHit() != null) {
-            assertNotNull(SearchContext.current());
-            if (query != null) {
-                assertNotNull(SearchContext.current().innerHits());
-                assertEquals(1, SearchContext.current().innerHits().getInnerHits().size());
-                assertTrue(SearchContext.current().innerHits().getInnerHits().containsKey("inner_hits_name"));
-                InnerHitsContext.BaseInnerHits innerHits = SearchContext.current().innerHits().getInnerHits().get("inner_hits_name");
-                assertEquals(innerHits.size(), 100);
-                assertEquals(innerHits.sort().getSort().length, 1);
-                assertEquals(innerHits.sort().getSort()[0].getField(), STRING_FIELD_NAME);
-            } else {
-                assertNull(SearchContext.current().innerHits());
-            }
-        }
-    }
-
-    public void testParseDeprecatedFilter() throws IOException {
-        XContentBuilder builder = XContentFactory.jsonBuilder().prettyPrint();
-        builder.startObject();
-            builder.startObject("nested");
-                builder.startObject("filter");
-                    builder.startObject("terms").array(STRING_FIELD_NAME, "a", "b").endObject();// deprecated
-                builder.endObject();
-                builder.field("path", "foo.bar");
-            builder.endObject();
-        builder.endObject();
-
-        QueryShardContext shardContext = createShardContext();
-        QueryParseContext context = shardContext.parseContext();
-        XContentParser parser = XContentFactory.xContent(XContentType.JSON).createParser(builder.string());
-        context.reset(parser);
-        context.parseFieldMatcher(ParseFieldMatcher.STRICT);
-        try {
-            context.parseInnerQueryBuilder();
-            fail("filter is deprecated");
-        } catch (IllegalArgumentException ex) {
-            assertEquals("Deprecated field [filter] used, replaced by [query]", ex.getMessage());
-        }
-
-        parser = XContentFactory.xContent(XContentType.JSON).createParser(builder.string());
-        context.reset(parser);
-        NestedQueryBuilder queryBuilder = (NestedQueryBuilder) context.parseInnerQueryBuilder();
-        QueryBuilder query = queryBuilder.query();
-        assertTrue(query instanceof TermsQueryBuilder);
-        TermsQueryBuilder tqb = (TermsQueryBuilder) query;
-        assertEquals(tqb.values(), Arrays.asList("a", "b"));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/NotQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/NotQueryBuilderTests.java
deleted file mode 100644
index ec0e105..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/NotQueryBuilderTests.java
+++ /dev/null
@@ -1,118 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.ParseFieldMatcher;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
-
-import static org.hamcrest.CoreMatchers.*;
-
-public class NotQueryBuilderTests extends AbstractQueryTestCase<NotQueryBuilder> {
-
-    /**
-     * @return a NotQueryBuilder with random limit between 0 and 20
-     */
-    @Override
-    protected NotQueryBuilder doCreateTestQueryBuilder() {
-        return new NotQueryBuilder(RandomQueryBuilder.createQuery(random()));
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(NotQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        Query filter = queryBuilder.innerQuery().toQuery(context);
-        if (filter == null) {
-            assertThat(query, nullValue());
-        } else {
-            assertThat(query, instanceOf(BooleanQuery.class));
-            BooleanQuery booleanQuery = (BooleanQuery) query;
-            assertThat(booleanQuery.clauses().size(), equalTo(2));
-            assertThat(booleanQuery.clauses().get(0).getOccur(), equalTo(BooleanClause.Occur.MUST));
-            assertThat(booleanQuery.clauses().get(0).getQuery(), instanceOf(MatchAllDocsQuery.class));
-            assertThat(booleanQuery.clauses().get(1).getOccur(), equalTo(BooleanClause.Occur.MUST_NOT));
-            assertThat(booleanQuery.clauses().get(1).getQuery(), equalTo(filter));
-        }
-    }
-
-    /**
-     * @throws IOException
-     */
-    @Test(expected=QueryParsingException.class)
-    public void testMissingFilterSection() throws IOException {
-        String queryString = "{ \"not\" : {}";
-        parseQuery(queryString);
-    }
-
-    @Override
-    protected Map<String, NotQueryBuilder> getAlternateVersions() {
-        Map<String, NotQueryBuilder> alternateVersions = new HashMap<>();
-        QueryBuilder innerQuery = createTestQueryBuilder().innerQuery();
-        //not doesn't support empty query when query/filter element is not specified
-        if (innerQuery != EmptyQueryBuilder.PROTOTYPE) {
-            NotQueryBuilder testQuery2 = new NotQueryBuilder(innerQuery);
-            String contentString2 = "{\n" +
-                    "    \"not\" : " + testQuery2.innerQuery().toString() +  "\n}";
-            alternateVersions.put(contentString2, testQuery2);
-        }
-
-        return alternateVersions;
-    }
-
-
-    public void testDeprecatedXContent() throws IOException {
-        String deprecatedJson = "{\n" +
-                "    \"not\" : {\n" +
-                "        \"filter\" : " + EmptyQueryBuilder.PROTOTYPE.toString() + "\n" +
-                "    }\n" +
-                "}";
-        try {
-            parseQuery(deprecatedJson);
-            fail("filter is deprecated");
-        } catch (IllegalArgumentException ex) {
-            assertEquals("Deprecated field [filter] used, expected [query] instead", ex.getMessage());
-        }
-
-        NotQueryBuilder queryBuilder = (NotQueryBuilder) parseQuery(deprecatedJson, ParseFieldMatcher.EMPTY);
-        assertEquals(EmptyQueryBuilder.PROTOTYPE, queryBuilder.innerQuery());
-    }
-
-    @Test
-    public void testValidate() {
-        QueryBuilder innerQuery = null;
-        int totalExpectedErrors = 0;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                innerQuery = RandomQueryBuilder.createInvalidQuery(random());
-            }
-            totalExpectedErrors++;
-        } else {
-            innerQuery = RandomQueryBuilder.createQuery(random());
-        }
-        NotQueryBuilder notQuery = new NotQueryBuilder(innerQuery);
-        assertValidate(notQuery, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/PrefixQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/PrefixQueryBuilderTests.java
deleted file mode 100644
index 3117462..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/PrefixQueryBuilderTests.java
+++ /dev/null
@@ -1,67 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.PrefixQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-
-public class PrefixQueryBuilderTests extends AbstractQueryTestCase<PrefixQueryBuilder> {
-
-    @Override
-    protected PrefixQueryBuilder doCreateTestQueryBuilder() {
-        String fieldName = randomBoolean() ? STRING_FIELD_NAME : randomAsciiOfLengthBetween(1, 10);
-        String value = randomAsciiOfLengthBetween(1, 10);
-        PrefixQueryBuilder query = new PrefixQueryBuilder(fieldName, value);
-
-        if (randomBoolean()) {
-            query.rewrite(getRandomRewriteMethod());
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(PrefixQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(PrefixQuery.class));
-        PrefixQuery prefixQuery = (PrefixQuery) query;
-        assertThat(prefixQuery.getPrefix().field(), equalTo(queryBuilder.fieldName()));
-    }
-
-    @Test
-    public void testValidate() {
-        PrefixQueryBuilder prefixQueryBuilder = new PrefixQueryBuilder("", "prefix");
-        assertThat(prefixQueryBuilder.validate().validationErrors().size(), is(1));
-
-        prefixQueryBuilder = new PrefixQueryBuilder("field", null);
-        assertThat(prefixQueryBuilder.validate().validationErrors().size(), is(1));
-
-        prefixQueryBuilder = new PrefixQueryBuilder("field", "prefix");
-        assertNull(prefixQueryBuilder.validate());
-
-        prefixQueryBuilder = new PrefixQueryBuilder(null, null);
-        assertThat(prefixQueryBuilder.validate().validationErrors().size(), is(2));
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/QueryFilterBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/QueryFilterBuilderTests.java
deleted file mode 100644
index c26fd9b..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/QueryFilterBuilderTests.java
+++ /dev/null
@@ -1,84 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.*;
-
-@SuppressWarnings("deprecation")
-public class QueryFilterBuilderTests extends AbstractQueryTestCase<QueryFilterBuilder> {
-
-    @Override
-    protected QueryFilterBuilder doCreateTestQueryBuilder() {
-        QueryBuilder innerQuery = RandomQueryBuilder.createQuery(random());
-        return new QueryFilterBuilder(innerQuery);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(QueryFilterBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        Query innerQuery = queryBuilder.innerQuery().toQuery(context);
-        if (innerQuery == null) {
-            assertThat(query, nullValue());
-        } else {
-            assertThat(query, instanceOf(ConstantScoreQuery.class));
-            ConstantScoreQuery constantScoreQuery = (ConstantScoreQuery) query;
-            assertThat(constantScoreQuery.getQuery(), equalTo(innerQuery));
-        }
-    }
-
-    @Override
-    protected boolean supportsBoostAndQueryName() {
-        return false;
-    }
-
-    /**
-     * test wrapping an inner filter that returns null also returns <tt>null</null> to pass on upwards
-     */
-    @Test
-    public void testInnerQueryReturnsNull() throws IOException {
-        // create inner filter
-        String queryString = "{ \"constant_score\" : { \"filter\" : {} } }";
-        QueryBuilder<?> innerQuery = parseQuery(queryString);
-        // check that when wrapping this filter, toQuery() returns null
-        QueryFilterBuilder queryFilterQuery = new QueryFilterBuilder(innerQuery);
-        assertNull(queryFilterQuery.toQuery(createShardContext()));
-    }
-
-    @Test
-    public void testValidate() {
-        QueryBuilder innerQuery = null;
-        int totalExpectedErrors = 0;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                innerQuery = RandomQueryBuilder.createInvalidQuery(random());
-            }
-            totalExpectedErrors++;
-        } else {
-            innerQuery = RandomQueryBuilder.createQuery(random());
-        }
-        QueryFilterBuilder fQueryFilter = new QueryFilterBuilder(innerQuery);
-        assertValidate(fQueryFilter, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/QueryStringQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/QueryStringQueryBuilderTests.java
deleted file mode 100644
index 287acd0..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/QueryStringQueryBuilderTests.java
+++ /dev/null
@@ -1,291 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.*;
-import org.apache.lucene.util.automaton.TooComplexToDeterminizeException;
-import org.elasticsearch.common.lucene.all.AllTermQuery;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.List;
-
-import static org.elasticsearch.index.query.QueryBuilders.queryStringQuery;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertBooleanSubQuery;
-import static org.hamcrest.CoreMatchers.either;
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-import static org.hamcrest.Matchers.*;
-
-public class QueryStringQueryBuilderTests extends AbstractQueryTestCase<QueryStringQueryBuilder> {
-
-    @Override
-    protected QueryStringQueryBuilder doCreateTestQueryBuilder() {
-        int numTerms = randomIntBetween(0, 5);
-        String query = "";
-        for (int i = 0; i < numTerms; i++) {
-            //min length 4 makes sure that the text is not an operator (AND/OR) so toQuery won't break
-            query += (randomBoolean() ? STRING_FIELD_NAME + ":" : "") + randomAsciiOfLengthBetween(4, 10) + " ";
-        }
-        QueryStringQueryBuilder queryStringQueryBuilder = new QueryStringQueryBuilder(query);
-        if (randomBoolean()) {
-            queryStringQueryBuilder.defaultField(randomBoolean() ? STRING_FIELD_NAME : randomAsciiOfLengthBetween(1, 10));
-        }
-        if (randomBoolean()) {
-            int numFields = randomIntBetween(1, 5);
-            for (int i = 0; i < numFields; i++) {
-                String fieldName = randomBoolean() ? STRING_FIELD_NAME : randomAsciiOfLengthBetween(1, 10);
-                if (randomBoolean()) {
-                    queryStringQueryBuilder.field(fieldName);
-                } else {
-                    queryStringQueryBuilder.field(fieldName, randomFloat());
-                }
-            }
-        }
-        if (randomBoolean()) {
-            queryStringQueryBuilder.defaultOperator(randomFrom(Operator.values()));
-        }
-        if (randomBoolean()) {
-            //we only use string fields (either mapped or unmapped)
-            queryStringQueryBuilder.fuzziness(randomFuzziness(STRING_FIELD_NAME));
-        }
-        if (randomBoolean()) {
-            queryStringQueryBuilder.analyzer(randomAnalyzer());
-        }
-        if (randomBoolean()) {
-            queryStringQueryBuilder.quoteAnalyzer(randomAnalyzer());
-        }
-        if (randomBoolean()) {
-            queryStringQueryBuilder.allowLeadingWildcard(randomBoolean());
-        }
-        if (randomBoolean()) {
-            queryStringQueryBuilder.analyzeWildcard(randomBoolean());
-        }
-        if (randomBoolean()) {
-            queryStringQueryBuilder.maxDeterminizedStates(randomIntBetween(1, 100));
-        }
-        if (randomBoolean()) {
-            queryStringQueryBuilder.lowercaseExpandedTerms(randomBoolean());
-        }
-        if (randomBoolean()) {
-            queryStringQueryBuilder.autoGeneratePhraseQueries(randomBoolean());
-        }
-        if (randomBoolean()) {
-            queryStringQueryBuilder.enablePositionIncrements(randomBoolean());
-        }
-        if (randomBoolean()) {
-            queryStringQueryBuilder.lenient(randomBoolean());
-        }
-        if (randomBoolean()) {
-            queryStringQueryBuilder.escape(randomBoolean());
-        }
-        if (randomBoolean()) {
-            queryStringQueryBuilder.phraseSlop(randomIntBetween(0, 10));
-        }
-        if (randomBoolean()) {
-            queryStringQueryBuilder.fuzzyMaxExpansions(randomIntBetween(0, 100));
-        }
-        if (randomBoolean()) {
-            queryStringQueryBuilder.fuzzyPrefixLength(randomIntBetween(0, 10));
-        }
-        if (randomBoolean()) {
-            queryStringQueryBuilder.fuzzyRewrite(getRandomRewriteMethod());
-        }
-        if (randomBoolean()) {
-            queryStringQueryBuilder.rewrite(getRandomRewriteMethod());
-        }
-        if (randomBoolean()) {
-            queryStringQueryBuilder.quoteFieldSuffix(randomAsciiOfLengthBetween(1, 3));
-        }
-        if (randomBoolean()) {
-            queryStringQueryBuilder.tieBreaker(randomFloat());
-        }
-        if (randomBoolean()) {
-            queryStringQueryBuilder.minimumShouldMatch(randomMinimumShouldMatch());
-        }
-        if (randomBoolean()) {
-            queryStringQueryBuilder.useDisMax(randomBoolean());
-        }
-        if (randomBoolean()) {
-            queryStringQueryBuilder.locale(randomLocale(getRandom()));
-        }
-        if (randomBoolean()) {
-            queryStringQueryBuilder.timeZone(randomTimeZone());
-        }
-        return queryStringQueryBuilder;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(QueryStringQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if ("".equals(queryBuilder.queryString())) {
-            assertThat(query, instanceOf(MatchNoDocsQuery.class));
-        } else {
-            assertThat(query, either(instanceOf(TermQuery.class)).or(instanceOf(AllTermQuery.class))
-                    .or(instanceOf(BooleanQuery.class)).or(instanceOf(DisjunctionMaxQuery.class)));
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        QueryValidationException queryValidationException = createTestQueryBuilder().validate();
-        assertNull(queryValidationException);
-
-        queryValidationException = new QueryStringQueryBuilder(null).validate();
-        assertNotNull(queryValidationException);
-        assertThat(queryValidationException.validationErrors().size(), equalTo(1));
-    }
-
-    @Test
-    public void testToQueryMatchAllQuery() throws Exception {
-        Query query = queryStringQuery("*:*").toQuery(createShardContext());
-        assertThat(query, instanceOf(MatchAllDocsQuery.class));
-    }
-
-    @Test
-    public void testToQueryTermQuery() throws IOException {
-        assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
-        Query query = queryStringQuery("test").defaultField(STRING_FIELD_NAME).toQuery(createShardContext());
-        assertThat(query, instanceOf(TermQuery.class));
-        TermQuery termQuery = (TermQuery) query;
-        assertThat(termQuery.getTerm(), equalTo(new Term(STRING_FIELD_NAME, "test")));
-    }
-
-    @Test
-    public void testToQueryPhraseQuery() throws IOException {
-        assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
-        Query query = queryStringQuery("\"term1 term2\"").defaultField(STRING_FIELD_NAME).phraseSlop(3).toQuery(createShardContext());
-        assertThat(query, instanceOf(DisjunctionMaxQuery.class));
-        DisjunctionMaxQuery disjunctionMaxQuery = (DisjunctionMaxQuery) query;
-        assertThat(disjunctionMaxQuery.getDisjuncts().size(), equalTo(1));
-        assertThat(disjunctionMaxQuery.getDisjuncts().get(0), instanceOf(PhraseQuery.class));
-        PhraseQuery phraseQuery = (PhraseQuery)disjunctionMaxQuery.getDisjuncts().get(0);
-        assertThat(phraseQuery.getTerms().length, equalTo(2));
-        assertThat(phraseQuery.getTerms()[0], equalTo(new Term(STRING_FIELD_NAME, "term1")));
-        assertThat(phraseQuery.getTerms()[1], equalTo(new Term(STRING_FIELD_NAME, "term2")));
-        assertThat(phraseQuery.getSlop(), equalTo(3));
-    }
-
-    @Test
-    public void testToQueryBoosts() throws Exception {
-        assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
-        QueryShardContext shardContext = createShardContext();
-        QueryStringQueryBuilder queryStringQuery = queryStringQuery(STRING_FIELD_NAME + ":boosted^2");
-        Query query = queryStringQuery.toQuery(shardContext);
-        assertThat(query, instanceOf(TermQuery.class));
-        assertThat(((TermQuery) query).getTerm(), equalTo(new Term(STRING_FIELD_NAME, "boosted")));
-        assertThat(query.getBoost(), equalTo(2.0f));
-        queryStringQuery.boost(2.0f);
-        query = queryStringQuery.toQuery(shardContext);
-        assertThat(query.getBoost(), equalTo(4.0f));
-
-        queryStringQuery = queryStringQuery("((" + STRING_FIELD_NAME + ":boosted^2) AND (" + STRING_FIELD_NAME + ":foo^1.5))^3");
-        query = queryStringQuery.toQuery(shardContext);
-        assertThat(query, instanceOf(BooleanQuery.class));
-        assertThat(assertBooleanSubQuery(query, TermQuery.class, 0).getTerm(), equalTo(new Term(STRING_FIELD_NAME, "boosted")));
-        assertThat(assertBooleanSubQuery(query, TermQuery.class, 0).getBoost(), equalTo(2.0f));
-        assertThat(assertBooleanSubQuery(query, TermQuery.class, 1).getTerm(), equalTo(new Term(STRING_FIELD_NAME, "foo")));
-        assertThat(assertBooleanSubQuery(query, TermQuery.class, 1).getBoost(), equalTo(1.5f));
-        assertThat(query.getBoost(), equalTo(3.0f));
-        queryStringQuery.boost(2.0f);
-        query = queryStringQuery.toQuery(shardContext);
-        assertThat(query.getBoost(), equalTo(6.0f));
-    }
-
-    @Test
-    public void testToQueryMultipleTermsBooleanQuery() throws Exception {
-        assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
-        Query query = queryStringQuery("test1 test2").field(STRING_FIELD_NAME).useDisMax(false).toQuery(createShardContext());
-        assertThat(query, instanceOf(BooleanQuery.class));
-        BooleanQuery bQuery = (BooleanQuery) query;
-        assertThat(bQuery.clauses().size(), equalTo(2));
-        assertThat(assertBooleanSubQuery(query, TermQuery.class, 0).getTerm(), equalTo(new Term(STRING_FIELD_NAME, "test1")));
-        assertThat(assertBooleanSubQuery(query, TermQuery.class, 1).getTerm(), equalTo(new Term(STRING_FIELD_NAME, "test2")));
-    }
-
-    @Test
-    public void testToQueryMultipleFieldsBooleanQuery() throws Exception {
-        assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
-        Query query = queryStringQuery("test").field(STRING_FIELD_NAME).field(STRING_FIELD_NAME_2).useDisMax(false).toQuery(createShardContext());
-        assertThat(query, instanceOf(BooleanQuery.class));
-        BooleanQuery bQuery = (BooleanQuery) query;
-        assertThat(bQuery.clauses().size(), equalTo(2));
-        assertThat(assertBooleanSubQuery(query, TermQuery.class, 0).getTerm(), equalTo(new Term(STRING_FIELD_NAME, "test")));
-        assertThat(assertBooleanSubQuery(query, TermQuery.class, 1).getTerm(), equalTo(new Term(STRING_FIELD_NAME_2, "test")));
-    }
-
-    @Test
-    public void testToQueryMultipleFieldsDisMaxQuery() throws Exception {
-        assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
-        Query query = queryStringQuery("test").field(STRING_FIELD_NAME).field(STRING_FIELD_NAME_2).useDisMax(true).toQuery(createShardContext());
-        assertThat(query, instanceOf(DisjunctionMaxQuery.class));
-        DisjunctionMaxQuery disMaxQuery = (DisjunctionMaxQuery) query;
-        List<Query> disjuncts = disMaxQuery.getDisjuncts();
-        assertThat(((TermQuery) disjuncts.get(0)).getTerm(), equalTo(new Term(STRING_FIELD_NAME, "test")));
-        assertThat(((TermQuery) disjuncts.get(1)).getTerm(), equalTo(new Term(STRING_FIELD_NAME_2, "test")));
-    }
-
-    @Test
-    public void testToQueryFieldsWildcard() throws Exception {
-        assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
-        Query query = queryStringQuery("test").field("mapped_str*").useDisMax(false).toQuery(createShardContext());
-        assertThat(query, instanceOf(BooleanQuery.class));
-        BooleanQuery bQuery = (BooleanQuery) query;
-        assertThat(bQuery.clauses().size(), equalTo(2));
-        assertThat(assertBooleanSubQuery(query, TermQuery.class, 0).getTerm(), equalTo(new Term(STRING_FIELD_NAME, "test")));
-        assertThat(assertBooleanSubQuery(query, TermQuery.class, 1).getTerm(), equalTo(new Term(STRING_FIELD_NAME_2, "test")));
-    }
-
-    @Test
-    public void testToQueryDisMaxQuery() throws Exception {
-        assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
-        Query query = queryStringQuery("test").field(STRING_FIELD_NAME, 2.2f).field(STRING_FIELD_NAME_2).useDisMax(true).toQuery(createShardContext());
-        assertThat(query, instanceOf(DisjunctionMaxQuery.class));
-        DisjunctionMaxQuery disMaxQuery = (DisjunctionMaxQuery) query;
-        List<Query> disjuncts = disMaxQuery.getDisjuncts();
-        assertThat(((TermQuery) disjuncts.get(0)).getTerm(), equalTo(new Term(STRING_FIELD_NAME, "test")));
-        assertThat((double) disjuncts.get(0).getBoost(), closeTo(2.2, 0.01));
-        assertThat(((TermQuery) disjuncts.get(1)).getTerm(), equalTo(new Term(STRING_FIELD_NAME_2, "test")));
-        assertThat((double) disjuncts.get(1).getBoost(), closeTo(1, 0.01));
-    }
-
-    @Test
-    public void testToQueryRegExpQuery() throws Exception {
-        assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
-        Query query = queryStringQuery("/foo*bar/").defaultField(STRING_FIELD_NAME).maxDeterminizedStates(5000).toQuery(createShardContext());
-        assertThat(query, instanceOf(RegexpQuery.class));
-        RegexpQuery regexpQuery = (RegexpQuery) query;
-        assertTrue(regexpQuery.toString().contains("/foo*bar/"));
-    }
-
-    @Test(expected = TooComplexToDeterminizeException.class)
-    public void testToQueryRegExpQueryTooComplex() throws Exception {
-        assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
-        queryStringQuery("/[ac]*a[ac]{50,200}/").defaultField(STRING_FIELD_NAME).toQuery(createShardContext());
-    }
-
-    @Test
-    public void testToQueryNumericRangeQuery() throws Exception {
-        assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
-        Query query = queryStringQuery("12~0.2").defaultField(INT_FIELD_NAME).toQuery(createShardContext());
-        assertThat(query, instanceOf(NumericRangeQuery.class));
-
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/RandomQueryBuilder.java b/core/src/test/java/org/elasticsearch/index/query/RandomQueryBuilder.java
deleted file mode 100644
index a25a7a3..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/RandomQueryBuilder.java
+++ /dev/null
@@ -1,91 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import com.carrotsearch.randomizedtesting.generators.RandomInts;
-import com.carrotsearch.randomizedtesting.generators.RandomStrings;
-
-import java.util.Random;
-
-/**
- * Utility class for creating random QueryBuilders.
- * So far only leaf queries like {@link MatchAllQueryBuilder}, {@link TermQueryBuilder} or
- * {@link IdsQueryBuilder} are returned.
- */
-public class RandomQueryBuilder {
-
-    /**
-     * Create a new query of a random type
-     * @param r random seed
-     * @return a random {@link QueryBuilder}
-     */
-    public static QueryBuilder createQuery(Random r) {
-        switch (RandomInts.randomIntBetween(r, 0, 4)) {
-            case 0:
-                return new MatchAllQueryBuilderTests().createTestQueryBuilder();
-            case 1:
-                return new TermQueryBuilderTests().createTestQueryBuilder();
-            case 2:
-                return new IdsQueryBuilderTests().createTestQueryBuilder();
-            case 3:
-                return createMultiTermQuery(r);
-            case 4:
-                return EmptyQueryBuilder.PROTOTYPE;
-            default:
-                throw new UnsupportedOperationException();
-        }
-    }
-
-    /**
-     * Create a new multi term query of a random type
-     * @param r random seed
-     * @return a random {@link MultiTermQueryBuilder}
-     */
-    public static MultiTermQueryBuilder createMultiTermQuery(Random r) {
-        // for now, only use String Rangequeries for MultiTerm test, numeric and date makes little sense
-        // see issue #12123 for discussion
-        // Prefix / Fuzzy / RegEx / Wildcard can go here later once refactored and they have random query generators
-        RangeQueryBuilder query = new RangeQueryBuilder(AbstractQueryTestCase.STRING_FIELD_NAME);
-        query.from("a" + RandomStrings.randomAsciiOfLengthBetween(r, 1, 10));
-        query.to("z" + RandomStrings.randomAsciiOfLengthBetween(r, 1, 10));
-        return query;
-    }
-
-    /**
-     * Create a new invalid query of a random type
-     * @param r random seed
-     * @return a random {@link QueryBuilder} that is invalid, meaning that calling validate against it
-     * will return an error. We can rely on the fact that a single error will be returned per query.
-     */
-    public static QueryBuilder createInvalidQuery(Random r) {
-        switch (RandomInts.randomIntBetween(r, 0, 3)) {
-            case 0:
-                return new TermQueryBuilder("", "test");
-            case 1:
-                return new BoostingQueryBuilder(new MatchAllQueryBuilder(), new MatchAllQueryBuilder()).negativeBoost(-1f);
-            case 2:
-                return new CommonTermsQueryBuilder("", "text");
-            case 3:
-                return new SimpleQueryStringBuilder(null);
-            default:
-                throw new UnsupportedOperationException();
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/RangeQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/RangeQueryBuilderTests.java
deleted file mode 100644
index 3ad2b78..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/RangeQueryBuilderTests.java
+++ /dev/null
@@ -1,140 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.NumericRangeQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermRangeQuery;
-import org.joda.time.DateTime;
-import org.joda.time.DateTimeZone;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-
-public class RangeQueryBuilderTests extends AbstractQueryTestCase<RangeQueryBuilder> {
-
-    @Override
-    protected RangeQueryBuilder doCreateTestQueryBuilder() {
-        RangeQueryBuilder query;
-        // switch between numeric and date ranges
-        switch (randomIntBetween(0, 2)) {
-            case 0:
-                if (randomBoolean()) {
-                    // use mapped integer field for numeric range queries
-                    query = new RangeQueryBuilder(INT_FIELD_NAME);
-                    query.from(randomIntBetween(1, 100));
-                    query.to(randomIntBetween(101, 200));
-                } else {
-                    // use unmapped field for numeric range queries
-                    query = new RangeQueryBuilder(randomAsciiOfLengthBetween(1, 10));
-                    query.from(0.0 - randomDouble());
-                    query.to(randomDouble());
-                }
-                break;
-            case 1:
-                // use mapped date field, using date string representation
-                query = new RangeQueryBuilder(DATE_FIELD_NAME);
-                query.from(new DateTime(System.currentTimeMillis() - randomIntBetween(0, 1000000), DateTimeZone.UTC).toString());
-                query.to(new DateTime(System.currentTimeMillis() + randomIntBetween(0, 1000000), DateTimeZone.UTC).toString());
-                // Create timestamp option only then we have a date mapper,
-                // otherwise we could trigger exception.
-                if (createShardContext().mapperService().smartNameFieldType(DATE_FIELD_NAME) != null) {
-                    if (randomBoolean()) {
-                        query.timeZone(randomTimeZone());
-                    }
-                    if (randomBoolean()) {
-                        query.format("yyyy-MM-dd'T'HH:mm:ss.SSSZZ");
-                    }
-                }
-                break;
-            case 2:
-            default:
-                query = new RangeQueryBuilder(STRING_FIELD_NAME);
-                query.from("a" + randomAsciiOfLengthBetween(1, 10));
-                query.to("z" + randomAsciiOfLengthBetween(1, 10));
-                break;
-        }
-        query.includeLower(randomBoolean()).includeUpper(randomBoolean());
-        if (randomBoolean()) {
-            query.from(null);
-        }
-        if (randomBoolean()) {
-            query.to(null);
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(RangeQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if (getCurrentTypes().length == 0 || (queryBuilder.fieldName().equals(DATE_FIELD_NAME) == false && queryBuilder.fieldName().equals(INT_FIELD_NAME) == false)) {
-            assertThat(query, instanceOf(TermRangeQuery.class));
-        } else if (queryBuilder.fieldName().equals(DATE_FIELD_NAME)) {
-            //we can't properly test unmapped dates because LateParsingQuery is package private
-        } else if (queryBuilder.fieldName().equals(INT_FIELD_NAME)) {
-            assertThat(query, instanceOf(NumericRangeQuery.class));
-        } else {
-            throw new UnsupportedOperationException();
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        RangeQueryBuilder rangeQueryBuilder = new RangeQueryBuilder("");
-        assertThat(rangeQueryBuilder.validate().validationErrors().size(), is(1));
-
-        rangeQueryBuilder = new RangeQueryBuilder("okay").timeZone("UTC");
-        assertNull(rangeQueryBuilder.validate());
-
-        rangeQueryBuilder.timeZone("blab");
-        assertThat(rangeQueryBuilder.validate().validationErrors().size(), is(1));
-
-        rangeQueryBuilder.timeZone("UTC").format("basicDate");
-        assertNull(rangeQueryBuilder.validate());
-
-        rangeQueryBuilder.timeZone("UTC").format("broken_xx");
-        assertThat(rangeQueryBuilder.validate().validationErrors().size(), is(1));
-
-        rangeQueryBuilder.timeZone("xXx").format("broken_xx");
-        assertThat(rangeQueryBuilder.validate().validationErrors().size(), is(2));
-    }
-
-    /**
-     * Specifying a timezone together with a numeric range query should throw an exception.
-     */
-    @Test(expected=QueryShardException.class)
-    public void testToQueryNonDateWithTimezone() throws QueryShardException, IOException {
-        RangeQueryBuilder query = new RangeQueryBuilder(INT_FIELD_NAME);
-        query.from(1).to(10).timeZone("UTC");
-        query.toQuery(createShardContext());
-    }
-
-    /**
-     * Specifying a timezone together with an unmapped field should throw an exception.
-     */
-    @Test(expected=QueryShardException.class)
-    public void testToQueryUnmappedWithTimezone() throws QueryShardException, IOException {
-        RangeQueryBuilder query = new RangeQueryBuilder("bogus_field");
-        query.from(1).to(10).timeZone("UTC");
-        query.toQuery(createShardContext());
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/RegexpQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/RegexpQueryBuilderTests.java
deleted file mode 100644
index 75edf29..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/RegexpQueryBuilderTests.java
+++ /dev/null
@@ -1,78 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.RegexpQuery;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-
-public class RegexpQueryBuilderTests extends AbstractQueryTestCase<RegexpQueryBuilder> {
-
-    @Override
-    protected RegexpQueryBuilder doCreateTestQueryBuilder() {
-        // mapped or unmapped fields
-        String fieldName = randomBoolean() ? STRING_FIELD_NAME : randomAsciiOfLengthBetween(1, 10);
-        String value = randomAsciiOfLengthBetween(1, 10);
-        RegexpQueryBuilder query = new RegexpQueryBuilder(fieldName, value);
-
-        if (randomBoolean()) {
-            List<RegexpFlag> flags = new ArrayList<>();
-            int iter = randomInt(5);
-            for (int i = 0; i < iter; i++) {
-                flags.add(randomFrom(RegexpFlag.values()));
-            }
-            query.flags(flags.toArray(new RegexpFlag[flags.size()]));
-        }
-        if (randomBoolean()) {
-            query.maxDeterminizedStates(randomInt(50000));
-        }
-        if (randomBoolean()) {
-            query.rewrite(randomFrom(getRandomRewriteMethod()));
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(RegexpQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(RegexpQuery.class));
-    }
-
-    @Test
-    public void testValidate() {
-        RegexpQueryBuilder regexQueryBuilder = new RegexpQueryBuilder("", "regex");
-        assertThat(regexQueryBuilder.validate().validationErrors().size(), is(1));
-
-        regexQueryBuilder = new RegexpQueryBuilder("field", null);
-        assertThat(regexQueryBuilder.validate().validationErrors().size(), is(1));
-
-        regexQueryBuilder = new RegexpQueryBuilder("field", "regex");
-        assertNull(regexQueryBuilder.validate());
-
-        regexQueryBuilder = new RegexpQueryBuilder(null, null);
-        assertThat(regexQueryBuilder.validate().validationErrors().size(), is(2));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/ScoreTypeTests.java b/core/src/test/java/org/elasticsearch/index/query/ScoreTypeTests.java
deleted file mode 100644
index efbcc10..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/ScoreTypeTests.java
+++ /dev/null
@@ -1,74 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.query;
-
-import org.elasticsearch.index.query.ScoreType;
-import org.elasticsearch.test.ESTestCase;
-import org.junit.Test;
-
-import static org.hamcrest.MatcherAssert.assertThat;
-import static org.hamcrest.Matchers.equalTo;
-
-/**
- * Tests {@link ScoreType} to ensure backward compatibility of any changes.
- */
-public class ScoreTypeTests extends ESTestCase {
-    @Test
-    public void minFromString() {
-        assertThat("fromString(min) != MIN", ScoreType.MIN, equalTo(ScoreType.fromString("min")));
-    }
-
-    @Test
-    public void maxFromString() {
-        assertThat("fromString(max) != MAX", ScoreType.MAX, equalTo(ScoreType.fromString("max")));
-    }
-
-    @Test
-    public void avgFromString() {
-        assertThat("fromString(avg) != AVG", ScoreType.AVG, equalTo(ScoreType.fromString("avg")));
-    }
-
-    @Test
-    public void sumFromString() {
-        assertThat("fromString(sum) != SUM", ScoreType.SUM, equalTo(ScoreType.fromString("sum")));
-        // allowed for consistency with ScoreMode.Total:
-        assertThat("fromString(total) != SUM", ScoreType.SUM, equalTo(ScoreType.fromString("total")));
-    }
-
-    @Test
-    public void noneFromString() {
-        assertThat("fromString(none) != NONE", ScoreType.NONE, equalTo(ScoreType.fromString("none")));
-    }
-
-    /**
-     * Should throw {@link IllegalArgumentException} instead of NPE.
-     */
-    @Test(expected = IllegalArgumentException.class)
-    public void nullFromString_throwsException() {
-        ScoreType.fromString(null);
-    }
-
-    /**
-     * Failure should not change (and the value should never match anything...).
-     */
-    @Test(expected = IllegalArgumentException.class)
-    public void unrecognizedFromString_throwsException() {
-        ScoreType.fromString("unrecognized value");
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/ScriptQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/ScriptQueryBuilderTests.java
deleted file mode 100644
index 4cacd65..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/ScriptQueryBuilderTests.java
+++ /dev/null
@@ -1,60 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.elasticsearch.script.Script;
-import org.elasticsearch.script.ScriptService.ScriptType;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
-
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-
-public class ScriptQueryBuilderTests extends AbstractQueryTestCase<ScriptQueryBuilder> {
-
-    @Override
-    protected ScriptQueryBuilder doCreateTestQueryBuilder() {
-        String script;
-        Map<String, Object> params = null;
-        if (randomBoolean()) {
-            script = "5 * 2 > param";
-            params = new HashMap<>();
-            params.put("param", 1);
-        } else {
-            script = "5 * 2 > 2";
-        }
-        return new ScriptQueryBuilder(new Script(script, ScriptType.INLINE, "expression", params));
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(ScriptQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(ScriptQueryBuilder.ScriptQuery.class));
-    }
-
-    @Test
-    public void testValidate() {
-        ScriptQueryBuilder scriptQueryBuilder = new ScriptQueryBuilder(null);
-        assertThat(scriptQueryBuilder.validate().validationErrors().size(), is(1));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java b/core/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java
index d7d72d0..96c849a 100644
--- a/core/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java
+++ b/core/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java
@@ -19,35 +19,63 @@
 
 package org.elasticsearch.index.query;
 
-import com.google.common.collect.Sets;
 import org.apache.lucene.analysis.core.WhitespaceAnalyzer;
-import org.apache.lucene.index.*;
+import org.apache.lucene.index.Fields;
+import org.apache.lucene.index.MultiFields;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.Terms;
+import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.index.memory.MemoryIndex;
 import org.apache.lucene.queries.BoostingQuery;
 import org.apache.lucene.queries.ExtendedCommonTermsQuery;
 import org.apache.lucene.queries.TermsQuery;
-import org.apache.lucene.search.*;
-import org.apache.lucene.search.spans.*;
+import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.BoostQuery;
+import org.apache.lucene.search.ConstantScoreQuery;
+import org.apache.lucene.search.DisjunctionMaxQuery;
+import org.apache.lucene.search.FuzzyQuery;
+import org.apache.lucene.search.MatchAllDocsQuery;
+import org.apache.lucene.search.MultiTermQuery;
+import org.apache.lucene.search.NumericRangeQuery;
+import org.apache.lucene.search.PrefixQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.QueryWrapperFilter;
+import org.apache.lucene.search.RegexpQuery;
+import org.apache.lucene.search.TermQuery;
+import org.apache.lucene.search.TermRangeQuery;
+import org.apache.lucene.search.WildcardQuery;
+import org.apache.lucene.search.spans.FieldMaskingSpanQuery;
+import org.apache.lucene.search.spans.SpanContainingQuery;
+import org.apache.lucene.search.spans.SpanFirstQuery;
+import org.apache.lucene.search.spans.SpanMultiTermQueryWrapper;
+import org.apache.lucene.search.spans.SpanNearQuery;
+import org.apache.lucene.search.spans.SpanNotQuery;
+import org.apache.lucene.search.spans.SpanOrQuery;
+import org.apache.lucene.search.spans.SpanTermQuery;
+import org.apache.lucene.search.spans.SpanWithinQuery;
 import org.apache.lucene.spatial.prefix.IntersectsPrefixTreeFilter;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 import org.apache.lucene.util.CharsRefBuilder;
 import org.apache.lucene.util.NumericUtils;
 import org.apache.lucene.util.automaton.TooComplexToDeterminizeException;
-import org.elasticsearch.action.support.PlainActionFuture;
-import org.elasticsearch.action.termvectors.*;
-import org.elasticsearch.client.Client;
+import org.elasticsearch.action.termvectors.MultiTermVectorsItemResponse;
+import org.elasticsearch.action.termvectors.MultiTermVectorsResponse;
+import org.elasticsearch.action.termvectors.TermVectorsRequest;
+import org.elasticsearch.action.termvectors.TermVectorsResponse;
+import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.compress.CompressedXContent;
 import org.elasticsearch.common.lucene.search.MoreLikeThisQuery;
 import org.elasticsearch.common.lucene.search.Queries;
-import org.elasticsearch.common.lucene.search.function.BoostScoreFunction;
 import org.elasticsearch.common.lucene.search.function.FunctionScoreQuery;
 import org.elasticsearch.common.lucene.search.function.WeightFactorFunction;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.DistanceUnit;
 import org.elasticsearch.common.unit.Fuzziness;
+import org.elasticsearch.common.util.set.Sets;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.engine.Engine;
@@ -59,6 +87,7 @@ import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders;
 import org.elasticsearch.index.search.geo.GeoDistanceRangeQuery;
 import org.elasticsearch.index.search.geo.GeoPolygonQuery;
 import org.elasticsearch.index.search.geo.InMemoryGeoBoundingBoxQuery;
+import org.elasticsearch.index.search.morelikethis.MoreLikeThisFetchService;
 import org.elasticsearch.search.internal.SearchContext;
 import org.elasticsearch.test.ESSingleNodeTestCase;
 import org.hamcrest.Matchers;
@@ -66,21 +95,50 @@ import org.junit.Before;
 import org.junit.Test;
 
 import java.io.IOException;
-import java.lang.reflect.InvocationHandler;
-import java.lang.reflect.Method;
-import java.lang.reflect.Proxy;
 import java.util.Arrays;
 import java.util.EnumSet;
 import java.util.HashSet;
 import java.util.List;
-import java.util.concurrent.ExecutionException;
+import java.util.Locale;
 
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.index.query.QueryBuilders.*;
+import static org.elasticsearch.index.query.QueryBuilders.boolQuery;
+import static org.elasticsearch.index.query.QueryBuilders.boostingQuery;
+import static org.elasticsearch.index.query.QueryBuilders.commonTermsQuery;
+import static org.elasticsearch.index.query.QueryBuilders.constantScoreQuery;
+import static org.elasticsearch.index.query.QueryBuilders.disMaxQuery;
+import static org.elasticsearch.index.query.QueryBuilders.functionScoreQuery;
+import static org.elasticsearch.index.query.QueryBuilders.fuzzyQuery;
+import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
+import static org.elasticsearch.index.query.QueryBuilders.moreLikeThisQuery;
+import static org.elasticsearch.index.query.QueryBuilders.multiMatchQuery;
+import static org.elasticsearch.index.query.QueryBuilders.notQuery;
+import static org.elasticsearch.index.query.QueryBuilders.prefixQuery;
+import static org.elasticsearch.index.query.QueryBuilders.queryStringQuery;
+import static org.elasticsearch.index.query.QueryBuilders.rangeQuery;
+import static org.elasticsearch.index.query.QueryBuilders.regexpQuery;
+import static org.elasticsearch.index.query.QueryBuilders.spanContainingQuery;
+import static org.elasticsearch.index.query.QueryBuilders.spanFirstQuery;
+import static org.elasticsearch.index.query.QueryBuilders.spanNearQuery;
+import static org.elasticsearch.index.query.QueryBuilders.spanNotQuery;
+import static org.elasticsearch.index.query.QueryBuilders.spanOrQuery;
+import static org.elasticsearch.index.query.QueryBuilders.spanTermQuery;
+import static org.elasticsearch.index.query.QueryBuilders.spanWithinQuery;
+import static org.elasticsearch.index.query.QueryBuilders.termQuery;
+import static org.elasticsearch.index.query.QueryBuilders.termsQuery;
+import static org.elasticsearch.index.query.QueryBuilders.wildcardQuery;
 import static org.elasticsearch.test.StreamsUtils.copyToBytesFromClasspath;
 import static org.elasticsearch.test.StreamsUtils.copyToStringFromClasspath;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertBooleanSubQuery;
-import static org.hamcrest.Matchers.*;
+import static org.hamcrest.Matchers.closeTo;
+import static org.hamcrest.Matchers.containsString;
+import static org.hamcrest.Matchers.equalTo;
+import static org.hamcrest.Matchers.instanceOf;
+import static org.hamcrest.Matchers.is;
+import static org.hamcrest.Matchers.not;
+import static org.hamcrest.Matchers.notNullValue;
+import static org.hamcrest.Matchers.nullValue;
+import static org.hamcrest.Matchers.sameInstance;
 
 public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
 
@@ -140,25 +198,30 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
     public void testQueryStringBoostsBuilder() throws Exception {
         IndexQueryParserService queryParser = queryParser();
         QueryStringQueryBuilder builder = queryStringQuery("field:boosted^2");
+        Query expected = new BoostQuery(new TermQuery(new Term("field", "boosted")), 2);
         Query parsedQuery = queryParser.parse(builder).query();
-        assertThat(parsedQuery, instanceOf(TermQuery.class));
-        assertThat(((TermQuery) parsedQuery).getTerm(), equalTo(new Term("field", "boosted")));
-        assertThat(parsedQuery.getBoost(), equalTo(2.0f));
+        assertEquals(expected, parsedQuery);
+
         builder.boost(2.0f);
+        expected = new BoostQuery(new TermQuery(new Term("field", "boosted")), 4);
         parsedQuery = queryParser.parse(builder).query();
-        assertThat(parsedQuery.getBoost(), equalTo(4.0f));
+        assertEquals(expected, parsedQuery);
 
         builder = queryStringQuery("((field:boosted^2) AND (field:foo^1.5))^3");
+        expected = new BoostQuery(new BooleanQuery.Builder()
+            .add(new BoostQuery(new TermQuery(new Term("field", "boosted")), 2), Occur.MUST)
+            .add(new BoostQuery(new TermQuery(new Term("field", "foo")), 1.5f), Occur.MUST)
+            .build(), 3);
         parsedQuery = queryParser.parse(builder).query();
-        assertThat(parsedQuery, instanceOf(BooleanQuery.class));
-        assertThat(assertBooleanSubQuery(parsedQuery, TermQuery.class, 0).getTerm(), equalTo(new Term("field", "boosted")));
-        assertThat(assertBooleanSubQuery(parsedQuery, TermQuery.class, 0).getBoost(), equalTo(2.0f));
-        assertThat(assertBooleanSubQuery(parsedQuery, TermQuery.class, 1).getTerm(), equalTo(new Term("field", "foo")));
-        assertThat(assertBooleanSubQuery(parsedQuery, TermQuery.class, 1).getBoost(), equalTo(1.5f));
-        assertThat(parsedQuery.getBoost(), equalTo(3.0f));
+        assertEquals(expected, parsedQuery);
+
         builder.boost(2.0f);
+        expected = new BoostQuery(new BooleanQuery.Builder()
+            .add(new BoostQuery(new TermQuery(new Term("field", "boosted")), 2), Occur.MUST)
+            .add(new BoostQuery(new TermQuery(new Term("field", "foo")), 1.5f), Occur.MUST)
+            .build(), 6);
         parsedQuery = queryParser.parse(builder).query();
-        assertThat(parsedQuery.getBoost(), equalTo(6.0f));
+        assertEquals(expected, parsedQuery);
     }
 
     @Test
@@ -717,7 +780,7 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
     @Test
     public void testBoostingQueryBuilder() throws IOException {
         IndexQueryParserService queryParser = queryParser();
-        Query parsedQuery = queryParser.parse(boostingQuery(termQuery("field1", "value1"), termQuery("field1", "value2")).negativeBoost(0.2f)).query();
+        Query parsedQuery = queryParser.parse(boostingQuery().positive(termQuery("field1", "value1")).negative(termQuery("field1", "value2")).negativeBoost(0.2f)).query();
         assertThat(parsedQuery, instanceOf(BoostingQuery.class));
     }
 
@@ -1000,7 +1063,7 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
     @Test
     public void testSpanNotQueryBuilder() throws IOException {
         IndexQueryParserService queryParser = queryParser();
-        Query parsedQuery = queryParser.parse(spanNotQuery(spanTermQuery("age", 34), spanTermQuery("age", 35))).query();
+        Query parsedQuery = queryParser.parse(spanNotQuery().include(spanTermQuery("age", 34)).exclude(spanTermQuery("age", 35))).query();
         assertThat(parsedQuery, instanceOf(SpanNotQuery.class));
         SpanNotQuery spanNotQuery = (SpanNotQuery) parsedQuery;
         // since age is automatically registered in data, we encode it as numeric
@@ -1029,7 +1092,9 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
         little.setBoost(3);
         Query expectedQuery = new SpanWithinQuery(big, little);
 
-        SpanWithinQueryBuilder spanWithinQueryBuilder = spanWithinQuery(spanTermQuery("age", 34).boost(2), spanTermQuery("age", 35).boost(3));
+        SpanWithinQueryBuilder spanWithinQueryBuilder = spanWithinQuery()
+                .big(spanTermQuery("age", 34).boost(2))
+                .little(spanTermQuery("age", 35).boost(3));
         Query actualQuery = queryParser.parse(spanWithinQueryBuilder).query();
         assertEquals(expectedQuery, actualQuery);
 
@@ -1059,7 +1124,9 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
         little.setBoost(3);
         Query expectedQuery = new SpanContainingQuery(big, little);
 
-        SpanContainingQueryBuilder spanContainingQueryBuilder = spanContainingQuery(spanTermQuery("age", 34).boost(2), spanTermQuery("age", 35).boost(3));
+        SpanContainingQueryBuilder spanContainingQueryBuilder = spanContainingQuery()
+                .big(spanTermQuery("age", 34).boost(2))
+                .little(spanTermQuery("age", 35).boost(3));
         Query actualQuery = queryParser.parse(spanContainingQueryBuilder).query();
         assertEquals(expectedQuery, actualQuery);
 
@@ -1106,7 +1173,7 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
     @Test
     public void testSpanNearQueryBuilder() throws IOException {
         IndexQueryParserService queryParser = queryParser();
-        Query parsedQuery = queryParser.parse(spanNearQuery(12).clause(spanTermQuery("age", 34)).clause(spanTermQuery("age", 35)).clause(spanTermQuery("age", 36)).inOrder(false).collectPayloads(false)).query();
+        Query parsedQuery = queryParser.parse(spanNearQuery().clause(spanTermQuery("age", 34)).clause(spanTermQuery("age", 35)).clause(spanTermQuery("age", 36)).slop(12).inOrder(false).collectPayloads(false)).query();
         assertThat(parsedQuery, instanceOf(SpanNearQuery.class));
         SpanNearQuery spanNearQuery = (SpanNearQuery) parsedQuery;
         assertThat(spanNearQuery.getClauses().length, equalTo(3));
@@ -1226,7 +1293,7 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
         NumericRangeQuery<Long> expectedWrapped = NumericRangeQuery.newLongRange("age", NumberFieldMapper.Defaults.PRECISION_STEP_64_BIT, 7l, 17l, true, true);
         expectedWrapped.setBoost(2.0f);
         SpanMultiTermQueryWrapper<MultiTermQuery> wrapper = (SpanMultiTermQueryWrapper<MultiTermQuery>) parsedQuery;
-        assertThat(wrapper, equalTo(new SpanMultiTermQueryWrapper<>(expectedWrapped)));
+        assertThat(wrapper, equalTo(new SpanMultiTermQueryWrapper<MultiTermQuery>(expectedWrapped)));
     }
 
     @Test
@@ -1238,7 +1305,7 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
         NumericRangeQuery<Long> expectedWrapped = NumericRangeQuery.newLongRange("age", NumberFieldMapper.Defaults.PRECISION_STEP_64_BIT, 10l, 20l, true, false);
         expectedWrapped.setBoost(2.0f);
         SpanMultiTermQueryWrapper<MultiTermQuery> wrapper = (SpanMultiTermQueryWrapper<MultiTermQuery>) parsedQuery;
-        assertThat(wrapper, equalTo(new SpanMultiTermQueryWrapper<>(expectedWrapped)));
+        assertThat(wrapper, equalTo(new SpanMultiTermQueryWrapper<MultiTermQuery>(expectedWrapped)));
     }
 
     @Test
@@ -1250,7 +1317,7 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
         TermRangeQuery expectedWrapped = TermRangeQuery.newStringRange("user", "alice", "bob", true, false);
         expectedWrapped.setBoost(2.0f);
         SpanMultiTermQueryWrapper<MultiTermQuery> wrapper = (SpanMultiTermQueryWrapper<MultiTermQuery>) parsedQuery;
-        assertThat(wrapper, equalTo(new SpanMultiTermQueryWrapper<>(expectedWrapped)));
+        assertThat(wrapper, equalTo(new SpanMultiTermQueryWrapper<MultiTermQuery>(expectedWrapped)));
     }
 
     @Test
@@ -1281,16 +1348,12 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
 
     @Test
     public void testMoreLikeThisIds() throws Exception {
+        MoreLikeThisQueryParser parser = (MoreLikeThisQueryParser) queryParser.queryParser("more_like_this");
+        parser.setFetchService(new MockMoreLikeThisFetchService());
+
         IndexQueryParserService queryParser = queryParser();
-        final Client proxy = getMLTClientProxy();
         String query = copyToStringFromClasspath("/org/elasticsearch/index/query/mlt-items.json");
-        QueryShardContext ctx = new QueryShardContext(queryParser.index(), queryParser) {
-            @Override
-            public Client getClient() {
-                return proxy;
-            }
-        };
-        Query parsedQuery = queryParser.parse(ctx, new BytesArray(query)).query();
+        Query parsedQuery = queryParser.parse(query).query();
         assertThat(parsedQuery, instanceOf(BooleanQuery.class));
         BooleanQuery booleanQuery = (BooleanQuery) parsedQuery;
         assertThat(booleanQuery.getClauses().length, is(1));
@@ -1308,51 +1371,16 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
         }
     }
 
-    private Client getMLTClientProxy() {
-        return (Client) Proxy.newProxyInstance(
-                Client.class.getClassLoader(),
-                new Class[]{Client.class},
-                (proxy1, method, args) -> {
-                    if (method.equals(Client.class.getDeclaredMethod("multiTermVectors", MultiTermVectorsRequest.class))) {
-                        return new PlainActionFuture<MultiTermVectorsResponse>() {
-                            @Override
-                            public MultiTermVectorsResponse get() throws InterruptedException, ExecutionException {
-                                try {
-                                    MultiTermVectorsRequest request = (MultiTermVectorsRequest) args[0];
-                                    MultiTermVectorsItemResponse[] responses = new MultiTermVectorsItemResponse[request.size()];
-                                    int i = 0;
-                                    for (TermVectorsRequest item : request) {
-                                        TermVectorsResponse response = new TermVectorsResponse(item.index(), item.type(), item.id());
-                                        response.setExists(true);
-                                        Fields generatedFields = generateFields(item.selectedFields().toArray(new String[0]), item.id());
-                                        EnumSet<TermVectorsRequest.Flag> flags = EnumSet.of(TermVectorsRequest.Flag.Positions, TermVectorsRequest.Flag.Offsets);
-                                        response.setFields(generatedFields, item.selectedFields(), flags, generatedFields);
-                                        responses[i++] = new MultiTermVectorsItemResponse(response, null);
-                                    }
-                                    return new MultiTermVectorsResponse(responses);
-                                } catch (IOException ex) {
-                                    throw new ExecutionException(ex);
-                                }
-                            }
-                        };
-                    }
-                    throw new UnsupportedOperationException("not supported");
-                });
-    }
-
     @Test
     public void testMLTMinimumShouldMatch() throws Exception {
-        final Client proxy = getMLTClientProxy();
+        // setup for mocking fetching items
+        MoreLikeThisQueryParser parser = (MoreLikeThisQueryParser) queryParser.queryParser("more_like_this");
+        parser.setFetchService(new MockMoreLikeThisFetchService());
+
         // parsing the ES query
         IndexQueryParserService queryParser = queryParser();
         String query = copyToStringFromClasspath("/org/elasticsearch/index/query/mlt-items.json");
-        QueryShardContext ctx = new QueryShardContext(queryParser.index(), queryParser) {
-            @Override
-            public Client getClient() {
-                return proxy;
-            }
-        };
-        BooleanQuery parsedQuery = (BooleanQuery) queryParser.parse(ctx, new BytesArray(query)).query();
+        BooleanQuery parsedQuery = (BooleanQuery) queryParser.parse(query).query();
 
         // get MLT query, other clause is for include/exclude items
         MoreLikeThisQuery mltQuery = (MoreLikeThisQuery) parsedQuery.getClauses()[0].getQuery();
@@ -1380,6 +1408,27 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
         assertThat(minNumberShouldMatch, is(2));
     }
 
+    private static class MockMoreLikeThisFetchService extends MoreLikeThisFetchService {
+
+        public MockMoreLikeThisFetchService() {
+            super(null, Settings.Builder.EMPTY_SETTINGS);
+        }
+
+        @Override
+        public MultiTermVectorsResponse fetchResponse(List<Item> items, List<Item> unlikeItems, SearchContext searchContext) throws IOException {
+            MultiTermVectorsItemResponse[] responses = new MultiTermVectorsItemResponse[items.size()];
+            int i = 0;
+            for (Item item : items) {
+                TermVectorsResponse response = new TermVectorsResponse(item.index(), item.type(), item.id());
+                response.setExists(true);
+                Fields generatedFields = generateFields(item.fields(), item.id());
+                EnumSet<TermVectorsRequest.Flag> flags = EnumSet.of(TermVectorsRequest.Flag.Positions, TermVectorsRequest.Flag.Offsets);
+                response.setFields(generatedFields, new HashSet<String>(Arrays.asList(item.fields())), flags, generatedFields);
+                responses[i++] = new MultiTermVectorsItemResponse(response, null);
+            }
+            return new MultiTermVectorsResponse(responses);
+        }
+    }
 
     private static Fields generateFields(String[] fieldNames, String text) throws IOException {
         MemoryIndex index = new MemoryIndex();
@@ -1903,16 +1952,39 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
 
             BooleanQuery.Builder expected = new BooleanQuery.Builder();
             expected.add(new TermQuery(new Term("foobar", "banon")), Occur.SHOULD);
-            TermQuery tq1 = new TermQuery(new Term("name.first", "banon"));
-            tq1.setBoost(2);
-            TermQuery tq2 = new TermQuery(new Term("name.last", "banon"));
-            tq2.setBoost(3);
+            Query tq1 = new BoostQuery(new TermQuery(new Term("name.first", "banon")), 2);
+            Query tq2 = new BoostQuery(new TermQuery(new Term("name.last", "banon")), 3);
             expected.add(new DisjunctionMaxQuery(Arrays.<Query>asList(tq1, tq2), 0f), Occur.SHOULD);
             assertEquals(expected.build(), rewrittenQuery);
         }
     }
 
     @Test
+    public void testSimpleQueryString() throws Exception {
+        IndexQueryParserService queryParser = queryParser();
+        String query = copyToStringFromClasspath("/org/elasticsearch/index/query/simple-query-string.json");
+        Query parsedQuery = queryParser.parse(query).query();
+        assertThat(parsedQuery, instanceOf(BooleanQuery.class));
+    }
+
+    @Test
+    public void testSimpleQueryStringBoost() throws Exception {
+        IndexQueryParserService queryParser = queryParser();
+        SimpleQueryStringBuilder simpleQueryStringBuilder = new SimpleQueryStringBuilder("test");
+        simpleQueryStringBuilder.field("body", 5);
+        Query parsedQuery = queryParser.parse(simpleQueryStringBuilder.toString()).query();
+        assertThat(parsedQuery, instanceOf(TermQuery.class));
+        assertThat(parsedQuery.getBoost(), equalTo(5f));
+
+        simpleQueryStringBuilder = new SimpleQueryStringBuilder("test");
+        simpleQueryStringBuilder.field("body", 5);
+        simpleQueryStringBuilder.boost(2);
+        parsedQuery = queryParser.parse(simpleQueryStringBuilder.toString()).query();
+        assertThat(parsedQuery, instanceOf(TermQuery.class));
+        assertThat(parsedQuery.getBoost(), equalTo(10f));
+    }
+
+    @Test
     public void testMatchWithFuzzyTranspositions() throws Exception {
         IndexQueryParserService queryParser = queryParser();
         String query = copyToStringFromClasspath("/org/elasticsearch/index/query/match-with-fuzzy-transpositions.json");
@@ -1984,18 +2056,7 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
         IndexQueryParserService queryParser = queryParser();
         String query = jsonBuilder().startObject().startObject("function_score")
                 .startArray("functions")
-                .startObject().field("weight", 2).field("boost_factor", 2).endObject()
-                .endArray()
-                .endObject().endObject().string();
-        try {
-            queryParser.parse(query).query();
-            fail("Expect exception here because boost_factor must not have a weight");
-        } catch (QueryParsingException e) {
-            assertThat(e.getDetailedMessage(), containsString(BoostScoreFunction.BOOST_WEIGHT_ERROR_MESSAGE));
-        }
-        query = jsonBuilder().startObject().startObject("function_score")
-                .startArray("functions")
-                .startObject().field("boost_factor",2).endObject()
+                .startObject().startObject("script_score").field("script", "3").endObject().endObject()
                 .endArray()
                 .field("weight", 2)
                 .endObject().endObject().string();
@@ -2008,7 +2069,7 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
         query = jsonBuilder().startObject().startObject("function_score")
                 .field("weight", 2)
                 .startArray("functions")
-                .startObject().field("boost_factor",2).endObject()
+                .startObject().endObject()
                 .endArray()
                 .endObject().endObject().string();
         try {
@@ -2018,10 +2079,9 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
             assertThat(e.getDetailedMessage(), containsString("you can either define [functions] array or a single function, not both. already found [weight], now encountering [functions]."));
         }
     }
-
-    /**
-     * helper to extract term from TermQuery.
-     */
+    
+    /** 
+     * helper to extract term from TermQuery. */
     private Term getTerm(Query query) {
         while (query instanceof QueryWrapperFilter) {
             query = ((QueryWrapperFilter) query).getQuery();
@@ -2072,4 +2132,19 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
             assertThat(prefixQuery.getRewriteMethod(), instanceOf(MultiTermQuery.TopTermsBlendedFreqScoringRewrite.class));
         }
     }
+
+    @Test
+    public void testSimpleQueryStringNoFields() throws Exception {
+        IndexQueryParserService queryParser = queryParser();
+        String queryText = randomAsciiOfLengthBetween(1, 10).toLowerCase(Locale.ROOT);
+        String query = "{\n" +
+                "    \"simple_query_string\" : {\n" +
+                "        \"query\" : \"" + queryText + "\"\n" +
+                "    }\n" +
+                "}";
+        Query parsedQuery = queryParser.parse(query).query();
+        assertThat(parsedQuery, instanceOf(TermQuery.class));
+        TermQuery termQuery = (TermQuery) parsedQuery;
+        assertThat(termQuery.getTerm(), equalTo(new Term(MetaData.ALL, queryText)));
+    }
 }
diff --git a/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTests.java
deleted file mode 100644
index 956230e..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTests.java
+++ /dev/null
@@ -1,333 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.*;
-import org.elasticsearch.Version;
-import org.elasticsearch.cluster.metadata.MetaData;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.*;
-
-import static org.hamcrest.Matchers.*;
-
-public class SimpleQueryStringBuilderTests extends AbstractQueryTestCase<SimpleQueryStringBuilder> {
-
-    @Override
-    protected SimpleQueryStringBuilder doCreateTestQueryBuilder() {
-        SimpleQueryStringBuilder result = new SimpleQueryStringBuilder(randomAsciiOfLengthBetween(1, 10));
-        if (randomBoolean()) {
-            result.analyzeWildcard(randomBoolean());
-        }
-        if (randomBoolean()) {
-            result.lenient(randomBoolean());
-        }
-        if (randomBoolean()) {
-            result.lowercaseExpandedTerms(randomBoolean());
-        }
-        if (randomBoolean()) {
-            result.locale(randomLocale(getRandom()));
-        }
-        if (randomBoolean()) {
-            result.minimumShouldMatch(randomMinimumShouldMatch());
-        }
-        if (randomBoolean()) {
-            result.analyzer(randomAnalyzer());
-        }
-        if (randomBoolean()) {
-            result.defaultOperator(randomFrom(Operator.values()));
-        }
-        if (randomBoolean()) {
-            Set<SimpleQueryStringFlag> flagSet = new HashSet<>();
-            int size = randomIntBetween(0, SimpleQueryStringFlag.values().length);
-            for (int i = 0; i < size; i++) {
-                flagSet.add(randomFrom(SimpleQueryStringFlag.values()));
-            }
-            if (flagSet.size() > 0) {
-                result.flags(flagSet.toArray(new SimpleQueryStringFlag[flagSet.size()]));
-            }
-        }
-
-        int fieldCount = randomIntBetween(0, 10);
-        Map<String, Float> fields = new HashMap<>();
-        for (int i = 0; i < fieldCount; i++) {
-            if (randomBoolean()) {
-                fields.put(randomAsciiOfLengthBetween(1, 10), AbstractQueryBuilder.DEFAULT_BOOST);
-            } else {
-                fields.put(randomBoolean() ? STRING_FIELD_NAME : randomAsciiOfLengthBetween(1, 10), 2.0f / randomIntBetween(1, 20));
-            }
-        }
-        result.fields(fields);
-
-        return result;
-    }
-
-    @Test
-    public void testDefaults() {
-        SimpleQueryStringBuilder qb = new SimpleQueryStringBuilder("The quick brown fox.");
-
-        assertEquals("Wrong default default boost.", AbstractQueryBuilder.DEFAULT_BOOST, qb.boost(), 0.001);
-        assertEquals("Wrong default default boost field.", AbstractQueryBuilder.DEFAULT_BOOST, SimpleQueryStringBuilder.DEFAULT_BOOST,
-                0.001);
-
-        assertEquals("Wrong default flags.", SimpleQueryStringFlag.ALL.value, qb.flags());
-        assertEquals("Wrong default flags field.", SimpleQueryStringFlag.ALL.value(), SimpleQueryStringBuilder.DEFAULT_FLAGS);
-
-        assertEquals("Wrong default default operator.", Operator.OR, qb.defaultOperator());
-        assertEquals("Wrong default default operator field.", Operator.OR, SimpleQueryStringBuilder.DEFAULT_OPERATOR);
-
-        assertEquals("Wrong default default locale.", Locale.ROOT, qb.locale());
-        assertEquals("Wrong default default locale field.", Locale.ROOT, SimpleQueryStringBuilder.DEFAULT_LOCALE);
-
-        assertEquals("Wrong default default analyze_wildcard.", false, qb.analyzeWildcard());
-        assertEquals("Wrong default default analyze_wildcard field.", false, SimpleQueryStringBuilder.DEFAULT_ANALYZE_WILDCARD);
-
-        assertEquals("Wrong default default lowercase_expanded_terms.", true, qb.lowercaseExpandedTerms());
-        assertEquals("Wrong default default lowercase_expanded_terms field.", true,
-                SimpleQueryStringBuilder.DEFAULT_LOWERCASE_EXPANDED_TERMS);
-
-        assertEquals("Wrong default default lenient.", false, qb.lenient());
-        assertEquals("Wrong default default lenient field.", false, SimpleQueryStringBuilder.DEFAULT_LENIENT);
-
-        assertEquals("Wrong default default locale.", Locale.ROOT, qb.locale());
-        assertEquals("Wrong default default locale field.", Locale.ROOT, SimpleQueryStringBuilder.DEFAULT_LOCALE);
-    }
-
-    @Test
-    public void testDefaultNullLocale() {
-        SimpleQueryStringBuilder qb = new SimpleQueryStringBuilder("The quick brown fox.");
-        qb.locale(null);
-        assertEquals("Setting locale to null should result in returning to default value.", SimpleQueryStringBuilder.DEFAULT_LOCALE,
-                qb.locale());
-    }
-
-    @Test
-    public void testDefaultNullComplainFlags() {
-        SimpleQueryStringBuilder qb = new SimpleQueryStringBuilder("The quick brown fox.");
-        qb.flags((SimpleQueryStringFlag[]) null);
-        assertEquals("Setting flags to null should result in returning to default value.", SimpleQueryStringBuilder.DEFAULT_FLAGS,
-                qb.flags());
-    }
-
-    @Test
-    public void testDefaultEmptyComplainFlags() {
-        SimpleQueryStringBuilder qb = new SimpleQueryStringBuilder("The quick brown fox.");
-        qb.flags(new SimpleQueryStringFlag[]{});
-        assertEquals("Setting flags to empty should result in returning to default value.", SimpleQueryStringBuilder.DEFAULT_FLAGS,
-                qb.flags());
-    }
-
-    @Test
-    public void testDefaultNullComplainOp() {
-        SimpleQueryStringBuilder qb = new SimpleQueryStringBuilder("The quick brown fox.");
-        qb.defaultOperator(null);
-        assertEquals("Setting operator to null should result in returning to default value.", SimpleQueryStringBuilder.DEFAULT_OPERATOR,
-                qb.defaultOperator());
-    }
-
-    // Check operator handling, and default field handling.
-    @Test
-    public void testDefaultOperatorHandling() throws IOException {
-        SimpleQueryStringBuilder qb = new SimpleQueryStringBuilder("The quick brown fox.").field(STRING_FIELD_NAME);
-        QueryShardContext shardContext = createShardContext();
-        shardContext.setAllowUnmappedFields(true); // to avoid occasional cases
-                                                   // in setup where we didn't
-                                                   // add types but strict field
-                                                   // resolution
-        BooleanQuery boolQuery = (BooleanQuery) qb.toQuery(shardContext);
-        assertThat(shouldClauses(boolQuery), is(4));
-
-        qb.defaultOperator(Operator.AND);
-        boolQuery = (BooleanQuery) qb.toQuery(shardContext);
-        assertThat(shouldClauses(boolQuery), is(0));
-
-        qb.defaultOperator(Operator.OR);
-        boolQuery = (BooleanQuery) qb.toQuery(shardContext);
-        assertThat(shouldClauses(boolQuery), is(4));
-    }
-
-    @Test
-    public void testValidation() {
-        SimpleQueryStringBuilder qb = createTestQueryBuilder();
-        assertNull(qb.validate());
-    }
-
-    @Test
-    public void testNullQueryTextGeneratesException() {
-        SimpleQueryStringBuilder builder = new SimpleQueryStringBuilder(null);
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-    }
-
-    @Test(expected = IllegalArgumentException.class)
-    public void testFieldCannotBeNull() {
-        SimpleQueryStringBuilder qb = createTestQueryBuilder();
-        qb.field(null);
-    }
-
-    @Test(expected = IllegalArgumentException.class)
-    public void testFieldCannotBeNullAndWeighted() {
-        SimpleQueryStringBuilder qb = createTestQueryBuilder();
-        qb.field(null, AbstractQueryBuilder.DEFAULT_BOOST);
-    }
-
-    @Test(expected = IllegalArgumentException.class)
-    public void testFieldCannotBeEmpty() {
-        SimpleQueryStringBuilder qb = createTestQueryBuilder();
-        qb.field("");
-    }
-
-    @Test(expected = IllegalArgumentException.class)
-    public void testFieldCannotBeEmptyAndWeighted() {
-        SimpleQueryStringBuilder qb = createTestQueryBuilder();
-        qb.field("", AbstractQueryBuilder.DEFAULT_BOOST);
-    }
-
-    /**
-     * The following should fail fast - never silently set the map containing
-     * fields and weights to null but refuse to accept null instead.
-     * */
-    @Test(expected = NullPointerException.class)
-    public void testFieldsCannotBeSetToNull() {
-        SimpleQueryStringBuilder qb = createTestQueryBuilder();
-        qb.fields(null);
-    }
-
-    @Test
-    public void testDefaultFieldParsing() throws IOException {
-        QueryParseContext context = createParseContext();
-        String query = randomAsciiOfLengthBetween(1, 10).toLowerCase(Locale.ROOT);
-        String contentString = "{\n" +
-                "    \"simple_query_string\" : {\n" +
-                "      \"query\" : \"" + query + "\"" +
-                "    }\n" +
-                "}";
-        XContentParser parser = XContentFactory.xContent(contentString).createParser(contentString);
-        context.reset(parser);
-        SimpleQueryStringBuilder queryBuilder = new SimpleQueryStringParser().fromXContent(context);
-        assertThat(queryBuilder.value(), equalTo(query));
-        assertThat(queryBuilder.fields(), notNullValue());
-        assertThat(queryBuilder.fields().size(), equalTo(0));
-        QueryShardContext shardContext = createShardContext();
-
-        // the remaining tests requires either a mapping that we register with types in base test setup
-        // no strict field resolution (version before V_1_4_0_Beta1)
-        if (getCurrentTypes().length > 0 || shardContext.indexQueryParserService().getIndexCreatedVersion().before(Version.V_1_4_0_Beta1)) {
-            Query luceneQuery = queryBuilder.toQuery(shardContext);
-            assertThat(luceneQuery, instanceOf(TermQuery.class));
-            TermQuery termQuery = (TermQuery) luceneQuery;
-            assertThat(termQuery.getTerm(), equalTo(new Term(MetaData.ALL, query)));
-        }
-    }
-
-    /*
-     * This assumes that Lucene query parsing is being checked already, adding
-     * checks only for our parsing extensions.
-     * 
-     * Also this relies on {@link SimpleQueryStringTests} to test most of the
-     * actual functionality of query parsing.
-     */
-    @Override
-    protected void doAssertLuceneQuery(SimpleQueryStringBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, notNullValue());
-
-        if ("".equals(queryBuilder.value())) {
-            assertTrue("Query should have been MatchNoDocsQuery but was " + query.getClass().getName(), query instanceof MatchNoDocsQuery);
-        } else if (queryBuilder.fields().size() > 1) {
-            assertTrue("Query should have been BooleanQuery but was " + query.getClass().getName(), query instanceof BooleanQuery);
-
-            BooleanQuery boolQuery = (BooleanQuery) query;
-            if (queryBuilder.lowercaseExpandedTerms()) {
-                for (BooleanClause clause : boolQuery.clauses()) {
-                    if (clause.getQuery() instanceof TermQuery) {
-                        TermQuery inner = (TermQuery) clause.getQuery();
-                        assertThat(inner.getTerm().bytes().toString(), is(inner.getTerm().bytes().toString().toLowerCase(Locale.ROOT)));
-                    }
-                }
-            }
-
-            assertThat(boolQuery.clauses().size(), equalTo(queryBuilder.fields().size()));
-            Iterator<String> fields = queryBuilder.fields().keySet().iterator();
-            for (BooleanClause booleanClause : boolQuery) {
-                assertThat(booleanClause.getQuery(), instanceOf(TermQuery.class));
-                TermQuery termQuery = (TermQuery) booleanClause.getQuery();
-                assertThat(termQuery.getTerm().field(), equalTo(fields.next()));
-                assertThat(termQuery.getTerm().text().toLowerCase(Locale.ROOT), equalTo(queryBuilder.value().toLowerCase(Locale.ROOT)));
-            }
-
-            if (queryBuilder.minimumShouldMatch() != null) {
-                assertThat(boolQuery.getMinimumNumberShouldMatch(), greaterThan(0));
-            }
-        } else if (queryBuilder.fields().size() <= 1) {
-            assertTrue("Query should have been TermQuery but was " + query.getClass().getName(), query instanceof TermQuery);
-
-            TermQuery termQuery = (TermQuery) query;
-            String field;
-            if (queryBuilder.fields().size() == 0) {
-                field = MetaData.ALL;
-            } else {
-                field = queryBuilder.fields().keySet().iterator().next();
-            }
-            assertThat(termQuery.getTerm().field(), equalTo(field));
-            assertThat(termQuery.getTerm().text().toLowerCase(Locale.ROOT), equalTo(queryBuilder.value().toLowerCase(Locale.ROOT)));
-        } else {
-            fail("Encountered lucene query type we do not have a validation implementation for in our " + SimpleQueryStringBuilderTests.class.getSimpleName());
-        }
-    }
-
-    @Override
-    protected void assertBoost(SimpleQueryStringBuilder queryBuilder, Query query) throws IOException {
-        //boost may get parsed from the random query, we then combine the main boost with that one coming from lucene
-        //instead of trying to reparse the query and guess what the boost should be, we delegate boost checks to specific boost tests below
-    }
-
-
-    private int shouldClauses(BooleanQuery query) {
-        int result = 0;
-        for (BooleanClause c : query.clauses()) {
-            if (c.getOccur() == BooleanClause.Occur.SHOULD) {
-                result++;
-            }
-        }
-        return result;
-    }
-
-    @Test
-    public void testToQueryBoost() throws IOException {
-        assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
-        QueryShardContext shardContext = createShardContext();
-        SimpleQueryStringBuilder simpleQueryStringBuilder = new SimpleQueryStringBuilder("test");
-        simpleQueryStringBuilder.field(STRING_FIELD_NAME, 5);
-        Query query = simpleQueryStringBuilder.toQuery(shardContext);
-        assertThat(query, instanceOf(TermQuery.class));
-        assertThat(query.getBoost(), equalTo(5f));
-
-        simpleQueryStringBuilder = new SimpleQueryStringBuilder("test");
-        simpleQueryStringBuilder.field(STRING_FIELD_NAME, 5);
-        simpleQueryStringBuilder.boost(2);
-        query = simpleQueryStringBuilder.toQuery(shardContext);
-        assertThat(query, instanceOf(TermQuery.class));
-        assertThat(query.getBoost(), equalTo(10f));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanContainingQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/SpanContainingQueryBuilderTests.java
deleted file mode 100644
index 75a4ab9..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanContainingQueryBuilderTests.java
+++ /dev/null
@@ -1,82 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanContainingQuery;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class SpanContainingQueryBuilderTests extends AbstractQueryTestCase<SpanContainingQueryBuilder> {
-
-    @Override
-    protected SpanContainingQueryBuilder doCreateTestQueryBuilder() {
-        SpanTermQueryBuilder[] spanTermQueries = new SpanTermQueryBuilderTests().createSpanTermQueryBuilders(2);
-        return new SpanContainingQueryBuilder(spanTermQueries[0], spanTermQueries[1]);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanContainingQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanContainingQuery.class));
-    }
-
-    @Override
-    protected void assertBoost(SpanContainingQueryBuilder queryBuilder, Query query) throws IOException {
-        if (queryBuilder.boost() == AbstractQueryBuilder.DEFAULT_BOOST) {
-            //lucene default behaviour
-            assertThat(query.getBoost(), equalTo(queryBuilder.bigQuery().boost()));
-        } else {
-            assertThat(query.getBoost(), equalTo(queryBuilder.boost()));
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        int totalExpectedErrors = 0;
-        SpanQueryBuilder bigSpanQueryBuilder;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                bigSpanQueryBuilder = new SpanTermQueryBuilder("", "test");
-            } else {
-                bigSpanQueryBuilder = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            bigSpanQueryBuilder = new SpanTermQueryBuilder("name", "value");
-        }
-        SpanQueryBuilder littleSpanQueryBuilder;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                littleSpanQueryBuilder = new SpanTermQueryBuilder("", "test");
-            } else {
-                littleSpanQueryBuilder = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            littleSpanQueryBuilder = new SpanTermQueryBuilder("name", "value");
-        }
-        SpanContainingQueryBuilder queryBuilder = new SpanContainingQueryBuilder(bigSpanQueryBuilder, littleSpanQueryBuilder);
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanFirstQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/SpanFirstQueryBuilderTests.java
deleted file mode 100644
index cd9ca82..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanFirstQueryBuilderTests.java
+++ /dev/null
@@ -1,108 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanFirstQuery;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.elasticsearch.index.query.QueryBuilders.spanTermQuery;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class SpanFirstQueryBuilderTests extends AbstractQueryTestCase<SpanFirstQueryBuilder> {
-
-    @Override
-    protected SpanFirstQueryBuilder doCreateTestQueryBuilder() {
-        SpanTermQueryBuilder[] spanTermQueries = new SpanTermQueryBuilderTests().createSpanTermQueryBuilders(1);
-        return new SpanFirstQueryBuilder(spanTermQueries[0], randomIntBetween(0, 1000));
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanFirstQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanFirstQuery.class));
-    }
-
-    @Test
-    public void testValidate() {
-        int totalExpectedErrors = 0;
-        SpanQueryBuilder innerSpanQueryBuilder;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                innerSpanQueryBuilder = new SpanTermQueryBuilder("", "test");
-            } else {
-                innerSpanQueryBuilder = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            innerSpanQueryBuilder = new SpanTermQueryBuilder("name", "value");
-        }
-        int end = randomIntBetween(0, 10);
-        if (randomBoolean()) {
-            end = randomIntBetween(-10, -1);
-            totalExpectedErrors++;
-        }
-        SpanFirstQueryBuilder queryBuilder = new SpanFirstQueryBuilder(innerSpanQueryBuilder, end);
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-
-    /**
-     * test exception on missing `end` and `match` parameter in parser
-     */
-    @Test
-    public void testParseEnd() throws IOException {
-
-        {
-            XContentBuilder builder = XContentFactory.jsonBuilder();
-            builder.startObject();
-            builder.startObject(SpanFirstQueryBuilder.NAME);
-            builder.field("match");
-            spanTermQuery("description", "jumped").toXContent(builder, null);
-            builder.endObject();
-            builder.endObject();
-
-            try {
-                parseQuery(builder.string());
-                fail("missing [end] parameter should raise exception");
-            } catch (QueryParsingException e) {
-                assertTrue(e.getMessage().contains("spanFirst must have [end] set"));
-            }
-        }
-
-        {
-            XContentBuilder builder = XContentFactory.jsonBuilder();
-            builder.startObject();
-            builder.startObject(SpanFirstQueryBuilder.NAME);
-            builder.field("end", 10);
-            builder.endObject();
-            builder.endObject();
-
-            try {
-                parseQuery(builder.string());
-                fail("missing [match] parameter should raise exception");
-            } catch (QueryParsingException e) {
-                assertTrue(e.getMessage().contains("spanFirst must have [match] span query clause"));
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilderTests.java
deleted file mode 100644
index 52551ae..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilderTests.java
+++ /dev/null
@@ -1,87 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanMultiTermQueryWrapper;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class SpanMultiTermQueryBuilderTests extends AbstractQueryTestCase<SpanMultiTermQueryBuilder> {
-
-    @Override
-    protected SpanMultiTermQueryBuilder doCreateTestQueryBuilder() {
-        MultiTermQueryBuilder multiTermQueryBuilder = RandomQueryBuilder.createMultiTermQuery(random());
-        return new SpanMultiTermQueryBuilder(multiTermQueryBuilder);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanMultiTermQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanMultiTermQueryWrapper.class));
-        SpanMultiTermQueryWrapper spanMultiTermQueryWrapper = (SpanMultiTermQueryWrapper) query;
-        Query multiTermQuery = queryBuilder.innerQuery().toQuery(context);
-        assertThat(multiTermQuery, instanceOf(MultiTermQuery.class));
-        assertThat(spanMultiTermQueryWrapper.getWrappedQuery(), equalTo(new SpanMultiTermQueryWrapper<>((MultiTermQuery)multiTermQuery).getWrappedQuery()));
-    }
-
-    @Test
-    public void testValidate() {
-        int totalExpectedErrors = 0;
-        MultiTermQueryBuilder multiTermQueryBuilder;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                multiTermQueryBuilder = new RangeQueryBuilder("");
-            } else {
-                multiTermQueryBuilder = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            multiTermQueryBuilder = new RangeQueryBuilder("field");
-        }
-        SpanMultiTermQueryBuilder queryBuilder = new SpanMultiTermQueryBuilder(multiTermQueryBuilder);
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-
-    /**
-     * test checks that we throw an {@link UnsupportedOperationException} if the query wrapped
-     * by {@link SpanMultiTermQueryBuilder} does not generate a lucene {@link MultiTermQuery}.
-     * This is currently the case for {@link RangeQueryBuilder} when the target field is mapped
-     * to a date.
-     */
-    @Test
-    public void testUnsupportedInnerQueryType() throws IOException {
-        QueryShardContext context = createShardContext();
-        // test makes only sense if we have at least one type registered with date field mapping
-        if (getCurrentTypes().length > 0 && context.fieldMapper(DATE_FIELD_NAME) != null) {
-            try {
-                RangeQueryBuilder query = new RangeQueryBuilder(DATE_FIELD_NAME);
-                new SpanMultiTermQueryBuilder(query).toQuery(createShardContext());
-                fail("Exception expected, range query on date fields should not generate a lucene " + MultiTermQuery.class.getName());
-            } catch (UnsupportedOperationException e) {
-                assert(e.getMessage().contains("unsupported inner query, should be " + MultiTermQuery.class.getName()));
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanNearQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/SpanNearQueryBuilderTests.java
deleted file mode 100644
index f9c9e32..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanNearQueryBuilderTests.java
+++ /dev/null
@@ -1,81 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanNearQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.Iterator;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class SpanNearQueryBuilderTests extends AbstractQueryTestCase<SpanNearQueryBuilder> {
-
-    @Override
-    protected SpanNearQueryBuilder doCreateTestQueryBuilder() {
-        SpanNearQueryBuilder queryBuilder = new SpanNearQueryBuilder(randomIntBetween(-10, 10));
-        SpanTermQueryBuilder[] spanTermQueries = new SpanTermQueryBuilderTests().createSpanTermQueryBuilders(randomIntBetween(1, 6));
-        for (SpanTermQueryBuilder clause : spanTermQueries) {
-            queryBuilder.clause(clause);
-        }
-        queryBuilder.inOrder(randomBoolean());
-        queryBuilder.collectPayloads(randomBoolean());
-        return queryBuilder;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanNearQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanNearQuery.class));
-        SpanNearQuery spanNearQuery = (SpanNearQuery) query;
-        assertThat(spanNearQuery.getSlop(), equalTo(queryBuilder.slop()));
-        assertThat(spanNearQuery.isInOrder(), equalTo(queryBuilder.inOrder()));
-        assertThat(spanNearQuery.getClauses().length, equalTo(queryBuilder.clauses().size()));
-        Iterator<SpanQueryBuilder> spanQueryBuilderIterator = queryBuilder.clauses().iterator();
-        for (SpanQuery spanQuery : spanNearQuery.getClauses()) {
-            assertThat(spanQuery, equalTo(spanQueryBuilderIterator.next().toQuery(context)));
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        SpanNearQueryBuilder queryBuilder = new SpanNearQueryBuilder(1);
-        assertValidate(queryBuilder, 1); // empty clause list
-
-        int totalExpectedErrors = 0;
-        int clauses = randomIntBetween(1, 10);
-        for (int i = 0; i < clauses; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    queryBuilder.clause(new SpanTermQueryBuilder("", "test"));
-                } else {
-                    queryBuilder.clause(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                queryBuilder.clause(new SpanTermQueryBuilder("name", "value"));
-            }
-        }
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanNotQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/SpanNotQueryBuilderTests.java
deleted file mode 100644
index 49d1a9e..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanNotQueryBuilderTests.java
+++ /dev/null
@@ -1,205 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanNotQuery;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.elasticsearch.index.query.QueryBuilders.spanNearQuery;
-import static org.elasticsearch.index.query.QueryBuilders.spanTermQuery;
-import static org.hamcrest.Matchers.*;
-
-public class SpanNotQueryBuilderTests extends AbstractQueryTestCase<SpanNotQueryBuilder> {
-
-    @Override
-    protected SpanNotQueryBuilder doCreateTestQueryBuilder() {
-        SpanTermQueryBuilder[] spanTermQueries = new SpanTermQueryBuilderTests().createSpanTermQueryBuilders(2);
-        SpanNotQueryBuilder queryBuilder = new SpanNotQueryBuilder(spanTermQueries[0], spanTermQueries[1]);
-        if (randomBoolean()) {
-            // also test negative values, they should implicitly be changed to 0
-            queryBuilder.dist(randomIntBetween(-2, 10));
-        } else {
-            if (randomBoolean()) {
-                queryBuilder.pre(randomIntBetween(-2, 10));
-            }
-            if (randomBoolean()) {
-                queryBuilder.post(randomIntBetween(-2, 10));
-            }
-        }
-        return queryBuilder;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanNotQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanNotQuery.class));
-        SpanNotQuery spanNotQuery = (SpanNotQuery) query;
-        assertThat(spanNotQuery.getExclude(), equalTo(queryBuilder.excludeQuery().toQuery(context)));
-        assertThat(spanNotQuery.getInclude(), equalTo(queryBuilder.includeQuery().toQuery(context)));
-    }
-
-    @Test
-    public void testValidate() {
-        int totalExpectedErrors = 0;
-        SpanQueryBuilder include;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                include = new SpanTermQueryBuilder("", "test");
-            } else {
-                include = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            include = new SpanTermQueryBuilder("name", "value");
-        }
-        SpanQueryBuilder exclude;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                exclude = new SpanTermQueryBuilder("", "test");
-            } else {
-                exclude = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            exclude = new SpanTermQueryBuilder("name", "value");
-        }
-        SpanNotQueryBuilder queryBuilder = new SpanNotQueryBuilder(include, exclude);
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-
-    @Test
-    public void testDist() {
-        SpanNotQueryBuilder builder = new SpanNotQueryBuilder(new SpanTermQueryBuilder("name1", "value1"), new SpanTermQueryBuilder("name2", "value2"));
-        assertThat(builder.pre(), equalTo(0));
-        assertThat(builder.post(), equalTo(0));
-        builder.dist(-4);
-        assertThat(builder.pre(), equalTo(0));
-        assertThat(builder.post(), equalTo(0));
-        builder.dist(4);
-        assertThat(builder.pre(), equalTo(4));
-        assertThat(builder.post(), equalTo(4));
-    }
-
-    @Test
-    public void testPrePost() {
-        SpanNotQueryBuilder builder = new SpanNotQueryBuilder(new SpanTermQueryBuilder("name1", "value1"), new SpanTermQueryBuilder("name2", "value2"));
-        assertThat(builder.pre(), equalTo(0));
-        assertThat(builder.post(), equalTo(0));
-        builder.pre(-4).post(-4);
-        assertThat(builder.pre(), equalTo(0));
-        assertThat(builder.post(), equalTo(0));
-        builder.pre(1).post(2);
-        assertThat(builder.pre(), equalTo(1));
-        assertThat(builder.post(), equalTo(2));
-    }
-
-    /**
-     * test correct parsing of `dist` parameter, this should create builder with pre/post set to same value
-     */
-    @Test
-    public void testParseDist() throws IOException {
-        XContentBuilder builder = XContentFactory.jsonBuilder();
-        builder.startObject();
-        builder.startObject(SpanNotQueryBuilder.NAME);
-        builder.field("exclude");
-        spanTermQuery("description", "jumped").toXContent(builder, null);
-        builder.field("include");
-        spanNearQuery(1).clause(QueryBuilders.spanTermQuery("description", "quick"))
-                .clause(QueryBuilders.spanTermQuery("description", "fox")).toXContent(builder, null);
-        builder.field("dist", 3);
-        builder.endObject();
-        builder.endObject();
-        SpanNotQueryBuilder query = (SpanNotQueryBuilder)parseQuery(builder.string());
-        assertThat(query.pre(), equalTo(3));
-        assertThat(query.post(), equalTo(3));
-        assertNotNull(query.includeQuery());
-        assertNotNull(query.excludeQuery());
-    }
-
-    /**
-     * test exceptions for three types of broken json, missing include / exclude and both dist and pre/post specified
-     */
-    @Test
-    public void testParserExceptions() throws IOException {
-
-        {
-            XContentBuilder builder = XContentFactory.jsonBuilder();
-            builder.startObject();
-            builder.startObject(SpanNotQueryBuilder.NAME);
-            builder.field("exclude");
-            spanTermQuery("description", "jumped").toXContent(builder, null);
-            builder.field("dist", 2);
-            builder.endObject();
-            builder.endObject();
-
-            try {
-                parseQuery(builder.string());
-                fail("QueryParsingException should have been caught");
-            } catch (QueryParsingException e) {
-                assertThat("QueryParsingException should have been caught", e.getDetailedMessage(), containsString("spanNot must have [include]"));
-            }
-        }
-
-        {
-            XContentBuilder builder = XContentFactory.jsonBuilder();
-            builder.startObject();
-            builder.startObject(SpanNotQueryBuilder.NAME);
-            builder.field("include");
-            spanNearQuery(1).clause(QueryBuilders.spanTermQuery("description", "quick"))
-                    .clause(QueryBuilders.spanTermQuery("description", "fox")).toXContent(builder, null);
-            builder.field("dist", 2);
-            builder.endObject();
-            builder.endObject();
-
-            try {
-                parseQuery(builder.string());
-                fail("QueryParsingException should have been caught");
-            } catch (QueryParsingException e) {
-                assertThat("QueryParsingException should have been caught", e.getDetailedMessage(), containsString("spanNot must have [exclude]"));
-            }
-        }
-
-        {
-            XContentBuilder builder = XContentFactory.jsonBuilder();
-            builder.startObject();
-            builder.startObject(SpanNotQueryBuilder.NAME);
-            builder.field("include");
-            spanNearQuery(1).clause(QueryBuilders.spanTermQuery("description", "quick"))
-                    .clause(QueryBuilders.spanTermQuery("description", "fox")).toXContent(builder, null);
-            builder.field("exclude");
-            spanTermQuery("description", "jumped").toXContent(builder, null);
-            builder.field("dist", 2);
-            builder.field("pre", 2);
-            builder.endObject();
-            builder.endObject();
-
-            try {
-                parseQuery(builder.string());
-                fail("QueryParsingException should have been caught");
-            } catch (QueryParsingException e) {
-                assertThat("QueryParsingException should have been caught", e.getDetailedMessage(), containsString("spanNot can either use [dist] or [pre] & [post] (or none)"));
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanOrQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/SpanOrQueryBuilderTests.java
deleted file mode 100644
index bc4519a..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanOrQueryBuilderTests.java
+++ /dev/null
@@ -1,77 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanOrQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.Iterator;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class SpanOrQueryBuilderTests extends AbstractQueryTestCase<SpanOrQueryBuilder> {
-
-    @Override
-    protected SpanOrQueryBuilder doCreateTestQueryBuilder() {
-        SpanOrQueryBuilder queryBuilder = new SpanOrQueryBuilder();
-        SpanTermQueryBuilder[] spanTermQueries = new SpanTermQueryBuilderTests().createSpanTermQueryBuilders(randomIntBetween(1, 6));
-        for (SpanTermQueryBuilder clause : spanTermQueries) {
-            queryBuilder.clause(clause);
-        }
-        return queryBuilder;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanOrQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanOrQuery.class));
-        SpanOrQuery spanOrQuery = (SpanOrQuery) query;
-        assertThat(spanOrQuery.getClauses().length, equalTo(queryBuilder.clauses().size()));
-        Iterator<SpanQueryBuilder> spanQueryBuilderIterator = queryBuilder.clauses().iterator();
-        for (SpanQuery spanQuery : spanOrQuery.getClauses()) {
-            assertThat(spanQuery, equalTo(spanQueryBuilderIterator.next().toQuery(context)));
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        SpanOrQueryBuilder queryBuilder = new SpanOrQueryBuilder();
-        assertValidate(queryBuilder, 1); // empty clause list
-
-        int totalExpectedErrors = 0;
-        int clauses = randomIntBetween(1, 10);
-        for (int i = 0; i < clauses; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    queryBuilder.clause(new SpanTermQueryBuilder("", "test"));
-                } else {
-                    queryBuilder.clause(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                queryBuilder.clause(new SpanTermQueryBuilder("name", "value"));
-            }
-        }
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanTermQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/SpanTermQueryBuilderTests.java
deleted file mode 100644
index a51efc6..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanTermQueryBuilderTests.java
+++ /dev/null
@@ -1,75 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanTermQuery;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.lucene.BytesRefs;
-import org.elasticsearch.index.mapper.MappedFieldType;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class SpanTermQueryBuilderTests extends AbstractTermQueryTestCase<SpanTermQueryBuilder> {
-
-    @Override
-    protected SpanTermQueryBuilder createQueryBuilder(String fieldName, Object value) {
-        return new SpanTermQueryBuilder(fieldName, value);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanTermQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanTermQuery.class));
-        SpanTermQuery spanTermQuery = (SpanTermQuery) query;
-        assertThat(spanTermQuery.getTerm().field(), equalTo(queryBuilder.fieldName()));
-        MappedFieldType mapper = context.fieldMapper(queryBuilder.fieldName());
-        if (mapper != null) {
-            BytesRef bytesRef = mapper.indexedValueForSearch(queryBuilder.value());
-            assertThat(spanTermQuery.getTerm().bytes(), equalTo(bytesRef));
-        } else {
-            assertThat(spanTermQuery.getTerm().bytes(), equalTo(BytesRefs.toBytesRef(queryBuilder.value())));
-        }
-    }
-
-    /**
-     * @param amount the number of clauses that will be returned
-     * @return an array of random {@link SpanTermQueryBuilder} with same field name
-     */
-    public SpanTermQueryBuilder[] createSpanTermQueryBuilders(int amount) {
-        SpanTermQueryBuilder[] clauses = new SpanTermQueryBuilder[amount];
-        SpanTermQueryBuilder first = createTestQueryBuilder();
-        clauses[0] = first;
-        for (int i = 1; i < amount; i++) {
-            // we need same field name in all clauses, so we only randomize value
-            SpanTermQueryBuilder spanTermQuery = new SpanTermQueryBuilder(first.fieldName(), getRandomValueForFieldName(first.fieldName()));
-            if (randomBoolean()) {
-                spanTermQuery.boost(2.0f / randomIntBetween(1, 20));
-            }
-            if (randomBoolean()) {
-                spanTermQuery.queryName(randomAsciiOfLengthBetween(1, 10));
-            }
-            clauses[i] = spanTermQuery;
-        }
-        return clauses;
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanWithinQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/SpanWithinQueryBuilderTests.java
deleted file mode 100644
index 9d18e9e..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanWithinQueryBuilderTests.java
+++ /dev/null
@@ -1,82 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanWithinQuery;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class SpanWithinQueryBuilderTests extends AbstractQueryTestCase<SpanWithinQueryBuilder> {
-
-    @Override
-    protected SpanWithinQueryBuilder doCreateTestQueryBuilder() {
-        SpanTermQueryBuilder[] spanTermQueries = new SpanTermQueryBuilderTests().createSpanTermQueryBuilders(2);
-        return new SpanWithinQueryBuilder(spanTermQueries[0], spanTermQueries[1]);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanWithinQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanWithinQuery.class));
-    }
-
-    @Override
-    protected void assertBoost(SpanWithinQueryBuilder queryBuilder, Query query) throws IOException {
-        if (queryBuilder.boost() == AbstractQueryBuilder.DEFAULT_BOOST) {
-            //lucene default behaviour
-            assertThat(query.getBoost(), equalTo(queryBuilder.littleQuery().boost()));
-        } else {
-            assertThat(query.getBoost(), equalTo(queryBuilder.boost()));
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        int totalExpectedErrors = 0;
-        SpanQueryBuilder bigSpanQueryBuilder;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                bigSpanQueryBuilder = new SpanTermQueryBuilder("", "test");
-            } else {
-                bigSpanQueryBuilder = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            bigSpanQueryBuilder = new SpanTermQueryBuilder("name", "value");
-        }
-        SpanQueryBuilder littleSpanQueryBuilder;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                littleSpanQueryBuilder = new SpanTermQueryBuilder("", "test");
-            } else {
-                littleSpanQueryBuilder = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            littleSpanQueryBuilder = new SpanTermQueryBuilder("name", "value");
-        }
-        SpanWithinQueryBuilder queryBuilder = new SpanWithinQueryBuilder(bigSpanQueryBuilder, littleSpanQueryBuilder);
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/TemplateQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/TemplateQueryBuilderTests.java
index 00e980c..647ac44 100644
--- a/core/src/test/java/org/elasticsearch/index/query/TemplateQueryBuilderTests.java
+++ b/core/src/test/java/org/elasticsearch/index/query/TemplateQueryBuilderTests.java
@@ -16,60 +16,23 @@
  * specific language governing permissions and limitations
  * under the License.
  */
-
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.script.ScriptService.ScriptType;
 import org.elasticsearch.script.Template;
-import org.junit.BeforeClass;
+import org.elasticsearch.test.ESTestCase;
 import org.junit.Test;
 
 import java.io.IOException;
 import java.util.HashMap;
 import java.util.Map;
 
-import static org.hamcrest.Matchers.is;
-
-public class TemplateQueryBuilderTests extends AbstractQueryTestCase<TemplateQueryBuilder> {
-
-    /**
-     * The query type all template tests will be based on.
-     */
-    private static QueryBuilder<?> templateBase;
-
-    @BeforeClass
-    public static void setupClass() {
-        templateBase = RandomQueryBuilder.createQuery(getRandom());
-    }
-
-    @Override
-    protected boolean supportsBoostAndQueryName() {
-        return false;
-    }
-
-    @Override
-    protected TemplateQueryBuilder doCreateTestQueryBuilder() {
-        return new TemplateQueryBuilder(new Template(templateBase.toString()));
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(TemplateQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertEquals(templateBase.toQuery(context), query);
-    }
-
-    @Test
-    public void testValidate() {
-        TemplateQueryBuilder templateQueryBuilder = new TemplateQueryBuilder(null);
-        assertThat(templateQueryBuilder.validate().validationErrors().size(), is(1));
-    }
-
-    @Override
-    protected void assertBoost(TemplateQueryBuilder queryBuilder, Query query) throws IOException {
-        //no-op boost is checked already above as part of doAssertLuceneQuery as we rely on lucene equals impl
-    }
+/**
+ * Test building and serialising a template search request.
+ * */
+public class TemplateQueryBuilderTests extends ESTestCase {
 
     @Test
     public void testJSONGeneration() throws IOException {
diff --git a/core/src/test/java/org/elasticsearch/index/query/TemplateQueryParserTests.java b/core/src/test/java/org/elasticsearch/index/query/TemplateQueryParserTests.java
index 1959758..df65adc 100644
--- a/core/src/test/java/org/elasticsearch/index/query/TemplateQueryParserTests.java
+++ b/core/src/test/java/org/elasticsearch/index/query/TemplateQueryParserTests.java
@@ -21,7 +21,6 @@ package org.elasticsearch.index.query;
 import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.search.Query;
 import org.elasticsearch.Version;
-import org.elasticsearch.client.Client;
 import org.elasticsearch.cluster.ClusterService;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.inject.AbstractModule;
@@ -55,9 +54,6 @@ import org.junit.Before;
 import org.junit.Test;
 
 import java.io.IOException;
-import java.lang.reflect.InvocationHandler;
-import java.lang.reflect.Method;
-import java.lang.reflect.Proxy;
 
 /**
  * Test parsing and executing a template request.
@@ -66,7 +62,7 @@ import java.lang.reflect.Proxy;
 public class TemplateQueryParserTests extends ESTestCase {
 
     private Injector injector;
-    private QueryShardContext context;
+    private QueryParseContext context;
 
     @Before
     public void setup() throws IOException {
@@ -76,11 +72,7 @@ public class TemplateQueryParserTests extends ESTestCase {
                 .put("name", getClass().getName())
                 .put(IndexMetaData.SETTING_VERSION_CREATED, Version.CURRENT)
                 .build();
-        final Client proxy = (Client) Proxy.newProxyInstance(
-                Client.class.getClassLoader(),
-                new Class[]{Client.class}, (proxy1, method, args) -> {
-                    throw new UnsupportedOperationException("client is just a dummy");
-                });
+
         Index index = new Index("test");
         injector = new ModulesBuilder().add(
                 new EnvironmentModule(new Environment(settings)),
@@ -102,7 +94,6 @@ public class TemplateQueryParserTests extends ESTestCase {
                 new AbstractModule() {
                     @Override
                     protected void configure() {
-                        bind(Client.class).toInstance(proxy); // not needed here
                         Multibinder.newSetBinder(binder(), ScoreFunctionParser.class);
                         bind(ClusterService.class).toProvider(Providers.of((ClusterService) null));
                         bind(CircuitBreakerService.class).to(NoneCircuitBreakerService.class);
@@ -111,7 +102,7 @@ public class TemplateQueryParserTests extends ESTestCase {
         ).createInjector();
 
         IndexQueryParserService queryParserService = injector.getInstance(IndexQueryParserService.class);
-        context = new QueryShardContext(index, queryParserService);
+        context = new QueryParseContext(index, queryParserService);
     }
 
     @Override
diff --git a/core/src/test/java/org/elasticsearch/index/query/TermQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/TermQueryBuilderTests.java
deleted file mode 100644
index b2a8410..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/TermQueryBuilderTests.java
+++ /dev/null
@@ -1,56 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.lucene.BytesRefs;
-import org.elasticsearch.index.mapper.MappedFieldType;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class TermQueryBuilderTests extends AbstractTermQueryTestCase<TermQueryBuilder> {
-
-    /**
-     * @return a TermQuery with random field name and value, optional random boost and queryname
-     */
-    @Override
-    protected TermQueryBuilder createQueryBuilder(String fieldName, Object value) {
-        return new TermQueryBuilder(fieldName, value);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(TermQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(TermQuery.class));
-        TermQuery termQuery = (TermQuery) query;
-        assertThat(termQuery.getTerm().field(), equalTo(queryBuilder.fieldName()));
-        MappedFieldType mapper = context.fieldMapper(queryBuilder.fieldName());
-        if (mapper != null) {
-            BytesRef bytesRef = mapper.indexedValueForSearch(queryBuilder.value());
-            assertThat(termQuery.getTerm().bytes(), equalTo(bytesRef));
-        } else {
-            assertThat(termQuery.getTerm().bytes(), equalTo(BytesRefs.toBytesRef(queryBuilder.value())));
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/TermsQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/TermsQueryBuilderTests.java
deleted file mode 100644
index ea4896d..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/TermsQueryBuilderTests.java
+++ /dev/null
@@ -1,275 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import com.carrotsearch.randomizedtesting.generators.RandomPicks;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.elasticsearch.ElasticsearchException;
-import org.elasticsearch.action.get.GetRequest;
-import org.elasticsearch.action.get.GetResponse;
-import org.elasticsearch.common.ParseFieldMatcher;
-import org.elasticsearch.common.bytes.BytesArray;
-import org.elasticsearch.common.xcontent.ToXContent;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.get.GetResult;
-import org.elasticsearch.indices.cache.query.terms.TermsLookup;
-import org.hamcrest.Matchers;
-import org.junit.Before;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Iterator;
-import java.util.List;
-
-import static org.hamcrest.Matchers.*;
-
-public class TermsQueryBuilderTests extends AbstractQueryTestCase<TermsQueryBuilder> {
-
-    private List<Object> randomTerms;
-    private String termsPath;
-
-    @Before
-    public void randomTerms() {
-        List<Object> randomTerms = new ArrayList<>();
-        String[] strings = generateRandomStringArray(10, 10, false, true);
-        for (String string : strings) {
-            randomTerms.add(string);
-            if (rarely()) {
-                randomTerms.add(null);
-            }
-        }
-        this.randomTerms = randomTerms;
-        termsPath = randomAsciiOfLength(10).replace('.', '_');
-    }
-
-    @Override
-    protected TermsQueryBuilder doCreateTestQueryBuilder() {
-        TermsQueryBuilder query;
-        // terms query or lookup query
-        if (randomBoolean()) {
-            // make between 0 and 5 different values of the same type
-            String fieldName = getRandomFieldName();
-            Object[] values = new Object[randomInt(5)];
-            for (int i = 0; i < values.length; i++) {
-                values[i] = getRandomValueForFieldName(fieldName);
-            }
-            query = new TermsQueryBuilder(fieldName, values);
-        } else {
-            // right now the mock service returns us a list of strings
-            query = new TermsQueryBuilder(randomBoolean() ? randomAsciiOfLengthBetween(1,10) : STRING_FIELD_NAME);
-            query.termsLookup(randomTermsLookup());
-        }
-        return query;
-    }
-
-    private TermsLookup randomTermsLookup() {
-        return new TermsLookup(
-                randomBoolean() ? randomAsciiOfLength(10) : null,
-                randomAsciiOfLength(10),
-                randomAsciiOfLength(10),
-                termsPath
-        ).routing(randomBoolean() ? randomAsciiOfLength(10) : null);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(TermsQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(BooleanQuery.class));
-        BooleanQuery booleanQuery = (BooleanQuery) query;
-
-        // we only do the check below for string fields (otherwise we'd have to decode the values)
-        if (queryBuilder.fieldName().equals(INT_FIELD_NAME) || queryBuilder.fieldName().equals(DOUBLE_FIELD_NAME)
-                || queryBuilder.fieldName().equals(BOOLEAN_FIELD_NAME) || queryBuilder.fieldName().equals(DATE_FIELD_NAME)) {
-            return;
-        }
-
-        // expected returned terms depending on whether we have a terms query or a terms lookup query
-        List<Object> terms;
-        if (queryBuilder.termsLookup() != null) {
-            terms = randomTerms;
-        } else {
-            terms = queryBuilder.values();
-        }
-
-        // compare whether we have the expected list of terms returned
-        Iterator<Object> iter = terms.iterator();
-        for (BooleanClause booleanClause : booleanQuery) {
-            assertThat(booleanClause.getQuery(), instanceOf(TermQuery.class));
-            Term term = ((TermQuery) booleanClause.getQuery()).getTerm();
-            Object next = iter.next();
-            if (next == null) {
-                continue;
-            }
-            assertThat(term, equalTo(new Term(queryBuilder.fieldName(), next.toString())));
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        TermsQueryBuilder termsQueryBuilder = new TermsQueryBuilder(null, "term");
-        assertThat(termsQueryBuilder.validate().validationErrors().size(), is(1));
-
-        termsQueryBuilder = new TermsQueryBuilder("field", "term").termsLookup(randomTermsLookup());
-        assertThat(termsQueryBuilder.validate().validationErrors().size(), is(1));
-
-        termsQueryBuilder = new TermsQueryBuilder(null, "term").termsLookup(randomTermsLookup());
-        assertThat(termsQueryBuilder.validate().validationErrors().size(), is(2));
-
-        termsQueryBuilder = new TermsQueryBuilder("field", "term");
-        assertNull(termsQueryBuilder.validate());
-    }
-
-    @Test
-    public void testValidateLookupQuery() {
-        TermsQueryBuilder termsQuery = new TermsQueryBuilder("field").termsLookup(new TermsLookup());
-        int totalExpectedErrors = 3;
-        if (randomBoolean()) {
-            termsQuery.lookupId("id");
-            totalExpectedErrors--;
-        }
-        if (randomBoolean()) {
-            termsQuery.lookupType("type");
-            totalExpectedErrors--;
-        }
-        if (randomBoolean()) {
-            termsQuery.lookupPath("path");
-            totalExpectedErrors--;
-        }
-        assertValidate(termsQuery, totalExpectedErrors);
-    }
-
-    @Test
-    public void testNullValues() {
-        try {
-            switch (randomInt(6)) {
-                case 0:
-                    new TermsQueryBuilder("field", (String[]) null);
-                    break;
-                case 1:
-                    new TermsQueryBuilder("field", (int[]) null);
-                    break;
-                case 2:
-                    new TermsQueryBuilder("field", (long[]) null);
-                    break;
-                case 3:
-                    new TermsQueryBuilder("field", (float[]) null);
-                    break;
-                case 4:
-                    new TermsQueryBuilder("field", (double[]) null);
-                    break;
-                case 5:
-                    new TermsQueryBuilder("field", (Object[]) null);
-                    break;
-                default:
-                    new TermsQueryBuilder("field", (Iterable<?>) null);
-                    break;
-            }
-            fail("should have failed with IllegalArgumentException");
-        } catch (IllegalArgumentException e) {
-            assertThat(e.getMessage(), Matchers.containsString("No value specified for terms query"));
-        }
-    }
-
-    @Test
-    public void testBothValuesAndLookupSet() throws IOException {
-        String query = "{\n" +
-                "  \"terms\": {\n" +
-                "    \"field\": [\n" +
-                "      \"blue\",\n" +
-                "      \"pill\"\n" +
-                "    ],\n" +
-                "    \"field_lookup\": {\n" +
-                "      \"index\": \"pills\",\n" +
-                "      \"type\": \"red\",\n" +
-                "      \"id\": \"3\",\n" +
-                "      \"path\": \"white rabbit\"\n" +
-                "    }\n" +
-                "  }\n" +
-                "}";
-        QueryBuilder termsQueryBuilder = parseQuery(query);
-        assertThat(termsQueryBuilder.validate().validationErrors().size(), is(1));
-    }
-
-    public void testDeprecatedXContent() throws IOException {
-        String query = "{\n" +
-                "  \"terms\": {\n" +
-                "    \"field\": [\n" +
-                "      \"blue\",\n" +
-                "      \"pill\"\n" +
-                "    ],\n" +
-                "    \"disable_coord\": true\n" +
-                "  }\n" +
-                "}";
-        try {
-            parseQuery(query);
-            fail("disable_coord is deprecated");
-        } catch (IllegalArgumentException ex) {
-            assertEquals("Deprecated field [disable_coord] used, replaced by [Use [bool] query instead]", ex.getMessage());
-        }
-
-        TermsQueryBuilder queryBuilder = (TermsQueryBuilder) parseQuery(query, ParseFieldMatcher.EMPTY);
-        TermsQueryBuilder copy = assertSerialization(queryBuilder);
-        assertTrue(queryBuilder.disableCoord());
-        assertTrue(copy.disableCoord());
-
-        String randomMinShouldMatch = RandomPicks.randomFrom(random(), Arrays.asList("min_match", "min_should_match", "minimum_should_match"));
-        query = "{\n" +
-                "  \"terms\": {\n" +
-                "    \"field\": [\n" +
-                "      \"blue\",\n" +
-                "      \"pill\"\n" +
-                "    ],\n" +
-                "    \"" + randomMinShouldMatch +"\": \"42%\"\n" +
-                "  }\n" +
-                "}";
-        try {
-            parseQuery(query);
-            fail(randomMinShouldMatch + " is deprecated");
-        } catch (IllegalArgumentException ex) {
-            assertEquals("Deprecated field [" + randomMinShouldMatch + "] used, replaced by [Use [bool] query instead]", ex.getMessage());
-        }
-        queryBuilder = (TermsQueryBuilder) parseQuery(query, ParseFieldMatcher.EMPTY);
-        copy = assertSerialization(queryBuilder);
-        assertEquals("42%", queryBuilder.minimumShouldMatch());
-        assertEquals("42%", copy.minimumShouldMatch());
-    }
-
-    @Override
-    public GetResponse executeGet(GetRequest getRequest) {
-        String json;
-        try {
-            XContentBuilder builder = XContentFactory.jsonBuilder().prettyPrint();
-            builder.startObject();
-            builder.array(termsPath, randomTerms);
-            builder.endObject();
-            json = builder.string();
-        } catch (IOException ex) {
-            throw new ElasticsearchException("boom", ex);
-        }
-        return new GetResponse(new GetResult(getRequest.index(), getRequest.type(), getRequest.id(), 0, true, new BytesArray(json), null));
-    }
-}
-
diff --git a/core/src/test/java/org/elasticsearch/index/query/TypeQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/TypeQueryBuilderTests.java
deleted file mode 100644
index 46af02f..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/TypeQueryBuilderTests.java
+++ /dev/null
@@ -1,56 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.*;
-
-public class TypeQueryBuilderTests extends AbstractQueryTestCase<TypeQueryBuilder> {
-
-    @Override
-    protected TypeQueryBuilder doCreateTestQueryBuilder() {
-        return new TypeQueryBuilder(getRandomType());
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(TypeQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, either(instanceOf(TermQuery.class)).or(instanceOf(ConstantScoreQuery.class)));
-        if (query instanceof ConstantScoreQuery) {
-            query = ((ConstantScoreQuery) query).getQuery();
-            assertThat(query, instanceOf(TermQuery.class));
-        }
-        TermQuery termQuery = (TermQuery) query;
-        assertThat(termQuery.getTerm().field(), equalTo(TypeFieldMapper.NAME));
-        assertThat(termQuery.getTerm().text(), equalTo(queryBuilder.type()));
-    }
-
-    @Test
-    public void testValidate() {
-        TypeQueryBuilder typeQueryBuilder = new TypeQueryBuilder((String) null);
-        assertThat(typeQueryBuilder.validate().validationErrors().size(), is(1));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/WildcardQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/WildcardQueryBuilderTests.java
deleted file mode 100644
index 18bd489..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/WildcardQueryBuilderTests.java
+++ /dev/null
@@ -1,78 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.WildcardQuery;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-
-public class WildcardQueryBuilderTests extends AbstractQueryTestCase<WildcardQueryBuilder> {
-
-    @Override
-    protected WildcardQueryBuilder doCreateTestQueryBuilder() {
-        WildcardQueryBuilder query;
-
-        // mapped or unmapped field
-        String text = randomAsciiOfLengthBetween(1, 10);
-        if (randomBoolean()) {
-            query = new WildcardQueryBuilder(STRING_FIELD_NAME, text);
-        } else {
-            query = new WildcardQueryBuilder(randomAsciiOfLengthBetween(1, 10), text);
-        }
-        if (randomBoolean()) {
-            query.rewrite(randomFrom(getRandomRewriteMethod()));
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(WildcardQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(WildcardQuery.class));
-    }
-
-    @Test
-    public void testValidate() {
-        WildcardQueryBuilder wildcardQueryBuilder = new WildcardQueryBuilder("", "text");
-        assertThat(wildcardQueryBuilder.validate().validationErrors().size(), is(1));
-
-        wildcardQueryBuilder = new WildcardQueryBuilder("field", null);
-        assertThat(wildcardQueryBuilder.validate().validationErrors().size(), is(1));
-
-        wildcardQueryBuilder = new WildcardQueryBuilder(null, null);
-        assertThat(wildcardQueryBuilder.validate().validationErrors().size(), is(2));
-
-        wildcardQueryBuilder = new WildcardQueryBuilder("field", "text");
-        assertNull(wildcardQueryBuilder.validate());
-    }
-
-    @Test
-    public void testEmptyValue() throws IOException {
-        QueryShardContext context = createShardContext();
-        context.setAllowUnmappedFields(true);
-
-        WildcardQueryBuilder wildcardQueryBuilder = new WildcardQueryBuilder(getRandomType(), "");
-        assertEquals(wildcardQueryBuilder.toQuery(context).getClass(), WildcardQuery.class);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/WrapperQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/WrapperQueryBuilderTests.java
deleted file mode 100644
index ab80378..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/WrapperQueryBuilderTests.java
+++ /dev/null
@@ -1,78 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.is;
-
-public class WrapperQueryBuilderTests extends AbstractQueryTestCase<WrapperQueryBuilder> {
-
-    @Override
-    protected boolean supportsBoostAndQueryName() {
-        return false;
-    }
-
-    @Override
-    protected WrapperQueryBuilder doCreateTestQueryBuilder() {
-        QueryBuilder wrappedQuery = RandomQueryBuilder.createQuery(random());
-        switch (randomInt(2)) {
-            case 0:
-                return new WrapperQueryBuilder(wrappedQuery.toString());
-            case 1:
-                return new WrapperQueryBuilder(wrappedQuery.buildAsBytes().toBytes());
-            case 2:
-                return new WrapperQueryBuilder(wrappedQuery.buildAsBytes());
-            default:
-                throw new UnsupportedOperationException();
-        }
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(WrapperQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        try (XContentParser qSourceParser = XContentFactory.xContent(queryBuilder.source()).createParser(queryBuilder.source())) {
-            final QueryShardContext contextCopy = new QueryShardContext(context.index(), context.indexQueryParserService());
-            contextCopy.reset(qSourceParser);
-            QueryBuilder<?> innerQuery = contextCopy.parseContext().parseInnerQueryBuilder();
-            Query expected = innerQuery.toQuery(context);
-            assertThat(query, equalTo(expected));
-        }
-    }
-
-    @Override
-    protected void assertBoost(WrapperQueryBuilder queryBuilder, Query query) throws IOException {
-        //no-op boost is checked already above as part of doAssertLuceneQuery as we rely on lucene equals impl
-    }
-
-    @Test
-    public void testValidate() {
-        WrapperQueryBuilder wrapperQueryBuilder = new WrapperQueryBuilder((byte[]) null);
-        assertThat(wrapperQueryBuilder.validate().validationErrors().size(), is(1));
-
-        wrapperQueryBuilder = new WrapperQueryBuilder("");
-        assertThat(wrapperQueryBuilder.validate().validationErrors().size(), is(1));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/plugin/DummyQueryParserPlugin.java b/core/src/test/java/org/elasticsearch/index/query/plugin/DummyQueryParserPlugin.java
index 2311f1c..dbbc358 100644
--- a/core/src/test/java/org/elasticsearch/index/query/plugin/DummyQueryParserPlugin.java
+++ b/core/src/test/java/org/elasticsearch/index/query/plugin/DummyQueryParserPlugin.java
@@ -25,7 +25,10 @@ import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Weight;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.*;
+import org.elasticsearch.index.query.QueryBuilder;
+import org.elasticsearch.index.query.QueryParseContext;
+import org.elasticsearch.index.query.QueryParser;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.indices.IndicesModule;
 import org.elasticsearch.plugins.Plugin;
 
@@ -47,41 +50,24 @@ public class DummyQueryParserPlugin extends Plugin {
         module.registerQueryParser(DummyQueryParser.class);
     }
 
-    public static class DummyQueryBuilder extends AbstractQueryBuilder<DummyQueryBuilder> {
-        private static final String NAME = "dummy";
-
+    public static class DummyQueryBuilder extends QueryBuilder {
         @Override
         protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-            builder.startObject(NAME).endObject();
-        }
-
-        @Override
-        protected Query doToQuery(QueryShardContext context) throws IOException {
-            return new DummyQuery(context.isFilter());
-        }
-
-        @Override
-        public String getWriteableName() {
-            return NAME;
+            builder.startObject("dummy").endObject();
         }
     }
 
-    public static class DummyQueryParser extends BaseQueryParser {
+    public static class DummyQueryParser implements QueryParser {
         @Override
         public String[] names() {
-            return new String[]{DummyQueryBuilder.NAME};
+            return new String[]{"dummy"};
         }
 
         @Override
-        public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+        public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
             XContentParser.Token token = parseContext.parser().nextToken();
             assert token == XContentParser.Token.END_OBJECT;
-            return new DummyQueryBuilder();
-        }
-
-        @Override
-        public DummyQueryBuilder getBuilderPrototype() {
-            return new DummyQueryBuilder();
+            return new DummyQuery(parseContext.isFilter());
         }
     }
 
diff --git a/core/src/test/java/org/elasticsearch/index/query/support/QueryInnerHitsTests.java b/core/src/test/java/org/elasticsearch/index/query/support/QueryInnerHitsTests.java
deleted file mode 100644
index 2c4e317..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/support/QueryInnerHitsTests.java
+++ /dev/null
@@ -1,80 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.query.support;
-
-import org.elasticsearch.common.io.stream.BytesStreamOutput;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.xcontent.ToXContent;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsBuilder;
-import org.elasticsearch.test.ESTestCase;
-
-import java.io.IOException;
-
-public class QueryInnerHitsTests extends ESTestCase {
-
-    public void testSerialize() throws IOException {
-        copyAndAssert(new QueryInnerHits());
-        copyAndAssert(new QueryInnerHits("foo", new InnerHitsBuilder.InnerHit()));
-        copyAndAssert(new QueryInnerHits("foo", null));
-        copyAndAssert(new QueryInnerHits("foo", new InnerHitsBuilder.InnerHit().setSize(randomIntBetween(0, 100))));
-    }
-
-    public void testToXContent() throws IOException {
-        assertJson("{\"inner_hits\":{}}", new QueryInnerHits());
-        assertJson("{\"inner_hits\":{\"name\":\"foo\"}}", new QueryInnerHits("foo", new InnerHitsBuilder.InnerHit()));
-        assertJson("{\"inner_hits\":{\"name\":\"bar\"}}", new QueryInnerHits("bar", null));
-        assertJson("{\"inner_hits\":{\"name\":\"foo\",\"size\":42}}", new QueryInnerHits("foo", new InnerHitsBuilder.InnerHit().setSize(42)));
-        assertJson("{\"inner_hits\":{\"name\":\"boom\",\"from\":66,\"size\":666}}", new QueryInnerHits("boom", new InnerHitsBuilder.InnerHit().setFrom(66).setSize(666)));
-    }
-
-    private void assertJson(String expected, QueryInnerHits hits) throws IOException {
-        QueryInnerHits queryInnerHits = copyAndAssert(hits);
-        String actual;
-        if (randomBoolean()) {
-            actual = oneLineJSON(queryInnerHits);
-        } else {
-            actual = oneLineJSON(hits);
-        }
-        assertEquals(expected, actual);
-        XContentParser parser = hits.getXcontentParser();
-        assertEquals(XContentParser.Token.START_OBJECT, parser.nextToken());
-        QueryInnerHits other = copyAndAssert(new QueryInnerHits(parser));
-        assertEquals(expected, oneLineJSON(other));
-    }
-
-    public QueryInnerHits copyAndAssert(QueryInnerHits hits) throws IOException {
-        BytesStreamOutput out = new BytesStreamOutput();
-        hits.writeTo(out);
-        QueryInnerHits copy = randomBoolean() ? hits.readFrom(StreamInput.wrap(out.bytes())) : new QueryInnerHits(StreamInput.wrap(out.bytes()));
-        assertEquals(copy.toString() + " vs. " + hits.toString(), copy, hits);
-        return copy;
-    }
-
-    private String oneLineJSON(QueryInnerHits hits) throws IOException {
-        XContentBuilder builder = XContentFactory.jsonBuilder();
-        builder.startObject();
-        hits.toXContent(builder, ToXContent.EMPTY_PARAMS);
-        builder.endObject();
-        return builder.string().trim();
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java b/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java
index c7458e1..8892b57 100644
--- a/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java
+++ b/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java
@@ -86,9 +86,10 @@ import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_VERSION_CREATED;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
-import static org.elasticsearch.common.xcontent.ToXContent.EMPTY_PARAMS;
 import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
 import static org.hamcrest.Matchers.equalTo;
 
 /**
diff --git a/core/src/test/java/org/elasticsearch/index/translog/TranslogTests.java b/core/src/test/java/org/elasticsearch/index/translog/TranslogTests.java
index 5d153c7..93bc537 100644
--- a/core/src/test/java/org/elasticsearch/index/translog/TranslogTests.java
+++ b/core/src/test/java/org/elasticsearch/index/translog/TranslogTests.java
@@ -1157,8 +1157,7 @@ public class TranslogTests extends ESTestCase {
 
     public void testUpgradeOldTranslogFiles() throws IOException {
         List<Path> indexes = new ArrayList<>();
-        Path dir = getDataPath("/" + OldIndexBackwardsCompatibilityIT.class.getPackage().getName().replace('.', '/')); // the files are in the same pkg as the OldIndexBackwardsCompatibilityTests test
-        try (DirectoryStream<Path> stream = Files.newDirectoryStream(dir, "index-*.zip")) {
+        try (DirectoryStream<Path> stream = Files.newDirectoryStream(getBwcIndicesPath(), "index-*.zip")) {
             for (Path path : stream) {
                 indexes.add(path);
             }
diff --git a/core/src/test/java/org/elasticsearch/indexlifecycle/IndexLifecycleActionIT.java b/core/src/test/java/org/elasticsearch/indexlifecycle/IndexLifecycleActionIT.java
index 8ea074f..d9f8f71 100644
--- a/core/src/test/java/org/elasticsearch/indexlifecycle/IndexLifecycleActionIT.java
+++ b/core/src/test/java/org/elasticsearch/indexlifecycle/IndexLifecycleActionIT.java
@@ -21,7 +21,6 @@ package org.elasticsearch.indexlifecycle;
 
 import com.google.common.base.Function;
 import com.google.common.collect.Iterables;
-import com.google.common.collect.Sets;
 import org.elasticsearch.action.admin.cluster.health.ClusterHealthResponse;
 import org.elasticsearch.action.admin.cluster.health.ClusterHealthStatus;
 import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;
@@ -31,6 +30,7 @@ import org.elasticsearch.cluster.routing.RoutingNode;
 import org.elasticsearch.cluster.routing.RoutingNodes;
 import org.elasticsearch.common.Priority;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.util.set.Sets;
 import org.elasticsearch.discovery.Discovery;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.elasticsearch.test.ESIntegTestCase.ClusterScope;
@@ -43,10 +43,16 @@ import static org.elasticsearch.client.Requests.clusterHealthRequest;
 import static org.elasticsearch.client.Requests.createIndexRequest;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_REPLICAS;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
-import static org.elasticsearch.cluster.routing.ShardRoutingState.*;
+import static org.elasticsearch.cluster.routing.ShardRoutingState.INITIALIZING;
+import static org.elasticsearch.cluster.routing.ShardRoutingState.RELOCATING;
+import static org.elasticsearch.cluster.routing.ShardRoutingState.STARTED;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.elasticsearch.test.ESIntegTestCase.Scope;
-import static org.hamcrest.Matchers.*;
+import static org.hamcrest.Matchers.anyOf;
+import static org.hamcrest.Matchers.containsInAnyOrder;
+import static org.hamcrest.Matchers.equalTo;
+import static org.hamcrest.Matchers.not;
+import static org.hamcrest.Matchers.nullValue;
 
 
 /**
diff --git a/core/src/test/java/org/elasticsearch/indices/IndicesModuleTests.java b/core/src/test/java/org/elasticsearch/indices/IndicesModuleTests.java
index fcba11a..7727d8c 100644
--- a/core/src/test/java/org/elasticsearch/indices/IndicesModuleTests.java
+++ b/core/src/test/java/org/elasticsearch/indices/IndicesModuleTests.java
@@ -23,7 +23,10 @@ import org.apache.lucene.analysis.hunspell.Dictionary;
 import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.ModuleTestCase;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.index.query.*;
+import org.elasticsearch.index.query.QueryParseContext;
+import org.elasticsearch.index.query.QueryParser;
+import org.elasticsearch.index.query.QueryParsingException;
+import org.elasticsearch.index.query.TermQueryParser;
 
 import java.io.IOException;
 import java.io.InputStream;
@@ -36,19 +39,8 @@ public class IndicesModuleTests extends ModuleTestCase {
         public String[] names() {
             return new String[] {"fake-query-parser"};
         }
-
-        @Override
-        public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
-            return null;
-        }
-
-        @Override
-        public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-            return null;
-        }
-
         @Override
-        public QueryBuilder getBuilderPrototype() {
+        public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
             return null;
         }
     }
diff --git a/core/src/test/java/org/elasticsearch/indices/recovery/RecoveryStatusTests.java b/core/src/test/java/org/elasticsearch/indices/recovery/RecoveryStatusTests.java
index af5c2ef..ed73a44 100644
--- a/core/src/test/java/org/elasticsearch/indices/recovery/RecoveryStatusTests.java
+++ b/core/src/test/java/org/elasticsearch/indices/recovery/RecoveryStatusTests.java
@@ -18,11 +18,11 @@
  */
 package org.elasticsearch.indices.recovery;
 
-import com.google.common.collect.Sets;
 import org.apache.lucene.store.IndexOutput;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.common.transport.LocalTransportAddress;
+import org.elasticsearch.common.util.set.Sets;
 import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.shard.IndexShard;
 import org.elasticsearch.index.store.StoreFileMetaData;
diff --git a/core/src/test/java/org/elasticsearch/indices/stats/IndexStatsIT.java b/core/src/test/java/org/elasticsearch/indices/stats/IndexStatsIT.java
index b01ec78..d40ebf5 100644
--- a/core/src/test/java/org/elasticsearch/indices/stats/IndexStatsIT.java
+++ b/core/src/test/java/org/elasticsearch/indices/stats/IndexStatsIT.java
@@ -19,7 +19,9 @@
 
 package org.elasticsearch.indices.stats;
 
+import org.elasticsearch.index.VersionType;
 import org.elasticsearch.index.cache.IndexCacheModule;
+import org.elasticsearch.index.engine.VersionConflictEngineException;
 import org.elasticsearch.index.shard.MergeSchedulerConfig;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import org.apache.lucene.util.Version;
@@ -41,7 +43,6 @@ import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.BytesStreamOutput;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.index.cache.query.QueryCacheStats;
-import org.elasticsearch.index.cache.query.index.IndexQueryCache;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.index.shard.MergePolicyConfig;
 import org.elasticsearch.index.store.IndexStore;
@@ -368,7 +369,6 @@ public class IndexStatsIT extends ESIntegTestCase {
         client().prepareIndex("test1", "type1", Integer.toString(1)).setSource("field", "value").execute().actionGet();
         client().prepareIndex("test1", "type2", Integer.toString(1)).setSource("field", "value").execute().actionGet();
         client().prepareIndex("test2", "type", Integer.toString(1)).setSource("field", "value").execute().actionGet();
-
         refresh();
 
         NumShards test1 = getNumShards("test1");
@@ -381,6 +381,7 @@ public class IndexStatsIT extends ESIntegTestCase {
         assertThat(stats.getPrimaries().getDocs().getCount(), equalTo(3l));
         assertThat(stats.getTotal().getDocs().getCount(), equalTo(totalExpectedWrites));
         assertThat(stats.getPrimaries().getIndexing().getTotal().getIndexCount(), equalTo(3l));
+        assertThat(stats.getPrimaries().getIndexing().getTotal().getIndexFailedCount(), equalTo(0l));
         assertThat(stats.getPrimaries().getIndexing().getTotal().isThrottled(), equalTo(false));
         assertThat(stats.getPrimaries().getIndexing().getTotal().getThrottleTimeInMillis(), equalTo(0l));
         assertThat(stats.getTotal().getIndexing().getTotal().getIndexCount(), equalTo(totalExpectedWrites));
@@ -423,10 +424,12 @@ public class IndexStatsIT extends ESIntegTestCase {
         stats = client().admin().indices().prepareStats().setTypes("type1", "type").execute().actionGet();
         assertThat(stats.getPrimaries().getIndexing().getTypeStats().get("type1").getIndexCount(), equalTo(1l));
         assertThat(stats.getPrimaries().getIndexing().getTypeStats().get("type").getIndexCount(), equalTo(1l));
+        assertThat(stats.getPrimaries().getIndexing().getTypeStats().get("type1").getIndexFailedCount(), equalTo(0l));
         assertThat(stats.getPrimaries().getIndexing().getTypeStats().get("type2"), nullValue());
         assertThat(stats.getPrimaries().getIndexing().getTypeStats().get("type1").getIndexCurrent(), equalTo(0l));
         assertThat(stats.getPrimaries().getIndexing().getTypeStats().get("type1").getDeleteCurrent(), equalTo(0l));
 
+
         assertThat(stats.getTotal().getGet().getCount(), equalTo(0l));
         // check get
         GetResponse getResponse = client().prepareGet("test1", "type1", "1").execute().actionGet();
@@ -462,6 +465,30 @@ public class IndexStatsIT extends ESIntegTestCase {
         assertThat(stats.getTotal().getIndexing(), nullValue());
         assertThat(stats.getTotal().getGet(), nullValue());
         assertThat(stats.getTotal().getSearch(), nullValue());
+
+        // index failed
+        try {
+            client().prepareIndex("test1", "type1", Integer.toString(1)).setSource("field", "value").setVersion(1)
+                    .setVersionType(VersionType.EXTERNAL).execute().actionGet();
+            fail("Expected a version conflict");
+        } catch (VersionConflictEngineException e) {}
+        try {
+            client().prepareIndex("test1", "type2", Integer.toString(1)).setSource("field", "value").setVersion(1)
+                    .setVersionType(VersionType.EXTERNAL).execute().actionGet();
+            fail("Expected a version conflict");
+        } catch (VersionConflictEngineException e) {}
+        try {
+            client().prepareIndex("test2", "type", Integer.toString(1)).setSource("field", "value").setVersion(1)
+                    .setVersionType(VersionType.EXTERNAL).execute().actionGet();
+            fail("Expected a version conflict");
+        } catch (VersionConflictEngineException e) {}
+
+        stats = client().admin().indices().prepareStats().setTypes("type1", "type2").execute().actionGet();
+        assertThat(stats.getIndex("test1").getTotal().getIndexing().getTotal().getIndexFailedCount(), equalTo(2l));
+        assertThat(stats.getIndex("test2").getTotal().getIndexing().getTotal().getIndexFailedCount(), equalTo(1l));
+        assertThat(stats.getPrimaries().getIndexing().getTypeStats().get("type1").getIndexFailedCount(), equalTo(1L));
+        assertThat(stats.getPrimaries().getIndexing().getTypeStats().get("type2").getIndexFailedCount(), equalTo(1L));
+        assertThat(stats.getTotal().getIndexing().getTotal().getIndexFailedCount(), equalTo(3L));
     }
 
     @Test
diff --git a/core/src/test/java/org/elasticsearch/indices/template/SimpleIndexTemplateIT.java b/core/src/test/java/org/elasticsearch/indices/template/SimpleIndexTemplateIT.java
index 8be22a8..3282b94 100644
--- a/core/src/test/java/org/elasticsearch/indices/template/SimpleIndexTemplateIT.java
+++ b/core/src/test/java/org/elasticsearch/indices/template/SimpleIndexTemplateIT.java
@@ -18,7 +18,6 @@
  */
 package org.elasticsearch.indices.template;
 
-import com.google.common.collect.Sets;
 import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.action.ActionRequestValidationException;
 import org.elasticsearch.action.admin.indices.alias.Alias;
@@ -42,12 +41,24 @@ import org.junit.Test;
 
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
 
 import static org.elasticsearch.index.query.QueryBuilders.termQuery;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
-import static org.hamcrest.Matchers.*;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertThrows;
+import static org.hamcrest.Matchers.anyOf;
+import static org.hamcrest.Matchers.containsInAnyOrder;
+import static org.hamcrest.Matchers.containsString;
+import static org.hamcrest.Matchers.empty;
+import static org.hamcrest.Matchers.equalTo;
+import static org.hamcrest.Matchers.hasSize;
+import static org.hamcrest.Matchers.instanceOf;
+import static org.hamcrest.Matchers.is;
+import static org.hamcrest.Matchers.notNullValue;
+import static org.hamcrest.Matchers.nullValue;
 
 /**
  *
@@ -379,7 +390,7 @@ public class SimpleIndexTemplateIT extends ESIntegTestCase {
         searchResponse = client().prepareSearch("complex_filtered_alias").get();
         assertHitCount(searchResponse, 3l);
 
-        Set<String> types = Sets.newHashSet();
+        Set<String> types = new HashSet<>();
         for (SearchHit searchHit : searchResponse.getHits().getHits()) {
             types.add(searchHit.getType());
         }
diff --git a/core/src/test/java/org/elasticsearch/monitor/os/OsProbeTests.java b/core/src/test/java/org/elasticsearch/monitor/os/OsProbeTests.java
index 6b8818a..94bae66 100644
--- a/core/src/test/java/org/elasticsearch/monitor/os/OsProbeTests.java
+++ b/core/src/test/java/org/elasticsearch/monitor/os/OsProbeTests.java
@@ -54,11 +54,14 @@ public class OsProbeTests extends ESTestCase {
         }
 
         assertNotNull(stats.getMem());
-        assertThat(stats.getMem().getTotal().bytes(), greaterThan(0L));
-        assertThat(stats.getMem().getFree().bytes(), greaterThan(0L));
-        assertThat(stats.getMem().getFreePercent(), allOf(greaterThanOrEqualTo((short) 0), lessThanOrEqualTo((short) 100)));
-        assertThat(stats.getMem().getUsed().bytes(), greaterThan(0L));
-        assertThat(stats.getMem().getUsedPercent(), allOf(greaterThanOrEqualTo((short) 0), lessThanOrEqualTo((short) 100)));
+        // TODO: once java 9 is sorted out make these hard checks (currently 9-ea and 9-ea-jigsaw will differ)
+        if (!Constants.JRE_IS_MINIMUM_JAVA9) {
+            assertThat(stats.getMem().getTotal().bytes(), greaterThan(0L));
+            assertThat(stats.getMem().getFree().bytes(), greaterThan(0L));
+            assertThat(stats.getMem().getFreePercent(), allOf(greaterThanOrEqualTo((short) 0), lessThanOrEqualTo((short) 100)));
+            assertThat(stats.getMem().getUsed().bytes(), greaterThan(0L));
+            assertThat(stats.getMem().getUsedPercent(), allOf(greaterThanOrEqualTo((short) 0), lessThanOrEqualTo((short) 100)));
+        }
 
         assertNotNull(stats.getSwap());
         assertNotNull(stats.getSwap().getTotal());
@@ -70,9 +73,12 @@ public class OsProbeTests extends ESTestCase {
             assertThat(stats.getSwap().getUsed().bytes(), greaterThanOrEqualTo(0L));
         } else {
             // On platforms with no swap
-            assertThat(stats.getSwap().getTotal().bytes(), equalTo(0L));
-            assertThat(stats.getSwap().getFree().bytes(), equalTo(0L));
-            assertThat(stats.getSwap().getUsed().bytes(), equalTo(0L));
+            // TODO: one java 9 is sorted out make these hard checks (currently 9-ea and 9-ea-jigsaw will differ)
+            if (!Constants.JRE_IS_MINIMUM_JAVA9) {
+                assertThat(stats.getSwap().getTotal().bytes(), equalTo(0L));
+                assertThat(stats.getSwap().getFree().bytes(), equalTo(0L));
+                assertThat(stats.getSwap().getUsed().bytes(), equalTo(0L));
+            }
         }
     }
 }
diff --git a/core/src/test/java/org/elasticsearch/monitor/process/ProcessProbeTests.java b/core/src/test/java/org/elasticsearch/monitor/process/ProcessProbeTests.java
index 18b5f7a..21bfcb2 100644
--- a/core/src/test/java/org/elasticsearch/monitor/process/ProcessProbeTests.java
+++ b/core/src/test/java/org/elasticsearch/monitor/process/ProcessProbeTests.java
@@ -51,8 +51,11 @@ public class ProcessProbeTests extends ESTestCase {
             assertThat(stats.getOpenFileDescriptors(), equalTo(-1L));
             assertThat(stats.getMaxFileDescriptors(), equalTo(-1L));
         } else {
-            assertThat(stats.getOpenFileDescriptors(), greaterThan(0L));
-            assertThat(stats.getMaxFileDescriptors(), greaterThan(0L));
+            // TODO: once java 9 is sorted out make these hard checks (currently 9-ea and 9-ea-jigsaw will differ)
+            if (!Constants.JRE_IS_MINIMUM_JAVA9) {
+                assertThat(stats.getOpenFileDescriptors(), greaterThan(0L));
+                assertThat(stats.getMaxFileDescriptors(), greaterThan(0L));
+            }
         }
 
         ProcessStats.Cpu cpu = stats.getCpu();
@@ -62,11 +65,14 @@ public class ProcessProbeTests extends ESTestCase {
         assertThat(cpu.getPercent(), anyOf(lessThan((short) 0), allOf(greaterThanOrEqualTo((short) 0), lessThanOrEqualTo((short) 100))));
 
         // CPU time can return -1 if the the platform does not support this operation, let's see which platforms fail
-        assertThat(cpu.total, greaterThan(0L));
+        if (!Constants.JRE_IS_MINIMUM_JAVA9) {
+            // TODO: once java 9 is sorted out make these hard checks (currently 9-ea and 9-ea-jigsaw will differ)
+            assertThat(cpu.total, greaterThan(0L));
 
-        ProcessStats.Mem mem = stats.getMem();
-        assertNotNull(mem);
-        // Commited total virtual memory can return -1 if not supported, let's see which platforms fail
-        assertThat(mem.totalVirtual, greaterThan(0L));
+            ProcessStats.Mem mem = stats.getMem();
+            assertNotNull(mem);
+            // Commited total virtual memory can return -1 if not supported, let's see which platforms fail
+            assertThat(mem.totalVirtual, greaterThan(0L));
+        }
     }
 }
diff --git a/core/src/test/java/org/elasticsearch/nested/SimpleNestedIT.java b/core/src/test/java/org/elasticsearch/nested/SimpleNestedIT.java
index 258c4ad..96db9bf 100644
--- a/core/src/test/java/org/elasticsearch/nested/SimpleNestedIT.java
+++ b/core/src/test/java/org/elasticsearch/nested/SimpleNestedIT.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.nested;
 
 import org.apache.lucene.search.Explanation;
-import org.apache.lucene.search.join.ScoreMode;
 import org.elasticsearch.action.admin.cluster.health.ClusterHealthStatus;
 import org.elasticsearch.action.admin.cluster.stats.ClusterStatsResponse;
 import org.elasticsearch.action.admin.indices.stats.IndicesStatsResponse;
@@ -312,7 +311,7 @@ public class SimpleNestedIT extends ESIntegTestCase {
                 .execute().actionGet();
 
         SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(nestedQuery("nested1", termQuery("nested1.n_field1", "n_value1")).scoreMode(ScoreMode.Total))
+                .setQuery(nestedQuery("nested1", termQuery("nested1.n_field1", "n_value1")).scoreMode("total"))
                 .setExplain(true)
                 .execute().actionGet();
         assertNoFailures(searchResponse);
diff --git a/core/src/test/java/org/elasticsearch/network/DirectBufferNetworkIT.java b/core/src/test/java/org/elasticsearch/network/DirectBufferNetworkIT.java
index 6d79de9..40da9ae 100644
--- a/core/src/test/java/org/elasticsearch/network/DirectBufferNetworkIT.java
+++ b/core/src/test/java/org/elasticsearch/network/DirectBufferNetworkIT.java
@@ -54,6 +54,7 @@ public class DirectBufferNetworkIT extends ESIntegTestCase {
      */
     @Test
     public void verifySaneDirectBufferAllocations() throws Exception {
+        assumeTrue("test cannot run with security manager enabled", System.getSecurityManager() == null);
         createIndex("test");
 
         int estimatedBytesSize = scaledRandomIntBetween(ByteSizeValue.parseBytesSizeValue("1.1mb", "estimatedBytesSize").bytesAsInt(),
diff --git a/core/src/test/java/org/elasticsearch/percolator/MultiPercolatorIT.java b/core/src/test/java/org/elasticsearch/percolator/MultiPercolatorIT.java
index d080680..77a4b63 100644
--- a/core/src/test/java/org/elasticsearch/percolator/MultiPercolatorIT.java
+++ b/core/src/test/java/org/elasticsearch/percolator/MultiPercolatorIT.java
@@ -18,7 +18,6 @@
  */
 package org.elasticsearch.percolator;
 
-import org.apache.lucene.search.join.ScoreMode;
 import org.elasticsearch.action.ShardOperationFailedException;
 import org.elasticsearch.action.percolate.MultiPercolateRequestBuilder;
 import org.elasticsearch.action.percolate.MultiPercolateResponse;
@@ -27,7 +26,6 @@ import org.elasticsearch.client.Requests;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.query.MatchQueryBuilder;
-import org.elasticsearch.index.query.Operator;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
@@ -362,7 +360,7 @@ public class MultiPercolatorIT extends ESIntegTestCase {
         ensureGreen("nestedindex");
 
         client().prepareIndex("nestedindex", PercolatorService.TYPE_NAME, "Q").setSource(jsonBuilder().startObject()
-                .field("query", QueryBuilders.nestedQuery("employee", QueryBuilders.matchQuery("employee.name", "virginia potts").operator(Operator.AND)).scoreMode(ScoreMode.Avg)).endObject()).get();
+                .field("query", QueryBuilders.nestedQuery("employee", QueryBuilders.matchQuery("employee.name", "virginia potts").operator(MatchQueryBuilder.Operator.AND)).scoreMode("avg")).endObject()).get();
 
         refresh();
 
diff --git a/core/src/test/java/org/elasticsearch/percolator/PercolatorBackwardsCompatibilityIT.java b/core/src/test/java/org/elasticsearch/percolator/PercolatorBackwardsCompatibilityIT.java
index f250e92..ecee193 100644
--- a/core/src/test/java/org/elasticsearch/percolator/PercolatorBackwardsCompatibilityIT.java
+++ b/core/src/test/java/org/elasticsearch/percolator/PercolatorBackwardsCompatibilityIT.java
@@ -23,8 +23,8 @@ import org.elasticsearch.action.index.IndexRequestBuilder;
 import org.elasticsearch.action.percolate.PercolateResponse;
 import org.elasticsearch.action.percolate.PercolateSourceBuilder;
 import org.elasticsearch.index.percolator.PercolatorException;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.test.ESIntegTestCase;
-import org.elasticsearch.index.query.QueryShardException;
 import org.junit.Test;
 
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
@@ -67,7 +67,7 @@ public class PercolatorBackwardsCompatibilityIT extends ESIntegTestCase {
             fail();
         } catch (PercolatorException e) {
             e.printStackTrace();
-            assertThat(e.getRootCause(), instanceOf(QueryShardException.class));
+            assertThat(e.getRootCause(), instanceOf(QueryParsingException.class));
         }
     }
 
diff --git a/core/src/test/java/org/elasticsearch/percolator/PercolatorIT.java b/core/src/test/java/org/elasticsearch/percolator/PercolatorIT.java
index 85b46a6..6eca391 100644
--- a/core/src/test/java/org/elasticsearch/percolator/PercolatorIT.java
+++ b/core/src/test/java/org/elasticsearch/percolator/PercolatorIT.java
@@ -18,7 +18,6 @@
  */
 package org.elasticsearch.percolator;
 
-import org.apache.lucene.search.join.ScoreMode;
 import org.elasticsearch.action.ShardOperationFailedException;
 import org.elasticsearch.action.admin.cluster.node.stats.NodeStats;
 import org.elasticsearch.action.admin.cluster.node.stats.NodesStatsResponse;
@@ -42,11 +41,11 @@ import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.engine.DocumentMissingException;
 import org.elasticsearch.index.engine.VersionConflictEngineException;
 import org.elasticsearch.index.percolator.PercolatorException;
-import org.elasticsearch.index.query.Operator;
+import org.elasticsearch.index.query.MatchQueryBuilder;
 import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.index.query.QueryShardException;
-import org.elasticsearch.index.query.functionscore.factor.FactorBuilder;
-import org.elasticsearch.index.query.support.QueryInnerHits;
+import org.elasticsearch.index.query.QueryParsingException;
+import org.elasticsearch.index.query.functionscore.weight.WeightBuilder;
+import org.elasticsearch.index.query.support.QueryInnerHitBuilder;
 import org.elasticsearch.rest.RestStatus;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.search.highlight.HighlightBuilder;
@@ -55,43 +54,16 @@ import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Comparator;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.NavigableSet;
-import java.util.Set;
-import java.util.TreeSet;
+import java.util.*;
 
 import static org.elasticsearch.action.percolate.PercolateSourceBuilder.docBuilder;
 import static org.elasticsearch.common.settings.Settings.builder;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
-import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.common.xcontent.XContentFactory.smileBuilder;
-import static org.elasticsearch.common.xcontent.XContentFactory.yamlBuilder;
+import static org.elasticsearch.common.xcontent.XContentFactory.*;
 import static org.elasticsearch.index.query.QueryBuilders.*;
 import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.scriptFunction;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAllSuccessful;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertMatchCount;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
-import static org.hamcrest.Matchers.anyOf;
-import static org.hamcrest.Matchers.arrayContaining;
-import static org.hamcrest.Matchers.arrayContainingInAnyOrder;
-import static org.hamcrest.Matchers.arrayWithSize;
-import static org.hamcrest.Matchers.containsString;
-import static org.hamcrest.Matchers.emptyArray;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.greaterThan;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.nullValue;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
+import static org.hamcrest.Matchers.*;
 
 /**
  *
@@ -1447,7 +1419,7 @@ public class PercolatorIT extends ESIntegTestCase {
                 .setSize(5)
                 .setPercolateDoc(docBuilder().setDoc(jsonBuilder().startObject().field("field1", "The quick brown fox jumps over the lazy dog").endObject()))
                 .setHighlightBuilder(new HighlightBuilder().field("field1"))
-                .setPercolateQuery(functionScoreQuery(matchAllQuery()).add(new FactorBuilder().boostFactor(5.5f)))
+                .setPercolateQuery(functionScoreQuery(matchAllQuery()).add(new WeightBuilder().setWeight(5.5f)))
                 .setScore(true)
                 .execute().actionGet();
         assertNoFailures(response);
@@ -1479,7 +1451,7 @@ public class PercolatorIT extends ESIntegTestCase {
                 .setSize(5)
                 .setPercolateDoc(docBuilder().setDoc(jsonBuilder().startObject().field("field1", "The quick brown fox jumps over the lazy dog").endObject()))
                 .setHighlightBuilder(new HighlightBuilder().field("field1"))
-                .setPercolateQuery(functionScoreQuery(matchAllQuery()).add(new FactorBuilder().boostFactor(5.5f)))
+                .setPercolateQuery(functionScoreQuery(matchAllQuery()).add(new WeightBuilder().setWeight(5.5f)))
                 .setSortByScore(true)
                 .execute().actionGet();
         assertMatchCount(response, 5l);
@@ -1511,7 +1483,7 @@ public class PercolatorIT extends ESIntegTestCase {
                 .setSize(5)
                 .setPercolateDoc(docBuilder().setDoc(jsonBuilder().startObject().field("field1", "The quick brown fox jumps over the lazy dog").endObject()))
                 .setHighlightBuilder(new HighlightBuilder().field("field1").highlightQuery(QueryBuilders.matchQuery("field1", "jumps")))
-                .setPercolateQuery(functionScoreQuery(matchAllQuery()).add(new FactorBuilder().boostFactor(5.5f)))
+                .setPercolateQuery(functionScoreQuery(matchAllQuery()).add(new WeightBuilder().setWeight(5.5f)))
                 .setSortByScore(true)
                 .execute().actionGet();
         assertMatchCount(response, 5l);
@@ -1548,7 +1520,7 @@ public class PercolatorIT extends ESIntegTestCase {
                 .setSize(5)
                 .setGetRequest(Requests.getRequest("test").type("type").id("1"))
                 .setHighlightBuilder(new HighlightBuilder().field("field1"))
-                .setPercolateQuery(functionScoreQuery(matchAllQuery()).add(new FactorBuilder().boostFactor(5.5f)))
+                .setPercolateQuery(functionScoreQuery(matchAllQuery()).add(new WeightBuilder().setWeight(5.5f)))
                 .setSortByScore(true)
                 .execute().actionGet();
         assertMatchCount(response, 5l);
@@ -1765,7 +1737,7 @@ public class PercolatorIT extends ESIntegTestCase {
                     .get();
             fail();
         } catch (PercolatorException e) {
-            assertThat(e.getRootCause(), instanceOf(QueryShardException.class));
+            assertThat(e.getRootCause(), instanceOf(QueryParsingException.class));
         }
 
         try {
@@ -1774,7 +1746,7 @@ public class PercolatorIT extends ESIntegTestCase {
                     .get();
             fail();
         } catch (PercolatorException e) {
-            assertThat(e.getRootCause(), instanceOf(QueryShardException.class));
+            assertThat(e.getRootCause(), instanceOf(QueryParsingException.class));
         }
     }
 
@@ -1813,7 +1785,7 @@ public class PercolatorIT extends ESIntegTestCase {
         ensureGreen("nestedindex");
 
         client().prepareIndex("nestedindex", PercolatorService.TYPE_NAME, "Q").setSource(jsonBuilder().startObject()
-                .field("query", QueryBuilders.nestedQuery("employee", QueryBuilders.matchQuery("employee.name", "virginia potts").operator(Operator.AND)).scoreMode(ScoreMode.Avg)).endObject()).get();
+                .field("query", QueryBuilders.nestedQuery("employee", QueryBuilders.matchQuery("employee.name", "virginia potts").operator(MatchQueryBuilder.Operator.AND)).scoreMode("avg")).endObject()).get();
 
         refresh();
 
@@ -2013,11 +1985,11 @@ public class PercolatorIT extends ESIntegTestCase {
         assertAcked(prepareCreate("index").addMapping("mapping", mapping));
         try {
             client().prepareIndex("index", PercolatorService.TYPE_NAME, "1")
-                    .setSource(jsonBuilder().startObject().field("query", nestedQuery("nested", matchQuery("nested.name", "value")).innerHit(new QueryInnerHits())).endObject())
+                    .setSource(jsonBuilder().startObject().field("query", nestedQuery("nested", matchQuery("nested.name", "value")).innerHit(new QueryInnerHitBuilder())).endObject())
                     .execute().actionGet();
             fail("Expected a parse error, because inner_hits isn't supported in the percolate api");
         } catch (Exception e) {
-            assertThat(e.getCause(), instanceOf(QueryShardException.class));
+            assertThat(e.getCause(), instanceOf(QueryParsingException.class));
             assertThat(e.getCause().getMessage(), containsString("inner_hits unsupported"));
         }
     }
diff --git a/core/src/test/java/org/elasticsearch/plugins/PluginManagerCliTests.java b/core/src/test/java/org/elasticsearch/plugins/PluginManagerCliTests.java
index 0c9db6c..30946cc 100644
--- a/core/src/test/java/org/elasticsearch/plugins/PluginManagerCliTests.java
+++ b/core/src/test/java/org/elasticsearch/plugins/PluginManagerCliTests.java
@@ -19,12 +19,14 @@
 
 package org.elasticsearch.plugins;
 
+import org.elasticsearch.common.cli.CliTool;
 import org.elasticsearch.common.cli.CliToolTestCase;
 import org.junit.Test;
 
 import java.io.IOException;
 
 import static org.elasticsearch.common.cli.CliTool.ExitStatus.OK_AND_EXIT;
+import static org.elasticsearch.common.cli.CliTool.ExitStatus.IO_ERROR;
 import static org.hamcrest.Matchers.*;
 
 public class PluginManagerCliTests extends CliToolTestCase {
@@ -50,4 +52,11 @@ public class PluginManagerCliTests extends CliToolTestCase {
         assertThat(new PluginManagerCliParser(terminal).execute(args("list -h")), is(OK_AND_EXIT));
         assertTerminalOutputContainsHelpFile(terminal, "/org/elasticsearch/plugins/plugin-list.help");
     }
+
+    public void testUrlSpacesInPath() {
+        CliToolTestCase.CaptureOutputTerminal terminal = new CliToolTestCase.CaptureOutputTerminal();
+        CliTool.ExitStatus execute = new PluginManagerCliParser(terminal).execute(args("install file://foo%20deps"));
+        assertThat(execute.status(), is(IO_ERROR.status()));
+
+    }
 }
diff --git a/core/src/test/java/org/elasticsearch/routing/AliasResolveRoutingIT.java b/core/src/test/java/org/elasticsearch/routing/AliasResolveRoutingIT.java
index db6741b..2d82329 100644
--- a/core/src/test/java/org/elasticsearch/routing/AliasResolveRoutingIT.java
+++ b/core/src/test/java/org/elasticsearch/routing/AliasResolveRoutingIT.java
@@ -29,8 +29,8 @@ import java.util.HashMap;
 import java.util.Map;
 import java.util.Set;
 
-import static com.google.common.collect.Sets.newHashSet;
 import static org.elasticsearch.cluster.metadata.AliasAction.newAddAliasAction;
+import static org.elasticsearch.common.util.set.Sets.newHashSet;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.nullValue;
 
diff --git a/core/src/test/java/org/elasticsearch/script/ScriptModesTests.java b/core/src/test/java/org/elasticsearch/script/ScriptModesTests.java
index 2d1a563..f9db13b 100644
--- a/core/src/test/java/org/elasticsearch/script/ScriptModesTests.java
+++ b/core/src/test/java/org/elasticsearch/script/ScriptModesTests.java
@@ -21,7 +21,6 @@ package org.elasticsearch.script;
 
 import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Sets;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.script.ScriptService.ScriptType;
@@ -121,7 +120,7 @@ public class ScriptModesTests extends ESTestCase {
     @Test
     public void testScriptTypeGenericSettings() {
         int randomInt = randomIntBetween(1, ScriptType.values().length - 1);
-        Set<ScriptType> randomScriptTypesSet = Sets.newHashSet();
+        Set<ScriptType> randomScriptTypesSet = new HashSet<>();
         ScriptMode[] randomScriptModes = new ScriptMode[randomInt];
         for (int i = 0; i < randomInt; i++) {
             boolean added = false;
@@ -154,7 +153,7 @@ public class ScriptModesTests extends ESTestCase {
     @Test
     public void testScriptContextGenericSettings() {
         int randomInt = randomIntBetween(1, scriptContexts.length - 1);
-        Set<ScriptContext> randomScriptContextsSet = Sets.newHashSet();
+        Set<ScriptContext> randomScriptContextsSet = new HashSet<>();
         ScriptMode[] randomScriptModes = new ScriptMode[randomInt];
         for (int i = 0; i < randomInt; i++) {
             boolean added = false;
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/GeoDistanceIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/GeoDistanceIT.java
index f6dff6e..6bbbdb5 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/GeoDistanceIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/GeoDistanceIT.java
@@ -18,8 +18,6 @@
  */
 package org.elasticsearch.search.aggregations.bucket;
 
-import com.google.common.collect.Sets;
-
 import org.elasticsearch.action.index.IndexRequestBuilder;
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.common.unit.DistanceUnit;
@@ -35,6 +33,7 @@ import org.junit.Test;
 
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
 
@@ -360,7 +359,7 @@ public class GeoDistanceIT extends ESIntegTestCase {
         assertThat(bucket.getAggregations().asList().isEmpty(), is(false));
         Terms cities = bucket.getAggregations().get("cities");
         assertThat(cities, Matchers.notNullValue());
-        Set<String> names = Sets.newHashSet();
+        Set<String> names = new HashSet<>();
         for (Terms.Bucket city : cities.getBuckets()) {
             names.add(city.getKeyAsString());
         }
@@ -380,7 +379,7 @@ public class GeoDistanceIT extends ESIntegTestCase {
         assertThat(bucket.getAggregations().asList().isEmpty(), is(false));
         cities = bucket.getAggregations().get("cities");
         assertThat(cities, Matchers.notNullValue());
-        names = Sets.newHashSet();
+        names = new HashSet<>();
         for (Terms.Bucket city : cities.getBuckets()) {
             names.add(city.getKeyAsString());
         }
@@ -400,7 +399,7 @@ public class GeoDistanceIT extends ESIntegTestCase {
         assertThat(bucket.getAggregations().asList().isEmpty(), is(false));
         cities = bucket.getAggregations().get("cities");
         assertThat(cities, Matchers.notNullValue());
-        names = Sets.newHashSet();
+        names = new HashSet<>();
         for (Terms.Bucket city : cities.getBuckets()) {
             names.add(city.getKeyAsString());
         }
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/SignificantTermsSignificanceScoreIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/SignificantTermsSignificanceScoreIT.java
index 26cb3a9..27bfab0 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/SignificantTermsSignificanceScoreIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/SignificantTermsSignificanceScoreIT.java
@@ -29,7 +29,7 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.index.query.QueryShardException;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.script.ScriptModule;
@@ -237,7 +237,7 @@ public class SignificantTermsSignificanceScoreIT extends ESIntegTestCase {
 
             @Override
             public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher, SearchContext context)
-                    throws IOException, QueryShardException {
+                    throws IOException, QueryParsingException {
                 parser.nextToken();
                 return new SimpleHeuristic();
             }
@@ -621,4 +621,4 @@ public class SignificantTermsSignificanceScoreIT extends ESIntegTestCase {
         }
         indexRandom(true, indexRequestBuilderList);
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/PercentilesBucketIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/PercentilesBucketIT.java
index 507939e..f7c1d06 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/PercentilesBucketIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/PercentilesBucketIT.java
@@ -19,10 +19,10 @@ package org.elasticsearch.search.aggregations.pipeline;
  * under the License.
  */
 
+import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.action.index.IndexRequestBuilder;
 import org.elasticsearch.action.search.SearchPhaseExecutionException;
 import org.elasticsearch.action.search.SearchResponse;
-import org.elasticsearch.search.SearchParseException;
 import org.elasticsearch.search.aggregations.bucket.histogram.Histogram;
 import org.elasticsearch.search.aggregations.bucket.terms.Terms;
 import org.elasticsearch.search.aggregations.metrics.percentiles.Percentile;
@@ -41,9 +41,9 @@ import static org.elasticsearch.search.aggregations.AggregationBuilders.histogra
 import static org.elasticsearch.search.aggregations.AggregationBuilders.sum;
 import static org.elasticsearch.search.aggregations.AggregationBuilders.terms;
 import static org.elasticsearch.search.aggregations.pipeline.PipelineAggregatorBuilders.percentilesBucket;
-import static org.elasticsearch.search.aggregations.pipeline.PipelineAggregatorBuilders.sumBucket;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchResponse;
+import static org.hamcrest.Matchers.containsString;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.greaterThan;
 import static org.hamcrest.core.IsNull.notNullValue;
@@ -433,30 +433,22 @@ public class PercentilesBucketIT extends ESIntegTestCase {
     }
 
     @Test
-    @AwaitsFix(bugUrl = "https://github.com/elastic/elasticsearch/issues/13179")
     public void testBadPercents() throws Exception {
         Double[] badPercents = {-1.0, 110.0};
 
         try {
-            SearchResponse response = client().prepareSearch("idx")
+            client().prepareSearch("idx")
                     .addAggregation(terms("terms").field("tag").subAggregation(sum("sum").field(SINGLE_VALUED_FIELD_NAME)))
                     .addAggregation(percentilesBucket("percentiles_bucket")
                             .setBucketsPaths("terms>sum")
                             .percents(badPercents)).execute().actionGet();
 
-            assertSearchResponse(response);
-
-            Terms terms = response.getAggregations().get("terms");
-            assertThat(terms, notNullValue());
-            assertThat(terms.getName(), equalTo("terms"));
-            List<Terms.Bucket> buckets = terms.getBuckets();
-            assertThat(buckets.size(), equalTo(0));
-
-            PercentilesBucket percentilesBucketValue = response.getAggregations().get("percentiles_bucket");
-
             fail("Illegal percent's were provided but no exception was thrown.");
         } catch (SearchPhaseExecutionException exception) {
-            // All good
+            ElasticsearchException[] rootCauses = exception.guessRootCauses();
+            assertThat(rootCauses.length, equalTo(1));
+            ElasticsearchException rootCause = rootCauses[0];
+            assertThat(rootCause.getMessage(), containsString("must only contain non-null doubles from 0.0-100.0 inclusive"));
         }
 
     }
@@ -466,7 +458,7 @@ public class PercentilesBucketIT extends ESIntegTestCase {
         Double[] badPercents = {-1.0, 110.0};
 
         try {
-        SearchResponse response = client()
+            client()
                 .prepareSearch("idx")
                 .addAggregation(
                         terms("terms")
@@ -479,11 +471,12 @@ public class PercentilesBucketIT extends ESIntegTestCase {
                                         .setBucketsPaths("histo>_count")
                                         .percents(badPercents))).execute().actionGet();
 
-            PercentilesBucket percentilesBucketValue = response.getAggregations().get("percentiles_bucket");
-
             fail("Illegal percent's were provided but no exception was thrown.");
         } catch (SearchPhaseExecutionException exception) {
-            // All good
+            ElasticsearchException[] rootCauses = exception.guessRootCauses();
+            assertThat(rootCauses.length, equalTo(1));
+            ElasticsearchException rootCause = rootCauses[0];
+            assertThat(rootCause.getMessage(), containsString("must only contain non-null doubles from 0.0-100.0 inclusive"));
         }
 
     }
diff --git a/core/src/test/java/org/elasticsearch/search/basic/TransportTwoNodesSearchIT.java b/core/src/test/java/org/elasticsearch/search/basic/TransportTwoNodesSearchIT.java
index 246da25..969a2d7 100644
--- a/core/src/test/java/org/elasticsearch/search/basic/TransportTwoNodesSearchIT.java
+++ b/core/src/test/java/org/elasticsearch/search/basic/TransportTwoNodesSearchIT.java
@@ -20,18 +20,14 @@
 package org.elasticsearch.search.basic;
 
 
-
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.unit.TimeValue;
-
 import com.google.common.base.Charsets;
-import com.google.common.collect.Sets;
-
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.action.search.MultiSearchResponse;
 import org.elasticsearch.action.search.SearchPhaseExecutionException;
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.client.Requests;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.index.query.functionscore.script.ScriptScoreFunctionBuilder;
@@ -48,20 +44,29 @@ import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
 
 import java.io.IOException;
+import java.util.HashSet;
 import java.util.Set;
-
-import static org.elasticsearch.action.search.SearchType.*;
-import static org.elasticsearch.client.Requests.*;
+import java.util.TreeSet;
+
+import static org.elasticsearch.action.search.SearchType.DFS_QUERY_AND_FETCH;
+import static org.elasticsearch.action.search.SearchType.DFS_QUERY_THEN_FETCH;
+import static org.elasticsearch.action.search.SearchType.QUERY_AND_FETCH;
+import static org.elasticsearch.action.search.SearchType.QUERY_THEN_FETCH;
+import static org.elasticsearch.client.Requests.createIndexRequest;
+import static org.elasticsearch.client.Requests.searchRequest;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.elasticsearch.common.unit.TimeValue.timeValueMinutes;
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.index.query.QueryBuilders.termQuery;
 import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
 import static org.elasticsearch.index.query.QueryBuilders.termQuery;
 import static org.elasticsearch.search.builder.SearchSourceBuilder.searchSource;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
-import static org.hamcrest.Matchers.*;
+import static org.hamcrest.Matchers.equalTo;
+import static org.hamcrest.Matchers.instanceOf;
+import static org.hamcrest.Matchers.lessThanOrEqualTo;
+import static org.hamcrest.Matchers.notNullValue;
+import static org.hamcrest.Matchers.nullValue;
 
 public class TransportTwoNodesSearchIT extends ESIntegTestCase {
 
@@ -75,7 +80,7 @@ public class TransportTwoNodesSearchIT extends ESIntegTestCase {
     }
 
     private Set<String> prepareData(int numShards) throws Exception {
-        Set<String> fullExpectedIds = Sets.newTreeSet();
+        Set<String> fullExpectedIds = new TreeSet<>();
 
         Settings.Builder settingsBuilder = settingsBuilder()
                 .put(indexSettings())
@@ -214,7 +219,7 @@ public class TransportTwoNodesSearchIT extends ESIntegTestCase {
                 .query(matchAllQuery())
                 .explain(true);
 
-        Set<String> collectedIds = Sets.newTreeSet();
+        Set<String> collectedIds = new TreeSet<>();
 
         SearchResponse searchResponse = client().search(searchRequest("test").source(source.from(0).size(60)).searchType(QUERY_THEN_FETCH)).actionGet();
         assertNoFailures(searchResponse);
@@ -268,7 +273,7 @@ public class TransportTwoNodesSearchIT extends ESIntegTestCase {
                 .query(termQuery("multi", "test"))
                 .from(0).size(20).explain(true);
 
-        Set<String> expectedIds = Sets.newHashSet();
+        Set<String> expectedIds = new HashSet<>();
         for (int i = 0; i < 100; i++) {
             expectedIds.add(Integer.toString(i));
         }
@@ -308,7 +313,7 @@ public class TransportTwoNodesSearchIT extends ESIntegTestCase {
                 .query(termQuery("multi", "test"))
                 .from(0).size(20).explain(true);
 
-        Set<String> expectedIds = Sets.newHashSet();
+        Set<String> expectedIds = new HashSet<>();
         for (int i = 0; i < 100; i++) {
             expectedIds.add(Integer.toString(i));
         }
diff --git a/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchIT.java b/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchIT.java
index c9d8b81..9724e8d 100644
--- a/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchIT.java
+++ b/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchIT.java
@@ -18,6 +18,7 @@
  */
 package org.elasticsearch.search.child;
 
+import org.apache.lucene.search.join.ScoreMode;
 import org.elasticsearch.action.admin.indices.mapping.get.GetMappingsResponse;
 import org.elasticsearch.action.admin.indices.mapping.put.PutMappingResponse;
 import org.elasticsearch.action.count.CountResponse;
@@ -26,6 +27,7 @@ import org.elasticsearch.action.index.IndexRequestBuilder;
 import org.elasticsearch.action.search.SearchPhaseExecutionException;
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.action.search.SearchType;
+import org.elasticsearch.common.collect.HppcMaps;
 import org.elasticsearch.common.lucene.search.function.CombineFunction;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
@@ -34,7 +36,6 @@ import org.elasticsearch.index.mapper.MergeMappingException;
 import org.elasticsearch.index.query.HasChildQueryBuilder;
 import org.elasticsearch.index.query.QueryBuilder;
 import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.index.query.ScoreType;
 import org.elasticsearch.rest.RestStatus;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.search.aggregations.AggregationBuilders;
@@ -74,7 +75,6 @@ import static org.elasticsearch.index.query.QueryBuilders.termQuery;
 import static org.elasticsearch.index.query.QueryBuilders.termsQuery;
 import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.scriptFunction;
 import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.weightFactorFunction;
-import static org.elasticsearch.test.StreamsUtils.copyToStringFromClasspath;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
@@ -293,11 +293,11 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         for (int i = 1; i <= 10; i++) {
             logger.info("Round {}", i);
             SearchResponse searchResponse = client().prepareSearch("test")
-                    .setQuery(constantScoreQuery(hasChildQuery("child", matchAllQuery()).scoreType(ScoreType.MAX)))
+                    .setQuery(constantScoreQuery(hasChildQuery("child", matchAllQuery()).scoreMode("max")))
                     .get();
             assertNoFailures(searchResponse);
             searchResponse = client().prepareSearch("test")
-                    .setQuery(constantScoreQuery(hasParentQuery("parent", matchAllQuery()).score(true)))
+                    .setQuery(constantScoreQuery(hasParentQuery("parent", matchAllQuery()).scoreMode("score")))
                     .get();
             assertNoFailures(searchResponse);
         }
@@ -555,11 +555,11 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         client().prepareIndex("test", "child", "c1").setSource("c_field", "1").setParent(parentId).get();
         refresh();
 
-        CountResponse countResponse = client().prepareCount("test").setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreType(ScoreType.MAX))
+        CountResponse countResponse = client().prepareCount("test").setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreMode("max"))
                 .get();
         assertHitCount(countResponse, 1l);
 
-        countResponse = client().prepareCount("test").setQuery(hasParentQuery("parent", termQuery("p_field", "1")).score(true))
+        countResponse = client().prepareCount("test").setQuery(hasParentQuery("parent", termQuery("p_field", "1")).scoreMode("score"))
                 .get();
         assertHitCount(countResponse, 1l);
 
@@ -586,20 +586,20 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
 
         SearchResponse searchResponse = client().prepareSearch("test")
                 .setExplain(true)
-                .setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreType(ScoreType.MAX))
+                .setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreMode("max"))
                 .get();
         assertHitCount(searchResponse, 1l);
         assertThat(searchResponse.getHits().getAt(0).explanation().getDescription(), equalTo("Score based on join value p1"));
 
         searchResponse = client().prepareSearch("test")
                 .setExplain(true)
-                .setQuery(hasParentQuery("parent", termQuery("p_field", "1")).score(true))
+                .setQuery(hasParentQuery("parent", termQuery("p_field", "1")).scoreMode("score"))
                 .get();
         assertHitCount(searchResponse, 1l);
         assertThat(searchResponse.getHits().getAt(0).explanation().getDescription(), equalTo("Score based on join value p1"));
 
         ExplainResponse explainResponse = client().prepareExplain("test", "parent", parentId)
-                .setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreType(ScoreType.MAX))
+                .setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreMode("max"))
                 .get();
         assertThat(explainResponse.isExists(), equalTo(true));
         assertThat(explainResponse.getExplanation().getDetails()[0].getDescription(), equalTo("Score based on join value p1"));
@@ -677,7 +677,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
                                 "child",
                                 QueryBuilders.functionScoreQuery(matchQuery("c_field2", 0),
                                         scriptFunction(new Script("doc['c_field1'].value")))
-                                        .boostMode(CombineFunction.REPLACE.getName())).scoreType(ScoreType.SUM)).get();
+                                        .boostMode(CombineFunction.REPLACE.getName())).scoreMode("total")).get();
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("1"));
@@ -694,7 +694,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
                                 "child",
                                 QueryBuilders.functionScoreQuery(matchQuery("c_field2", 0),
                                         scriptFunction(new Script("doc['c_field1'].value")))
-                                        .boostMode(CombineFunction.REPLACE.getName())).scoreType(ScoreType.MAX)).get();
+                                        .boostMode(CombineFunction.REPLACE.getName())).scoreMode("max")).get();
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
@@ -711,7 +711,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
                                 "child",
                                 QueryBuilders.functionScoreQuery(matchQuery("c_field2", 0),
                                         scriptFunction(new Script("doc['c_field1'].value")))
-                                        .boostMode(CombineFunction.REPLACE.getName())).scoreType(ScoreType.AVG)).get();
+                                        .boostMode(CombineFunction.REPLACE.getName())).scoreMode("avg")).get();
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
@@ -728,7 +728,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
                                 "parent",
                                 QueryBuilders.functionScoreQuery(matchQuery("p_field1", "p_value3"),
                                         scriptFunction(new Script("doc['p_field2'].value")))
-                                        .boostMode(CombineFunction.REPLACE.getName())).score(true))
+                                        .boostMode(CombineFunction.REPLACE.getName())).scoreMode("score"))
                 .addSort(SortBuilders.fieldSort("c_field3")).addSort(SortBuilders.scoreSort()).get();
 
         assertThat(response.getHits().totalHits(), equalTo(7l));
@@ -768,7 +768,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertNoFailures(response);
         assertThat(response.getHits().totalHits(), equalTo(0l));
 
-        response = client().prepareSearch("test").setQuery(QueryBuilders.hasChildQuery("child", matchQuery("text", "value")).scoreType(ScoreType.MAX))
+        response = client().prepareSearch("test").setQuery(QueryBuilders.hasChildQuery("child", matchQuery("text", "value")).scoreMode("max"))
                 .get();
         assertNoFailures(response);
         assertThat(response.getHits().totalHits(), equalTo(0l));
@@ -777,7 +777,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertNoFailures(response);
         assertThat(response.getHits().totalHits(), equalTo(0l));
 
-        response = client().prepareSearch("test").setQuery(QueryBuilders.hasParentQuery("child", matchQuery("text", "value")).score(true))
+        response = client().prepareSearch("test").setQuery(QueryBuilders.hasParentQuery("child", matchQuery("text", "value")).scoreMode("score"))
                 .get();
         assertNoFailures(response);
         assertThat(response.getHits().totalHits(), equalTo(0l));
@@ -864,7 +864,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         SearchType[] searchTypes = new SearchType[]{SearchType.QUERY_THEN_FETCH, SearchType.DFS_QUERY_THEN_FETCH};
         for (SearchType searchType : searchTypes) {
             SearchResponse searchResponse = client().prepareSearch("test").setSearchType(searchType)
-                    .setQuery(hasChildQuery("child", prefixQuery("c_field", "c")).scoreType(ScoreType.MAX)).addSort("p_field", SortOrder.ASC)
+                    .setQuery(hasChildQuery("child", prefixQuery("c_field", "c")).scoreMode("max")).addSort("p_field", SortOrder.ASC)
                     .setSize(5).get();
             assertNoFailures(searchResponse);
             assertThat(searchResponse.getHits().totalHits(), equalTo(10L));
@@ -875,7 +875,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
             assertThat(searchResponse.getHits().hits()[4].id(), equalTo("p004"));
 
             searchResponse = client().prepareSearch("test").setSearchType(searchType)
-                    .setQuery(hasParentQuery("parent", prefixQuery("p_field", "p")).score(true)).addSort("c_field", SortOrder.ASC)
+                    .setQuery(hasParentQuery("parent", prefixQuery("p_field", "p")).scoreMode("score")).addSort("c_field", SortOrder.ASC)
                     .setSize(5).get();
             assertNoFailures(searchResponse);
             assertThat(searchResponse.getHits().totalHits(), equalTo(500L));
@@ -907,7 +907,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         refresh();
 
         SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(hasChildQuery("child", termQuery("c_field", "yellow")).scoreType(ScoreType.SUM)).get();
+                .setQuery(hasChildQuery("child", termQuery("c_field", "yellow")).scoreMode("total")).get();
         assertNoFailures(searchResponse);
         assertThat(searchResponse.getHits().totalHits(), equalTo(1l));
         assertThat(searchResponse.getHits().getAt(0).id(), equalTo("p1"));
@@ -917,7 +917,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
                 .prepareSearch("test")
                 .setQuery(
                         boolQuery().must(matchQuery("c_field", "x")).must(
-                                hasParentQuery("parent", termQuery("p_field", "p_value2")).score(true))).get();
+                                hasParentQuery("parent", termQuery("p_field", "p_value2")).scoreMode("score"))).get();
         assertNoFailures(searchResponse);
         assertThat(searchResponse.getHits().totalHits(), equalTo(2l));
         assertThat(searchResponse.getHits().getAt(0).id(), equalTo("c3"));
@@ -932,7 +932,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
             client().admin().indices().prepareRefresh("test").get();
         }
 
-        searchResponse = client().prepareSearch("test").setQuery(hasChildQuery("child", termQuery("c_field", "yellow")).scoreType(ScoreType.SUM))
+        searchResponse = client().prepareSearch("test").setQuery(hasChildQuery("child", termQuery("c_field", "yellow")).scoreMode("total"))
                 .get();
         assertNoFailures(searchResponse);
         assertThat(searchResponse.getHits().totalHits(), equalTo(1l));
@@ -943,7 +943,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
                 .prepareSearch("test")
                 .setQuery(
                         boolQuery().must(matchQuery("c_field", "x")).must(
-                                hasParentQuery("parent", termQuery("p_field", "p_value2")).score(true))).get();
+                                hasParentQuery("parent", termQuery("p_field", "p_value2")).scoreMode("score"))).get();
         assertNoFailures(searchResponse);
         assertThat(searchResponse.getHits().totalHits(), equalTo(2l));
         assertThat(searchResponse.getHits().getAt(0).id(), Matchers.anyOf(equalTo("c3"), equalTo("c4")));
@@ -968,7 +968,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         client().prepareIndex("test", "child", "c5").setSource("c_field", "x").setParent("p2").get();
         refresh();
 
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(hasChildQuery("child", matchAllQuery()).scoreType(ScoreType.SUM))
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(hasChildQuery("child", matchAllQuery()).scoreMode("total"))
                 .setMinScore(3) // Score needs to be 3 or above!
                 .get();
         assertNoFailures(searchResponse);
@@ -1237,15 +1237,15 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         client().prepareIndex("test", "child", "c3").setParent("p2").setSource("c_field", "red").get();
         refresh();
 
-        ScoreType scoreMode = ScoreType.values()[getRandom().nextInt(ScoreType.values().length)];
+        String scoreMode = ScoreMode.values()[getRandom().nextInt(ScoreMode.values().length)].name().toLowerCase(Locale.ROOT);
         SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(boolQuery().must(QueryBuilders.hasChildQuery("child", termQuery("c_field", "blue")).scoreType(scoreMode)).filter(notQuery(termQuery("p_field", "3"))))
+                .setQuery(boolQuery().must(QueryBuilders.hasChildQuery("child", termQuery("c_field", "blue")).scoreMode(scoreMode)).filter(notQuery(termQuery("p_field", "3"))))
                 .get();
         assertNoFailures(searchResponse);
         assertThat(searchResponse.getHits().totalHits(), equalTo(1l));
 
         searchResponse = client().prepareSearch("test")
-                .setQuery(boolQuery().must(QueryBuilders.hasChildQuery("child", termQuery("c_field", "red")).scoreType(scoreMode)).filter(notQuery(termQuery("p_field", "3"))))
+                .setQuery(boolQuery().must(QueryBuilders.hasChildQuery("child", termQuery("c_field", "red")).scoreMode(scoreMode)).filter(notQuery(termQuery("p_field", "3"))))
                 .get();
         assertNoFailures(searchResponse);
         assertThat(searchResponse.getHits().totalHits(), equalTo(2l));
@@ -1263,13 +1263,13 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         client().prepareIndex("test", "child", "c1").setSource("c_field", "1").setParent(parentId).get();
         refresh();
 
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreType(ScoreType.MAX).queryName("test"))
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreMode("max").queryName("test"))
                 .get();
         assertHitCount(searchResponse, 1l);
         assertThat(searchResponse.getHits().getAt(0).getMatchedQueries().length, equalTo(1));
         assertThat(searchResponse.getHits().getAt(0).getMatchedQueries()[0], equalTo("test"));
 
-        searchResponse = client().prepareSearch("test").setQuery(hasParentQuery("parent", termQuery("p_field", "1")).score(true).queryName("test"))
+        searchResponse = client().prepareSearch("test").setQuery(hasParentQuery("parent", termQuery("p_field", "1")).scoreMode("score").queryName("test"))
                 .get();
         assertHitCount(searchResponse, 1l);
         assertThat(searchResponse.getHits().getAt(0).getMatchedQueries().length, equalTo(1));
@@ -1311,7 +1311,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
 
         try {
             client().prepareSearch("test")
-                    .setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreType(ScoreType.MAX))
+                    .setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreMode("max"))
                     .get();
             fail();
         } catch (SearchPhaseExecutionException e) {
@@ -1329,7 +1329,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
 
         try {
             client().prepareSearch("test")
-                    .setQuery(hasParentQuery("parent", termQuery("p_field", "1")).score(true))
+                    .setQuery(hasParentQuery("parent", termQuery("p_field", "1")).scoreMode("score"))
                     .get();
             fail();
         } catch (SearchPhaseExecutionException e) {
@@ -1579,28 +1579,23 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         return indexBuilders;
     }
 
-    private SearchResponse minMaxQuery(ScoreType scoreType, int minChildren, int maxChildren) throws SearchPhaseExecutionException {
-        return client()
-                .prepareSearch("test")
-                .setQuery(
-                        QueryBuilders
-                                .hasChildQuery(
-                                        "child",
-                                        QueryBuilders.functionScoreQuery(constantScoreQuery(QueryBuilders.termQuery("foo", "two"))).boostMode("replace").scoreMode("sum")
-                                                .add(QueryBuilders.matchAllQuery(), weightFactorFunction(1))
-                                                .add(QueryBuilders.termQuery("foo", "three"), weightFactorFunction(1))
-                                                .add(QueryBuilders.termQuery("foo", "four"), weightFactorFunction(1))).scoreType(scoreType)
-                                .minChildren(minChildren).maxChildren(maxChildren))
-                .addSort("_score", SortOrder.DESC).addSort("id", SortOrder.ASC).get();
-    }
+    private SearchResponse minMaxQuery(String scoreMode, int minChildren, Integer maxChildren) throws SearchPhaseExecutionException {
+        HasChildQueryBuilder hasChildQuery = hasChildQuery(
+                "child",
+                QueryBuilders.functionScoreQuery(constantScoreQuery(QueryBuilders.termQuery("foo", "two"))).boostMode("replace").scoreMode("sum")
+                        .add(QueryBuilders.matchAllQuery(), weightFactorFunction(1))
+                        .add(QueryBuilders.termQuery("foo", "three"), weightFactorFunction(1))
+                        .add(QueryBuilders.termQuery("foo", "four"), weightFactorFunction(1))).scoreMode(scoreMode)
+                .minChildren(minChildren);
+
+        if (maxChildren != null) {
+            hasChildQuery.maxChildren(maxChildren);
+        }
 
-    private SearchResponse minMaxFilter(int minChildren, int maxChildren) throws SearchPhaseExecutionException {
         return client()
                 .prepareSearch("test")
-                .setQuery(
-                        QueryBuilders.constantScoreQuery(QueryBuilders.hasChildQuery("child", termQuery("foo", "two"))
-                                .minChildren(minChildren).maxChildren(maxChildren)))
-                .addSort("id", SortOrder.ASC).setTrackScores(true).get();
+                .setQuery(hasChildQuery)
+                .addSort("_score", SortOrder.DESC).addSort("id", SortOrder.ASC).get();
     }
 
     @Test
@@ -1614,7 +1609,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         SearchResponse response;
 
         // Score mode = NONE
-        response = minMaxQuery(ScoreType.NONE, 0, 0);
+        response = minMaxQuery("none", 0, null);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("2"));
@@ -1624,7 +1619,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("4"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.NONE, 1, 0);
+        response = minMaxQuery("none", 1, null);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("2"));
@@ -1634,7 +1629,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("4"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.NONE, 2, 0);
+        response = minMaxQuery("none", 2, null);
 
         assertThat(response.getHits().totalHits(), equalTo(2l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
@@ -1642,17 +1637,17 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[1].id(), equalTo("4"));
         assertThat(response.getHits().hits()[1].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.NONE, 3, 0);
+        response = minMaxQuery("none", 3, null);
 
         assertThat(response.getHits().totalHits(), equalTo(1l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
         assertThat(response.getHits().hits()[0].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.NONE, 4, 0);
+        response = minMaxQuery("none", 4, null);
 
         assertThat(response.getHits().totalHits(), equalTo(0l));
 
-        response = minMaxQuery(ScoreType.NONE, 0, 4);
+        response = minMaxQuery("none", 0, 4);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("2"));
@@ -1662,7 +1657,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("4"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.NONE, 0, 3);
+        response = minMaxQuery("none", 0, 3);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("2"));
@@ -1672,7 +1667,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("4"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.NONE, 0, 2);
+        response = minMaxQuery("none", 0, 2);
 
         assertThat(response.getHits().totalHits(), equalTo(2l));
         assertThat(response.getHits().hits()[0].id(), equalTo("2"));
@@ -1680,21 +1675,21 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[1].id(), equalTo("3"));
         assertThat(response.getHits().hits()[1].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.NONE, 2, 2);
+        response = minMaxQuery("none", 2, 2);
 
         assertThat(response.getHits().totalHits(), equalTo(1l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
         assertThat(response.getHits().hits()[0].score(), equalTo(1f));
 
         try {
-            response = minMaxQuery(ScoreType.NONE, 3, 2);
+            response = minMaxQuery("none", 3, 2);
             fail();
         } catch (SearchPhaseExecutionException e) {
             assertThat(e.toString(), containsString("[has_child] 'max_children' is less than 'min_children'"));
         }
 
-        // Score mode = SUM
-        response = minMaxQuery(ScoreType.SUM, 0, 0);
+        // Score mode = TOTAL
+        response = minMaxQuery("total", 0, null);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1704,7 +1699,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.SUM, 1, 0);
+        response = minMaxQuery("total", 1, null);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1714,7 +1709,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.SUM, 2, 0);
+        response = minMaxQuery("total", 2, null);
 
         assertThat(response.getHits().totalHits(), equalTo(2l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1722,17 +1717,17 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[1].id(), equalTo("3"));
         assertThat(response.getHits().hits()[1].score(), equalTo(3f));
 
-        response = minMaxQuery(ScoreType.SUM, 3, 0);
+        response = minMaxQuery("total", 3, null);
 
         assertThat(response.getHits().totalHits(), equalTo(1l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
         assertThat(response.getHits().hits()[0].score(), equalTo(6f));
 
-        response = minMaxQuery(ScoreType.SUM, 4, 0);
+        response = minMaxQuery("total", 4, null);
 
         assertThat(response.getHits().totalHits(), equalTo(0l));
 
-        response = minMaxQuery(ScoreType.SUM, 0, 4);
+        response = minMaxQuery("total", 0, 4);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1742,7 +1737,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.SUM, 0, 3);
+        response = minMaxQuery("total", 0, 3);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1752,7 +1747,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.SUM, 0, 2);
+        response = minMaxQuery("total", 0, 2);
 
         assertThat(response.getHits().totalHits(), equalTo(2l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
@@ -1760,21 +1755,21 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[1].id(), equalTo("2"));
         assertThat(response.getHits().hits()[1].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.SUM, 2, 2);
+        response = minMaxQuery("total", 2, 2);
 
         assertThat(response.getHits().totalHits(), equalTo(1l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
         assertThat(response.getHits().hits()[0].score(), equalTo(3f));
 
         try {
-            response = minMaxQuery(ScoreType.SUM, 3, 2);
+            response = minMaxQuery("total", 3, 2);
             fail();
         } catch (SearchPhaseExecutionException e) {
             assertThat(e.toString(), containsString("[has_child] 'max_children' is less than 'min_children'"));
         }
 
         // Score mode = MAX
-        response = minMaxQuery(ScoreType.MAX, 0, 0);
+        response = minMaxQuery("max", 0, null);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1784,7 +1779,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.MAX, 1, 0);
+        response = minMaxQuery("max", 1, null);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1794,7 +1789,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.MAX, 2, 0);
+        response = minMaxQuery("max", 2, null);
 
         assertThat(response.getHits().totalHits(), equalTo(2l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1802,17 +1797,17 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[1].id(), equalTo("3"));
         assertThat(response.getHits().hits()[1].score(), equalTo(2f));
 
-        response = minMaxQuery(ScoreType.MAX, 3, 0);
+        response = minMaxQuery("max", 3, null);
 
         assertThat(response.getHits().totalHits(), equalTo(1l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
         assertThat(response.getHits().hits()[0].score(), equalTo(3f));
 
-        response = minMaxQuery(ScoreType.MAX, 4, 0);
+        response = minMaxQuery("max", 4, null);
 
         assertThat(response.getHits().totalHits(), equalTo(0l));
 
-        response = minMaxQuery(ScoreType.MAX, 0, 4);
+        response = minMaxQuery("max", 0, 4);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1822,7 +1817,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.MAX, 0, 3);
+        response = minMaxQuery("max", 0, 3);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1832,7 +1827,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.MAX, 0, 2);
+        response = minMaxQuery("max", 0, 2);
 
         assertThat(response.getHits().totalHits(), equalTo(2l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
@@ -1840,21 +1835,21 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[1].id(), equalTo("2"));
         assertThat(response.getHits().hits()[1].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.MAX, 2, 2);
+        response = minMaxQuery("max", 2, 2);
 
         assertThat(response.getHits().totalHits(), equalTo(1l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
         assertThat(response.getHits().hits()[0].score(), equalTo(2f));
 
         try {
-            response = minMaxQuery(ScoreType.MAX, 3, 2);
+            response = minMaxQuery("max", 3, 2);
             fail();
         } catch (SearchPhaseExecutionException e) {
             assertThat(e.toString(), containsString("[has_child] 'max_children' is less than 'min_children'"));
         }
 
         // Score mode = AVG
-        response = minMaxQuery(ScoreType.AVG, 0, 0);
+        response = minMaxQuery("avg", 0, null);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1864,7 +1859,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.AVG, 1, 0);
+        response = minMaxQuery("avg", 1, null);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1874,7 +1869,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.AVG, 2, 0);
+        response = minMaxQuery("avg", 2, null);
 
         assertThat(response.getHits().totalHits(), equalTo(2l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1882,17 +1877,17 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[1].id(), equalTo("3"));
         assertThat(response.getHits().hits()[1].score(), equalTo(1.5f));
 
-        response = minMaxQuery(ScoreType.AVG, 3, 0);
+        response = minMaxQuery("avg", 3, null);
 
         assertThat(response.getHits().totalHits(), equalTo(1l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
         assertThat(response.getHits().hits()[0].score(), equalTo(2f));
 
-        response = minMaxQuery(ScoreType.AVG, 4, 0);
+        response = minMaxQuery("avg", 4, null);
 
         assertThat(response.getHits().totalHits(), equalTo(0l));
 
-        response = minMaxQuery(ScoreType.AVG, 0, 4);
+        response = minMaxQuery("avg", 0, 4);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1902,7 +1897,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.AVG, 0, 3);
+        response = minMaxQuery("avg", 0, 3);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1912,7 +1907,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.AVG, 0, 2);
+        response = minMaxQuery("avg", 0, 2);
 
         assertThat(response.getHits().totalHits(), equalTo(2l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
@@ -1920,99 +1915,18 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[1].id(), equalTo("2"));
         assertThat(response.getHits().hits()[1].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.AVG, 2, 2);
+        response = minMaxQuery("avg", 2, 2);
 
         assertThat(response.getHits().totalHits(), equalTo(1l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
         assertThat(response.getHits().hits()[0].score(), equalTo(1.5f));
 
         try {
-            response = minMaxQuery(ScoreType.AVG, 3, 2);
+            response = minMaxQuery("avg", 3, 2);
             fail();
         } catch (SearchPhaseExecutionException e) {
             assertThat(e.toString(), containsString("[has_child] 'max_children' is less than 'min_children'"));
         }
-
-        // HasChildFilter
-        response = minMaxFilter(0, 0);
-
-        assertThat(response.getHits().totalHits(), equalTo(3l));
-        assertThat(response.getHits().hits()[0].id(), equalTo("2"));
-        assertThat(response.getHits().hits()[0].score(), equalTo(1f));
-        assertThat(response.getHits().hits()[1].id(), equalTo("3"));
-        assertThat(response.getHits().hits()[1].score(), equalTo(1f));
-        assertThat(response.getHits().hits()[2].id(), equalTo("4"));
-        assertThat(response.getHits().hits()[2].score(), equalTo(1f));
-
-        response = minMaxFilter(1, 0);
-
-        assertThat(response.getHits().totalHits(), equalTo(3l));
-        assertThat(response.getHits().hits()[0].id(), equalTo("2"));
-        assertThat(response.getHits().hits()[0].score(), equalTo(1f));
-        assertThat(response.getHits().hits()[1].id(), equalTo("3"));
-        assertThat(response.getHits().hits()[1].score(), equalTo(1f));
-        assertThat(response.getHits().hits()[2].id(), equalTo("4"));
-        assertThat(response.getHits().hits()[2].score(), equalTo(1f));
-
-        response = minMaxFilter(2, 0);
-
-        assertThat(response.getHits().totalHits(), equalTo(2l));
-        assertThat(response.getHits().hits()[0].id(), equalTo("3"));
-        assertThat(response.getHits().hits()[0].score(), equalTo(1f));
-        assertThat(response.getHits().hits()[1].id(), equalTo("4"));
-        assertThat(response.getHits().hits()[1].score(), equalTo(1f));
-
-        response = minMaxFilter(3, 0);
-
-        assertThat(response.getHits().totalHits(), equalTo(1l));
-        assertThat(response.getHits().hits()[0].id(), equalTo("4"));
-        assertThat(response.getHits().hits()[0].score(), equalTo(1f));
-
-        response = minMaxFilter(4, 0);
-
-        assertThat(response.getHits().totalHits(), equalTo(0l));
-
-        response = minMaxFilter(0, 4);
-
-        assertThat(response.getHits().totalHits(), equalTo(3l));
-        assertThat(response.getHits().hits()[0].id(), equalTo("2"));
-        assertThat(response.getHits().hits()[0].score(), equalTo(1f));
-        assertThat(response.getHits().hits()[1].id(), equalTo("3"));
-        assertThat(response.getHits().hits()[1].score(), equalTo(1f));
-        assertThat(response.getHits().hits()[2].id(), equalTo("4"));
-        assertThat(response.getHits().hits()[2].score(), equalTo(1f));
-
-        response = minMaxFilter(0, 3);
-
-        assertThat(response.getHits().totalHits(), equalTo(3l));
-        assertThat(response.getHits().hits()[0].id(), equalTo("2"));
-        assertThat(response.getHits().hits()[0].score(), equalTo(1f));
-        assertThat(response.getHits().hits()[1].id(), equalTo("3"));
-        assertThat(response.getHits().hits()[1].score(), equalTo(1f));
-        assertThat(response.getHits().hits()[2].id(), equalTo("4"));
-        assertThat(response.getHits().hits()[2].score(), equalTo(1f));
-
-        response = minMaxFilter(0, 2);
-
-        assertThat(response.getHits().totalHits(), equalTo(2l));
-        assertThat(response.getHits().hits()[0].id(), equalTo("2"));
-        assertThat(response.getHits().hits()[0].score(), equalTo(1f));
-        assertThat(response.getHits().hits()[1].id(), equalTo("3"));
-        assertThat(response.getHits().hits()[1].score(), equalTo(1f));
-
-        response = minMaxFilter(2, 2);
-
-        assertThat(response.getHits().totalHits(), equalTo(1l));
-        assertThat(response.getHits().hits()[0].id(), equalTo("3"));
-        assertThat(response.getHits().hits()[0].score(), equalTo(1f));
-
-        try {
-            response = minMaxFilter(3, 2);
-            fail();
-        } catch (SearchPhaseExecutionException e) {
-            assertThat(e.toString(), containsString("[has_child] 'max_children' is less than 'min_children'"));
-        }
-
     }
 
     @Test
diff --git a/core/src/test/java/org/elasticsearch/search/functionscore/DecayFunctionScoreIT.java b/core/src/test/java/org/elasticsearch/search/functionscore/DecayFunctionScoreIT.java
index 2d2d728..e285970 100644
--- a/core/src/test/java/org/elasticsearch/search/functionscore/DecayFunctionScoreIT.java
+++ b/core/src/test/java/org/elasticsearch/search/functionscore/DecayFunctionScoreIT.java
@@ -53,6 +53,7 @@ import static org.elasticsearch.search.builder.SearchSourceBuilder.searchSource;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
 import static org.hamcrest.Matchers.*;
 
+
 public class DecayFunctionScoreIT extends ESIntegTestCase {
 
     @Test
@@ -348,7 +349,7 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         SearchHits sh = sr.getHits();
         assertThat(sh.getTotalHits(), equalTo((long) (1)));
         assertThat(sh.getAt(0).getId(), equalTo("1"));
-        assertThat((double) sh.getAt(0).score(), closeTo(0.30685282, 1.e-5));
+        assertThat((double) sh.getAt(0).score(), closeTo(0.153426408, 1.e-5));
 
         response = client().search(
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
@@ -359,7 +360,7 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         sh = sr.getHits();
         assertThat(sh.getTotalHits(), equalTo((long) (1)));
         assertThat(sh.getAt(0).getId(), equalTo("1"));
-        assertThat((double) sh.getAt(0).score(), closeTo(1.0, 1.e-5));
+        assertThat((double) sh.getAt(0).score(), closeTo(0.5, 1.e-5));
 
         response = client().search(
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
@@ -370,7 +371,7 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         sh = sr.getHits();
         assertThat(sh.getTotalHits(), equalTo((long) (1)));
         assertThat(sh.getAt(0).getId(), equalTo("1"));
-        assertThat((double) sh.getAt(0).score(), closeTo(2.0 * (0.30685282 + 0.5), 1.e-5));
+        assertThat((double) sh.getAt(0).score(), closeTo(0.30685282 + 0.5, 1.e-5));
         logger.info("--> Hit[0] {} Explanation:\n {}", sr.getHits().getAt(0).id(), sr.getHits().getAt(0).explanation());
 
         response = client().search(
@@ -382,7 +383,7 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         sh = sr.getHits();
         assertThat(sh.getTotalHits(), equalTo((long) (1)));
         assertThat(sh.getAt(0).getId(), equalTo("1"));
-        assertThat((double) sh.getAt(0).score(), closeTo((0.30685282 + 0.5), 1.e-5));
+        assertThat((double) sh.getAt(0).score(), closeTo((0.30685282 + 0.5) / 2, 1.e-5));
 
         response = client().search(
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
@@ -393,7 +394,7 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         sh = sr.getHits();
         assertThat(sh.getTotalHits(), equalTo((long) (1)));
         assertThat(sh.getAt(0).getId(), equalTo("1"));
-        assertThat((double) sh.getAt(0).score(), closeTo(2.0 * (0.30685282), 1.e-5));
+        assertThat((double) sh.getAt(0).score(), closeTo(0.30685282, 1.e-5));
 
         response = client().search(
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
@@ -404,7 +405,7 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         sh = sr.getHits();
         assertThat(sh.getTotalHits(), equalTo((long) (1)));
         assertThat(sh.getAt(0).getId(), equalTo("1"));
-        assertThat((double) sh.getAt(0).score(), closeTo(1.0, 1.e-5));
+        assertThat((double) sh.getAt(0).score(), closeTo(0.5, 1.e-5));
 
     }
 
@@ -797,21 +798,8 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         refresh();
 
         XContentBuilder query = XContentFactory.jsonBuilder();
-        // query that contains a functions[] array but also a single function
-        query.startObject().startObject("function_score").startArray("functions").startObject().field("boost_factor", "1.3").endObject().endArray().field("boost_factor", "1").endObject().endObject();
-        try {
-            client().search(
-                    searchRequest().source(
-                            searchSource().query(query))).actionGet();
-            fail("Search should result in SearchPhaseExecutionException");
-        } catch (SearchPhaseExecutionException e) {
-            logger.info(e.shardFailures()[0].reason());
-            assertThat(e.shardFailures()[0].reason(), containsString("already found [functions] array, now encountering [boost_factor]. did you mean [boost] instead?"));
-        }
-
-        query = XContentFactory.jsonBuilder();
         // query that contains a single function and a functions[] array
-        query.startObject().startObject("function_score").field("boost_factor", "1").startArray("functions").startObject().field("boost_factor", "1.3").endObject().endArray().endObject().endObject();
+        query.startObject().startObject("function_score").field("weight", "1").startArray("functions").startObject().startObject("script_score").field("script", "3").endObject().endObject().endArray().endObject().endObject();
         try {
             client().search(
                     searchRequest().source(
@@ -819,7 +807,7 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
             fail("Search should result in SearchPhaseExecutionException");
         } catch (SearchPhaseExecutionException e) {
             logger.info(e.shardFailures()[0].reason());
-            assertThat(e.shardFailures()[0].reason(), containsString("already found [boost_factor], now encountering [functions]. did you mean [boost] instead?"));
+            assertThat(e.shardFailures()[0].reason(), containsString("already found [weight], now encountering [functions]."));
         }
 
         query = XContentFactory.jsonBuilder();
@@ -887,7 +875,7 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
                 "              \"text\": \"baseball\"\n" +
                 "            }\n" +
                 "          },\n" +
-                "          \"boost_factor\": 2\n" +
+                "          \"weight\": 2\n" +
                 "        },\n" +
                 "        {\n" +
                 "          \"filter\": {\n" +
diff --git a/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreIT.java b/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreIT.java
index 7e13816..9db8b98 100644
--- a/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreIT.java
+++ b/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreIT.java
@@ -178,7 +178,7 @@ public class FunctionScoreIT extends ESIntegTestCase {
 
         assertThat(
                 responseWithWeights.getHits().getAt(0).getExplanation().toString(),
-                equalTo("6.0 = function score, product of:\n  1.0 = ConstantScore(text_field:value), product of:\n    1.0 = boost\n    1.0 = queryNorm\n  6.0 = min of:\n    6.0 = function score, score mode [multiply]\n      1.0 = function score, product of:\n        1.0 = match filter: *:*\n        1.0 = Function for field geo_point_field:\n          1.0 = exp(-0.5*pow(MIN of: [Math.max(arcDistance([10.0, 20.0](=doc value),[10.0, 20.0](=origin)) - 0.0(=offset), 0)],2.0)/7.213475204444817E11)\n      2.0 = function score, product of:\n        1.0 = match filter: *:*\n        2.0 = product of:\n          1.0 = field value function: ln(doc['double_field'].value * factor=1.0)\n          2.0 = weight\n      3.0 = function score, product of:\n        1.0 = match filter: *:*\n        3.0 = product of:\n          1.0 = script score function, computed with script:\"[script: _index['text_field']['value'].tf(), type: inline, lang: null, params: null]\n            1.0 = _score: \n              1.0 = ConstantScore(text_field:value), product of:\n                1.0 = boost\n                1.0 = queryNorm\n          3.0 = weight\n    3.4028235E38 = maxBoost\n  1.0 = queryBoost\n"));
+                equalTo("6.0 = function score, product of:\n  1.0 = ConstantScore(text_field:value), product of:\n    1.0 = boost\n    1.0 = queryNorm\n  6.0 = min of:\n    6.0 = function score, score mode [multiply]\n      1.0 = function score, product of:\n        1.0 = match filter: *:*\n        1.0 = Function for field geo_point_field:\n          1.0 = exp(-0.5*pow(MIN of: [Math.max(arcDistance([10.0, 20.0](=doc value),[10.0, 20.0](=origin)) - 0.0(=offset), 0)],2.0)/7.213475204444817E11)\n      2.0 = function score, product of:\n        1.0 = match filter: *:*\n        2.0 = product of:\n          1.0 = field value function: ln(doc['double_field'].value * factor=1.0)\n          2.0 = weight\n      3.0 = function score, product of:\n        1.0 = match filter: *:*\n        3.0 = product of:\n          1.0 = script score function, computed with script:\"[script: _index['text_field']['value'].tf(), type: inline, lang: null, params: null]\n            1.0 = _score: \n              1.0 = ConstantScore(text_field:value), product of:\n                1.0 = boost\n                1.0 = queryNorm\n          3.0 = weight\n    3.4028235E38 = maxBoost\n"));
         responseWithWeights = client().search(
                 searchRequest().source(
                         searchSource().query(
@@ -186,7 +186,7 @@ public class FunctionScoreIT extends ESIntegTestCase {
                                 .explain(true))).actionGet();
         assertThat(
                 responseWithWeights.getHits().getAt(0).getExplanation().toString(),
-                equalTo("4.0 = function score, product of:\n  1.0 = ConstantScore(text_field:value), product of:\n    1.0 = boost\n    1.0 = queryNorm\n  4.0 = min of:\n    4.0 = product of:\n      1.0 = constant score 1.0 - no function provided\n      4.0 = weight\n    3.4028235E38 = maxBoost\n  1.0 = queryBoost\n"));
+                equalTo("4.0 = function score, product of:\n  1.0 = ConstantScore(text_field:value), product of:\n    1.0 = boost\n    1.0 = queryNorm\n  4.0 = min of:\n    4.0 = product of:\n      1.0 = constant score 1.0 - no function provided\n      4.0 = weight\n    3.4028235E38 = maxBoost\n"));
 
     }
 
diff --git a/core/src/test/java/org/elasticsearch/search/geo/GeoShapeIntegrationIT.java b/core/src/test/java/org/elasticsearch/search/geo/GeoShapeIntegrationIT.java
index 33593e9..5607266 100644
--- a/core/src/test/java/org/elasticsearch/search/geo/GeoShapeIntegrationIT.java
+++ b/core/src/test/java/org/elasticsearch/search/geo/GeoShapeIntegrationIT.java
@@ -49,10 +49,7 @@ import static org.elasticsearch.index.query.QueryBuilders.geoShapeQuery;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchResponse;
-import static org.hamcrest.Matchers.containsString;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.nullValue;
+import static org.hamcrest.Matchers.*;
 
 public class GeoShapeIntegrationIT extends ESIntegTestCase {
 
@@ -289,28 +286,28 @@ public class GeoShapeIntegrationIT extends ESIntegTestCase {
                         .endObject().endObject()));
         ensureSearchable("test", "shapes");
 
-        GeoShapeQueryBuilder filter = QueryBuilders.geoShapeQuery("location", "1", "type").relation(ShapeRelation.INTERSECTS)
+        GeoShapeQueryBuilder filter = QueryBuilders.geoShapeQuery("location", "1", "type", ShapeRelation.INTERSECTS)
                 .indexedShapeIndex("shapes")
                 .indexedShapePath("location");
         SearchResponse result = client().prepareSearch("test").setQuery(QueryBuilders.matchAllQuery())
                 .setPostFilter(filter).get();
         assertSearchResponse(result);
         assertHitCount(result, 1);
-        filter = QueryBuilders.geoShapeQuery("location", "1", "type").relation(ShapeRelation.INTERSECTS)
+        filter = QueryBuilders.geoShapeQuery("location", "1", "type", ShapeRelation.INTERSECTS)
                 .indexedShapeIndex("shapes")
                 .indexedShapePath("1.location");
         result = client().prepareSearch("test").setQuery(QueryBuilders.matchAllQuery())
                 .setPostFilter(filter).get();
         assertSearchResponse(result);
         assertHitCount(result, 1);
-        filter = QueryBuilders.geoShapeQuery("location", "1", "type").relation(ShapeRelation.INTERSECTS)
+        filter = QueryBuilders.geoShapeQuery("location", "1", "type", ShapeRelation.INTERSECTS)
                 .indexedShapeIndex("shapes")
                 .indexedShapePath("1.2.location");
         result = client().prepareSearch("test").setQuery(QueryBuilders.matchAllQuery())
                 .setPostFilter(filter).get();
         assertSearchResponse(result);
         assertHitCount(result, 1);
-        filter = QueryBuilders.geoShapeQuery("location", "1", "type").relation(ShapeRelation.INTERSECTS)
+        filter = QueryBuilders.geoShapeQuery("location", "1", "type", ShapeRelation.INTERSECTS)
                 .indexedShapeIndex("shapes")
                 .indexedShapePath("1.2.3.location");
         result = client().prepareSearch("test").setQuery(QueryBuilders.matchAllQuery())
@@ -363,8 +360,7 @@ public class GeoShapeIntegrationIT extends ESIntegTestCase {
 
         ShapeBuilder filterShape = (gcb.getShapeAt(randomIntBetween(0, gcb.numShapes() - 1)));
 
-        GeoShapeQueryBuilder filter = QueryBuilders.geoShapeQuery("location", filterShape);
-        filter.relation(ShapeRelation.INTERSECTS);
+        GeoShapeQueryBuilder filter = QueryBuilders.geoShapeQuery("location", filterShape, ShapeRelation.INTERSECTS);
         SearchResponse result = client().prepareSearch("test").setQuery(QueryBuilders.matchAllQuery())
                 .setPostFilter(filter).get();
         assertSearchResponse(result);
@@ -403,30 +399,19 @@ public class GeoShapeIntegrationIT extends ESIntegTestCase {
                 .setSource(docSource));
         ensureSearchable("test");
 
-        GeoShapeQueryBuilder filter = QueryBuilders.geoShapeQuery(
-                "location",
-                ShapeBuilder.newGeometryCollection()
-                        .polygon(
-                                ShapeBuilder.newPolygon().point(99.0, -1.0).point(99.0, 3.0).point(103.0, 3.0).point(103.0, -1.0)
-                                        .point(99.0, -1.0))).relation(ShapeRelation.INTERSECTS);
+        GeoShapeQueryBuilder filter = QueryBuilders.geoShapeQuery("location", ShapeBuilder.newGeometryCollection().polygon(ShapeBuilder.newPolygon().point(99.0, -1.0).point(99.0, 3.0).point(103.0, 3.0).point(103.0, -1.0).point(99.0, -1.0)), ShapeRelation.INTERSECTS);
         SearchResponse result = client().prepareSearch("test").setQuery(QueryBuilders.matchAllQuery())
                 .setPostFilter(filter).get();
         assertSearchResponse(result);
         assertHitCount(result, 1);
-        filter = QueryBuilders.geoShapeQuery(
-                "location",
-                ShapeBuilder.newGeometryCollection().polygon(
-                        ShapeBuilder.newPolygon().point(199.0, -11.0).point(199.0, 13.0).point(193.0, 13.0).point(193.0, -11.0)
-                                .point(199.0, -11.0))).relation(ShapeRelation.INTERSECTS);
+        filter = QueryBuilders.geoShapeQuery("location", ShapeBuilder.newGeometryCollection().polygon(ShapeBuilder.newPolygon().point(199.0, -11.0).point(199.0, 13.0).point(193.0, 13.0).point(193.0, -11.0).point(199.0, -11.0)), ShapeRelation.INTERSECTS);
         result = client().prepareSearch("test").setQuery(QueryBuilders.matchAllQuery())
                 .setPostFilter(filter).get();
         assertSearchResponse(result);
         assertHitCount(result, 0);
         filter = QueryBuilders.geoShapeQuery("location", ShapeBuilder.newGeometryCollection()
                 .polygon(ShapeBuilder.newPolygon().point(99.0, -1.0).point(99.0, 3.0).point(103.0, 3.0).point(103.0, -1.0).point(99.0, -1.0))
-                        .polygon(
-                                ShapeBuilder.newPolygon().point(199.0, -11.0).point(199.0, 13.0).point(193.0, 13.0).point(193.0, -11.0)
-                                        .point(199.0, -11.0))).relation(ShapeRelation.INTERSECTS);
+                .polygon(ShapeBuilder.newPolygon().point(199.0, -11.0).point(199.0, 13.0).point(193.0, 13.0).point(193.0, -11.0).point(199.0, -11.0)), ShapeRelation.INTERSECTS);
         result = client().prepareSearch("test").setQuery(QueryBuilders.matchAllQuery())
                 .setPostFilter(filter).get();
         assertSearchResponse(result);
diff --git a/core/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchIT.java b/core/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchIT.java
index a6b5876..05947e1 100644
--- a/core/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchIT.java
+++ b/core/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchIT.java
@@ -27,11 +27,11 @@ import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.common.settings.Settings.Builder;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.query.*;
+import org.elasticsearch.index.query.BoostableQueryBuilder;
 import org.elasticsearch.index.query.IdsQueryBuilder;
 import org.elasticsearch.index.query.MatchQueryBuilder;
-import org.elasticsearch.index.search.MatchQuery.Type;
-import org.elasticsearch.index.search.MatchQuery;
+import org.elasticsearch.index.query.MatchQueryBuilder.Operator;
+import org.elasticsearch.index.query.MatchQueryBuilder.Type;
 import org.elasticsearch.index.query.MultiMatchQueryBuilder;
 import org.elasticsearch.index.query.QueryBuilder;
 import org.elasticsearch.index.query.QueryBuilders;
@@ -70,7 +70,12 @@ import static org.elasticsearch.index.query.QueryBuilders.typeQuery;
 import static org.elasticsearch.index.query.QueryBuilders.wildcardQuery;
 import static org.elasticsearch.search.builder.SearchSourceBuilder.highlight;
 import static org.elasticsearch.search.builder.SearchSourceBuilder.searchSource;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertFailures;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHighlight;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNotHighlighted;
 import static org.elasticsearch.test.hamcrest.RegexMatcher.matches;
 import static org.hamcrest.Matchers.anyOf;
 import static org.hamcrest.Matchers.containsString;
@@ -964,12 +969,12 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         assertHighlight(resp, 0, "foo", 0, equalTo("junk junk <em>cats</em> junk junk"));
 
         // which can also be written by searching on the subfield
-        resp = req.setQuery(queryStringQuery("cats").field("foo").field("foo.plain", 5)).get();
+        resp = req.setQuery(queryStringQuery("cats").field("foo").field("foo.plain^5")).get();
         assertHighlight(resp, 0, "foo", 0, equalTo("junk junk <em>cats</em> junk junk"));
 
         // Speaking of two fields, you can have two fields, only one of which has matchedFields enabled
-        QueryBuilder twoFieldsQuery = queryStringQuery("cats").field("foo").field("foo.plain", 5)
-                .field("bar").field("bar.plain", 5);
+        QueryBuilder twoFieldsQuery = queryStringQuery("cats").field("foo").field("foo.plain^5")
+                .field("bar").field("bar.plain^5");
         resp = req.setQuery(twoFieldsQuery).addHighlightedField(barField).get();
         assertHighlight(resp, 0, "foo", 0, equalTo("junk junk <em>cats</em> junk junk"));
         assertHighlight(resp, 0, "bar", 0, equalTo("<em>cat</em> <em>cat</em> junk junk junk junk"));
@@ -1391,7 +1396,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource()
-                .query(boostingQuery(termQuery("field2", "brown"), termQuery("field2", "foobar")).negativeBoost(0.5f))
+                .query(boostingQuery().positive(termQuery("field2", "brown")).negative(termQuery("field2", "foobar")).negativeBoost(0.5f))
                 .highlight(highlight().field("field2").order("score").preTags("<x>").postTags("</x>"));
 
         SearchResponse searchResponse = client().prepareSearch("test").setSource(source.buildAsBytes()).get();
@@ -1410,7 +1415,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource()
-                .query(boostingQuery(termQuery("field2", "brown"), termQuery("field2", "foobar")).negativeBoost(0.5f))
+                .query(boostingQuery().positive(termQuery("field2", "brown")).negative(termQuery("field2", "foobar")).negativeBoost(0.5f))
                 .highlight(highlight().field("field2").order("score").preTags("<x>").postTags("</x>"));
 
         SearchResponse searchResponse = client().prepareSearch("test").setSource(source.buildAsBytes()).get();
@@ -1536,7 +1541,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         refresh();
 
         SearchResponse response = client().prepareSearch("test")
-                .setQuery(QueryBuilders.matchQuery("tags", "long tag").type(MatchQuery.Type.PHRASE))
+                .setQuery(QueryBuilders.matchQuery("tags", "long tag").type(MatchQueryBuilder.Type.PHRASE))
                 .addHighlightedField(new HighlightBuilder.Field("tags")
                         .fragmentSize(-1).numOfFragments(2).fragmenter("simple")).get();
 
@@ -1544,7 +1549,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         assertHighlight(response, 0, "tags", 1, 2, equalTo("here is another one that is very <em>long</em> <em>tag</em> and has the <em>tag</em> token near the end"));
 
         response = client().prepareSearch("test")
-                .setQuery(QueryBuilders.matchQuery("tags", "long tag").type(MatchQuery.Type.PHRASE))
+                .setQuery(QueryBuilders.matchQuery("tags", "long tag").type(MatchQueryBuilder.Type.PHRASE))
                 .addHighlightedField(new HighlightBuilder.Field("tags")
                         .fragmentSize(-1).numOfFragments(2).fragmenter("span")).get();
 
@@ -1552,7 +1557,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         assertHighlight(response, 0, "tags", 1, 2, equalTo("here is another one that is very <em>long</em> <em>tag</em> and has the <em>tag</em> token near the end"));
 
         assertFailures(client().prepareSearch("test")
-                        .setQuery(QueryBuilders.matchQuery("tags", "long tag").type(MatchQuery.Type.PHRASE))
+                        .setQuery(QueryBuilders.matchQuery("tags", "long tag").type(MatchQueryBuilder.Type.PHRASE))
                         .addHighlightedField(new HighlightBuilder.Field("tags")
                                 .fragmentSize(-1).numOfFragments(2).fragmenter("invalid")),
                 RestStatus.BAD_REQUEST,
@@ -1607,7 +1612,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         // This query used to fail when the field to highlight was absent
         SearchResponse response = client().prepareSearch("test")
-                .setQuery(QueryBuilders.matchQuery("field", "highlight").type(MatchQuery.Type.BOOLEAN))
+                .setQuery(QueryBuilders.matchQuery("field", "highlight").type(MatchQueryBuilder.Type.BOOLEAN))
                 .addHighlightedField(new HighlightBuilder.Field("highlight_field")
                         .fragmentSize(-1).numOfFragments(1).fragmenter("simple")).get();
         assertThat(response.getHits().hits()[0].highlightFields().isEmpty(), equalTo(true));
@@ -1627,7 +1632,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         refresh();
 
         SearchResponse response = client().prepareSearch("test")
-                .setQuery(QueryBuilders.matchQuery("text", "test").type(MatchQuery.Type.BOOLEAN))
+                .setQuery(QueryBuilders.matchQuery("text", "test").type(MatchQueryBuilder.Type.BOOLEAN))
                 .addHighlightedField("text")
                 .addHighlightedField("byte")
                 .addHighlightedField("short")
@@ -1657,7 +1662,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         refresh();
 
         SearchResponse response = client().prepareSearch("test")
-                .setQuery(QueryBuilders.matchQuery("text", "test").type(MatchQuery.Type.BOOLEAN))
+                .setQuery(QueryBuilders.matchQuery("text", "test").type(MatchQueryBuilder.Type.BOOLEAN))
                 .addHighlightedField("text").execute().actionGet();
         // PatternAnalyzer will throw an exception if it is resetted twice
         assertHitCount(response, 1l);
@@ -2324,7 +2329,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource()
-                .query(boostingQuery(termQuery("field2", "brown"), termQuery("field2", "foobar")).negativeBoost(0.5f))
+                .query(boostingQuery().positive(termQuery("field2", "brown")).negative(termQuery("field2", "foobar")).negativeBoost(0.5f))
                 .highlight(highlight().field("field2").preTags("<x>").postTags("</x>"));
         SearchResponse searchResponse = client().search(searchRequest("test").source(source)).actionGet();
 
@@ -2610,10 +2615,10 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         // Query string boosting the field
         phraseBoostTestCaseForClauses(highlighterType, 1f,
                 queryStringQuery("highlight words together").field("field1"),
-                queryStringQuery("\"highlight words together\"").field("field1", 100).autoGeneratePhraseQueries(true));
+                queryStringQuery("\"highlight words together\"").field("field1^100").autoGeneratePhraseQueries(true));
     }
 
-    private <P extends AbstractQueryBuilder<P>> void
+    private <P extends QueryBuilder & BoostableQueryBuilder<?>> void
             phraseBoostTestCaseForClauses(String highlighterType, float boost, QueryBuilder terms, P phrase) {
         Matcher<String> highlightedMatcher = Matchers.either(containsString("<em>highlight words together</em>")).or(
                 containsString("<em>highlight</em> <em>words</em> <em>together</em>"));
@@ -2627,10 +2632,10 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         assertHighlight(response, 0, "field1", 0, 1, highlightedMatcher);
         phrase.boost(1);
         // Try with a boosting query
-        response = search.setQuery(boostingQuery(phrase, terms).boost(boost).negativeBoost(1)).get();
+        response = search.setQuery(boostingQuery().positive(phrase).negative(terms).boost(boost).negativeBoost(1)).get();
         assertHighlight(response, 0, "field1", 0, 1, highlightedMatcher);
         // Try with a boosting query using a negative boost
-        response = search.setQuery(boostingQuery(phrase, terms).boost(1).negativeBoost(1/boost)).get();
+        response = search.setQuery(boostingQuery().positive(phrase).negative(terms).boost(1).negativeBoost(1/boost)).get();
         assertHighlight(response, 0, "field1", 0, 1, highlightedMatcher);
     }
 }
diff --git a/core/src/test/java/org/elasticsearch/search/innerhits/InnerHitsIT.java b/core/src/test/java/org/elasticsearch/search/innerhits/InnerHitsIT.java
index 16c54c4..ba43286 100644
--- a/core/src/test/java/org/elasticsearch/search/innerhits/InnerHitsIT.java
+++ b/core/src/test/java/org/elasticsearch/search/innerhits/InnerHitsIT.java
@@ -28,7 +28,7 @@ import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.index.query.BoolQueryBuilder;
-import org.elasticsearch.index.query.support.QueryInnerHits;
+import org.elasticsearch.index.query.support.QueryInnerHitBuilder;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.search.SearchHit;
 import org.elasticsearch.search.SearchHits;
@@ -88,9 +88,9 @@ public class InnerHitsIT extends ESIntegTestCase {
 
         // Inner hits can be defined in two ways: 1) with the query 2) as seperate inner_hit definition
         SearchRequest[] searchRequests = new SearchRequest[]{
-                client().prepareSearch("articles").setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHits("comment", null))).request(),
+                client().prepareSearch("articles").setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHitBuilder().setName("comment"))).request(),
                 client().prepareSearch("articles").setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")))
-                        .addNestedInnerHits("comment", "comments", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("comments.message", "fox"))).request()
+                        .addInnerHit("comment", new InnerHitsBuilder.InnerHit().setPath("comments").setQuery(matchQuery("comments.message", "fox"))).request()
         };
         for (SearchRequest searchRequest : searchRequests) {
             SearchResponse response = client().search(searchRequest).actionGet();
@@ -112,11 +112,11 @@ public class InnerHitsIT extends ESIntegTestCase {
         searchRequests = new SearchRequest[] {
                 client().prepareSearch("articles")
                         .setQuery(nestedQuery("comments", matchQuery("comments.message", "elephant")))
-                        .addNestedInnerHits("comment", "comments", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("comments.message", "elephant"))).request(),
+                        .addInnerHit("comment", new InnerHitsBuilder.InnerHit().setPath("comments").setQuery(matchQuery("comments.message", "elephant"))).request(),
                 client().prepareSearch("articles")
-                        .setQuery(nestedQuery("comments", matchQuery("comments.message", "elephant")).innerHit(new QueryInnerHits("comment", null))).request(),
+                        .setQuery(nestedQuery("comments", matchQuery("comments.message", "elephant")).innerHit(new QueryInnerHitBuilder().setName("comment"))).request(),
                 client().prepareSearch("articles")
-                        .setQuery(nestedQuery("comments", matchQuery("comments.message", "elephant")).innerHit(new QueryInnerHits("comment", new InnerHitsBuilder.InnerHit().addSort("_doc", SortOrder.DESC)))).request()
+                        .setQuery(nestedQuery("comments", matchQuery("comments.message", "elephant")).innerHit(new QueryInnerHitBuilder().setName("comment").addSort("_doc", SortOrder.DESC))).request()
         };
         for (SearchRequest searchRequest : searchRequests) {
             SearchResponse response = client().search(searchRequest).actionGet();
@@ -138,24 +138,24 @@ public class InnerHitsIT extends ESIntegTestCase {
             assertThat(innerHits.getAt(2).getNestedIdentity().getField().string(), equalTo("comments"));
             assertThat(innerHits.getAt(2).getNestedIdentity().getOffset(), equalTo(2));
         }
-        InnerHitsBuilder.InnerHit innerHit = new InnerHitsBuilder.InnerHit();
-        innerHit.highlightBuilder().field("comments.message");
-        innerHit.setExplain(true);
-        innerHit.addFieldDataField("comments.message");
-        innerHit.addScriptField("script", new Script("doc['comments.message'].value"));
-        innerHit.setSize(1);
+
         searchRequests = new SearchRequest[] {
                 client().prepareSearch("articles")
                         .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")))
-                        .addNestedInnerHits("comments", "comments", new InnerHitsBuilder.InnerHit()
+                        .addInnerHit("comments", new InnerHitsBuilder.InnerHit().setPath("comments")
                                 .setQuery(matchQuery("comments.message", "fox"))
                                 .addHighlightedField("comments.message")
                                 .setExplain(true)
                                 .addFieldDataField("comments.message")
-                                .addScriptField("script", new Script("doc['comments.message'].value"))
+                                        .addScriptField("script", new Script("doc['comments.message'].value"))
                                 .setSize(1)).request(),
                 client().prepareSearch("articles")
-                        .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHits(null, innerHit))).request()
+                        .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHitBuilder()
+                                .addHighlightedField("comments.message")
+                                .setExplain(true)
+                                .addFieldDataField("comments.message")
+                                                .addScriptField("script", new Script("doc['comments.message'].value"))
+                                .setSize(1))).request()
         };
 
         for (SearchRequest searchRequest : searchRequests) {
@@ -201,17 +201,17 @@ public class InnerHitsIT extends ESIntegTestCase {
             searchResponse = client().prepareSearch("idx")
                     .setSize(numDocs)
                     .addSort("_uid", SortOrder.ASC)
-                    .addNestedInnerHits("a", "field1", new InnerHitsBuilder.InnerHit().addSort("_doc", SortOrder.DESC).setSize(size)) // Sort order is DESC, because we reverse the inner objects during indexing!
-                    .addNestedInnerHits("b", "field2", new InnerHitsBuilder.InnerHit().addSort("_doc", SortOrder.DESC).setSize(size))
+                    .addInnerHit("a", new InnerHitsBuilder.InnerHit().setPath("field1").addSort("_doc", SortOrder.DESC).setSize(size)) // Sort order is DESC, because we reverse the inner objects during indexing!
+                    .addInnerHit("b", new InnerHitsBuilder.InnerHit().setPath("field2").addSort("_doc", SortOrder.DESC).setSize(size))
                     .get();
         } else {
             BoolQueryBuilder boolQuery = new BoolQueryBuilder();
             if (randomBoolean()) {
-                boolQuery.should(nestedQuery("field1", matchAllQuery()).innerHit(new QueryInnerHits("a", new InnerHitsBuilder.InnerHit().addSort("_doc", SortOrder.DESC).setSize(size))));
-                boolQuery.should(nestedQuery("field2", matchAllQuery()).innerHit(new QueryInnerHits("b", new InnerHitsBuilder.InnerHit().addSort("_doc", SortOrder.DESC).setSize(size))));
+                boolQuery.should(nestedQuery("field1", matchAllQuery()).innerHit(new QueryInnerHitBuilder().setName("a").addSort("_doc", SortOrder.DESC).setSize(size)));
+                boolQuery.should(nestedQuery("field2", matchAllQuery()).innerHit(new QueryInnerHitBuilder().setName("b").addSort("_doc", SortOrder.DESC).setSize(size)));
             } else {
-                boolQuery.should(constantScoreQuery(nestedQuery("field1", matchAllQuery()).innerHit(new QueryInnerHits("a", new InnerHitsBuilder.InnerHit().addSort("_doc", SortOrder.DESC).setSize(size)))));
-                boolQuery.should(constantScoreQuery(nestedQuery("field2", matchAllQuery()).innerHit(new QueryInnerHits("b", new InnerHitsBuilder.InnerHit().addSort("_doc", SortOrder.DESC).setSize(size)))));
+                boolQuery.should(constantScoreQuery(nestedQuery("field1", matchAllQuery()).innerHit(new QueryInnerHitBuilder().setName("a").addSort("_doc", SortOrder.DESC).setSize(size))));
+                boolQuery.should(constantScoreQuery(nestedQuery("field2", matchAllQuery()).innerHit(new QueryInnerHitBuilder().setName("b").addSort("_doc", SortOrder.DESC).setSize(size))));
             }
             searchResponse = client().prepareSearch("idx")
                     .setQuery(boolQuery)
@@ -267,10 +267,10 @@ public class InnerHitsIT extends ESIntegTestCase {
         SearchRequest[] searchRequests = new SearchRequest[]{
                 client().prepareSearch("articles")
                         .setQuery(hasChildQuery("comment", matchQuery("message", "fox")))
-                        .addParentChildInnerHits("comment", "comment", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("message", "fox")))
+                        .addInnerHit("comment", new InnerHitsBuilder.InnerHit().setType("comment").setQuery(matchQuery("message", "fox")))
                         .request(),
                 client().prepareSearch("articles")
-                        .setQuery(hasChildQuery("comment", matchQuery("message", "fox")).innerHit(new QueryInnerHits("comment", null)))
+                        .setQuery(hasChildQuery("comment", matchQuery("message", "fox")).innerHit(new QueryInnerHitBuilder().setName("comment")))
                         .request()
         };
         for (SearchRequest searchRequest : searchRequests) {
@@ -293,10 +293,10 @@ public class InnerHitsIT extends ESIntegTestCase {
         searchRequests = new SearchRequest[] {
                 client().prepareSearch("articles")
                         .setQuery(hasChildQuery("comment", matchQuery("message", "elephant")))
-                        .addParentChildInnerHits("comment", "comment", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("message", "elephant")))
+                        .addInnerHit("comment", new InnerHitsBuilder.InnerHit().setType("comment").setQuery(matchQuery("message", "elephant")))
                         .request(),
                 client().prepareSearch("articles")
-                        .setQuery(hasChildQuery("comment", matchQuery("message", "elephant")).innerHit(new QueryInnerHits()))
+                        .setQuery(hasChildQuery("comment", matchQuery("message", "elephant")).innerHit(new QueryInnerHitBuilder()))
                         .request()
         };
         for (SearchRequest searchRequest : searchRequests) {
@@ -316,16 +316,11 @@ public class InnerHitsIT extends ESIntegTestCase {
             assertThat(innerHits.getAt(2).getId(), equalTo("6"));
             assertThat(innerHits.getAt(2).type(), equalTo("comment"));
         }
-        InnerHitsBuilder.InnerHit innerHit = new InnerHitsBuilder.InnerHit();
-        innerHit.highlightBuilder().field("message");
-        innerHit.setExplain(true);
-        innerHit.addFieldDataField("message");
-        innerHit.addScriptField("script", new Script("doc['message'].value"));
-        innerHit.setSize(1);
+
         searchRequests = new SearchRequest[] {
                 client().prepareSearch("articles")
                         .setQuery(hasChildQuery("comment", matchQuery("message", "fox")))
-                        .addParentChildInnerHits("comment", "comment", new InnerHitsBuilder.InnerHit()
+                        .addInnerHit("comment", new InnerHitsBuilder.InnerHit().setType("comment")
                                         .setQuery(matchQuery("message", "fox"))
                                         .addHighlightedField("message")
                                         .setExplain(true)
@@ -333,11 +328,12 @@ public class InnerHitsIT extends ESIntegTestCase {
                                         .addScriptField("script", new Script("doc['message'].value"))
                                         .setSize(1)
                         ).request(),
-
                 client().prepareSearch("articles")
                         .setQuery(
                                 hasChildQuery("comment", matchQuery("message", "fox")).innerHit(
-                                        new QueryInnerHits(null, innerHit))).request() };
+                                        new QueryInnerHitBuilder().addHighlightedField("message").setExplain(true)
+                                                .addFieldDataField("message").addScriptField("script", new Script("doc['message'].value"))
+                                                .setSize(1))).request() };
 
         for (SearchRequest searchRequest : searchRequests) {
             SearchResponse response = client().search(searchRequest).actionGet();
@@ -389,17 +385,17 @@ public class InnerHitsIT extends ESIntegTestCase {
                     .setSize(numDocs)
                     .setTypes("parent")
                     .addSort("_uid", SortOrder.ASC)
-                    .addParentChildInnerHits("a", "child1", new InnerHitsBuilder.InnerHit().addSort("_uid", SortOrder.ASC).setSize(size))
-                    .addParentChildInnerHits("b", "child2", new InnerHitsBuilder.InnerHit().addSort("_uid", SortOrder.ASC).setSize(size))
+                    .addInnerHit("a", new InnerHitsBuilder.InnerHit().setType("child1").addSort("_uid", SortOrder.ASC).setSize(size))
+                    .addInnerHit("b", new InnerHitsBuilder.InnerHit().setType("child2").addSort("_uid", SortOrder.ASC).setSize(size))
                     .get();
         } else {
             BoolQueryBuilder boolQuery = new BoolQueryBuilder();
             if (randomBoolean()) {
-                boolQuery.should(hasChildQuery("child1", matchAllQuery()).innerHit(new QueryInnerHits("a", new InnerHitsBuilder.InnerHit().addSort("_uid", SortOrder.ASC).setSize(size))));
-                boolQuery.should(hasChildQuery("child2", matchAllQuery()).innerHit(new QueryInnerHits("b", new InnerHitsBuilder.InnerHit().addSort("_uid", SortOrder.ASC).setSize(size))));
+                boolQuery.should(hasChildQuery("child1", matchAllQuery()).innerHit(new QueryInnerHitBuilder().setName("a").addSort("_uid", SortOrder.ASC).setSize(size)));
+                boolQuery.should(hasChildQuery("child2", matchAllQuery()).innerHit(new QueryInnerHitBuilder().setName("b").addSort("_uid", SortOrder.ASC).setSize(size)));
             } else {
-                boolQuery.should(constantScoreQuery(hasChildQuery("child1", matchAllQuery()).innerHit(new QueryInnerHits("a", new InnerHitsBuilder.InnerHit().addSort("_uid", SortOrder.ASC).setSize(size)))));
-                boolQuery.should(constantScoreQuery(hasChildQuery("child2", matchAllQuery()).innerHit(new QueryInnerHits("b", new InnerHitsBuilder.InnerHit().addSort("_uid", SortOrder.ASC).setSize(size)))));
+                boolQuery.should(constantScoreQuery(hasChildQuery("child1", matchAllQuery()).innerHit(new QueryInnerHitBuilder().setName("a").addSort("_uid", SortOrder.ASC).setSize(size))));
+                boolQuery.should(constantScoreQuery(hasChildQuery("child2", matchAllQuery()).innerHit(new QueryInnerHitBuilder().setName("b").addSort("_uid", SortOrder.ASC).setSize(size))));
             }
             searchResponse = client().prepareSearch("idx")
                     .setSize(numDocs)
@@ -451,7 +447,7 @@ public class InnerHitsIT extends ESIntegTestCase {
         ensureGreen("articles");
         try {
             client().prepareSearch("articles")
-                    .addParentChildInnerHits("comment", null, new InnerHitsBuilder.InnerHit())
+                    .addInnerHit("comment", new InnerHitsBuilder.InnerHit())
                     .get();
         } catch (Exception e) {
             assertThat(e.getMessage(), containsString("Failed to build"));
@@ -478,7 +474,7 @@ public class InnerHitsIT extends ESIntegTestCase {
                 .setQuery(
                         boolQuery()
                                 .must(matchQuery("body", "fail2ban"))
-                                .must(hasParentQuery("question", matchAllQuery()).innerHit(new QueryInnerHits()))
+                                .must(hasParentQuery("question", matchAllQuery()).innerHit(new QueryInnerHitBuilder()))
                 ).get();
         assertNoFailures(response);
         assertHitCount(response, 2);
@@ -517,10 +513,10 @@ public class InnerHitsIT extends ESIntegTestCase {
 
         SearchResponse response = client().prepareSearch("articles")
                 .setQuery(hasChildQuery("comment", hasChildQuery("remark", matchQuery("message", "good"))))
-                .addParentChildInnerHits("comment", "comment",
-                        new InnerHitsBuilder.InnerHit()
+                .addInnerHit("comment",
+                        new InnerHitsBuilder.InnerHit().setType("comment")
                                 .setQuery(hasChildQuery("remark", matchQuery("message", "good")))
-                                .addParentChildInnerHits("remark", "remark", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("message", "good")))
+                                .addInnerHit("remark", new InnerHitsBuilder.InnerHit().setType("remark").setQuery(matchQuery("message", "good")))
                 )
                 .get();
 
@@ -541,10 +537,10 @@ public class InnerHitsIT extends ESIntegTestCase {
 
         response = client().prepareSearch("articles")
                 .setQuery(hasChildQuery("comment", hasChildQuery("remark", matchQuery("message", "bad"))))
-                .addParentChildInnerHits("comment", "comment",
-                        new InnerHitsBuilder.InnerHit()
+                .addInnerHit("comment",
+                        new InnerHitsBuilder.InnerHit().setType("comment")
                                 .setQuery(hasChildQuery("remark", matchQuery("message", "bad")))
-                                .addParentChildInnerHits("remark", "remark", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("message", "bad")))
+                                .addInnerHit("remark", new InnerHitsBuilder.InnerHit().setType("remark").setQuery(matchQuery("message", "bad")))
                 )
                 .get();
 
@@ -609,9 +605,10 @@ public class InnerHitsIT extends ESIntegTestCase {
 
         SearchResponse response = client().prepareSearch("articles")
                 .setQuery(nestedQuery("comments", nestedQuery("comments.remarks", matchQuery("comments.remarks.message", "good"))))
-                .addNestedInnerHits("comment", "comments", new InnerHitsBuilder.InnerHit()
+                .addInnerHit("comment", new InnerHitsBuilder.InnerHit()
+                                .setPath("comments")
                                 .setQuery(nestedQuery("comments.remarks", matchQuery("comments.remarks.message", "good")))
-                                .addNestedInnerHits("remark", "comments.remarks", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("comments.remarks.message", "good")))
+                                .addInnerHit("remark", new InnerHitsBuilder.InnerHit().setPath("comments.remarks").setQuery(matchQuery("comments.remarks.message", "good")))
                 ).get();
         assertNoFailures(response);
         assertHitCount(response, 1);
@@ -634,7 +631,7 @@ public class InnerHitsIT extends ESIntegTestCase {
 
         // Directly refer to the second level:
         response = client().prepareSearch("articles")
-                .setQuery(nestedQuery("comments.remarks", matchQuery("comments.remarks.message", "bad")).innerHit(new QueryInnerHits()))
+                .setQuery(nestedQuery("comments.remarks", matchQuery("comments.remarks.message", "bad")).innerHit(new QueryInnerHitBuilder()))
                 .get();
         assertNoFailures(response);
         assertHitCount(response, 1);
@@ -651,9 +648,10 @@ public class InnerHitsIT extends ESIntegTestCase {
 
         response = client().prepareSearch("articles")
                 .setQuery(nestedQuery("comments", nestedQuery("comments.remarks", matchQuery("comments.remarks.message", "bad"))))
-                .addNestedInnerHits("comment", "comments", new InnerHitsBuilder.InnerHit()
-                        .setQuery(nestedQuery("comments.remarks", matchQuery("comments.remarks.message", "bad")))
-                        .addNestedInnerHits("remark", "comments.remarks", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("comments.remarks.message", "bad"))))
+                .addInnerHit("comment", new InnerHitsBuilder.InnerHit()
+                                .setPath("comments")
+                                .setQuery(nestedQuery("comments.remarks", matchQuery("comments.remarks.message", "bad")))
+                                .addInnerHit("remark", new InnerHitsBuilder.InnerHit().setPath("comments.remarks").setQuery(matchQuery("comments.remarks.message", "bad"))))
                 .get();
         assertNoFailures(response);
         assertHitCount(response, 1);
@@ -688,7 +686,7 @@ public class InnerHitsIT extends ESIntegTestCase {
         indexRandom(true, requests);
 
         SearchResponse response = client().prepareSearch("articles")
-                .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHits()))
+                .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHitBuilder()))
                 .get();
         assertNoFailures(response);
         assertHitCount(response, 1);
@@ -726,8 +724,8 @@ public class InnerHitsIT extends ESIntegTestCase {
         indexRandom(true, requests);
 
         SearchResponse response = client().prepareSearch("articles")
-                .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHits(null, new InnerHitsBuilder.InnerHit().field("comments.message"))))
-                        .get();
+                .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHitBuilder().field("comments.message")))
+                .get();
         assertNoFailures(response);
         assertHitCount(response, 1);
         assertThat(response.getHits().getAt(0).id(), equalTo("1"));
@@ -763,10 +761,9 @@ public class InnerHitsIT extends ESIntegTestCase {
                 .startObject("comments").field("message", "fox eat quick").endObject()
                 .endObject()));
         indexRandom(true, requests);
-        InnerHitsBuilder.InnerHit builder = new InnerHitsBuilder.InnerHit();
-        builder.highlightBuilder().field("comments.message");
+
         SearchResponse response = client().prepareSearch("articles")
-                .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHits(null, builder)))
+                .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHitBuilder().addHighlightedField("comments.message")))
                 .get();
         assertNoFailures(response);
         assertHitCount(response, 1);
@@ -785,13 +782,13 @@ public class InnerHitsIT extends ESIntegTestCase {
                         .addMapping("article", jsonBuilder().startObject()
                                         .startObject("_source").field("excludes", new String[]{"comments"}).endObject()
                                         .startObject("properties")
-                                        .startObject("comments")
-                                        .field("type", "nested")
-                                        .startObject("properties")
-                                        .startObject("message").field("type", "string").field("store", "yes").endObject()
-                                        .endObject()
-                                        .endObject()
-                                        .endObject()
+                                            .startObject("comments")
+                                                .field("type", "nested")
+                                                .startObject("properties")
+                                                    .startObject("message").field("type", "string").field("store", "yes").endObject()
+                                                .endObject()
+                                                .endObject()
+                                            .endObject()
                                         .endObject()
                         )
         );
@@ -802,11 +799,9 @@ public class InnerHitsIT extends ESIntegTestCase {
                 .startObject("comments").field("message", "fox eat quick").endObject()
                 .endObject()));
         indexRandom(true, requests);
-        InnerHitsBuilder.InnerHit builder = new InnerHitsBuilder.InnerHit();
-        builder.field("comments.message");
-        builder.setFetchSource(true);
+
         SearchResponse response = client().prepareSearch("articles")
-                .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHits(null, builder)))
+                .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHitBuilder().field("comments.message").setFetchSource(true)))
                 .get();
         assertNoFailures(response);
         assertHitCount(response, 1);
@@ -842,11 +837,10 @@ public class InnerHitsIT extends ESIntegTestCase {
                 .startObject("comments").field("message", "fox eat quick").endObject()
                 .endObject()));
         indexRandom(true, requests);
-        InnerHitsBuilder.InnerHit builder = new InnerHitsBuilder.InnerHit();
-        builder.highlightBuilder().field("comments.message");
+
         SearchResponse response = client().prepareSearch("articles")
-                .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHits(null, builder)))
-                        .get();
+                .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHitBuilder().addHighlightedField("comments.message")))
+                .get();
         assertNoFailures(response);
         assertHitCount(response, 1);
         assertThat(response.getHits().getAt(0).id(), equalTo("1"));
@@ -887,7 +881,7 @@ public class InnerHitsIT extends ESIntegTestCase {
         indexRandom(true, requests);
 
         SearchResponse response = client().prepareSearch("articles")
-                .setQuery(nestedQuery("comments.messages", matchQuery("comments.messages.message", "fox")).innerHit(new QueryInnerHits()))
+                .setQuery(nestedQuery("comments.messages", matchQuery("comments.messages.message", "fox")).innerHit(new QueryInnerHitBuilder()))
                 .get();
         assertNoFailures(response);
         assertHitCount(response, 1);
@@ -899,7 +893,7 @@ public class InnerHitsIT extends ESIntegTestCase {
         assertThat(response.getHits().getAt(0).getInnerHits().get("comments.messages").getAt(0).getNestedIdentity().getChild(), nullValue());
 
         response = client().prepareSearch("articles")
-                .setQuery(nestedQuery("comments.messages", matchQuery("comments.messages.message", "bear")).innerHit(new QueryInnerHits()))
+                .setQuery(nestedQuery("comments.messages", matchQuery("comments.messages.message", "bear")).innerHit(new QueryInnerHitBuilder()))
                 .get();
         assertNoFailures(response);
         assertHitCount(response, 1);
@@ -918,7 +912,7 @@ public class InnerHitsIT extends ESIntegTestCase {
                 .endObject()));
         indexRandom(true, requests);
         response = client().prepareSearch("articles")
-                .setQuery(nestedQuery("comments.messages", matchQuery("comments.messages.message", "fox")).innerHit(new QueryInnerHits()))
+                .setQuery(nestedQuery("comments.messages", matchQuery("comments.messages.message", "fox")).innerHit(new QueryInnerHitBuilder()))
                 .get();
         assertNoFailures(response);
         assertHitCount(response, 1);
@@ -934,11 +928,11 @@ public class InnerHitsIT extends ESIntegTestCase {
     public void testRoyals() throws Exception {
         assertAcked(
                 prepareCreate("royals")
-                        .addMapping("king")
-                        .addMapping("prince", "_parent", "type=king")
-                        .addMapping("duke", "_parent", "type=prince")
-                        .addMapping("earl", "_parent", "type=duke")
-                        .addMapping("baron", "_parent", "type=earl")
+                .addMapping("king")
+                .addMapping("prince", "_parent", "type=king")
+                .addMapping("duke", "_parent", "type=prince")
+                .addMapping("earl", "_parent", "type=duke")
+                .addMapping("baron", "_parent", "type=earl")
         );
 
         List<IndexRequestBuilder> requests = new ArrayList<>();
@@ -957,14 +951,15 @@ public class InnerHitsIT extends ESIntegTestCase {
 
         SearchResponse response = client().prepareSearch("royals")
                 .setTypes("duke")
-                .addParentChildInnerHits("earls", "earl", new InnerHitsBuilder.InnerHit()
+                .addInnerHit("earls", new InnerHitsBuilder.InnerHit()
+                                .setType("earl")
                                 .addSort(SortBuilders.fieldSort("_uid").order(SortOrder.ASC))
                                 .setSize(4)
-                                .addParentChildInnerHits("barons", "baron", new InnerHitsBuilder.InnerHit())
+                                .addInnerHit("barons", new InnerHitsBuilder.InnerHit().setType("baron"))
                 )
-                .addParentChildInnerHits("princes", "prince",
-                        new InnerHitsBuilder.InnerHit()
-                        .addParentChildInnerHits("kings", "king", new InnerHitsBuilder.InnerHit())
+                .addInnerHit("princes",
+                        new InnerHitsBuilder.InnerHit().setType("prince")
+                        .addInnerHit("kings", new InnerHitsBuilder.InnerHit().setType("king"))
                 )
                 .get();
         assertHitCount(response, 1);
@@ -1072,7 +1067,7 @@ public class InnerHitsIT extends ESIntegTestCase {
                                 .should(termQuery("nested1.n_field1", "n_value1_1").queryName("test1"))
                                 .should(termQuery("nested1.n_field1", "n_value1_3").queryName("test2"))
                                 .should(termQuery("nested1.n_field2", "n_value2_2").queryName("test3"))
-                ).innerHit(new QueryInnerHits(null, new InnerHitsBuilder.InnerHit().addSort("nested1.n_field1", SortOrder.ASC))))
+                ).innerHit(new QueryInnerHitBuilder().addSort("nested1.n_field1", SortOrder.ASC)))
                 .setSize(numDocs)
                 .addSort("field1", SortOrder.ASC)
                 .get();
@@ -1112,7 +1107,7 @@ public class InnerHitsIT extends ESIntegTestCase {
         indexRandom(true, requests);
 
         SearchResponse response = client().prepareSearch("index")
-                .setQuery(hasChildQuery("child", matchQuery("field", "value1").queryName("_name1")).innerHit(new QueryInnerHits()))
+                .setQuery(hasChildQuery("child", matchQuery("field", "value1").queryName("_name1")).innerHit(new QueryInnerHitBuilder()))
                 .addSort("_uid", SortOrder.ASC)
                 .get();
         assertHitCount(response, 2);
@@ -1127,7 +1122,7 @@ public class InnerHitsIT extends ESIntegTestCase {
         assertThat(response.getHits().getAt(1).getInnerHits().get("child").getAt(0).getMatchedQueries()[0], equalTo("_name1"));
 
         response = client().prepareSearch("index")
-                .setQuery(hasChildQuery("child", matchQuery("field", "value2").queryName("_name2")).innerHit(new QueryInnerHits()))
+                .setQuery(hasChildQuery("child", matchQuery("field", "value2").queryName("_name2")).innerHit(new QueryInnerHitBuilder()))
                 .addSort("_id", SortOrder.ASC)
                 .get();
         assertHitCount(response, 1);
@@ -1146,7 +1141,7 @@ public class InnerHitsIT extends ESIntegTestCase {
         indexRandom(true, requests);
 
         SearchResponse response = client().prepareSearch("index1")
-                .setQuery(hasChildQuery("child", matchQuery("field", "value1")).innerHit(new QueryInnerHits(null, new InnerHitsBuilder.InnerHit().setSize(ArrayUtil.MAX_ARRAY_LENGTH - 1))))
+                .setQuery(hasChildQuery("child", matchQuery("field", "value1")).innerHit(new QueryInnerHitBuilder().setSize(ArrayUtil.MAX_ARRAY_LENGTH - 1)))
                 .addSort("_uid", SortOrder.ASC)
                 .get();
         assertNoFailures(response);
@@ -1164,7 +1159,7 @@ public class InnerHitsIT extends ESIntegTestCase {
         .get();
 
         response = client().prepareSearch("index2")
-                .setQuery(nestedQuery("nested", matchQuery("nested.field", "value1")).innerHit(new QueryInnerHits(null, new InnerHitsBuilder.InnerHit().setSize(ArrayUtil.MAX_ARRAY_LENGTH - 1))))
+                .setQuery(nestedQuery("nested", matchQuery("nested.field", "value1")).innerHit(new QueryInnerHitBuilder().setSize(ArrayUtil.MAX_ARRAY_LENGTH - 1)))
                 .addSort("_uid", SortOrder.ASC)
                 .get();
         assertNoFailures(response);
diff --git a/core/src/test/java/org/elasticsearch/search/query/MultiMatchQueryIT.java b/core/src/test/java/org/elasticsearch/search/query/MultiMatchQueryIT.java
index 506da40..ca138d9 100644
--- a/core/src/test/java/org/elasticsearch/search/query/MultiMatchQueryIT.java
+++ b/core/src/test/java/org/elasticsearch/search/query/MultiMatchQueryIT.java
@@ -19,18 +19,15 @@
 package org.elasticsearch.search.query;
 
 import com.carrotsearch.randomizedtesting.generators.RandomPicks;
-import com.google.common.collect.Sets;
-
 import org.elasticsearch.action.admin.indices.create.CreateIndexRequestBuilder;
 import org.elasticsearch.action.index.IndexRequestBuilder;
 import org.elasticsearch.action.search.SearchResponse;
+import org.elasticsearch.common.util.set.Sets;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.query.MatchQueryBuilder;
 import org.elasticsearch.index.query.MultiMatchQueryBuilder;
-import org.elasticsearch.index.query.Operator;
 import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.index.search.MatchQuery;
 import org.elasticsearch.search.SearchHit;
 import org.elasticsearch.search.SearchHits;
 import org.elasticsearch.search.sort.SortBuilders;
@@ -49,9 +46,28 @@ import java.util.concurrent.ExecutionException;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_REPLICAS;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
-import static org.elasticsearch.index.query.QueryBuilders.*;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
-import static org.hamcrest.Matchers.*;
+import static org.elasticsearch.index.query.QueryBuilders.boolQuery;
+import static org.elasticsearch.index.query.QueryBuilders.disMaxQuery;
+import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
+import static org.elasticsearch.index.query.QueryBuilders.matchPhrasePrefixQuery;
+import static org.elasticsearch.index.query.QueryBuilders.matchPhraseQuery;
+import static org.elasticsearch.index.query.QueryBuilders.matchQuery;
+import static org.elasticsearch.index.query.QueryBuilders.multiMatchQuery;
+import static org.elasticsearch.index.query.QueryBuilders.termQuery;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertFirstHit;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchHits;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSecondHit;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.hasId;
+import static org.hamcrest.Matchers.anyOf;
+import static org.hamcrest.Matchers.closeTo;
+import static org.hamcrest.Matchers.empty;
+import static org.hamcrest.Matchers.equalTo;
+import static org.hamcrest.Matchers.greaterThan;
+import static org.hamcrest.Matchers.greaterThanOrEqualTo;
+import static org.hamcrest.Matchers.lessThan;
 
 public class MultiMatchQueryIT extends ESIntegTestCase {
 
@@ -153,10 +169,10 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
 
     @Test
     public void testDefaults() throws ExecutionException, InterruptedException {
-        MatchQuery.Type type = randomBoolean() ? null : MatchQuery.Type.BOOLEAN;
+        MatchQueryBuilder.Type type = randomBoolean() ? null : MatchQueryBuilder.Type.BOOLEAN;
         SearchResponse searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.OR))).get();
+                        .operator(MatchQueryBuilder.Operator.OR))).get();
         Set<String> topNIds = Sets.newHashSet("theone", "theother");
         for (int i = 0; i < searchResponse.getHits().hits().length; i++) {
             topNIds.remove(searchResponse.getHits().getAt(i).getId());
@@ -168,25 +184,25 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.OR).useDisMax(false).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).useDisMax(false).type(type))).get();
         assertFirstHit(searchResponse, anyOf(hasId("theone"), hasId("theother")));
         assertThat(searchResponse.getHits().hits()[0].getScore(), greaterThan(searchResponse.getHits().hits()[1].getScore()));
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.OR).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).type(type))).get();
         assertFirstHit(searchResponse, hasId("theother"));
 
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.AND).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.AND).type(type))).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("theone"));
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.AND).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.AND).type(type))).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("theone"));
     }
@@ -195,18 +211,18 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
     public void testPhraseType() {
         SearchResponse searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("Man the Ultimate", "full_name_phrase", "first_name_phrase", "last_name_phrase", "category_phrase")
-                        .operator(Operator.OR).type(MatchQuery.Type.PHRASE))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).type(MatchQueryBuilder.Type.PHRASE))).get();
         assertFirstHit(searchResponse, hasId("ultimate2"));
         assertHitCount(searchResponse, 1l);
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("Captain", "full_name_phrase", "first_name_phrase", "last_name_phrase", "category_phrase")
-                        .operator(Operator.OR).type(MatchQuery.Type.PHRASE))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).type(MatchQueryBuilder.Type.PHRASE))).get();
         assertThat(searchResponse.getHits().getTotalHits(), greaterThan(1l));
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("the Ul", "full_name_phrase", "first_name_phrase", "last_name_phrase", "category_phrase")
-                        .operator(Operator.OR).type(MatchQuery.Type.PHRASE_PREFIX))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).type(MatchQueryBuilder.Type.PHRASE_PREFIX))).get();
         assertSearchHits(searchResponse, "ultimate2", "ultimate1");
         assertHitCount(searchResponse, 2l);
     }
@@ -240,7 +256,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
                     .setQuery(multiMatchQueryBuilder).get();
             MatchQueryBuilder matchQueryBuilder = QueryBuilders.matchQuery(field, builder.toString());
             if (getType(multiMatchQueryBuilder) != null) {
-                matchQueryBuilder.type(MatchQuery.Type.valueOf(getType(multiMatchQueryBuilder).matchQueryType().toString()));
+                matchQueryBuilder.type(MatchQueryBuilder.Type.valueOf(getType(multiMatchQueryBuilder).matchQueryType().toString()));
             }
             SearchResponse matchResp = client().prepareSearch("test")
                     // _uid tie sort
@@ -261,11 +277,11 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
     public void testCutoffFreq() throws ExecutionException, InterruptedException {
         final long numDocs = client().prepareCount("test")
                 .setQuery(matchAllQuery()).get().getCount();
-        MatchQuery.Type type = randomBoolean() ? null : MatchQuery.Type.BOOLEAN;
+        MatchQueryBuilder.Type type = randomBoolean() ? null : MatchQueryBuilder.Type.BOOLEAN;
         Float cutoffFrequency = randomBoolean() ? Math.min(1, numDocs * 1.f / between(10, 20)) : 1.f / between(10, 20);
         SearchResponse searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.OR).cutoffFrequency(cutoffFrequency))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).cutoffFrequency(cutoffFrequency))).get();
         Set<String> topNIds = Sets.newHashSet("theone", "theother");
         for (int i = 0; i < searchResponse.getHits().hits().length; i++) {
             topNIds.remove(searchResponse.getHits().getAt(i).getId());
@@ -278,39 +294,39 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
         cutoffFrequency = randomBoolean() ? Math.min(1, numDocs * 1.f / between(10, 20)) : 1.f / between(10, 20);
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.OR).useDisMax(false).cutoffFrequency(cutoffFrequency).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).useDisMax(false).cutoffFrequency(cutoffFrequency).type(type))).get();
         assertFirstHit(searchResponse, anyOf(hasId("theone"), hasId("theother")));
         assertThat(searchResponse.getHits().hits()[0].getScore(), greaterThan(searchResponse.getHits().hits()[1].getScore()));
         long size = searchResponse.getHits().getTotalHits();
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.OR).useDisMax(false).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).useDisMax(false).type(type))).get();
         assertFirstHit(searchResponse, anyOf(hasId("theone"), hasId("theother")));
         assertThat("common terms expected to be a way smaller result set", size, lessThan(searchResponse.getHits().getTotalHits()));
 
         cutoffFrequency = randomBoolean() ? Math.min(1, numDocs * 1.f / between(10, 20)) : 1.f / between(10, 20);
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.OR).cutoffFrequency(cutoffFrequency).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).cutoffFrequency(cutoffFrequency).type(type))).get();
         assertFirstHit(searchResponse, hasId("theother"));
 
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.AND).cutoffFrequency(cutoffFrequency).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.AND).cutoffFrequency(cutoffFrequency).type(type))).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("theone"));
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.AND).cutoffFrequency(cutoffFrequency).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.AND).cutoffFrequency(cutoffFrequency).type(type))).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("theone"));
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero", "first_name", "last_name", "category")
-                        .operator(Operator.AND).cutoffFrequency(cutoffFrequency)
+                        .operator(MatchQueryBuilder.Operator.AND).cutoffFrequency(cutoffFrequency)
                         .analyzer("category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS))).get();
         assertHitCount(searchResponse, 1l);
@@ -326,13 +342,13 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
         int numIters = scaledRandomIntBetween(5, 10);
         for (int i = 0; i < numIters; i++) {
             {
-                MatchQuery.Type type = randomBoolean() ? null : MatchQuery.Type.BOOLEAN;
+                MatchQueryBuilder.Type type = randomBoolean() ? null : MatchQueryBuilder.Type.BOOLEAN;
                 MultiMatchQueryBuilder multiMatchQueryBuilder = randomBoolean() ? multiMatchQuery("marvel hero captain america", "full_name", "first_name", "last_name", "category") :
                         multiMatchQuery("marvel hero captain america", "*_name", randomBoolean() ? "category" : "categ*");
                 SearchResponse left = client().prepareSearch("test").setSize(numDocs)
                         .addSort(SortBuilders.scoreSort()).addSort(SortBuilders.fieldSort("_uid"))
                         .setQuery(randomizeType(multiMatchQueryBuilder
-                                .operator(Operator.OR).type(type))).get();
+                                .operator(MatchQueryBuilder.Operator.OR).type(type))).get();
 
                 SearchResponse right = client().prepareSearch("test").setSize(numDocs)
                         .addSort(SortBuilders.scoreSort()).addSort(SortBuilders.fieldSort("_uid"))
@@ -346,9 +362,9 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
             }
 
             {
-                MatchQuery.Type type = randomBoolean() ? null : MatchQuery.Type.BOOLEAN;
+                MatchQueryBuilder.Type type = randomBoolean() ? null : MatchQueryBuilder.Type.BOOLEAN;
                 String minShouldMatch = randomBoolean() ? null : "" + between(0, 1);
-                Operator op = randomBoolean() ? Operator.AND : Operator.OR;
+                MatchQueryBuilder.Operator op = randomBoolean() ? MatchQueryBuilder.Operator.AND : MatchQueryBuilder.Operator.OR;
                 MultiMatchQueryBuilder multiMatchQueryBuilder = randomBoolean() ? multiMatchQuery("captain america", "full_name", "first_name", "last_name", "category") :
                         multiMatchQuery("captain america", "*_name", randomBoolean() ? "category" : "categ*");
                 SearchResponse left = client().prepareSearch("test").setSize(numDocs)
@@ -369,11 +385,11 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
 
             {
                 String minShouldMatch = randomBoolean() ? null : "" + between(0, 1);
-                Operator op = randomBoolean() ? Operator.AND : Operator.OR;
+                MatchQueryBuilder.Operator op = randomBoolean() ? MatchQueryBuilder.Operator.AND : MatchQueryBuilder.Operator.OR;
                 SearchResponse left = client().prepareSearch("test").setSize(numDocs)
                         .addSort(SortBuilders.scoreSort()).addSort(SortBuilders.fieldSort("_uid"))
                         .setQuery(randomizeType(multiMatchQuery("capta", "full_name", "first_name", "last_name", "category")
-                                .type(MatchQuery.Type.PHRASE_PREFIX).useDisMax(false).minimumShouldMatch(minShouldMatch))).get();
+                                .type(MatchQueryBuilder.Type.PHRASE_PREFIX).useDisMax(false).minimumShouldMatch(minShouldMatch))).get();
 
                 SearchResponse right = client().prepareSearch("test").setSize(numDocs)
                         .addSort(SortBuilders.scoreSort()).addSort(SortBuilders.fieldSort("_uid"))
@@ -387,18 +403,18 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
             }
             {
                 String minShouldMatch = randomBoolean() ? null : "" + between(0, 1);
-                Operator op = randomBoolean() ? Operator.AND : Operator.OR;
+                MatchQueryBuilder.Operator op = randomBoolean() ? MatchQueryBuilder.Operator.AND : MatchQueryBuilder.Operator.OR;
                 SearchResponse left;
                 if (randomBoolean()) {
                     left = client().prepareSearch("test").setSize(numDocs)
                             .addSort(SortBuilders.scoreSort()).addSort(SortBuilders.fieldSort("_uid"))
                             .setQuery(randomizeType(multiMatchQuery("captain america", "full_name", "first_name", "last_name", "category")
-                                    .type(MatchQuery.Type.PHRASE).useDisMax(false).minimumShouldMatch(minShouldMatch))).get();
+                                    .type(MatchQueryBuilder.Type.PHRASE).useDisMax(false).minimumShouldMatch(minShouldMatch))).get();
                 } else {
                     left = client().prepareSearch("test").setSize(numDocs)
                             .addSort(SortBuilders.scoreSort()).addSort(SortBuilders.fieldSort("_uid"))
                             .setQuery(randomizeType(multiMatchQuery("captain america", "full_name", "first_name", "last_name", "category")
-                                    .type(MatchQuery.Type.PHRASE).tieBreaker(1.0f).minimumShouldMatch(minShouldMatch))).get();
+                                    .type(MatchQueryBuilder.Type.PHRASE).tieBreaker(1.0f).minimumShouldMatch(minShouldMatch))).get();
                 }
                 SearchResponse right = client().prepareSearch("test").setSize(numDocs)
                         .addSort(SortBuilders.scoreSort()).addSort(SortBuilders.fieldSort("_uid"))
@@ -418,13 +434,13 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
         SearchResponse searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america", "full_name", "first_name", "last_name")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
-                        .operator(Operator.OR))).get();
+                        .operator(MatchQueryBuilder.Operator.OR))).get();
         assertFirstHit(searchResponse, hasId("theone"));
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero captain america", "full_name", "first_name", "last_name", "category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
-                        .operator(Operator.OR))).get();
+                        .operator(MatchQueryBuilder.Operator.OR))).get();
         assertFirstHit(searchResponse, hasId("theone"));
         assertSecondHit(searchResponse, hasId("theother"));
         assertThat(searchResponse.getHits().hits()[0].getScore(), greaterThan(searchResponse.getHits().hits()[1].getScore()));
@@ -432,13 +448,13 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero", "full_name", "first_name", "last_name", "category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
-                        .operator(Operator.OR))).get();
+                        .operator(MatchQueryBuilder.Operator.OR))).get();
         assertFirstHit(searchResponse, hasId("theother"));
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america", "full_name", "first_name", "last_name", "category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
-                        .operator(Operator.AND))).get();
+                        .operator(MatchQueryBuilder.Operator.AND))).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("theone"));
 
@@ -446,7 +462,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
                 .setQuery(randomizeType(multiMatchQuery("captain america 15", "full_name", "first_name", "last_name", "category", "skill")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                         .analyzer("category")
-                        .operator(Operator.AND))).get();
+                        .operator(MatchQueryBuilder.Operator.AND))).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("theone"));
 
@@ -467,7 +483,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                         .cutoffFrequency(0.1f)
                         .analyzer("category")
-                        .operator(Operator.OR))).get();
+                        .operator(MatchQueryBuilder.Operator.OR))).get();
         assertFirstHit(searchResponse, anyOf(hasId("theother"), hasId("theone")));
         long numResults = searchResponse.getHits().totalHits();
 
@@ -475,7 +491,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
                 .setQuery(randomizeType(multiMatchQuery("captain america marvel hero", "first_name", "last_name", "category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                         .analyzer("category")
-                        .operator(Operator.OR))).get();
+                        .operator(MatchQueryBuilder.Operator.OR))).get();
         assertThat(numResults, lessThan(searchResponse.getHits().getTotalHits()));
         assertFirstHit(searchResponse, hasId("theone"));
 
@@ -485,28 +501,28 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
                 .setQuery(randomizeType(multiMatchQuery("captain america marvel hero", "first_name", "last_name", "category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                         .analyzer("category")
-                        .operator(Operator.AND))).get();
+                        .operator(MatchQueryBuilder.Operator.AND))).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("theone"));
         // counter example
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america marvel hero", "first_name", "last_name", "category")
                         .type(randomBoolean() ? MultiMatchQueryBuilder.Type.CROSS_FIELDS : null)
-                        .operator(Operator.AND))).get();
+                        .operator(MatchQueryBuilder.Operator.AND))).get();
         assertHitCount(searchResponse, 0l);
 
         // counter example
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america marvel hero", "first_name", "last_name", "category")
                         .type(randomBoolean() ? MultiMatchQueryBuilder.Type.CROSS_FIELDS : null)
-                        .operator(Operator.AND))).get();
+                        .operator(MatchQueryBuilder.Operator.AND))).get();
         assertHitCount(searchResponse, 0l);
 
         // test if boosts work
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("the ultimate", "full_name", "first_name", "last_name^2", "category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
-                        .operator(Operator.AND))).get();
+                        .operator(MatchQueryBuilder.Operator.AND))).get();
         assertFirstHit(searchResponse, hasId("ultimate1"));   // has ultimate in the last_name and that is boosted
         assertSecondHit(searchResponse, hasId("ultimate2"));
         assertThat(searchResponse.getHits().hits()[0].getScore(), greaterThan(searchResponse.getHits().hits()[1].getScore()));
@@ -516,7 +532,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("the ultimate", "full_name", "first_name", "last_name", "category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
-                        .operator(Operator.AND))).get();
+                        .operator(MatchQueryBuilder.Operator.AND))).get();
         assertFirstHit(searchResponse, hasId("ultimate2"));
         assertSecondHit(searchResponse, hasId("ultimate1"));
         assertThat(searchResponse.getHits().hits()[0].getScore(), greaterThan(searchResponse.getHits().hits()[1].getScore()));
@@ -583,24 +599,24 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
                 switch (type) {
                     case BEST_FIELDS:
                         if (randomBoolean()) {
-                            oType = MatchQuery.Type.BOOLEAN;
+                            oType = MatchQueryBuilder.Type.BOOLEAN;
                         }
                         break;
                     case MOST_FIELDS:
                         if (randomBoolean()) {
-                            oType = MatchQuery.Type.BOOLEAN;
+                            oType = MatchQueryBuilder.Type.BOOLEAN;
                         }
                         break;
                     case CROSS_FIELDS:
                         break;
                     case PHRASE:
                         if (randomBoolean()) {
-                            oType = MatchQuery.Type.PHRASE;
+                            oType = MatchQueryBuilder.Type.PHRASE;
                         }
                         break;
                     case PHRASE_PREFIX:
                         if (randomBoolean()) {
-                            oType = MatchQuery.Type.PHRASE_PREFIX;
+                            oType = MatchQueryBuilder.Type.PHRASE_PREFIX;
                         }
                         break;
                 }
diff --git a/core/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java b/core/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java
index fd71f4a..8ee123f 100644
--- a/core/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java
+++ b/core/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java
@@ -20,6 +20,7 @@
 package org.elasticsearch.search.query;
 
 import org.apache.lucene.util.English;
+import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.Version;
 import org.elasticsearch.action.admin.indices.create.CreateIndexRequestBuilder;
 import org.elasticsearch.action.index.IndexRequestBuilder;
@@ -31,9 +32,15 @@ import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.mapper.MapperParsingException;
-import org.elasticsearch.index.query.*;
-import org.elasticsearch.index.search.MatchQuery.Type;
-import org.elasticsearch.index.search.MatchQuery;
+import org.elasticsearch.index.query.BoolQueryBuilder;
+import org.elasticsearch.index.query.CommonTermsQueryBuilder.Operator;
+import org.elasticsearch.index.query.MatchQueryBuilder;
+import org.elasticsearch.index.query.MatchQueryBuilder.Type;
+import org.elasticsearch.index.query.MultiMatchQueryBuilder;
+import org.elasticsearch.index.query.QueryBuilders;
+import org.elasticsearch.index.query.QueryStringQueryBuilder;
+import org.elasticsearch.index.query.TermQueryBuilder;
+import org.elasticsearch.index.query.WrapperQueryBuilder;
 import org.elasticsearch.rest.RestStatus;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.search.SearchHit;
@@ -55,8 +62,24 @@ import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
 import static org.elasticsearch.index.query.QueryBuilders.*;
 import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.scriptFunction;
 import static org.elasticsearch.test.VersionUtils.randomVersion;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
-import static org.hamcrest.Matchers.*;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertFailures;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertFirstHit;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchHit;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchHits;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchResponse;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSecondHit;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertThirdHit;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.hasId;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.hasScore;
+import static org.hamcrest.Matchers.allOf;
+import static org.hamcrest.Matchers.closeTo;
+import static org.hamcrest.Matchers.containsString;
+import static org.hamcrest.Matchers.equalTo;
+import static org.hamcrest.Matchers.greaterThan;
+import static org.hamcrest.Matchers.is;
 
 public class SearchQueryIT extends ESIntegTestCase {
 
@@ -162,7 +185,7 @@ public class SearchQueryIT extends ESIntegTestCase {
                 client().prepareIndex("test", "type1", "1").setSource("field1", "quick brown fox", "field2", "quick brown fox"),
                 client().prepareIndex("test", "type1", "2").setSource("field1", "quick lazy huge brown fox", "field2", "quick lazy huge brown fox"));
 
-        SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("field2", "quick brown").type(Type.PHRASE).slop(0)).get();
+        SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("field2", "quick brown").type(MatchQueryBuilder.Type.PHRASE).slop(0)).get();
         assertHitCount(searchResponse, 1l);
 
         assertFailures(client().prepareSearch().setQuery(matchQuery("field1", "quick brown").type(Type.PHRASE).slop(0)),
@@ -326,18 +349,18 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertThirdHit(searchResponse, hasId("2"));
 
         // try the same with match query
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 2l);
         assertFirstHit(searchResponse, hasId("1"));
         assertSecondHit(searchResponse, hasId("2"));
 
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(Operator.OR)).get();
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.OR)).get();
         assertHitCount(searchResponse, 3l);
         assertFirstHit(searchResponse, hasId("1"));
         assertSecondHit(searchResponse, hasId("2"));
         assertThirdHit(searchResponse, hasId("3"));
 
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(Operator.AND).analyzer("stop")).get();
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.AND).analyzer("stop")).get();
         assertHitCount(searchResponse, 3l);
         // stop drops "the" since its a stopword
         assertFirstHit(searchResponse, hasId("1"));
@@ -345,7 +368,7 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertThirdHit(searchResponse, hasId("2"));
 
         // try the same with multi match query
-        searchResponse = client().prepareSearch().setQuery(multiMatchQuery("the quick brown", "field1", "field2").cutoffFrequency(3).operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch().setQuery(multiMatchQuery("the quick brown", "field1", "field2").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 3l);
         assertFirstHit(searchResponse, hasId("3")); // better score due to different query stats
         assertSecondHit(searchResponse, hasId("1"));
@@ -418,18 +441,18 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertThirdHit(searchResponse, hasId("2"));
 
         // try the same with match query
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 2l);
         assertFirstHit(searchResponse, hasId("1"));
         assertSecondHit(searchResponse, hasId("2"));
 
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(Operator.OR)).get();
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.OR)).get();
         assertHitCount(searchResponse, 3l);
         assertFirstHit(searchResponse, hasId("1"));
         assertSecondHit(searchResponse, hasId("2"));
         assertThirdHit(searchResponse, hasId("3"));
 
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(Operator.AND).analyzer("stop")).get();
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.AND).analyzer("stop")).get();
         assertHitCount(searchResponse, 3l);
         // stop drops "the" since its a stopword
         assertFirstHit(searchResponse, hasId("1"));
@@ -442,7 +465,7 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertSecondHit(searchResponse, hasId("2"));
 
         // try the same with multi match query
-        searchResponse = client().prepareSearch().setQuery(multiMatchQuery("the fast brown", "field1", "field2").cutoffFrequency(3).operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch().setQuery(multiMatchQuery("the fast brown", "field1", "field2").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 3l);
         assertFirstHit(searchResponse, hasId("3")); // better score due to different query stats
         assertSecondHit(searchResponse, hasId("1"));
@@ -466,10 +489,10 @@ public class SearchQueryIT extends ESIntegTestCase {
                         client().prepareIndex("test", "type1", "2").setSource("field1", "quick lazy huge brown fox", "field2", "quick lazy huge brown fox"));
 
 
-                SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("field2", "quick brown").type(Type.PHRASE).slop(0)).get();
+                SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("field2", "quick brown").type(MatchQueryBuilder.Type.PHRASE).slop(0)).get();
                 assertHitCount(searchResponse, 1l);
                 try {
-                    client().prepareSearch().setQuery(matchQuery("field1", "quick brown").type(Type.PHRASE).slop(0)).get();
+                    client().prepareSearch().setQuery(matchQuery("field1", "quick brown").type(MatchQueryBuilder.Type.PHRASE).slop(0)).get();
                     fail("SearchPhaseExecutionException should have been thrown");
                 } catch (SearchPhaseExecutionException e) {
                     assertTrue(e.toString().contains("IllegalStateException[field \"field1\" was indexed without position data; cannot run PhraseQuery"));
@@ -900,7 +923,7 @@ public class SearchQueryIT extends ESIntegTestCase {
 
         client().admin().indices().prepareRefresh("test").get();
         builder = multiMatchQuery("value1", "field1", "field2")
-                .operator(Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
+                .operator(MatchQueryBuilder.Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
         searchResponse = client().prepareSearch()
                 .setQuery(builder)
                 .get();
@@ -909,14 +932,14 @@ public class SearchQueryIT extends ESIntegTestCase {
 
         refresh();
         builder = multiMatchQuery("value1", "field1", "field3^1.5")
-                .operator(Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
+                .operator(MatchQueryBuilder.Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
         searchResponse = client().prepareSearch().setQuery(builder).get();
         assertHitCount(searchResponse, 2l);
         assertSearchHits(searchResponse, "3", "1");
 
         client().admin().indices().prepareRefresh("test").get();
         builder = multiMatchQuery("value1").field("field1").field("field3", 1.5f)
-                .operator(Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
+                .operator(MatchQueryBuilder.Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
         searchResponse = client().prepareSearch().setQuery(builder).get();
         assertHitCount(searchResponse, 2l);
         assertSearchHits(searchResponse, "3", "1");
@@ -946,18 +969,18 @@ public class SearchQueryIT extends ESIntegTestCase {
         refresh();
 
         BoolQueryBuilder boolQuery = boolQuery()
-                .must(matchQuery("field1", "a").zeroTermsQuery(MatchQuery.ZeroTermsQuery.NONE))
-                .must(matchQuery("field1", "value1").zeroTermsQuery(MatchQuery.ZeroTermsQuery.NONE));
+                .must(matchQuery("field1", "a").zeroTermsQuery(MatchQueryBuilder.ZeroTermsQuery.NONE))
+                .must(matchQuery("field1", "value1").zeroTermsQuery(MatchQueryBuilder.ZeroTermsQuery.NONE));
         SearchResponse searchResponse = client().prepareSearch().setQuery(boolQuery).get();
         assertHitCount(searchResponse, 0l);
 
         boolQuery = boolQuery()
-                .must(matchQuery("field1", "a").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL))
-                .must(matchQuery("field1", "value1").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL));
+                .must(matchQuery("field1", "a").zeroTermsQuery(MatchQueryBuilder.ZeroTermsQuery.ALL))
+                .must(matchQuery("field1", "value1").zeroTermsQuery(MatchQueryBuilder.ZeroTermsQuery.ALL));
         searchResponse = client().prepareSearch().setQuery(boolQuery).get();
         assertHitCount(searchResponse, 1l);
 
-        boolQuery = boolQuery().must(matchQuery("field1", "a").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL));
+        boolQuery = boolQuery().must(matchQuery("field1", "a").zeroTermsQuery(MatchQueryBuilder.ZeroTermsQuery.ALL));
         searchResponse = client().prepareSearch().setQuery(boolQuery).get();
         assertHitCount(searchResponse, 2l);
     }
@@ -971,18 +994,18 @@ public class SearchQueryIT extends ESIntegTestCase {
 
 
         BoolQueryBuilder boolQuery = boolQuery()
-                .must(multiMatchQuery("a", "field1", "field2").zeroTermsQuery(MatchQuery.ZeroTermsQuery.NONE))
-                .must(multiMatchQuery("value1", "field1", "field2").zeroTermsQuery(MatchQuery.ZeroTermsQuery.NONE)); // Fields are ORed together
+                .must(multiMatchQuery("a", "field1", "field2").zeroTermsQuery(MatchQueryBuilder.ZeroTermsQuery.NONE))
+                .must(multiMatchQuery("value1", "field1", "field2").zeroTermsQuery(MatchQueryBuilder.ZeroTermsQuery.NONE)); // Fields are ORed together
         SearchResponse searchResponse = client().prepareSearch().setQuery(boolQuery).get();
         assertHitCount(searchResponse, 0l);
 
         boolQuery = boolQuery()
-                .must(multiMatchQuery("a", "field1", "field2").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL))
-                .must(multiMatchQuery("value4", "field1", "field2").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL));
+                .must(multiMatchQuery("a", "field1", "field2").zeroTermsQuery(MatchQueryBuilder.ZeroTermsQuery.ALL))
+                .must(multiMatchQuery("value4", "field1", "field2").zeroTermsQuery(MatchQueryBuilder.ZeroTermsQuery.ALL));
         searchResponse = client().prepareSearch().setQuery(boolQuery).get();
         assertHitCount(searchResponse, 1l);
 
-        boolQuery = boolQuery().must(multiMatchQuery("a", "field1").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL));
+        boolQuery = boolQuery().must(multiMatchQuery("a", "field1").zeroTermsQuery(MatchQueryBuilder.ZeroTermsQuery.ALL));
         searchResponse = client().prepareSearch().setQuery(boolQuery).get();
         assertHitCount(searchResponse, 2l);
     }
@@ -1560,9 +1583,10 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertHitCount(searchResponse, 1l);
 
         searchResponse = client().prepareSearch("test").setQuery(
-                spanNearQuery(3)
+                spanNearQuery()
                         .clause(spanTermQuery("description", "foo"))
-                        .clause(spanTermQuery("description", "other"))).get();
+                        .clause(spanTermQuery("description", "other"))
+                        .slop(3)).get();
         assertHitCount(searchResponse, 3l);
     }
 
@@ -1607,22 +1631,33 @@ public class SearchQueryIT extends ESIntegTestCase {
         refresh();
 
         SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(spanNotQuery(spanNearQuery(1)
+                .setQuery(spanNotQuery().include(spanNearQuery()
                         .clause(QueryBuilders.spanTermQuery("description", "quick"))
-                        .clause(QueryBuilders.spanTermQuery("description", "fox")), spanTermQuery("description", "brown"))).get();
+                        .clause(QueryBuilders.spanTermQuery("description", "fox")).slop(1)).exclude(spanTermQuery("description", "brown"))).get();
         assertHitCount(searchResponse, 1l);
 
         searchResponse = client().prepareSearch("test")
-                .setQuery(spanNotQuery(spanNearQuery(1)
+                .setQuery(spanNotQuery().include(spanNearQuery()
                         .clause(QueryBuilders.spanTermQuery("description", "quick"))
-                        .clause(QueryBuilders.spanTermQuery("description", "fox")), spanTermQuery("description", "sleeping")).dist(5)).get();
+                        .clause(QueryBuilders.spanTermQuery("description", "fox")).slop(1)).exclude(spanTermQuery("description", "sleeping")).dist(5)).get();
         assertHitCount(searchResponse, 1l);
 
         searchResponse = client().prepareSearch("test")
-                .setQuery(spanNotQuery(spanNearQuery(1)
+                .setQuery(spanNotQuery().include(spanNearQuery()
                         .clause(QueryBuilders.spanTermQuery("description", "quick"))
-                        .clause(QueryBuilders.spanTermQuery("description", "fox")), spanTermQuery("description", "jumped")).pre(1).post(1)).get();
+                        .clause(QueryBuilders.spanTermQuery("description", "fox")).slop(1)).exclude(spanTermQuery("description", "jumped")).pre(1).post(1)).get();
         assertHitCount(searchResponse, 1l);
+
+        try {
+            client().prepareSearch("test")
+                    .setQuery(spanNotQuery().include(spanNearQuery()
+                            .clause(QueryBuilders.spanTermQuery("description", "quick"))
+                            .clause(QueryBuilders.spanTermQuery("description", "fox")).slop(1)).exclude(spanTermQuery("description", "jumped")).dist(2).pre(2)
+                    ).get();
+            fail("ElasticsearchIllegalArgumentException should have been caught");
+        } catch (ElasticsearchException e) {
+            assertThat("ElasticsearchIllegalArgumentException should have been caught", e.getDetailedMessage(), containsString("spanNot can either use [dist] or [pre] & [post] (or none)"));
+        }
     }
 
     @Test
@@ -1718,18 +1753,18 @@ public class SearchQueryIT extends ESIntegTestCase {
 
         client().prepareIndex("test", "test", "1").setSource("text", "quick brown fox").get();
         refresh();
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick").operator(Operator.AND)).get();
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick").operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1);
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick brown").operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick brown").operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1);
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fast").operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fast").operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1);
 
         client().prepareIndex("test", "test", "2").setSource("text", "fast brown fox").get();
         refresh();
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick").operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick").operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 2);
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick brown").operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick brown").operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 2);
     }
 
@@ -1749,12 +1784,12 @@ public class SearchQueryIT extends ESIntegTestCase {
 
         client().prepareIndex("test", "test", "1").setSource("text", "the fox runs across the street").get();
         refresh();
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fox runs").operator(Operator.AND)).get();
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fox runs").operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1);
 
         client().prepareIndex("test", "test", "2").setSource("text", "run fox run").get();
         refresh();
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fox runs").operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fox runs").operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 2);
     }
 
@@ -1775,19 +1810,19 @@ public class SearchQueryIT extends ESIntegTestCase {
         client().prepareIndex("test", "test", "1").setSource("text", "quick brown fox").get();
         refresh();
 
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick").defaultField("text").defaultOperator(Operator.AND)).get();
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick").defaultField("text").defaultOperator(QueryStringQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1);
-        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick brown").defaultField("text").defaultOperator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick brown").defaultField("text").defaultOperator(QueryStringQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1);
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("fast").defaultField("text").defaultOperator(Operator.AND)).get();
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("fast").defaultField("text").defaultOperator(QueryStringQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1);
 
         client().prepareIndex("test", "test", "2").setSource("text", "fast brown fox").get();
         refresh();
 
-        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick").defaultField("text").defaultOperator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick").defaultField("text").defaultOperator(QueryStringQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 2);
-        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick brown").defaultField("text").defaultOperator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick brown").defaultField("text").defaultOperator(QueryStringQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 2);
     }
 
@@ -1813,7 +1848,7 @@ public class SearchQueryIT extends ESIntegTestCase {
         SearchResponse response = client()
                 .prepareSearch("test")
                 .setQuery(
-                        queryStringQuery("foo.baz").useDisMax(false).defaultOperator(Operator.AND)
+                        queryStringQuery("foo.baz").useDisMax(false).defaultOperator(QueryStringQueryBuilder.Operator.AND)
                                 .field("field1").field("field2")).get();
         assertHitCount(response, 1l);
     }
@@ -1879,7 +1914,7 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertSearchHits(searchResponse, "1", "2", "3");
         searchResponse = client().prepareSearch("index1", "index2", "index3")
                 .setQuery(indicesQuery(matchQuery("text", "value1"), "index1")
-                        .noMatchQuery(QueryBuilders.matchAllQuery())).get();
+                        .noMatchQuery("all")).get();
         assertHitCount(searchResponse, 3l);
         assertSearchHits(searchResponse, "1", "2", "3");
 
@@ -1890,7 +1925,6 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertFirstHit(searchResponse, hasId("1"));
     }
 
-    @AwaitsFix(bugUrl = "https://github.com/elastic/elasticsearch/issues/12822")
     @Test // https://github.com/elasticsearch/elasticsearch/issues/2416
     public void testIndicesQuerySkipParsing() throws Exception {
         createIndex("simple");
diff --git a/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java b/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java
index a8c5ccb..e41c451 100644
--- a/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java
+++ b/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java
@@ -23,7 +23,7 @@ import org.elasticsearch.action.admin.indices.create.CreateIndexRequestBuilder;
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.query.BoolQueryBuilder;
-import org.elasticsearch.index.query.Operator;
+import org.elasticsearch.index.query.SimpleQueryStringBuilder;
 import org.elasticsearch.index.query.SimpleQueryStringFlag;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
@@ -33,7 +33,10 @@ import java.util.Locale;
 import java.util.concurrent.ExecutionException;
 
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.index.query.QueryBuilders.*;
+import static org.elasticsearch.index.query.QueryBuilders.boolQuery;
+import static org.elasticsearch.index.query.QueryBuilders.queryStringQuery;
+import static org.elasticsearch.index.query.QueryBuilders.simpleQueryStringQuery;
+import static org.elasticsearch.index.query.QueryBuilders.termQuery;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
 import static org.hamcrest.Matchers.equalTo;
 
@@ -67,7 +70,7 @@ public class SimpleQueryStringIT extends ESIntegTestCase {
         assertFirstHit(searchResponse, hasId("3"));
 
         searchResponse = client().prepareSearch().setQuery(
-                simpleQueryStringQuery("foo bar").defaultOperator(Operator.AND)).get();
+                simpleQueryStringQuery("foo bar").defaultOperator(SimpleQueryStringBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("3"));
 
@@ -248,21 +251,21 @@ public class SimpleQueryStringIT extends ESIntegTestCase {
 
         searchResponse = client().prepareSearch().setQuery(
                 simpleQueryStringQuery("foo | bar")
-                        .defaultOperator(Operator.AND)
+                        .defaultOperator(SimpleQueryStringBuilder.Operator.AND)
                         .flags(SimpleQueryStringFlag.OR)).get();
         assertHitCount(searchResponse, 3l);
         assertSearchHits(searchResponse, "1", "2", "3");
 
         searchResponse = client().prepareSearch().setQuery(
                 simpleQueryStringQuery("foo | bar")
-                        .defaultOperator(Operator.AND)
+                        .defaultOperator(SimpleQueryStringBuilder.Operator.AND)
                         .flags(SimpleQueryStringFlag.NONE)).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("3"));
 
         searchResponse = client().prepareSearch().setQuery(
                 simpleQueryStringQuery("baz | egg*")
-                        .defaultOperator(Operator.AND)
+                        .defaultOperator(SimpleQueryStringBuilder.Operator.AND)
                         .flags(SimpleQueryStringFlag.NONE)).get();
         assertHitCount(searchResponse, 0l);
 
@@ -279,7 +282,7 @@ public class SimpleQueryStringIT extends ESIntegTestCase {
 
         searchResponse = client().prepareSearch().setQuery(
                 simpleQueryStringQuery("baz | egg*")
-                        .defaultOperator(Operator.AND)
+                        .defaultOperator(SimpleQueryStringBuilder.Operator.AND)
                         .flags(SimpleQueryStringFlag.WHITESPACE, SimpleQueryStringFlag.PREFIX)).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("4"));
diff --git a/core/src/test/java/org/elasticsearch/search/rescore/QueryRescorerIT.java b/core/src/test/java/org/elasticsearch/search/rescore/QueryRescorerIT.java
index 5b559da..6aa31ca 100644
--- a/core/src/test/java/org/elasticsearch/search/rescore/QueryRescorerIT.java
+++ b/core/src/test/java/org/elasticsearch/search/rescore/QueryRescorerIT.java
@@ -33,7 +33,6 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.query.MatchQueryBuilder;
-import org.elasticsearch.index.query.Operator;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders;
 import org.elasticsearch.script.Script;
@@ -117,7 +116,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
         ensureYellow();
         refresh();
         SearchResponse searchResponse = client().prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(MatchQueryBuilder.Operator.OR))
                 .setRescorer(RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "quick brown").slop(2).boost(4.0f)).setRescoreQueryWeight(2))
                 .setRescoreWindow(5).execute().actionGet();
 
@@ -127,7 +126,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
         assertThat(searchResponse.getHits().getHits()[2].getId(), equalTo("2"));
 
         searchResponse = client().prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(MatchQueryBuilder.Operator.OR))
                 .setRescorer(RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "the quick brown").slop(3)))
                 .setRescoreWindow(5).execute().actionGet();
 
@@ -137,7 +136,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
         assertThirdHit(searchResponse, hasId("3"));
 
         searchResponse = client().prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(MatchQueryBuilder.Operator.OR))
                 .setRescorer(RescoreBuilder.queryRescorer((QueryBuilders.matchPhraseQuery("field1", "the quick brown"))))
                 .setRescoreWindow(5).execute().actionGet();
 
@@ -180,7 +179,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
         client().admin().indices().prepareRefresh("test").execute().actionGet();
         SearchResponse searchResponse = client()
                 .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(MatchQueryBuilder.Operator.OR))
                 .setFrom(0)
                 .setSize(5)
                 .setRescorer(
@@ -195,7 +194,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
 
         searchResponse = client()
                 .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(MatchQueryBuilder.Operator.OR))
                 .setFrom(0)
                 .setSize(5)
                 .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
@@ -212,7 +211,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
         // Make sure non-zero from works:
         searchResponse = client()
                 .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(MatchQueryBuilder.Operator.OR))
                 .setFrom(2)
                 .setSize(5)
                 .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
@@ -321,7 +320,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
 
         SearchResponse searchResponse = client()
                 .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts").operator(MatchQueryBuilder.Operator.OR))
                 .setFrom(0)
             .setSize(5).execute().actionGet();
         assertThat(searchResponse.getHits().hits().length, equalTo(4));
@@ -334,7 +333,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
         // Now, penalizing rescore (nothing matches the rescore query):
         searchResponse = client()
                 .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts").operator(MatchQueryBuilder.Operator.OR))
                 .setFrom(0)
                 .setSize(5)
                 .setRescorer(
@@ -426,7 +425,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
                     .prepareSearch()
                     .setSearchType(SearchType.QUERY_THEN_FETCH)
                     .setPreference("test") // ensure we hit the same shards for tie-breaking
-                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR))
+                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(MatchQueryBuilder.Operator.OR))
                     .setFrom(0)
                     .setSize(resultSize)
                     .setRescorer(
@@ -441,7 +440,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
             SearchResponse plain = client().prepareSearch()
                     .setSearchType(SearchType.QUERY_THEN_FETCH)
                     .setPreference("test") // ensure we hit the same shards for tie-breaking
-                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR)).setFrom(0).setSize(resultSize)
+                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(MatchQueryBuilder.Operator.OR)).setFrom(0).setSize(resultSize)
                     .execute().actionGet();
             
             // check equivalence
@@ -451,7 +450,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
                     .prepareSearch()
                     .setSearchType(SearchType.QUERY_THEN_FETCH)
                     .setPreference("test") // ensure we hit the same shards for tie-breaking
-                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR))
+                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(MatchQueryBuilder.Operator.OR))
                     .setFrom(0)
                     .setSize(resultSize)
                     .setRescorer(
@@ -469,7 +468,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
                     .prepareSearch()
                     .setSearchType(SearchType.QUERY_THEN_FETCH)
                     .setPreference("test") // ensure we hit the same shards for tie-breaking
-                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR))
+                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(MatchQueryBuilder.Operator.OR))
                     .setFrom(0)
                     .setSize(resultSize)
                     .setRescorer(
@@ -504,7 +503,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
             SearchResponse searchResponse = client()
                     .prepareSearch()
                     .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                    .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                    .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(MatchQueryBuilder.Operator.OR))
                     .setRescorer(
                             RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "the quick brown").slop(2).boost(4.0f))
                                     .setQueryWeight(0.5f).setRescoreQueryWeight(0.4f)).setRescoreWindow(5).setExplain(true).execute()
@@ -542,7 +541,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
             SearchResponse searchResponse = client()
                     .prepareSearch()
                     .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                    .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                    .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(MatchQueryBuilder.Operator.OR))
                     .setRescorer(innerRescoreQuery).setRescoreWindow(5).setExplain(true).execute()
                     .actionGet();
             assertHitCount(searchResponse, 3);
@@ -565,7 +564,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
                 searchResponse = client()
                         .prepareSearch()
                         .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                        .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                        .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(MatchQueryBuilder.Operator.OR))
                         .addRescorer(innerRescoreQuery).setRescoreWindow(5)
                         .addRescorer(outerRescoreQuery).setRescoreWindow(10)
                         .setExplain(true).get();
diff --git a/core/src/test/java/org/elasticsearch/search/scroll/SearchScrollIT.java b/core/src/test/java/org/elasticsearch/search/scroll/SearchScrollIT.java
index 1ac4d43..f5117ef 100644
--- a/core/src/test/java/org/elasticsearch/search/scroll/SearchScrollIT.java
+++ b/core/src/test/java/org/elasticsearch/search/scroll/SearchScrollIT.java
@@ -74,27 +74,27 @@ public class SearchScrollIT extends ESIntegTestCase {
                 .execute().actionGet();
         try {
             long counter = 0;
-    
+
             assertThat(searchResponse.getHits().getTotalHits(), equalTo(100l));
             assertThat(searchResponse.getHits().hits().length, equalTo(35));
             for (SearchHit hit : searchResponse.getHits()) {
                 assertThat(((Number) hit.sortValues()[0]).longValue(), equalTo(counter++));
             }
-    
+
             searchResponse = client().prepareSearchScroll(searchResponse.getScrollId())
                     .setScroll(TimeValue.timeValueMinutes(2))
                     .execute().actionGet();
-    
+
             assertThat(searchResponse.getHits().getTotalHits(), equalTo(100l));
             assertThat(searchResponse.getHits().hits().length, equalTo(35));
             for (SearchHit hit : searchResponse.getHits()) {
                 assertThat(((Number) hit.sortValues()[0]).longValue(), equalTo(counter++));
             }
-    
+
             searchResponse = client().prepareSearchScroll(searchResponse.getScrollId())
                     .setScroll(TimeValue.timeValueMinutes(2))
                     .execute().actionGet();
-    
+
             assertThat(searchResponse.getHits().getTotalHits(), equalTo(100l));
             assertThat(searchResponse.getHits().hits().length, equalTo(30));
             for (SearchHit hit : searchResponse.getHits()) {
@@ -133,47 +133,47 @@ public class SearchScrollIT extends ESIntegTestCase {
                 .execute().actionGet();
         try {
             long counter = 0;
-    
+
             assertThat(searchResponse.getHits().getTotalHits(), equalTo(100l));
             assertThat(searchResponse.getHits().hits().length, equalTo(3));
             for (SearchHit hit : searchResponse.getHits()) {
                 assertThat(((Number) hit.sortValues()[0]).longValue(), equalTo(counter++));
             }
-    
+
             for (int i = 0; i < 32; i++) {
                 searchResponse = client().prepareSearchScroll(searchResponse.getScrollId())
                         .setScroll(TimeValue.timeValueMinutes(2))
                         .execute().actionGet();
-    
+
                 assertThat(searchResponse.getHits().getTotalHits(), equalTo(100l));
                 assertThat(searchResponse.getHits().hits().length, equalTo(3));
                 for (SearchHit hit : searchResponse.getHits()) {
                     assertThat(((Number) hit.sortValues()[0]).longValue(), equalTo(counter++));
                 }
             }
-    
+
             // and now, the last one is one
             searchResponse = client().prepareSearchScroll(searchResponse.getScrollId())
                     .setScroll(TimeValue.timeValueMinutes(2))
                     .execute().actionGet();
-    
+
             assertThat(searchResponse.getHits().getTotalHits(), equalTo(100l));
             assertThat(searchResponse.getHits().hits().length, equalTo(1));
             for (SearchHit hit : searchResponse.getHits()) {
                 assertThat(((Number) hit.sortValues()[0]).longValue(), equalTo(counter++));
             }
-    
+
             // a the last is zero
             searchResponse = client().prepareSearchScroll(searchResponse.getScrollId())
                     .setScroll(TimeValue.timeValueMinutes(2))
                     .execute().actionGet();
-    
+
             assertThat(searchResponse.getHits().getTotalHits(), equalTo(100l));
             assertThat(searchResponse.getHits().hits().length, equalTo(0));
             for (SearchHit hit : searchResponse.getHits()) {
                 assertThat(((Number) hit.sortValues()[0]).longValue(), equalTo(counter++));
             }
-            
+
         } finally {
             clearScroll(searchResponse.getScrollId());
         }
@@ -212,7 +212,7 @@ public class SearchScrollIT extends ESIntegTestCase {
                 }
                 searchResponse = client().prepareSearchScroll(searchResponse.getScrollId()).setScroll(TimeValue.timeValueMinutes(2)).execute().actionGet();
             } while (searchResponse.getHits().hits().length > 0);
-    
+
             client().admin().indices().prepareRefresh().execute().actionGet();
             assertThat(client().prepareCount().setQuery(matchAllQuery()).execute().actionGet().getCount(), equalTo(500l));
             assertThat(client().prepareCount().setQuery(termQuery("message", "test")).execute().actionGet().getCount(), equalTo(0l));
@@ -410,9 +410,7 @@ public class SearchScrollIT extends ESIntegTestCase {
         assertThrows(internalCluster().transportClient().prepareSearchScroll(searchResponse2.getScrollId()).setScroll(TimeValue.timeValueMinutes(2)), RestStatus.NOT_FOUND);
     }
 
-    @Test
-    // https://github.com/elasticsearch/elasticsearch/issues/4156
-    public void testDeepPaginationWithOneDocIndexAndDoNotBlowUp() throws Exception {
+    public void testDeepScrollingDoesNotBlowUp() throws Exception {
         client().prepareIndex("index", "type", "1")
                 .setSource("field", "value")
                 .setRefresh(true)
@@ -422,11 +420,8 @@ public class SearchScrollIT extends ESIntegTestCase {
             SearchRequestBuilder builder = client().prepareSearch("index")
                     .setSearchType(searchType)
                     .setQuery(QueryBuilders.matchAllQuery())
-                    .setSize(Integer.MAX_VALUE);
-
-            if (randomBoolean()) {
-                builder.setScroll("1m");
-            }
+                    .setSize(Integer.MAX_VALUE)
+                    .setScroll("1m");
 
             SearchResponse response = builder.execute().actionGet();
             try {
diff --git a/core/src/test/java/org/elasticsearch/search/simple/SimpleSearchIT.java b/core/src/test/java/org/elasticsearch/search/simple/SimpleSearchIT.java
index ebf8b75..74e2ff3 100644
--- a/core/src/test/java/org/elasticsearch/search/simple/SimpleSearchIT.java
+++ b/core/src/test/java/org/elasticsearch/search/simple/SimpleSearchIT.java
@@ -22,11 +22,13 @@ package org.elasticsearch.search.simple;
 import org.apache.lucene.util.Constants;
 import org.elasticsearch.action.index.IndexRequestBuilder;
 import org.elasticsearch.action.search.SearchPhaseExecutionException;
+import org.elasticsearch.action.search.SearchRequestBuilder;
 import org.elasticsearch.action.search.SearchResponse;
+import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.query.QueryBuilders;
+import org.elasticsearch.search.internal.DefaultSearchContext;
 import org.elasticsearch.test.ESIntegTestCase;
-import org.junit.Test;
 
 import java.util.ArrayList;
 import java.util.List;
@@ -38,12 +40,12 @@ import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
 import static org.elasticsearch.index.query.QueryBuilders.boolQuery;
 import static org.elasticsearch.index.query.QueryBuilders.rangeQuery;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
 import static org.hamcrest.Matchers.containsString;
 
 public class SimpleSearchIT extends ESIntegTestCase {
-
-    @Test
     public void testSearchNullIndex() {
         try {
             client().prepareSearch((String) null).setQuery(QueryBuilders.termQuery("_id", "XXX1")).execute().actionGet();
@@ -60,7 +62,6 @@ public class SimpleSearchIT extends ESIntegTestCase {
         }
     }
 
-    @Test
     public void testSearchRandomPreference() throws InterruptedException, ExecutionException {
         createIndex("test");
         indexRandom(true, client().prepareIndex("test", "type", "1").setSource("field", "value"),
@@ -84,8 +85,7 @@ public class SimpleSearchIT extends ESIntegTestCase {
         }
     }
 
-    @Test
-    public void simpleIpTests() throws Exception {
+    public void testSimpleIp() throws Exception {
         createIndex("test");
 
         client().admin().indices().preparePutMapping("test").setType("type1")
@@ -104,8 +104,7 @@ public class SimpleSearchIT extends ESIntegTestCase {
         assertHitCount(search, 1l);
     }
 
-    @Test
-    public void simpleIdTests() {
+    public void testSimpleId() {
         createIndex("test");
 
         client().prepareIndex("test", "type", "XXX1").setSource("field", "value").setRefresh(true).execute().actionGet();
@@ -124,8 +123,7 @@ public class SimpleSearchIT extends ESIntegTestCase {
         assertHitCount(searchResponse, 1l);
     }
 
-    @Test
-    public void simpleDateRangeTests() throws Exception {
+    public void testSimpleDateRange() throws Exception {
         createIndex("test");
         client().prepareIndex("test", "type1", "1").setSource("field", "2010-01-05T02:00").execute().actionGet();
         client().prepareIndex("test", "type1", "2").setSource("field", "2010-01-06T02:00").execute().actionGet();
@@ -150,9 +148,8 @@ public class SimpleSearchIT extends ESIntegTestCase {
         searchResponse = client().prepareSearch("test").setQuery(QueryBuilders.queryStringQuery("field:[2010-01-03||+2d TO 2010-01-04||+2d/d]")).execute().actionGet();
         assertHitCount(searchResponse, 2l);
     }
-    
-    @Test
-    public void localeDependentDateTests() throws Exception {
+
+    public void testLocaleDependentDate() throws Exception {
         assumeFalse("Locals are buggy on JDK9EA", Constants.JRE_IS_MINIMUM_JAVA9 && systemPropertyAsBoolean("tests.security.manager", false));
         assertAcked(prepareCreate("test")
                 .addMapping("type1",
@@ -189,8 +186,7 @@ public class SimpleSearchIT extends ESIntegTestCase {
         }
     }
 
-    @Test
-    public void simpleTerminateAfterCountTests() throws Exception {
+    public void testSimpleTerminateAfterCount() throws Exception {
         prepareCreate("test").setSettings(
                 SETTING_NUMBER_OF_SHARDS, 1,
                 SETTING_NUMBER_OF_REPLICAS, 0).get();
@@ -225,16 +221,76 @@ public class SimpleSearchIT extends ESIntegTestCase {
         assertFalse(searchResponse.isTerminatedEarly());
     }
 
-    @Test
-    public void testInsaneFrom() throws Exception {
+    public void testInsaneFromAndSize() throws Exception {
+        createIndex("idx");
+        indexRandom(true, client().prepareIndex("idx", "type").setSource("{}"));
+
+        assertWindowFails(client().prepareSearch("idx").setFrom(Integer.MAX_VALUE));
+        assertWindowFails(client().prepareSearch("idx").setSize(Integer.MAX_VALUE));
+    }
+
+    public void testTooLargeFromAndSize() throws Exception {
         createIndex("idx");
         indexRandom(true, client().prepareIndex("idx", "type").setSource("{}"));
 
+        assertWindowFails(client().prepareSearch("idx").setFrom(DefaultSearchContext.Defaults.MAX_RESULT_WINDOW));
+        assertWindowFails(client().prepareSearch("idx").setSize(DefaultSearchContext.Defaults.MAX_RESULT_WINDOW + 1));
+        assertWindowFails(client().prepareSearch("idx").setSize(DefaultSearchContext.Defaults.MAX_RESULT_WINDOW)
+                .setFrom(DefaultSearchContext.Defaults.MAX_RESULT_WINDOW));
+    }
+
+    public void testLargeFromAndSizeSucceeds() throws Exception {
+        createIndex("idx");
+        indexRandom(true, client().prepareIndex("idx", "type").setSource("{}"));
+
+        assertHitCount(client().prepareSearch("idx").setFrom(DefaultSearchContext.Defaults.MAX_RESULT_WINDOW - 10).get(), 1);
+        assertHitCount(client().prepareSearch("idx").setSize(DefaultSearchContext.Defaults.MAX_RESULT_WINDOW).get(), 1);
+        assertHitCount(client().prepareSearch("idx").setSize(DefaultSearchContext.Defaults.MAX_RESULT_WINDOW / 2)
+                .setFrom(DefaultSearchContext.Defaults.MAX_RESULT_WINDOW / 2 - 1).get(), 1);
+    }
+
+    public void testTooLargeFromAndSizeOkBySetting() throws Exception {
+        prepareCreate("idx").setSettings(DefaultSearchContext.MAX_RESULT_WINDOW, DefaultSearchContext.Defaults.MAX_RESULT_WINDOW * 2).get();
+        indexRandom(true, client().prepareIndex("idx", "type").setSource("{}"));
+
+        assertHitCount(client().prepareSearch("idx").setFrom(DefaultSearchContext.Defaults.MAX_RESULT_WINDOW).get(), 1);
+        assertHitCount(client().prepareSearch("idx").setSize(DefaultSearchContext.Defaults.MAX_RESULT_WINDOW + 1).get(), 1);
+        assertHitCount(client().prepareSearch("idx").setSize(DefaultSearchContext.Defaults.MAX_RESULT_WINDOW)
+                .setFrom(DefaultSearchContext.Defaults.MAX_RESULT_WINDOW).get(), 1);
+    }
+
+    public void testTooLargeFromAndSizeOkByDynamicSetting() throws Exception {
+        createIndex("idx");
+        assertAcked(client().admin().indices().prepareUpdateSettings("idx")
+                .setSettings(
+                        Settings.builder().put(DefaultSearchContext.MAX_RESULT_WINDOW, DefaultSearchContext.Defaults.MAX_RESULT_WINDOW * 2))
+                .get());
+        indexRandom(true, client().prepareIndex("idx", "type").setSource("{}"));
+
+        assertHitCount(client().prepareSearch("idx").setFrom(DefaultSearchContext.Defaults.MAX_RESULT_WINDOW).get(), 1);
+        assertHitCount(client().prepareSearch("idx").setSize(DefaultSearchContext.Defaults.MAX_RESULT_WINDOW + 1).get(), 1);
+        assertHitCount(client().prepareSearch("idx").setSize(DefaultSearchContext.Defaults.MAX_RESULT_WINDOW)
+                .setFrom(DefaultSearchContext.Defaults.MAX_RESULT_WINDOW).get(), 1);
+    }
+
+    public void testTooLargeFromAndSizeBackwardsCompatibilityRecommendation() throws Exception {
+        prepareCreate("idx").setSettings(DefaultSearchContext.MAX_RESULT_WINDOW, Integer.MAX_VALUE).get();
+        indexRandom(true, client().prepareIndex("idx", "type").setSource("{}"));
+
+        assertHitCount(client().prepareSearch("idx").setFrom(DefaultSearchContext.Defaults.MAX_RESULT_WINDOW * 10).get(), 1);
+        assertHitCount(client().prepareSearch("idx").setSize(DefaultSearchContext.Defaults.MAX_RESULT_WINDOW * 10).get(), 1);
+        assertHitCount(client().prepareSearch("idx").setSize(DefaultSearchContext.Defaults.MAX_RESULT_WINDOW * 10)
+                .setFrom(DefaultSearchContext.Defaults.MAX_RESULT_WINDOW * 10).get(), 1);
+    }
+
+    private void assertWindowFails(SearchRequestBuilder search) {
         try {
-            client().prepareSearch("idx").setFrom(Integer.MAX_VALUE).get();
+            search.get();
             fail();
         } catch (SearchPhaseExecutionException e) {
-            assertThat(e.toString(), containsString("Result window is too large, from + size must be less than or equal to:"));
+            assertThat(e.toString(), containsString("Result window is too large, from + size must be less than or equal to: ["
+                    + DefaultSearchContext.Defaults.MAX_RESULT_WINDOW));
+            assertThat(e.toString(), containsString("See the scroll api for a more efficient way to request large data sets"));
         }
     }
 }
diff --git a/core/src/test/java/org/elasticsearch/search/suggest/ContextSuggestSearchIT.java b/core/src/test/java/org/elasticsearch/search/suggest/ContextSuggestSearchIT.java
index 28a5a1b..596c675 100644
--- a/core/src/test/java/org/elasticsearch/search/suggest/ContextSuggestSearchIT.java
+++ b/core/src/test/java/org/elasticsearch/search/suggest/ContextSuggestSearchIT.java
@@ -18,8 +18,7 @@
  */
 package org.elasticsearch.search.suggest;
 
-import com.google.common.collect.Sets;
-
+import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import org.elasticsearch.action.admin.indices.create.CreateIndexRequestBuilder;
 import org.elasticsearch.action.suggest.SuggestRequest;
 import org.elasticsearch.action.suggest.SuggestRequestBuilder;
@@ -27,6 +26,7 @@ import org.elasticsearch.action.suggest.SuggestResponse;
 import org.elasticsearch.common.geo.GeoHashUtils;
 import org.elasticsearch.common.geo.GeoPoint;
 import org.elasticsearch.common.unit.Fuzziness;
+import org.elasticsearch.common.util.set.Sets;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.index.mapper.MapperParsingException;
 import org.elasticsearch.search.suggest.Suggest.Suggestion;
@@ -38,15 +38,21 @@ import org.elasticsearch.search.suggest.completion.CompletionSuggestionFuzzyBuil
 import org.elasticsearch.search.suggest.context.ContextBuilder;
 import org.elasticsearch.search.suggest.context.ContextMapping;
 import org.elasticsearch.test.ESIntegTestCase;
-import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import org.hamcrest.Matchers;
 import org.junit.Test;
 
 import java.io.IOException;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
 
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSuggestion;
 import static org.elasticsearch.test.hamcrest.ElasticsearchGeoAssertions.assertDistance;
 import static org.hamcrest.Matchers.containsString;
 
diff --git a/core/src/test/java/org/elasticsearch/test/ESTestCase.java b/core/src/test/java/org/elasticsearch/test/ESTestCase.java
index 6d04adb..2916cbb 100644
--- a/core/src/test/java/org/elasticsearch/test/ESTestCase.java
+++ b/core/src/test/java/org/elasticsearch/test/ESTestCase.java
@@ -371,27 +371,17 @@ public abstract class ESTestCase extends LuceneTestCase {
         return RandomizedTest.randomRealisticUnicodeOfCodepointLength(codePoints);
     }
 
-    public static String[] generateRandomStringArray(int maxArraySize, int maxStringSize, boolean allowNull, boolean allowEmpty) {
+    public static String[] generateRandomStringArray(int maxArraySize, int maxStringSize, boolean allowNull) {
         if (allowNull && random().nextBoolean()) {
             return null;
         }
-        int arraySize = randomIntBetween(allowEmpty ? 0 : 1, maxArraySize);
-        String[] array = new String[arraySize];
-        for (int i = 0; i < arraySize; i++) {
+        String[] array = new String[random().nextInt(maxArraySize)]; // allow empty arrays
+        for (int i = 0; i < array.length; i++) {
             array[i] = RandomStrings.randomAsciiOfLength(random(), maxStringSize);
         }
         return array;
     }
 
-    public static String[] generateRandomStringArray(int maxArraySize, int maxStringSize, boolean allowNull) {
-        return generateRandomStringArray(maxArraySize, maxStringSize, allowNull, true);
-    }
-
-    public static String randomTimeValue() {
-        final String[] values = new String[]{"d", "H", "ms", "s", "S", "w"};
-        return randomIntBetween(0, 1000) + randomFrom(values);
-    }
-
     /**
      * Runs the code block for 10 seconds waiting for no assertion to trip.
      */
@@ -498,6 +488,10 @@ public abstract class ESTestCase extends LuceneTestCase {
         }
     }
 
+    public Path getBwcIndicesPath() {
+        return getDataPath("/indices/bwc");
+    }
+
     /** Returns a random number of temporary paths. */
     public String[] tmpPaths() {
         final int numPaths = TestUtil.nextInt(random(), 1, 3);
diff --git a/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java b/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java
index 48ad3f8..012ce95 100644
--- a/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java
+++ b/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java
@@ -25,7 +25,6 @@ import com.carrotsearch.randomizedtesting.generators.RandomInts;
 import com.carrotsearch.randomizedtesting.generators.RandomPicks;
 import com.carrotsearch.randomizedtesting.generators.RandomStrings;
 import com.google.common.collect.Iterators;
-import com.google.common.collect.Sets;
 import com.google.common.util.concurrent.Futures;
 import com.google.common.util.concurrent.ListenableFuture;
 import com.google.common.util.concurrent.SettableFuture;
@@ -65,6 +64,7 @@ import org.elasticsearch.common.unit.ByteSizeUnit;
 import org.elasticsearch.common.unit.ByteSizeValue;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.common.util.concurrent.EsExecutors;
+import org.elasticsearch.common.util.set.Sets;
 import org.elasticsearch.env.NodeEnvironment;
 import org.elasticsearch.http.HttpServerTransport;
 import org.elasticsearch.index.IndexService;
diff --git a/core/src/test/java/org/elasticsearch/test/rest/ESRestTestCase.java b/core/src/test/java/org/elasticsearch/test/rest/ESRestTestCase.java
index f3e18d7..33ddea0 100644
--- a/core/src/test/java/org/elasticsearch/test/rest/ESRestTestCase.java
+++ b/core/src/test/java/org/elasticsearch/test/rest/ESRestTestCase.java
@@ -155,6 +155,7 @@ public abstract class ESRestTestCase extends ESIntegTestCase {
         return Settings.builder()
             .putArray(URLRepository.ALLOWED_URLS_SETTING, "http://snapshot.test*")
             .put(Node.HTTP_ENABLED, true)
+            .put("node.testattr", "test")
             .put(super.nodeSettings(nodeOrdinal)).build();
     }
     
diff --git a/core/src/test/java/org/elasticsearch/test/rest/client/RestClient.java b/core/src/test/java/org/elasticsearch/test/rest/client/RestClient.java
index 49bb01f..b7173db 100644
--- a/core/src/test/java/org/elasticsearch/test/rest/client/RestClient.java
+++ b/core/src/test/java/org/elasticsearch/test/rest/client/RestClient.java
@@ -19,7 +19,6 @@
 package org.elasticsearch.test.rest.client;
 
 import com.carrotsearch.randomizedtesting.RandomizedTest;
-import com.google.common.collect.Sets;
 import org.apache.http.config.Registry;
 import org.apache.http.config.RegistryBuilder;
 import org.apache.http.conn.socket.ConnectionSocketFactory;
@@ -38,6 +37,7 @@ import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.logging.Loggers;
 import org.elasticsearch.common.network.NetworkAddress;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.util.set.Sets;
 import org.elasticsearch.test.rest.client.http.HttpRequestBuilder;
 import org.elasticsearch.test.rest.client.http.HttpResponse;
 import org.elasticsearch.test.rest.spec.RestApi;
diff --git a/core/src/test/java/org/elasticsearch/test/rest/section/RestTestSuite.java b/core/src/test/java/org/elasticsearch/test/rest/section/RestTestSuite.java
index 923ba93..d53671b 100644
--- a/core/src/test/java/org/elasticsearch/test/rest/section/RestTestSuite.java
+++ b/core/src/test/java/org/elasticsearch/test/rest/section/RestTestSuite.java
@@ -18,11 +18,10 @@
  */
 package org.elasticsearch.test.rest.section;
 
-import com.google.common.collect.Sets;
-
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Set;
+import java.util.TreeSet;
 
 /**
  * Holds a REST test suite loaded from a specific yaml file.
@@ -35,7 +34,7 @@ public class RestTestSuite {
 
     private SetupSection setupSection;
 
-    private Set<TestSection> testSections = Sets.newTreeSet();
+    private Set<TestSection> testSections = new TreeSet<>();
 
     public RestTestSuite(String api, String name) {
         this.api = api;
diff --git a/core/src/test/java/org/elasticsearch/test/rest/support/FileUtils.java b/core/src/test/java/org/elasticsearch/test/rest/support/FileUtils.java
index 7790d91..e73906e 100644
--- a/core/src/test/java/org/elasticsearch/test/rest/support/FileUtils.java
+++ b/core/src/test/java/org/elasticsearch/test/rest/support/FileUtils.java
@@ -18,7 +18,6 @@
  */
 package org.elasticsearch.test.rest.support;
 
-import com.google.common.collect.Sets;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.io.PathUtils;
 
@@ -156,7 +155,7 @@ public final class FileUtils {
                     String groupName = file.toAbsolutePath().getParent().getFileName().toString();
                     Set<Path> filesSet = files.get(groupName);
                     if (filesSet == null) {
-                        filesSet = Sets.newHashSet();
+                        filesSet = new HashSet<>();
                         files.put(groupName, filesSet);
                     }
                     filesSet.add(file);
diff --git a/core/src/test/java/org/elasticsearch/test/transport/AssertingLocalTransport.java b/core/src/test/java/org/elasticsearch/test/transport/AssertingLocalTransport.java
index c253a75..d9b9b49 100644
--- a/core/src/test/java/org/elasticsearch/test/transport/AssertingLocalTransport.java
+++ b/core/src/test/java/org/elasticsearch/test/transport/AssertingLocalTransport.java
@@ -80,7 +80,7 @@ public class AssertingLocalTransport extends LocalTransport {
         ElasticsearchAssertions.assertVersionSerializable(VersionUtils.randomVersionBetween(random, minVersion, maxVersion), response);
         super.handleParsedResponse(response, handler);
     }
-
+    
     @Override
     public void sendRequest(final DiscoveryNode node, final long requestId, final String action, final TransportRequest request, TransportRequestOptions options) throws IOException, TransportException {
         ElasticsearchAssertions.assertVersionSerializable(VersionUtils.randomVersionBetween(random, minVersion, maxVersion), request);
diff --git a/core/src/test/java/org/elasticsearch/threadpool/SimpleThreadPoolIT.java b/core/src/test/java/org/elasticsearch/threadpool/SimpleThreadPoolIT.java
index bf79185..0bf0491 100644
--- a/core/src/test/java/org/elasticsearch/threadpool/SimpleThreadPoolIT.java
+++ b/core/src/test/java/org/elasticsearch/threadpool/SimpleThreadPoolIT.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.threadpool;
 
-import com.google.common.collect.Sets;
 import org.elasticsearch.action.admin.cluster.node.info.NodeInfo;
 import org.elasticsearch.action.admin.cluster.node.info.NodesInfoResponse;
 import org.elasticsearch.action.index.IndexRequestBuilder;
@@ -44,16 +43,24 @@ import java.io.IOException;
 import java.lang.management.ManagementFactory;
 import java.lang.management.ThreadInfo;
 import java.lang.management.ThreadMXBean;
+import java.util.HashSet;
 import java.util.Map;
 import java.util.Set;
-import java.util.concurrent.*;
+import java.util.concurrent.BrokenBarrierException;
+import java.util.concurrent.CyclicBarrier;
+import java.util.concurrent.Executor;
+import java.util.concurrent.ThreadPoolExecutor;
+import java.util.concurrent.TimeUnit;
 import java.util.regex.Pattern;
 
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
 import static org.elasticsearch.test.ESIntegTestCase.Scope;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
-import static org.hamcrest.Matchers.*;
+import static org.hamcrest.Matchers.containsString;
+import static org.hamcrest.Matchers.equalTo;
+import static org.hamcrest.Matchers.not;
+import static org.hamcrest.Matchers.sameInstance;
 
 /**
  */
@@ -69,7 +76,7 @@ public class SimpleThreadPoolIT extends ESIntegTestCase {
     public void verifyThreadNames() throws Exception {
 
         ThreadMXBean threadBean = ManagementFactory.getThreadMXBean();
-        Set<String> preNodeStartThreadNames = Sets.newHashSet();
+        Set<String> preNodeStartThreadNames = new HashSet<>();
         for (long l : threadBean.getAllThreadIds()) {
             ThreadInfo threadInfo = threadBean.getThreadInfo(l);
             if (threadInfo != null) {
@@ -98,7 +105,7 @@ public class SimpleThreadPoolIT extends ESIntegTestCase {
             assertNoFailures(client().prepareSearch("idx").setQuery(QueryBuilders.termQuery("str_value", "s" + i)).get());
             assertNoFailures(client().prepareSearch("idx").setQuery(QueryBuilders.termQuery("l_value", i)).get());
         }
-        Set<String> threadNames = Sets.newHashSet();
+        Set<String> threadNames = new HashSet<>();
         for (long l : threadBean.getAllThreadIds()) {
             ThreadInfo threadInfo = threadBean.getThreadInfo(l);
             if (threadInfo != null) {
diff --git a/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java b/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java
index fd805bd..9df8092 100644
--- a/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java
+++ b/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java
@@ -54,7 +54,7 @@ import org.elasticsearch.index.query.GeoShapeQueryBuilder;
 import org.elasticsearch.index.query.MoreLikeThisQueryBuilder;
 import org.elasticsearch.index.query.MoreLikeThisQueryBuilder.Item;
 import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.index.query.TermsQueryBuilder;
+import org.elasticsearch.index.query.TermsLookupQueryBuilder;
 import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.rest.RestController;
 import org.elasticsearch.script.Script;
@@ -161,7 +161,7 @@ public class ContextAndHeaderTransportIT extends ESIntegTestCase {
                 .setSource(jsonBuilder().startObject().field("username", "foo").endObject()).get();
         transportClient().admin().indices().prepareRefresh(queryIndex, lookupIndex).get();
 
-        TermsQueryBuilder termsLookupFilterBuilder = QueryBuilders.termsLookupQuery("username").lookupIndex(lookupIndex).lookupType("type").lookupId("1").lookupPath("followers");
+        TermsLookupQueryBuilder termsLookupFilterBuilder = QueryBuilders.termsLookupQuery("username").lookupIndex(lookupIndex).lookupType("type").lookupId("1").lookupPath("followers");
         BoolQueryBuilder queryBuilder = QueryBuilders.boolQuery().must(QueryBuilders.matchAllQuery()).must(termsLookupFilterBuilder);
 
         SearchResponse searchResponse = transportClient()
diff --git a/core/src/test/java/org/elasticsearch/tribe/TribeIT.java b/core/src/test/java/org/elasticsearch/tribe/TribeIT.java
index 1f8b7f1..c9d7d93 100644
--- a/core/src/test/java/org/elasticsearch/tribe/TribeIT.java
+++ b/core/src/test/java/org/elasticsearch/tribe/TribeIT.java
@@ -442,4 +442,4 @@ public class TribeIT extends ESIntegTestCase {
         }
         return unicastHosts.toArray(new String[unicastHosts.size()]);
     }
-}
\ No newline at end of file
+}
diff --git a/core/src/test/java/org/elasticsearch/validate/SimpleValidateQueryIT.java b/core/src/test/java/org/elasticsearch/validate/SimpleValidateQueryIT.java
index 832f5d3..b55fd55 100644
--- a/core/src/test/java/org/elasticsearch/validate/SimpleValidateQueryIT.java
+++ b/core/src/test/java/org/elasticsearch/validate/SimpleValidateQueryIT.java
@@ -236,7 +236,7 @@ public class SimpleValidateQueryIT extends ESIntegTestCase {
                 containsString("+field:pidgin (field:huge field:brown)"), true);
         assertExplanation(QueryBuilders.commonTermsQuery("field", "the brown").analyzer("stop"),
                 containsString("field:brown"), true);
-
+        
         // match queries with cutoff frequency
         assertExplanation(QueryBuilders.matchQuery("field", "huge brown pidgin").cutoffFrequency(1),
                 containsString("+field:pidgin (field:huge field:brown)"), true);
@@ -276,7 +276,11 @@ public class SimpleValidateQueryIT extends ESIntegTestCase {
         assertThat(client().admin().indices().prepareValidateQuery("test").setSource(new BytesArray("{\"query\": {\"term\" : { \"user\" : \"kimchy\" }}, \"foo\": \"bar\"}")).get().isValid(), equalTo(false));
     }
 
-    private static void assertExplanation(QueryBuilder queryBuilder, Matcher<String> matcher, boolean withRewrite) {
+    private void assertExplanation(QueryBuilder queryBuilder, Matcher<String> matcher) {
+        assertExplanation(queryBuilder, matcher, false);
+    }
+
+    private void assertExplanation(QueryBuilder queryBuilder, Matcher<String> matcher, boolean withRewrite) {
         ValidateQueryResponse response = client().admin().indices().prepareValidateQuery("test")
                 .setTypes("type1")
                 .setQuery(queryBuilder)
diff --git a/core/src/test/resources/indices/bwc/index-0.90.0.Beta1.zip b/core/src/test/resources/indices/bwc/index-0.90.0.Beta1.zip
new file mode 100644
index 0000000..5bbdea4
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-0.90.0.Beta1.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-0.90.0.RC1.zip b/core/src/test/resources/indices/bwc/index-0.90.0.RC1.zip
new file mode 100644
index 0000000..d9072ce
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-0.90.0.RC1.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-0.90.0.RC2.zip b/core/src/test/resources/indices/bwc/index-0.90.0.RC2.zip
new file mode 100644
index 0000000..dce299b
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-0.90.0.RC2.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-0.90.0.zip b/core/src/test/resources/indices/bwc/index-0.90.0.zip
new file mode 100644
index 0000000..3ec908d
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-0.90.0.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-0.90.1.zip b/core/src/test/resources/indices/bwc/index-0.90.1.zip
new file mode 100644
index 0000000..67db98f
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-0.90.1.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-0.90.10.zip b/core/src/test/resources/indices/bwc/index-0.90.10.zip
new file mode 100644
index 0000000..6bdb9f2
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-0.90.10.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-0.90.11.zip b/core/src/test/resources/indices/bwc/index-0.90.11.zip
new file mode 100644
index 0000000..b5253f9
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-0.90.11.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-0.90.12.zip b/core/src/test/resources/indices/bwc/index-0.90.12.zip
new file mode 100644
index 0000000..0392049
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-0.90.12.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-0.90.13.zip b/core/src/test/resources/indices/bwc/index-0.90.13.zip
new file mode 100644
index 0000000..025b4c3
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-0.90.13.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-0.90.2.zip b/core/src/test/resources/indices/bwc/index-0.90.2.zip
new file mode 100644
index 0000000..413e08e
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-0.90.2.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-0.90.3.zip b/core/src/test/resources/indices/bwc/index-0.90.3.zip
new file mode 100644
index 0000000..c31d4de
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-0.90.3.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-0.90.4.zip b/core/src/test/resources/indices/bwc/index-0.90.4.zip
new file mode 100644
index 0000000..8b07a92
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-0.90.4.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-0.90.5.zip b/core/src/test/resources/indices/bwc/index-0.90.5.zip
new file mode 100644
index 0000000..dfd0fd0
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-0.90.5.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-0.90.6.zip b/core/src/test/resources/indices/bwc/index-0.90.6.zip
new file mode 100644
index 0000000..1f3cff2
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-0.90.6.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-0.90.7.zip b/core/src/test/resources/indices/bwc/index-0.90.7.zip
new file mode 100644
index 0000000..6d0e65c
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-0.90.7.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-0.90.8.zip b/core/src/test/resources/indices/bwc/index-0.90.8.zip
new file mode 100644
index 0000000..8ff8ac3
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-0.90.8.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-0.90.9.zip b/core/src/test/resources/indices/bwc/index-0.90.9.zip
new file mode 100644
index 0000000..4445b39
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-0.90.9.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.0.0.Beta1.zip b/core/src/test/resources/indices/bwc/index-1.0.0.Beta1.zip
new file mode 100644
index 0000000..167dde8
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.0.0.Beta1.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.0.0.Beta2.zip b/core/src/test/resources/indices/bwc/index-1.0.0.Beta2.zip
new file mode 100644
index 0000000..95fbfef
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.0.0.Beta2.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.0.0.RC1.zip b/core/src/test/resources/indices/bwc/index-1.0.0.RC1.zip
new file mode 100644
index 0000000..3ced97a
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.0.0.RC1.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.0.0.RC2.zip b/core/src/test/resources/indices/bwc/index-1.0.0.RC2.zip
new file mode 100644
index 0000000..1298cfb
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.0.0.RC2.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.0.0.zip b/core/src/test/resources/indices/bwc/index-1.0.0.zip
new file mode 100644
index 0000000..2cb9abc
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.0.0.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.0.1.zip b/core/src/test/resources/indices/bwc/index-1.0.1.zip
new file mode 100644
index 0000000..844271b
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.0.1.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.0.2.zip b/core/src/test/resources/indices/bwc/index-1.0.2.zip
new file mode 100644
index 0000000..dd8e393
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.0.2.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.0.3.zip b/core/src/test/resources/indices/bwc/index-1.0.3.zip
new file mode 100644
index 0000000..e4437ef
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.0.3.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.1.0.zip b/core/src/test/resources/indices/bwc/index-1.1.0.zip
new file mode 100644
index 0000000..4f05370
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.1.0.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.1.1.zip b/core/src/test/resources/indices/bwc/index-1.1.1.zip
new file mode 100644
index 0000000..effeb94
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.1.1.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.1.2.zip b/core/src/test/resources/indices/bwc/index-1.1.2.zip
new file mode 100644
index 0000000..bedffa4
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.1.2.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.2.0.zip b/core/src/test/resources/indices/bwc/index-1.2.0.zip
new file mode 100644
index 0000000..4644a38
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.2.0.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.2.1.zip b/core/src/test/resources/indices/bwc/index-1.2.1.zip
new file mode 100644
index 0000000..553b46b
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.2.1.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.2.2.zip b/core/src/test/resources/indices/bwc/index-1.2.2.zip
new file mode 100644
index 0000000..3f51a47
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.2.2.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.2.3.zip b/core/src/test/resources/indices/bwc/index-1.2.3.zip
new file mode 100644
index 0000000..8c8bfbd
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.2.3.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.2.4.zip b/core/src/test/resources/indices/bwc/index-1.2.4.zip
new file mode 100644
index 0000000..e3a1519
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.2.4.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.3.0.zip b/core/src/test/resources/indices/bwc/index-1.3.0.zip
new file mode 100644
index 0000000..d98958d
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.3.0.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.3.1.zip b/core/src/test/resources/indices/bwc/index-1.3.1.zip
new file mode 100644
index 0000000..167d0f4
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.3.1.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.3.2.zip b/core/src/test/resources/indices/bwc/index-1.3.2.zip
new file mode 100644
index 0000000..756eaf6
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.3.2.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.3.3.zip b/core/src/test/resources/indices/bwc/index-1.3.3.zip
new file mode 100644
index 0000000..8470dee
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.3.3.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.3.4.zip b/core/src/test/resources/indices/bwc/index-1.3.4.zip
new file mode 100644
index 0000000..2175012
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.3.4.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.3.5.zip b/core/src/test/resources/indices/bwc/index-1.3.5.zip
new file mode 100644
index 0000000..19d1e56
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.3.5.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.3.6.zip b/core/src/test/resources/indices/bwc/index-1.3.6.zip
new file mode 100644
index 0000000..ad8e8bd
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.3.6.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.3.7.zip b/core/src/test/resources/indices/bwc/index-1.3.7.zip
new file mode 100644
index 0000000..3a645a9
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.3.7.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.3.8.zip b/core/src/test/resources/indices/bwc/index-1.3.8.zip
new file mode 100644
index 0000000..f8ab0a2
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.3.8.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.3.9.zip b/core/src/test/resources/indices/bwc/index-1.3.9.zip
new file mode 100644
index 0000000..5ef35b2
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.3.9.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.4.0.Beta1.zip b/core/src/test/resources/indices/bwc/index-1.4.0.Beta1.zip
new file mode 100644
index 0000000..4546f5d
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.4.0.Beta1.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.4.0.zip b/core/src/test/resources/indices/bwc/index-1.4.0.zip
new file mode 100644
index 0000000..467d19a
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.4.0.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.4.1.zip b/core/src/test/resources/indices/bwc/index-1.4.1.zip
new file mode 100644
index 0000000..2adbb28
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.4.1.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.4.2.zip b/core/src/test/resources/indices/bwc/index-1.4.2.zip
new file mode 100644
index 0000000..4fac208
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.4.2.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.4.3.zip b/core/src/test/resources/indices/bwc/index-1.4.3.zip
new file mode 100644
index 0000000..1a0d667
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.4.3.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.4.4.zip b/core/src/test/resources/indices/bwc/index-1.4.4.zip
new file mode 100644
index 0000000..0328a9e
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.4.4.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.4.5.zip b/core/src/test/resources/indices/bwc/index-1.4.5.zip
new file mode 100644
index 0000000..eeb25ab
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.4.5.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.5.0.zip b/core/src/test/resources/indices/bwc/index-1.5.0.zip
new file mode 100644
index 0000000..f1dab08
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.5.0.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.5.1.zip b/core/src/test/resources/indices/bwc/index-1.5.1.zip
new file mode 100644
index 0000000..342e311
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.5.1.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.5.2.zip b/core/src/test/resources/indices/bwc/index-1.5.2.zip
new file mode 100644
index 0000000..fb36b19
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.5.2.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.6.0.zip b/core/src/test/resources/indices/bwc/index-1.6.0.zip
new file mode 100644
index 0000000..02a5806
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.6.0.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.6.1.zip b/core/src/test/resources/indices/bwc/index-1.6.1.zip
new file mode 100644
index 0000000..04820f9
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.6.1.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.6.2.zip b/core/src/test/resources/indices/bwc/index-1.6.2.zip
new file mode 100644
index 0000000..af6ce56
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.6.2.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.7.0.zip b/core/src/test/resources/indices/bwc/index-1.7.0.zip
new file mode 100644
index 0000000..941be64
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.7.0.zip differ
diff --git a/core/src/test/resources/indices/bwc/index-1.7.1.zip b/core/src/test/resources/indices/bwc/index-1.7.1.zip
new file mode 100644
index 0000000..debd797
Binary files /dev/null and b/core/src/test/resources/indices/bwc/index-1.7.1.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.0.0.Beta2.zip b/core/src/test/resources/indices/bwc/repo-1.0.0.Beta2.zip
new file mode 100644
index 0000000..020f6f4
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.0.0.Beta2.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.0.0.RC1.zip b/core/src/test/resources/indices/bwc/repo-1.0.0.RC1.zip
new file mode 100644
index 0000000..a84c507
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.0.0.RC1.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.0.0.RC2.zip b/core/src/test/resources/indices/bwc/repo-1.0.0.RC2.zip
new file mode 100644
index 0000000..e5d65eb
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.0.0.RC2.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.0.0.zip b/core/src/test/resources/indices/bwc/repo-1.0.0.zip
new file mode 100644
index 0000000..13f778d
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.0.0.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.0.1.zip b/core/src/test/resources/indices/bwc/repo-1.0.1.zip
new file mode 100644
index 0000000..76ed278
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.0.1.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.0.2.zip b/core/src/test/resources/indices/bwc/repo-1.0.2.zip
new file mode 100644
index 0000000..762eabf
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.0.2.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.0.3.zip b/core/src/test/resources/indices/bwc/repo-1.0.3.zip
new file mode 100644
index 0000000..ba79dea
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.0.3.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.1.0.zip b/core/src/test/resources/indices/bwc/repo-1.1.0.zip
new file mode 100644
index 0000000..cbf84c7
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.1.0.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.1.1.zip b/core/src/test/resources/indices/bwc/repo-1.1.1.zip
new file mode 100644
index 0000000..00ea044
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.1.1.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.1.2.zip b/core/src/test/resources/indices/bwc/repo-1.1.2.zip
new file mode 100644
index 0000000..18abd99
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.1.2.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.2.0.zip b/core/src/test/resources/indices/bwc/repo-1.2.0.zip
new file mode 100644
index 0000000..f5e62a1
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.2.0.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.2.1.zip b/core/src/test/resources/indices/bwc/repo-1.2.1.zip
new file mode 100644
index 0000000..935e71b
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.2.1.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.2.2.zip b/core/src/test/resources/indices/bwc/repo-1.2.2.zip
new file mode 100644
index 0000000..d69b22a
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.2.2.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.2.3.zip b/core/src/test/resources/indices/bwc/repo-1.2.3.zip
new file mode 100644
index 0000000..295f9f7
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.2.3.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.2.4.zip b/core/src/test/resources/indices/bwc/repo-1.2.4.zip
new file mode 100644
index 0000000..e9efc00
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.2.4.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.3.0.zip b/core/src/test/resources/indices/bwc/repo-1.3.0.zip
new file mode 100644
index 0000000..5a59e21
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.3.0.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.3.1.zip b/core/src/test/resources/indices/bwc/repo-1.3.1.zip
new file mode 100644
index 0000000..2ae1d7c
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.3.1.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.3.2.zip b/core/src/test/resources/indices/bwc/repo-1.3.2.zip
new file mode 100644
index 0000000..c67b997
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.3.2.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.3.3.zip b/core/src/test/resources/indices/bwc/repo-1.3.3.zip
new file mode 100644
index 0000000..64e3235
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.3.3.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.3.4.zip b/core/src/test/resources/indices/bwc/repo-1.3.4.zip
new file mode 100644
index 0000000..55e6744
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.3.4.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.3.5.zip b/core/src/test/resources/indices/bwc/repo-1.3.5.zip
new file mode 100644
index 0000000..35a5fd4
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.3.5.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.3.6.zip b/core/src/test/resources/indices/bwc/repo-1.3.6.zip
new file mode 100644
index 0000000..f1eb21c
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.3.6.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.3.7.zip b/core/src/test/resources/indices/bwc/repo-1.3.7.zip
new file mode 100644
index 0000000..543c13c
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.3.7.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.3.8.zip b/core/src/test/resources/indices/bwc/repo-1.3.8.zip
new file mode 100644
index 0000000..93abac3
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.3.8.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.3.9.zip b/core/src/test/resources/indices/bwc/repo-1.3.9.zip
new file mode 100644
index 0000000..7dc194d
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.3.9.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.4.0.Beta1.zip b/core/src/test/resources/indices/bwc/repo-1.4.0.Beta1.zip
new file mode 100644
index 0000000..5adf788
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.4.0.Beta1.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.4.0.zip b/core/src/test/resources/indices/bwc/repo-1.4.0.zip
new file mode 100644
index 0000000..21f867c
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.4.0.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.4.1.zip b/core/src/test/resources/indices/bwc/repo-1.4.1.zip
new file mode 100644
index 0000000..18166ea
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.4.1.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.4.2.zip b/core/src/test/resources/indices/bwc/repo-1.4.2.zip
new file mode 100644
index 0000000..f03625a
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.4.2.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.4.3.zip b/core/src/test/resources/indices/bwc/repo-1.4.3.zip
new file mode 100644
index 0000000..d78fbb1
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.4.3.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.4.4.zip b/core/src/test/resources/indices/bwc/repo-1.4.4.zip
new file mode 100644
index 0000000..1e89446
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.4.4.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.4.5.zip b/core/src/test/resources/indices/bwc/repo-1.4.5.zip
new file mode 100644
index 0000000..fcae439
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.4.5.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.5.0.zip b/core/src/test/resources/indices/bwc/repo-1.5.0.zip
new file mode 100644
index 0000000..a55e6c4
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.5.0.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.5.1.zip b/core/src/test/resources/indices/bwc/repo-1.5.1.zip
new file mode 100644
index 0000000..7cccbbe
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.5.1.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.5.2.zip b/core/src/test/resources/indices/bwc/repo-1.5.2.zip
new file mode 100644
index 0000000..cee5783
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.5.2.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.6.0.zip b/core/src/test/resources/indices/bwc/repo-1.6.0.zip
new file mode 100644
index 0000000..1c31a02
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.6.0.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.6.1.zip b/core/src/test/resources/indices/bwc/repo-1.6.1.zip
new file mode 100644
index 0000000..746f3ce
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.6.1.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.6.2.zip b/core/src/test/resources/indices/bwc/repo-1.6.2.zip
new file mode 100644
index 0000000..de4c5be
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.6.2.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.7.0.zip b/core/src/test/resources/indices/bwc/repo-1.7.0.zip
new file mode 100644
index 0000000..893689b
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.7.0.zip differ
diff --git a/core/src/test/resources/indices/bwc/repo-1.7.1.zip b/core/src/test/resources/indices/bwc/repo-1.7.1.zip
new file mode 100644
index 0000000..cd5c6c0
Binary files /dev/null and b/core/src/test/resources/indices/bwc/repo-1.7.1.zip differ
diff --git a/core/src/test/resources/indices/bwc/unsupported-0.20.6.zip b/core/src/test/resources/indices/bwc/unsupported-0.20.6.zip
new file mode 100644
index 0000000..753b577
Binary files /dev/null and b/core/src/test/resources/indices/bwc/unsupported-0.20.6.zip differ
diff --git a/core/src/test/resources/indices/bwc/unsupportedrepo-0.20.6.zip b/core/src/test/resources/indices/bwc/unsupportedrepo-0.20.6.zip
new file mode 100644
index 0000000..fab2f20
Binary files /dev/null and b/core/src/test/resources/indices/bwc/unsupportedrepo-0.20.6.zip differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.0.Beta1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.0.Beta1.zip
deleted file mode 100644
index 5bbdea4..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.0.Beta1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.0.RC1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.0.RC1.zip
deleted file mode 100644
index d9072ce..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.0.RC1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.0.RC2.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.0.RC2.zip
deleted file mode 100644
index dce299b..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.0.RC2.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.0.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.0.zip
deleted file mode 100644
index 3ec908d..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.0.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.1.zip
deleted file mode 100644
index 67db98f..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.10.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.10.zip
deleted file mode 100644
index 6bdb9f2..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.10.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.11.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.11.zip
deleted file mode 100644
index b5253f9..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.11.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.12.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.12.zip
deleted file mode 100644
index 0392049..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.12.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.13.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.13.zip
deleted file mode 100644
index 025b4c3..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.13.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.2.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.2.zip
deleted file mode 100644
index 413e08e..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.2.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.3.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.3.zip
deleted file mode 100644
index c31d4de..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.3.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.4.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.4.zip
deleted file mode 100644
index 8b07a92..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.4.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.5.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.5.zip
deleted file mode 100644
index dfd0fd0..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.5.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.6.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.6.zip
deleted file mode 100644
index 1f3cff2..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.6.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.7.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.7.zip
deleted file mode 100644
index 6d0e65c..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.7.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.8.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.8.zip
deleted file mode 100644
index 8ff8ac3..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.8.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.9.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.9.zip
deleted file mode 100644
index 4445b39..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-0.90.9.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.0.Beta1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.0.Beta1.zip
deleted file mode 100644
index 167dde8..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.0.Beta1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.0.Beta2.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.0.Beta2.zip
deleted file mode 100644
index 95fbfef..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.0.Beta2.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.0.RC1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.0.RC1.zip
deleted file mode 100644
index 3ced97a..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.0.RC1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.0.RC2.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.0.RC2.zip
deleted file mode 100644
index 1298cfb..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.0.RC2.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.0.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.0.zip
deleted file mode 100644
index 2cb9abc..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.0.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.1.zip
deleted file mode 100644
index 844271b..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.2.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.2.zip
deleted file mode 100644
index dd8e393..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.2.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.3.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.3.zip
deleted file mode 100644
index e4437ef..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.0.3.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.1.0.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.1.0.zip
deleted file mode 100644
index 4f05370..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.1.0.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.1.1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.1.1.zip
deleted file mode 100644
index effeb94..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.1.1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.1.2.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.1.2.zip
deleted file mode 100644
index bedffa4..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.1.2.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.2.0.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.2.0.zip
deleted file mode 100644
index 4644a38..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.2.0.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.2.1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.2.1.zip
deleted file mode 100644
index 553b46b..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.2.1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.2.2.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.2.2.zip
deleted file mode 100644
index 3f51a47..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.2.2.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.2.3.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.2.3.zip
deleted file mode 100644
index 8c8bfbd..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.2.3.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.2.4.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.2.4.zip
deleted file mode 100644
index e3a1519..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.2.4.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.0.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.0.zip
deleted file mode 100644
index d98958d..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.0.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.1.zip
deleted file mode 100644
index 167d0f4..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.2.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.2.zip
deleted file mode 100644
index 756eaf6..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.2.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.3.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.3.zip
deleted file mode 100644
index 8470dee..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.3.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.4.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.4.zip
deleted file mode 100644
index 2175012..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.4.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.5.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.5.zip
deleted file mode 100644
index 19d1e56..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.5.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.6.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.6.zip
deleted file mode 100644
index ad8e8bd..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.6.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.7.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.7.zip
deleted file mode 100644
index 3a645a9..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.7.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.8.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.8.zip
deleted file mode 100644
index f8ab0a2..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.8.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.9.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.9.zip
deleted file mode 100644
index 5ef35b2..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.3.9.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.4.0.Beta1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.4.0.Beta1.zip
deleted file mode 100644
index 4546f5d..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.4.0.Beta1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.4.0.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.4.0.zip
deleted file mode 100644
index 467d19a..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.4.0.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.4.1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.4.1.zip
deleted file mode 100644
index 2adbb28..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.4.1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.4.2.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.4.2.zip
deleted file mode 100644
index 4fac208..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.4.2.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.4.3.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.4.3.zip
deleted file mode 100644
index 1a0d667..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.4.3.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.4.4.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.4.4.zip
deleted file mode 100644
index 0328a9e..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.4.4.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.4.5.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.4.5.zip
deleted file mode 100644
index eeb25ab..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.4.5.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.5.0.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.5.0.zip
deleted file mode 100644
index f1dab08..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.5.0.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.5.1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.5.1.zip
deleted file mode 100644
index 342e311..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.5.1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.5.2.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.5.2.zip
deleted file mode 100644
index fb36b19..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.5.2.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.6.0.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.6.0.zip
deleted file mode 100644
index 02a5806..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.6.0.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.6.1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.6.1.zip
deleted file mode 100644
index 04820f9..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.6.1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.6.2.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.6.2.zip
deleted file mode 100644
index af6ce56..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.6.2.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.7.0.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.7.0.zip
deleted file mode 100644
index 941be64..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.7.0.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.7.1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/index-1.7.1.zip
deleted file mode 100644
index debd797..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/index-1.7.1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.0.0.Beta2.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.0.0.Beta2.zip
deleted file mode 100644
index 020f6f4..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.0.0.Beta2.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.0.0.RC1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.0.0.RC1.zip
deleted file mode 100644
index a84c507..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.0.0.RC1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.0.0.RC2.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.0.0.RC2.zip
deleted file mode 100644
index e5d65eb..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.0.0.RC2.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.0.0.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.0.0.zip
deleted file mode 100644
index 13f778d..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.0.0.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.0.1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.0.1.zip
deleted file mode 100644
index 76ed278..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.0.1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.0.2.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.0.2.zip
deleted file mode 100644
index 762eabf..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.0.2.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.0.3.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.0.3.zip
deleted file mode 100644
index ba79dea..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.0.3.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.1.0.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.1.0.zip
deleted file mode 100644
index cbf84c7..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.1.0.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.1.1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.1.1.zip
deleted file mode 100644
index 00ea044..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.1.1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.1.2.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.1.2.zip
deleted file mode 100644
index 18abd99..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.1.2.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.2.0.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.2.0.zip
deleted file mode 100644
index f5e62a1..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.2.0.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.2.1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.2.1.zip
deleted file mode 100644
index 935e71b..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.2.1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.2.2.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.2.2.zip
deleted file mode 100644
index d69b22a..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.2.2.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.2.3.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.2.3.zip
deleted file mode 100644
index 295f9f7..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.2.3.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.2.4.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.2.4.zip
deleted file mode 100644
index e9efc00..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.2.4.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.0.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.0.zip
deleted file mode 100644
index 5a59e21..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.0.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.1.zip
deleted file mode 100644
index 2ae1d7c..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.2.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.2.zip
deleted file mode 100644
index c67b997..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.2.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.3.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.3.zip
deleted file mode 100644
index 64e3235..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.3.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.4.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.4.zip
deleted file mode 100644
index 55e6744..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.4.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.5.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.5.zip
deleted file mode 100644
index 35a5fd4..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.5.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.6.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.6.zip
deleted file mode 100644
index f1eb21c..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.6.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.7.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.7.zip
deleted file mode 100644
index 543c13c..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.7.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.8.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.8.zip
deleted file mode 100644
index 93abac3..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.8.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.9.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.9.zip
deleted file mode 100644
index 7dc194d..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.3.9.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.4.0.Beta1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.4.0.Beta1.zip
deleted file mode 100644
index 5adf788..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.4.0.Beta1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.4.0.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.4.0.zip
deleted file mode 100644
index 21f867c..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.4.0.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.4.1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.4.1.zip
deleted file mode 100644
index 18166ea..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.4.1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.4.2.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.4.2.zip
deleted file mode 100644
index f03625a..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.4.2.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.4.3.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.4.3.zip
deleted file mode 100644
index d78fbb1..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.4.3.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.4.4.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.4.4.zip
deleted file mode 100644
index 1e89446..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.4.4.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.4.5.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.4.5.zip
deleted file mode 100644
index fcae439..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.4.5.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.5.0.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.5.0.zip
deleted file mode 100644
index a55e6c4..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.5.0.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.5.1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.5.1.zip
deleted file mode 100644
index 7cccbbe..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.5.1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.5.2.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.5.2.zip
deleted file mode 100644
index cee5783..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.5.2.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.6.0.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.6.0.zip
deleted file mode 100644
index 1c31a02..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.6.0.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.6.1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.6.1.zip
deleted file mode 100644
index 746f3ce..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.6.1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.6.2.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.6.2.zip
deleted file mode 100644
index de4c5be..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.6.2.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.7.0.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.7.0.zip
deleted file mode 100644
index 893689b..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.7.0.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.7.1.zip b/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.7.1.zip
deleted file mode 100644
index cd5c6c0..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/repo-1.7.1.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/unsupported-0.20.6.zip b/core/src/test/resources/org/elasticsearch/bwcompat/unsupported-0.20.6.zip
deleted file mode 100644
index 753b577..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/unsupported-0.20.6.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/bwcompat/unsupportedrepo-0.20.6.zip b/core/src/test/resources/org/elasticsearch/bwcompat/unsupportedrepo-0.20.6.zip
deleted file mode 100644
index fab2f20..0000000
Binary files a/core/src/test/resources/org/elasticsearch/bwcompat/unsupportedrepo-0.20.6.zip and /dev/null differ
diff --git a/core/src/test/resources/org/elasticsearch/index/query/function-filter-score-query.json b/core/src/test/resources/org/elasticsearch/index/query/function-filter-score-query.json
index e78c549..a7b4790 100644
--- a/core/src/test/resources/org/elasticsearch/index/query/function-filter-score-query.json
+++ b/core/src/test/resources/org/elasticsearch/index/query/function-filter-score-query.json
@@ -9,18 +9,12 @@
         },
         "functions":  [
             {
-                "boost_factor": 3,
+                "weight": 3,
                 "filter": {
-                    term:{
+                    "term":{
                         "name.last":"banon"
                     }
                 }
-            },
-            {
-                "boost_factor": 3
-            },
-            {
-                "boost_factor": 3
             }
         ],
         "boost" : 3,
diff --git a/core/src/test/resources/org/elasticsearch/index/query/has-child-with-inner-hits.json b/core/src/test/resources/org/elasticsearch/index/query/has-child-with-inner-hits.json
deleted file mode 100644
index 176131c..0000000
--- a/core/src/test/resources/org/elasticsearch/index/query/has-child-with-inner-hits.json
+++ /dev/null
@@ -1,30 +0,0 @@
-{
-  "has_child" : {
-    "query" : {
-      "range" : {
-        "mapped_string" : {
-          "from" : "agJhRET",
-          "to" : "zvqIq",
-          "include_lower" : true,
-          "include_upper" : true,
-          "boost" : 1.0
-        }
-      }
-    },
-    "child_type" : "child",
-    "score_type" : "avg",
-    "min_children" : 883170873,
-    "max_children" : 1217235442,
-    "boost" : 2.0,
-    "_name" : "WNzYMJKRwePuRBh",
-    "inner_hits" : {
-      "name" : "inner_hits_name",
-      "size" : 100,
-      "sort" : [ {
-        "mapped_string" : {
-          "order" : "asc"
-        }
-      } ]
-    }
-  }
-}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/simple-query-string.json b/core/src/test/resources/org/elasticsearch/index/query/simple-query-string.json
new file mode 100644
index 0000000..9208e88
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/simple-query-string.json
@@ -0,0 +1,8 @@
+{
+  "simple_query_string": {
+    "query": "foo bar",
+    "analyzer": "keyword",
+    "fields": ["body^5","_all"],
+    "default_operator": "and"
+  }
+}
diff --git a/dev-tools/Elasticsearch.launch b/dev-tools/Elasticsearch.launch
index 2016518..5995612 100644
--- a/dev-tools/Elasticsearch.launch
+++ b/dev-tools/Elasticsearch.launch
@@ -14,5 +14,5 @@
 <stringAttribute key="org.eclipse.jdt.launching.MAIN_TYPE" value="org.elasticsearch.bootstrap.Elasticsearch"/>
 <stringAttribute key="org.eclipse.jdt.launching.PROGRAM_ARGUMENTS" value="start"/>
 <stringAttribute key="org.eclipse.jdt.launching.PROJECT_ATTR" value="elasticsearch"/>
-<stringAttribute key="org.eclipse.jdt.launching.VM_ARGUMENTS" value="-Xms256m -Xmx1g -Djava.awt.headless=true -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=logs/heapdump.hprof -Delasticsearch -Des.foreground=yes -ea -Des.path.home=target/eclipse_run -Des.security.manager.enabled=false"/>
+<stringAttribute key="org.eclipse.jdt.launching.VM_ARGUMENTS" value="-Xms256m -Xmx1g -Djava.awt.headless=true -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=logs/heapdump.hprof -Delasticsearch -Des.foreground=yes -ea -Des.path.home=target/eclipse_run -Des.security.manager.enabled=false&#10;-Des.node.attr=test"/>
 </launchConfiguration>
diff --git a/dev-tools/create_bwc_index.py b/dev-tools/create_bwc_index.py
index 22ba7f7..d780b2a 100644
--- a/dev-tools/create_bwc_index.py
+++ b/dev-tools/create_bwc_index.py
@@ -333,7 +333,7 @@ def parse_config():
                         help='Recreate all existing backwards compatibility indexes')
   parser.add_argument('--releases-dir', '-d', default='backwards', metavar='DIR',
                       help='The directory containing elasticsearch releases')
-  parser.add_argument('--output-dir', '-o', default='core/src/test/resources/org/elasticsearch/bwcompat',
+  parser.add_argument('--output-dir', '-o', default='core/src/test/resources/indices/bwc',
                       help='The directory to write the zipped index into')
   parser.add_argument('--tcp-port', default=DEFAULT_TRANSPORT_TCP_PORT, type=int,
                       help='The port to use as the minimum port for TCP communication')
diff --git a/dev-tools/create_bwc_repo_with_ancient_indices.py b/dev-tools/create_bwc_repo_with_ancient_indices.py
index 27d166d..5c6b822 100644
--- a/dev-tools/create_bwc_repo_with_ancient_indices.py
+++ b/dev-tools/create_bwc_repo_with_ancient_indices.py
@@ -63,7 +63,7 @@ def main():
     create_bwc_index.shutdown_node(node)
     print('%s server output:\n%s' % (second_version, node.stdout.read().decode('utf-8')))
 
-    create_bwc_index.compress(tmp_dir, "src/test/resources/org/elasticsearch/bwcompat", 'unsupportedrepo-%s.zip' % first_version, 'repo')
+    create_bwc_index.compress(tmp_dir, "src/test/resources/indices/bwc", 'unsupportedrepo-%s.zip' % first_version, 'repo')
 
     node = None
   finally:
diff --git a/dev-tools/src/main/resources/ant/integration-tests.xml b/dev-tools/src/main/resources/ant/integration-tests.xml
index 23df373..f64f440 100644
--- a/dev-tools/src/main/resources/ant/integration-tests.xml
+++ b/dev-tools/src/main/resources/ant/integration-tests.xml
@@ -157,7 +157,7 @@
       <!-- run bin/elasticsearch with args -->
       <echo>Starting up external cluster...</echo>
 
-      <run-script script="@{home}/bin/elasticsearch" 
+      <run-script script="@{home}/bin/elasticsearch"
                   spawn="@{spawn}">
         <nested>
           <env key="JAVA_HOME" value="${java.home}"/>
@@ -172,6 +172,8 @@
           <arg value="-Des.path.shared_data=@{home}/../"/>
           <arg value="-Des.script.inline=on"/>
           <arg value="-Des.script.indexed=on"/>
+          <!-- Define a node attribute so we can test that it exists -->
+          <arg value="-Des.node.testattr=test"/>
           <arg value="-Des.repositories.url.allowed_urls=http://snapshot.test*"/>
           <additional-args/>
         </nested>
diff --git a/dev-tools/src/main/resources/forbidden/core-signatures.txt b/dev-tools/src/main/resources/forbidden/core-signatures.txt
index de3576f..92792ca 100644
--- a/dev-tools/src/main/resources/forbidden/core-signatures.txt
+++ b/dev-tools/src/main/resources/forbidden/core-signatures.txt
@@ -93,3 +93,9 @@ com.google.common.base.Predicates
 com.google.common.base.Strings
 com.google.common.base.Throwables
 com.google.common.collect.Maps
+com.google.common.collect.Sets
+com.google.common.base.Preconditions#checkNotNull(java.lang.Object)
+com.google.common.base.Preconditions#checkNotNull(java.lang.Object, java.lang.Object)
+com.google.common.base.Preconditions#checkNotNull(java.lang.Object, java.lang.String, java.lang.Object[])
+com.google.common.collect.ImmutableSortedSet
+com.google.common.collect.Queues
diff --git a/dev-tools/update_lucene.sh b/dev-tools/update_lucene.sh
new file mode 100644
index 0000000..4918c12
--- /dev/null
+++ b/dev-tools/update_lucene.sh
@@ -0,0 +1,14 @@
+#!/bin/sh
+mvn install -DskipTests
+perl dev-tools/src/main/resources/license-check/check_license_and_sha.pl \
+     --update distribution/licenses/ distribution/zip/target/releases/elasticsearch-3.0.0-SNAPSHOT.zip elasticsearch-3.0.0-SNAPSHOT
+perl dev-tools/src/main/resources/license-check/check_license_and_sha.pl \
+     --update plugins/analysis-icu/licenses/ plugins/analysis-icu/target/releases/analysis-icu-3.0.0-SNAPSHOT.zip analysis-icu-3.0.0-SNAPSHOT
+perl dev-tools/src/main/resources/license-check/check_license_and_sha.pl \
+     --update plugins/analysis-kuromoji/licenses/ plugins/analysis-kuromoji/target/releases/analysis-kuromoji-3.0.0-SNAPSHOT.zip analysis-kuromoji-3.0.0-SNAPSHOT
+perl dev-tools/src/main/resources/license-check/check_license_and_sha.pl \
+     --update plugins/analysis-phonetic/licenses/ plugins/analysis-phonetic/target/releases/analysis-phonetic-3.0.0-SNAPSHOT.zip analysis-phonetic-3.0.0-SNAPSHOT
+perl dev-tools/src/main/resources/license-check/check_license_and_sha.pl \
+     --update plugins/analysis-smartcn/licenses/ plugins/analysis-smartcn/target/releases/analysis-smartcn-3.0.0-SNAPSHOT.zip analysis-smartcn-3.0.0-SNAPSHOT
+perl dev-tools/src/main/resources/license-check/check_license_and_sha.pl \
+     --update plugins/analysis-stempel/licenses/ plugins/analysis-stempel/target/releases/analysis-stempel-3.0.0-SNAPSHOT.zip analysis-stempel-3.0.0-SNAPSHOT
diff --git a/distribution/licenses/lucene-analyzers-common-5.4.0-snapshot-1701068.jar.sha1 b/distribution/licenses/lucene-analyzers-common-5.4.0-snapshot-1701068.jar.sha1
deleted file mode 100644
index 3eff5a7..0000000
--- a/distribution/licenses/lucene-analyzers-common-5.4.0-snapshot-1701068.jar.sha1
+++ /dev/null
@@ -1 +0,0 @@
-35fca29c4597a15ce4d4eb7dc73a517038684a27
diff --git a/distribution/licenses/lucene-analyzers-common-5.4.0-snapshot-1702265.jar.sha1 b/distribution/licenses/lucene-analyzers-common-5.4.0-snapshot-1702265.jar.sha1
new file mode 100644
index 0000000..41febf7
--- /dev/null
+++ b/distribution/licenses/lucene-analyzers-common-5.4.0-snapshot-1702265.jar.sha1
@@ -0,0 +1 @@
+8243b938b75818e86aa8d270d8d99529e1847578
diff --git a/distribution/licenses/lucene-backward-codecs-5.4.0-snapshot-1701068.jar.sha1 b/distribution/licenses/lucene-backward-codecs-5.4.0-snapshot-1701068.jar.sha1
deleted file mode 100644
index 6fe7609..0000000
--- a/distribution/licenses/lucene-backward-codecs-5.4.0-snapshot-1701068.jar.sha1
+++ /dev/null
@@ -1 +0,0 @@
-e4769b5c05fad8339f4eaf9cfa9e850cbeaa10ec
diff --git a/distribution/licenses/lucene-backward-codecs-5.4.0-snapshot-1702265.jar.sha1 b/distribution/licenses/lucene-backward-codecs-5.4.0-snapshot-1702265.jar.sha1
new file mode 100644
index 0000000..17f6316
--- /dev/null
+++ b/distribution/licenses/lucene-backward-codecs-5.4.0-snapshot-1702265.jar.sha1
@@ -0,0 +1 @@
+ba85c6e5e77e1f76c52c31d34a59558afa135d47
diff --git a/distribution/licenses/lucene-core-5.4.0-snapshot-1701068.jar.sha1 b/distribution/licenses/lucene-core-5.4.0-snapshot-1701068.jar.sha1
deleted file mode 100644
index fb5b2dd..0000000
--- a/distribution/licenses/lucene-core-5.4.0-snapshot-1701068.jar.sha1
+++ /dev/null
@@ -1 +0,0 @@
-3bbab9d7a395bd0b6cc8b5bee26287105c8659e8
diff --git a/distribution/licenses/lucene-core-5.4.0-snapshot-1702265.jar.sha1 b/distribution/licenses/lucene-core-5.4.0-snapshot-1702265.jar.sha1
new file mode 100644
index 0000000..e6198d4
--- /dev/null
+++ b/distribution/licenses/lucene-core-5.4.0-snapshot-1702265.jar.sha1
@@ -0,0 +1 @@
+f8a38658b6393015c9b33c16b1b4122167b526b2
diff --git a/distribution/licenses/lucene-expressions-5.4.0-snapshot-1701068.jar.sha1 b/distribution/licenses/lucene-expressions-5.4.0-snapshot-1701068.jar.sha1
deleted file mode 100644
index 000759a..0000000
--- a/distribution/licenses/lucene-expressions-5.4.0-snapshot-1701068.jar.sha1
+++ /dev/null
@@ -1 +0,0 @@
-d60476428e7d3d8a68fe491d42dbda0d4024f589
diff --git a/distribution/licenses/lucene-expressions-5.4.0-snapshot-1702265.jar.sha1 b/distribution/licenses/lucene-expressions-5.4.0-snapshot-1702265.jar.sha1
new file mode 100644
index 0000000..ff8fd36
--- /dev/null
+++ b/distribution/licenses/lucene-expressions-5.4.0-snapshot-1702265.jar.sha1
@@ -0,0 +1 @@
+fa5d27ecadbe346caaf5a571ba71944b51761acf
diff --git a/distribution/licenses/lucene-grouping-5.4.0-snapshot-1701068.jar.sha1 b/distribution/licenses/lucene-grouping-5.4.0-snapshot-1701068.jar.sha1
deleted file mode 100644
index 1688910..0000000
--- a/distribution/licenses/lucene-grouping-5.4.0-snapshot-1701068.jar.sha1
+++ /dev/null
@@ -1 +0,0 @@
-8618da3f400f0a4b140f196bbbecb0686fe754db
diff --git a/distribution/licenses/lucene-grouping-5.4.0-snapshot-1702265.jar.sha1 b/distribution/licenses/lucene-grouping-5.4.0-snapshot-1702265.jar.sha1
new file mode 100644
index 0000000..7acdc72
--- /dev/null
+++ b/distribution/licenses/lucene-grouping-5.4.0-snapshot-1702265.jar.sha1
@@ -0,0 +1 @@
+2c1464fcf6ede7819f8ba434b9bc7c79f5968407
diff --git a/distribution/licenses/lucene-highlighter-5.4.0-snapshot-1701068.jar.sha1 b/distribution/licenses/lucene-highlighter-5.4.0-snapshot-1701068.jar.sha1
deleted file mode 100644
index 5b6a48e..0000000
--- a/distribution/licenses/lucene-highlighter-5.4.0-snapshot-1701068.jar.sha1
+++ /dev/null
@@ -1 +0,0 @@
-c7db4fe5587d08ab23b253c622566462aab6796a
diff --git a/distribution/licenses/lucene-highlighter-5.4.0-snapshot-1702265.jar.sha1 b/distribution/licenses/lucene-highlighter-5.4.0-snapshot-1702265.jar.sha1
new file mode 100644
index 0000000..9f46054
--- /dev/null
+++ b/distribution/licenses/lucene-highlighter-5.4.0-snapshot-1702265.jar.sha1
@@ -0,0 +1 @@
+a40f9a3ef224bc042ef2ad1b713e318911b6057a
diff --git a/distribution/licenses/lucene-join-5.4.0-snapshot-1701068.jar.sha1 b/distribution/licenses/lucene-join-5.4.0-snapshot-1701068.jar.sha1
deleted file mode 100644
index 9dbe328..0000000
--- a/distribution/licenses/lucene-join-5.4.0-snapshot-1701068.jar.sha1
+++ /dev/null
@@ -1 +0,0 @@
-f9c8d435d3e1d553b0dca05c99b1fa377568eed0
diff --git a/distribution/licenses/lucene-join-5.4.0-snapshot-1702265.jar.sha1 b/distribution/licenses/lucene-join-5.4.0-snapshot-1702265.jar.sha1
new file mode 100644
index 0000000..01a2d77
--- /dev/null
+++ b/distribution/licenses/lucene-join-5.4.0-snapshot-1702265.jar.sha1
@@ -0,0 +1 @@
+0a7642c9b98cb3d9013fb33be5c0751baf9f0b31
diff --git a/distribution/licenses/lucene-memory-5.4.0-snapshot-1701068.jar.sha1 b/distribution/licenses/lucene-memory-5.4.0-snapshot-1701068.jar.sha1
deleted file mode 100644
index 1c0f2f5..0000000
--- a/distribution/licenses/lucene-memory-5.4.0-snapshot-1701068.jar.sha1
+++ /dev/null
@@ -1 +0,0 @@
-571dd2e4363f0a0410de04b3f3f4bbf66e782c31
diff --git a/distribution/licenses/lucene-memory-5.4.0-snapshot-1702265.jar.sha1 b/distribution/licenses/lucene-memory-5.4.0-snapshot-1702265.jar.sha1
new file mode 100644
index 0000000..6f9b8b4
--- /dev/null
+++ b/distribution/licenses/lucene-memory-5.4.0-snapshot-1702265.jar.sha1
@@ -0,0 +1 @@
+a0d6461ab9cda93ea530560b0c074a28fe0dd717
diff --git a/distribution/licenses/lucene-misc-5.4.0-snapshot-1701068.jar.sha1 b/distribution/licenses/lucene-misc-5.4.0-snapshot-1701068.jar.sha1
deleted file mode 100644
index 0d44482..0000000
--- a/distribution/licenses/lucene-misc-5.4.0-snapshot-1701068.jar.sha1
+++ /dev/null
@@ -1 +0,0 @@
-423264f839aace3b9159a0dd54f56c250458fd46
diff --git a/distribution/licenses/lucene-misc-5.4.0-snapshot-1702265.jar.sha1 b/distribution/licenses/lucene-misc-5.4.0-snapshot-1702265.jar.sha1
new file mode 100644
index 0000000..f274d12
--- /dev/null
+++ b/distribution/licenses/lucene-misc-5.4.0-snapshot-1702265.jar.sha1
@@ -0,0 +1 @@
+85c5c7b78715c50157700c90ffd101537446533d
diff --git a/distribution/licenses/lucene-queries-5.4.0-snapshot-1701068.jar.sha1 b/distribution/licenses/lucene-queries-5.4.0-snapshot-1701068.jar.sha1
deleted file mode 100644
index a4391c6..0000000
--- a/distribution/licenses/lucene-queries-5.4.0-snapshot-1701068.jar.sha1
+++ /dev/null
@@ -1 +0,0 @@
-872530eeac156faa0989eb87145bbef74a72e66f
diff --git a/distribution/licenses/lucene-queries-5.4.0-snapshot-1702265.jar.sha1 b/distribution/licenses/lucene-queries-5.4.0-snapshot-1702265.jar.sha1
new file mode 100644
index 0000000..295a311
--- /dev/null
+++ b/distribution/licenses/lucene-queries-5.4.0-snapshot-1702265.jar.sha1
@@ -0,0 +1 @@
+70ca782d6ed458b5f777141353e09600083ed4fe
diff --git a/distribution/licenses/lucene-queryparser-5.4.0-snapshot-1701068.jar.sha1 b/distribution/licenses/lucene-queryparser-5.4.0-snapshot-1701068.jar.sha1
deleted file mode 100644
index 29c85e8..0000000
--- a/distribution/licenses/lucene-queryparser-5.4.0-snapshot-1701068.jar.sha1
+++ /dev/null
@@ -1 +0,0 @@
-6f6b6a024ca96017252efea6d2fc7dc97c69febd
diff --git a/distribution/licenses/lucene-queryparser-5.4.0-snapshot-1702265.jar.sha1 b/distribution/licenses/lucene-queryparser-5.4.0-snapshot-1702265.jar.sha1
new file mode 100644
index 0000000..88c548a
--- /dev/null
+++ b/distribution/licenses/lucene-queryparser-5.4.0-snapshot-1702265.jar.sha1
@@ -0,0 +1 @@
+b4832cdfe7a6cc7c586a3e28d7cd530acb182232
diff --git a/distribution/licenses/lucene-sandbox-5.4.0-snapshot-1701068.jar.sha1 b/distribution/licenses/lucene-sandbox-5.4.0-snapshot-1701068.jar.sha1
deleted file mode 100644
index dbc3ec8..0000000
--- a/distribution/licenses/lucene-sandbox-5.4.0-snapshot-1701068.jar.sha1
+++ /dev/null
@@ -1 +0,0 @@
-a6f5a5c84b165ebde104cdcde46fa9c5948650f0
diff --git a/distribution/licenses/lucene-sandbox-5.4.0-snapshot-1702265.jar.sha1 b/distribution/licenses/lucene-sandbox-5.4.0-snapshot-1702265.jar.sha1
new file mode 100644
index 0000000..54f5944
--- /dev/null
+++ b/distribution/licenses/lucene-sandbox-5.4.0-snapshot-1702265.jar.sha1
@@ -0,0 +1 @@
+bde73ae2b2324e1576c5789a7e6dd88b6543b939
diff --git a/distribution/licenses/lucene-spatial-5.4.0-snapshot-1701068.jar.sha1 b/distribution/licenses/lucene-spatial-5.4.0-snapshot-1701068.jar.sha1
deleted file mode 100644
index 1e2c1dc..0000000
--- a/distribution/licenses/lucene-spatial-5.4.0-snapshot-1701068.jar.sha1
+++ /dev/null
@@ -1 +0,0 @@
-a305601f93b6cb02444816c96276a74f91ac7d40
diff --git a/distribution/licenses/lucene-spatial-5.4.0-snapshot-1702265.jar.sha1 b/distribution/licenses/lucene-spatial-5.4.0-snapshot-1702265.jar.sha1
new file mode 100644
index 0000000..f3aa363
--- /dev/null
+++ b/distribution/licenses/lucene-spatial-5.4.0-snapshot-1702265.jar.sha1
@@ -0,0 +1 @@
+8d261ff1c2333ce1e040c3aefca9784d1ae71acc
diff --git a/distribution/licenses/lucene-spatial3d-5.4.0-snapshot-1701068.jar.sha1 b/distribution/licenses/lucene-spatial3d-5.4.0-snapshot-1701068.jar.sha1
deleted file mode 100644
index ab2be14..0000000
--- a/distribution/licenses/lucene-spatial3d-5.4.0-snapshot-1701068.jar.sha1
+++ /dev/null
@@ -1 +0,0 @@
-ef1fcaa5b6663dd9382719a1ad40d86fc962c690
diff --git a/distribution/licenses/lucene-spatial3d-5.4.0-snapshot-1702265.jar.sha1 b/distribution/licenses/lucene-spatial3d-5.4.0-snapshot-1702265.jar.sha1
new file mode 100644
index 0000000..d23a271
--- /dev/null
+++ b/distribution/licenses/lucene-spatial3d-5.4.0-snapshot-1702265.jar.sha1
@@ -0,0 +1 @@
+ee041e52dfcdb33a1aa6fab112042b5f33fc0c0c
diff --git a/distribution/licenses/lucene-suggest-5.4.0-snapshot-1701068.jar.sha1 b/distribution/licenses/lucene-suggest-5.4.0-snapshot-1701068.jar.sha1
deleted file mode 100644
index dd69c53..0000000
--- a/distribution/licenses/lucene-suggest-5.4.0-snapshot-1701068.jar.sha1
+++ /dev/null
@@ -1 +0,0 @@
-3698e0623f45e181d2ceead46e48a6dd8c2867dd
diff --git a/distribution/licenses/lucene-suggest-5.4.0-snapshot-1702265.jar.sha1 b/distribution/licenses/lucene-suggest-5.4.0-snapshot-1702265.jar.sha1
new file mode 100644
index 0000000..f2307a3
--- /dev/null
+++ b/distribution/licenses/lucene-suggest-5.4.0-snapshot-1702265.jar.sha1
@@ -0,0 +1 @@
+a8ceb11b26e53612eee9a265ff454351f6dc99f2
diff --git a/docs/plugins/integrations.asciidoc b/docs/plugins/integrations.asciidoc
index 0cb4648..52e3150 100644
--- a/docs/plugins/integrations.asciidoc
+++ b/docs/plugins/integrations.asciidoc
@@ -2,8 +2,7 @@
 
 == Integrations
 
-Integrations are not plugins, instead they are external tools or modules which
-make it easier to work with Elasticsearch.
+Integrations are not plugins, but are external tools or modules that make it easier to work with Elasticsearch.
 
 [float]
 [[cms-integrations]]
@@ -29,13 +28,24 @@ make it easier to work with Elasticsearch.
   search (facets, etc), along with some Natural Language Processing features
   (ex.: More like this)
 
-
 [float]
 [[data-integrations]]
 === Data import/export and validation
 
-NOTE: Rivers were used to import data from external systems into
-Elasticsearch, but they are no longer supported in Elasticsearch 2.0.
+NOTE: Rivers were used to import data from external systems into Elasticsearch prior to the 2.0 release. Elasticsearch 
+releases 2.0 and later do not support rivers.
+
+[float]
+==== Supported by the community:
+
+* https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html[Logstash output to Elasticsearch]:
+  The Logstash `elasticsearch` output plugin.
+* https://www.elastic.co/guide/en/logstash/current/plugins-inputs-elasticsearch.html[Elasticsearch input to Logstash]
+  The Logstash `elasticsearch` input plugin.
+* https://www.elastic.co/guide/en/logstash/current/plugins-filters-elasticsearch.html[Elasticsearch event filtering in Logstash]
+  The Logstash `elasticearch` filter plugin.
+* https://www.elastic.co/guide/en/logstash/current/plugins-codecs-es_bulk.html[Elasticsearch bulk codec]
+  The Logstash `es_bulk` plugin decodes the Elasticsearch bulk format into individual events. 
 
 [float]
 ==== Supported by the community:
@@ -44,15 +54,14 @@ Elasticsearch, but they are no longer supported in Elasticsearch 2.0.
   The Java Database Connection (JDBC) importer allows to fetch data from JDBC sources for indexing into Elasticsearch (by Jrg Prante)
 
 * https://github.com/reachkrishnaraj/kafka-elasticsearch-standalone-consumer[Kafka Standalone Consumer]:
-  Easily Scaleable & Extendable, Kafka Standalone Consumer that will read the messages from Kafka, processes and index them in ElasticSearch
+  Easily Scalable & Extendable Kafka Standalone Consumer that reads messages from Kafka, then processes and indexes the messages in ElasticSearch
 
 * https://github.com/ozlerhakan/mongolastic[Mongolastic]:
-  A tool that clone data from ElasticSearch to MongoDB and vice versa
+  A tool that clones data from ElasticSearch to MongoDB and vice versa
 
 * https://github.com/Aconex/scrutineer[Scrutineer]:
   A high performance consistency checker to compare what you've indexed
-  with your source of truth content (e.g. DB)
-
+  with your source of truth content
 
 [float]
 [[deployment]]
@@ -207,7 +216,7 @@ These projects appear to have been abandoned:
   Protocol dissection for Zen discovery, HTTP and the binary protocol
 
 
-These projects appears to have been abandoned:
+These projects appear to have been abandoned:
 
 * http://www.github.com/neogenix/daikon[daikon]:
   Daikon Elasticsearch CLI
@@ -216,5 +225,4 @@ These projects appears to have been abandoned:
   A set of AngularJS directives that provide common visualizations for elasticsearch based on
   D3.
 * https://github.com/OlegKunitsyn/eslogd[eslogd]:
-  Linux daemon that replicates events to a central Elasticsearch server in real-time
-
+  Linux daemon that replicates events to a central Elasticsearch server in realtime
diff --git a/docs/reference/aggregations/bucket/histogram-aggregation.asciidoc b/docs/reference/aggregations/bucket/histogram-aggregation.asciidoc
index bc8a6e1..e01a067 100644
--- a/docs/reference/aggregations/bucket/histogram-aggregation.asciidoc
+++ b/docs/reference/aggregations/bucket/histogram-aggregation.asciidoc
@@ -148,7 +148,7 @@ Example:
 --------------------------------------------------
 {
     "query" : {
-        "filtered" : { "filter": { "range" : { "price" : { "to" : "500" } } } }
+        "constant_score" : { "filter": { "range" : { "price" : { "to" : "500" } } } }
     },
     "aggs" : {
         "prices" : {
diff --git a/docs/reference/aggregations/metrics/sum-aggregation.asciidoc b/docs/reference/aggregations/metrics/sum-aggregation.asciidoc
index 98286e9..d55fcd0 100644
--- a/docs/reference/aggregations/metrics/sum-aggregation.asciidoc
+++ b/docs/reference/aggregations/metrics/sum-aggregation.asciidoc
@@ -9,8 +9,7 @@ Assuming the data consists of documents representing stock ticks, where each tic
 --------------------------------------------------
 {
     "query" : {
-        "filtered" : {
-            "query" : { "match_all" : {}},
+        "constant_score" : {
             "filter" : {
                 "range" : { "timestamp" : { "from" : "now/1d+9.5h", "to" : "now/1d+16h" }}
             }
diff --git a/docs/reference/getting-started.asciidoc b/docs/reference/getting-started.asciidoc
index e69cfb4..473287d 100755
--- a/docs/reference/getting-started.asciidoc
+++ b/docs/reference/getting-started.asciidoc
@@ -862,17 +862,17 @@ In the previous section, we skipped over a little detail called the document sco
 
 But queries do not always need to produce scores, in particular when they are only used for "filtering" the document set. Elasticsearch detects these situations and automatically optimizes query execution in order not to compute useless scores.
 
-To understand filters, let's first introduce the <<query-dsl-filtered-query,`filtered` query>>, which allows you to combine a query (like `match_all`, `match`, `bool`, etc.) together with another query which is only used for filtering. As an example, let's introduce the <<query-dsl-range-query,`range` query>>, which allows us to filter documents by a range of values. This is generally used for numeric or date filtering.
+The <<query-dsl-range-query,`range` query>> that we introduced in the previous section also supports `filter` clauses which allow to use a query to restrict the documents that will be matched by other clauses, without changing how scores are computed. As an example, let's introduce the <<query-dsl-range-query,`range` query>>, which allows us to filter documents by a range of values. This is generally used for numeric or date filtering.
 
-This example uses a filtered query to return all accounts with balances between 20000 and 30000, inclusive. In other words, we want to find accounts with a balance that is greater than or equal to 20000 and less than or equal to 30000.
+This example uses a bool query to return all accounts with balances between 20000 and 30000, inclusive. In other words, we want to find accounts with a balance that is greater than or equal to 20000 and less than or equal to 30000.
 
 [source,sh]
 --------------------------------------------------
 curl -XPOST 'localhost:9200/bank/_search?pretty' -d '
 {
   "query": {
-    "filtered": {
-      "query": { "match_all": {} },
+    "bool": {
+      "must": { "match_all": {} },
       "filter": {
         "range": {
           "balance": {
@@ -886,9 +886,9 @@ curl -XPOST 'localhost:9200/bank/_search?pretty' -d '
 }'
 --------------------------------------------------
 
-Dissecting the above, the filtered query contains a `match_all` query (the query part) and a `range` query (the filter part). We can substitute any other queries into the query and the filter parts. In the above case, the range query makes perfect sense since documents falling into the range all match "equally", i.e., no document is more relevant than another.
+Dissecting the above, the bool query contains a `match_all` query (the query part) and a `range` query (the filter part). We can substitute any other queries into the query and the filter parts. In the above case, the range query makes perfect sense since documents falling into the range all match "equally", i.e., no document is more relevant than another.
 
-In addition to the `match_all`, `match`, `bool`, `filtered`, and `range` queries, there are a lot of other query types that are available and we won't go into them here. Since we already have a basic understanding of how they work, it shouldn't be too difficult to apply this knowledge in learning and experimenting with the other query types.
+In addition to the `match_all`, `match`, `bool`, and `range` queries, there are a lot of other query types that are available and we won't go into them here. Since we already have a basic understanding of how they work, it shouldn't be too difficult to apply this knowledge in learning and experimenting with the other query types.
 
 === Executing Aggregations
 
diff --git a/docs/reference/index-modules.asciidoc b/docs/reference/index-modules.asciidoc
index 3a1c2de..78ede99 100644
--- a/docs/reference/index-modules.asciidoc
+++ b/docs/reference/index-modules.asciidoc
@@ -98,6 +98,14 @@ specific index module:
     index visible to search.  Defaults to `1s`.  Can be set to `-1` to disable
     refresh.
 
+`index.max_result_window`::
+
+    The maximum value of `from + size` for searches to this index. Defaults to
+    `10000`. Search requests take heap memory and time proportional to
+    `from + size` and this limits that memory. See
+    {ref}/search-request-scroll.html[Scroll] for a more efficient alternative
+    to raising this.
+
 `index.blocks.read_only`::
 
     Set to `true` to make the index and index metadata read only, `false` to
@@ -184,5 +192,3 @@ include::index-modules/slowlog.asciidoc[]
 include::index-modules/store.asciidoc[]
 
 include::index-modules/translog.asciidoc[]
-
-
diff --git a/docs/reference/migration/migrate_1_0.asciidoc b/docs/reference/migration/migrate_1_0.asciidoc
index 66b1245..c8750d1 100644
--- a/docs/reference/migration/migrate_1_0.asciidoc
+++ b/docs/reference/migration/migrate_1_0.asciidoc
@@ -188,7 +188,7 @@ GET /_count
 Also, the top-level `filter` parameter in search has been renamed to
 <<search-request-post-filter,`post_filter`>>, to indicate that it should not
 be used as the primary way to filter search results (use a
-<<query-dsl-filtered-query,`filtered` query>> instead), but only to filter
+<<query-dsl-bool-query,`bool` query>> instead), but only to filter
 results AFTER aggregations have been calculated.
 
 This example counts the top colors in all matching docs, but only returns docs
diff --git a/docs/reference/migration/migrate_2_1.asciidoc b/docs/reference/migration/migrate_2_1.asciidoc
index b51cf47..1dbef8b 100644
--- a/docs/reference/migration/migrate_2_1.asciidoc
+++ b/docs/reference/migration/migrate_2_1.asciidoc
@@ -26,6 +26,16 @@ Scroll requests sorted by `_doc` have been optimized to more efficiently resume
 from where the previous request stopped, so this will have the same performance
 characteristics as the former `scan` search type.
 
+==== from + size limits
+
+Elasticsearch will now return an error message if a query's `from` + `size` is
+more than the `index.max_result_window` parameter. This parameter defaults to
+10,000 which is safe for almost all clusters. Values higher than can consume
+significant chunks of heap memory per search and per shard executing the
+search. It's safest to leave this value as it is an use the scroll api for any
+deep scrolling but this setting is dynamic so it can raised or lowered as
+needed.
+
 === Update changes
 
 ==== Updates now `detect_noop` by default
diff --git a/docs/reference/migration/migrate_3_0.asciidoc b/docs/reference/migration/migrate_3_0.asciidoc
index a0c96da..1d61fca 100644
--- a/docs/reference/migration/migrate_3_0.asciidoc
+++ b/docs/reference/migration/migrate_3_0.asciidoc
@@ -71,4 +71,20 @@ with `_parent` field mapping created before version `2.0.0`. The data of these i
 The format of the join between parent and child documents have changed with the `2.0.0` release. The old
 format can't read from version `3.0.0` and onwards. The new format allows for a much more efficient and
 scalable join between parent and child documents and the join data structures are stored on on disk
-data structures as opposed as before the join data structures were stored in the jvm heap space.
\ No newline at end of file
+data structures as opposed as before the join data structures were stored in the jvm heap space.
+
+==== `score_type` has been removed
+
+The `score_type` option has been removed from the `has_child` and `has_parent` queries in favour of the `score_mode` option
+which does the exact same thing.
+
+==== `sum` score mode removed
+
+The `sum` score mode has been removed in favour of the `total` mode which doesn the same and is already available in
+previous versions.
+
+==== `max_children` option
+
+When `max_children` was set to `0` on the `has_child` query then there was no upper limit on how many children documents
+are allowed to match. This has changed and `0` now really means to zero child documents are allowed. If no upper limit
+is needed then the `max_children` option shouldn't be defined at all on the `has_child` query.
\ No newline at end of file
diff --git a/docs/reference/migration/migrate_query_refactoring.asciidoc b/docs/reference/migration/migrate_query_refactoring.asciidoc
deleted file mode 100644
index 560de94..0000000
--- a/docs/reference/migration/migrate_query_refactoring.asciidoc
+++ /dev/null
@@ -1,90 +0,0 @@
-[[breaking-changes query-refactoring]]
-== Breaking changes on the query-refactoring branch
-
-This section discusses changes that are breaking to the current rest or java-api
-on the query-refactoring feature branch.
-
-=== Plugins
-
-Plugins implementing custom queries need to implement the `fromXContent(QueryParseContext)` method in their
-`QueryParser` subclass rather than `parse`. This method will take care of parsing the query from `XContent` format
-into an intermediate query representation that can be streamed between the nodes in binary format, effectively the
-query object used in the java api. Also, the query parser needs to implement the `getBuilderPrototype` method that
-returns a prototype of the streamable query, which allows to deserialize an incoming query by calling
-`readFrom(StreamInput)` against it, which will create a new object, see usages of `Writeable`. The `QueryParser`
-also needs to declare the generic type of the query that it supports and it's able to parse.
-The query object can then transform itself into a lucene query through the new `toQuery(QueryShardContext)` method,
-which returns a lucene query to be executed on the data node. The query implementation also needs to implement the
-`validate` method that allows to validate the content of the query, no matter whether it came in through the java api
-directly or through the REST layer.
-
-=== Java-API
-
-==== BoostingQueryBuilder
-
-Removed setters for mandatory positive/negative query. Both arguments now have
-to be supplied at construction time already and have to be non-null.
-
-==== SpanContainingQueryBuilder
-
-Removed setters for mandatory big/little inner span queries. Both arguments now have
-to be supplied at construction time already and have to be non-null. Updated
-static factory methods in QueryBuilders accordingly.
-
-==== SpanNearQueryBuilder
-
-Removed setter for mandatory slop parameter, needs to be set in constructor now.
-Updated the static factory methods in QueryBuilders accordingly.
-
-==== SpanNotQueryBuilder
-
-Removed setter for mandatory include/exclude span query clause, needs to be set in constructor now.
-Updated the static factory methods in QueryBuilders and tests accordingly.
-
-==== SpanWithinQueryBuilder
-
-Removed setters for mandatory big/little inner span queries. Both arguments now have
-to be supplied at construction time already and have to be non-null. Updated
-static factory methods in QueryBuilders accordingly.
-
-==== QueryFilterBuilder
-
-Removed the setter `queryName(String queryName)` since this field is not supported
-in this type of query. Use `FQueryFilterBuilder.queryName(String queryName)` instead 
-when in need to wrap a named query as a filter.
-
-==== WrapperQueryBuilder
-
-Removed `wrapperQueryBuilder(byte[] source, int offset, int length)`. Instead simply
-use  `wrapperQueryBuilder(byte[] source)`. Updated the static factory methods in
-QueryBuilders accordingly.
-
-==== QueryStringQueryBuilder
-
-Removed ability to pass in boost value using `field(String field)` method in form e.g. `field^2`.
-Use the `field(String, float)` method instead.
-
-==== Operator
-
-Removed the enums called `Operator` from `MatchQueryBuilder`, `QueryStringQueryBuilder`,
-`SimpleQueryStringBuilder`, and `CommonTermsQueryBuilder` in favour of using the enum
-defined in `org.elasticsearch.index.query.Operator` in an effort to consolidate the
-codebase and avoid duplication.
-
-==== queryName and boost support
-
-Support for `queryName` and `boost` has been streamlined to all of the queries. That is
-a breaking change till queries get sent over the network as serialized json rather
-than in `Streamable` format. In fact whenever additional fields are added to the json
-representation of the query, older nodes might throw error when they find unknown fields.
-
-==== InnerHitsBuilder
-
-InnerHitsBuilder now has a dedicated addParentChildInnerHits and addNestedInnerHits methods
-to differentiate between inner hits for nested vs. parent / child documents. This change
-makes the type / path parameter mandatory.
-
-==== MatchQueryBuilder
-
-Moving MatchQueryBuilder.Type and MatchQueryBuilder.ZeroTermsQuery enum to MatchQuery.Type.
-Also reusing new Operator enum.
diff --git a/docs/reference/modules/cluster/allocation_awareness.asciidoc b/docs/reference/modules/cluster/allocation_awareness.asciidoc
index 6b896aa..ee3cbc1 100644
--- a/docs/reference/modules/cluster/allocation_awareness.asciidoc
+++ b/docs/reference/modules/cluster/allocation_awareness.asciidoc
@@ -69,6 +69,11 @@ cluster.routing.allocation.awareness.attributes: rack_id,zone
 NOTE: When using awareness attributes, shards will not be allocated to
 nodes that don't have values set for those attributes.
 
+NOTE: Number of primary/replica of a shard allocated on a specific group
+of nodes with the same awareness attribute value is determined by the number
+of attribute values. When the number of nodes in groups is unbalanced and
+there are many replicas, replica shards may be left unassigned.
+
 [float]
 [[forced-awareness]]
 === Forced Awareness
diff --git a/docs/reference/query-dsl/and-query.asciidoc b/docs/reference/query-dsl/and-query.asciidoc
deleted file mode 100644
index 5ef23af..0000000
--- a/docs/reference/query-dsl/and-query.asciidoc
+++ /dev/null
@@ -1,34 +0,0 @@
-[[query-dsl-and-query]]
-=== And Query
-
-deprecated[2.0.0-beta1, Use the `bool` query instead]
-
-A query that matches documents using the `AND` boolean operator on other
-queries.
-
-[source,js]
---------------------------------------------------
-{
-    "filtered" : {
-        "query" : {
-            "term" : { "name.first" : "shay" }
-        },
-        "filter" : {
-            "and" : [
-                {
-                    "range" : { 
-                        "postDate" : { 
-                            "from" : "2010-03-01",
-                            "to" : "2010-04-01"
-                        }
-                    }
-                },
-                {
-                    "prefix" : { "name.second" : "ba" }
-                }
-            ]
-        }
-    }
-}
---------------------------------------------------
-
diff --git a/docs/reference/query-dsl/compound-queries.asciidoc b/docs/reference/query-dsl/compound-queries.asciidoc
index 0228ddd..c6a1f0f 100644
--- a/docs/reference/query-dsl/compound-queries.asciidoc
+++ b/docs/reference/query-dsl/compound-queries.asciidoc
@@ -41,18 +41,6 @@ documents which also match a `negative` query.
 
 Execute one query for the specified indices, and another for other indices.
 
-<<query-dsl-and-query,`and`>>, <<query-dsl-or-query,`or`>>, <<query-dsl-not-query,`not`>>::
-
-Synonyms for the `bool` query.
-
-<<query-dsl-filtered-query,`filtered` query>>::
-
-Combine a query clause in query context with another in filter context. deprecated[2.0.0-beta1,Use the `bool` query instead]
-
-<<query-dsl-limit-query,`limit` query>>::
-
-Limits the number of documents examined per shard.
-
 
 include::constant-score-query.asciidoc[]
 include::bool-query.asciidoc[]
@@ -60,10 +48,5 @@ include::dis-max-query.asciidoc[]
 include::function-score-query.asciidoc[]
 include::boosting-query.asciidoc[]
 include::indices-query.asciidoc[]
-include::and-query.asciidoc[]
 include::not-query.asciidoc[]
-include::or-query.asciidoc[]
-include::filtered-query.asciidoc[]
-include::limit-query.asciidoc[]
-
 
diff --git a/docs/reference/query-dsl/filtered-query.asciidoc b/docs/reference/query-dsl/filtered-query.asciidoc
deleted file mode 100644
index 5d399d0..0000000
--- a/docs/reference/query-dsl/filtered-query.asciidoc
+++ /dev/null
@@ -1,96 +0,0 @@
-[[query-dsl-filtered-query]]
-=== Filtered Query
-
-deprecated[2.0.0-beta1, Use the `bool` query instead with a `must` clause for the query and a `filter` clause for the filter]
-
-The `filtered` query is used to combine a query which will be used for
-scoring with another query which will only be used for filtering the result
-set.
-
-TIP: Exclude as many document as you can with a filter, then query just the
-documents that remain.
-
-[source,js]
---------------------------------------------------
-{
-  "filtered": {
-    "query": {
-      "match": { "tweet": "full text search" }
-    },
-    "filter": {
-      "range": { "created": { "gte": "now-1d/d" }}
-    }
-  }
-}
---------------------------------------------------
-
-The `filtered` query can be used wherever a `query` is expected, for instance,
-to use the above example in search request:
-
-[source,js]
---------------------------------------------------
-curl -XGET localhost:9200/_search -d '
-{
-  "query": {
-    "filtered": { <1>
-      "query": {
-        "match": { "tweet": "full text search" }
-      },
-      "filter": {
-        "range": { "created": { "gte": "now-1d/d" }}
-      }
-    }
-  }
-}
-'
---------------------------------------------------
-<1> The `filtered` query is passed as the value of the `query`
-    parameter in the search request.
-
-==== Filtering without a query
-
-If a `query` is not specified, it defaults to the
-<<query-dsl-match-all-query,`match_all` query>>.  This means that the
-`filtered` query can be used to wrap just a filter, so that it can be used
-wherever a query is expected.
-
-[source,js]
---------------------------------------------------
-curl -XGET localhost:9200/_search -d '
-{
-  "query": {
-    "filtered": { <1>
-      "filter": {
-        "range": { "created": { "gte": "now-1d/d" }}
-      }
-    }
-  }
-}
-'
---------------------------------------------------
-<1> No `query` has been specified, so this request applies just the filter,
-   returning all documents created since yesterday.
-
-===== Multiple filters
-
-Multiple filters can be applied by wrapping them in a
-<<query-dsl-bool-query,`bool` query>>, for example:
-
-[source,js]
---------------------------------------------------
-{
-  "filtered": {
-    "query": { "match": { "tweet": "full text search" }},
-    "filter": {
-      "bool": {
-        "must": { "range": { "created": { "gte": "now-1d/d" }}},
-        "should": [
-          { "term": { "featured": true }},
-          { "term": { "starred":  true }}
-        ],
-        "must_not": { "term": { "deleted": false }}
-      }
-    }
-  }
-}
---------------------------------------------------
diff --git a/docs/reference/query-dsl/geo-bounding-box-query.asciidoc b/docs/reference/query-dsl/geo-bounding-box-query.asciidoc
index 60aab15..6710461 100644
--- a/docs/reference/query-dsl/geo-bounding-box-query.asciidoc
+++ b/docs/reference/query-dsl/geo-bounding-box-query.asciidoc
@@ -22,8 +22,8 @@ Then the following simple query can be executed with a
 [source,js]
 --------------------------------------------------
 {
-    "filtered" : {
-        "query" : {
+    "bool" : {
+        "must" : {
             "match_all" : {}
         },
         "filter" : {
@@ -75,8 +75,8 @@ representation of the geo point, the filter can accept it as well:
 [source,js]
 --------------------------------------------------
 {
-    "filtered" : {
-        "query" : {
+    "boost" : {
+        "must" : {
             "match_all" : {}
         },
         "filter" : {
@@ -106,8 +106,8 @@ conform with http://geojson.org/[GeoJSON].
 [source,js]
 --------------------------------------------------
 {
-    "filtered" : {
-        "query" : {
+    "bool" : {
+        "must" : {
             "match_all" : {}
         },
         "filter" : {
@@ -130,8 +130,8 @@ Format in `lat,lon`.
 [source,js]
 --------------------------------------------------
 {
-    "filtered" : {
-        "query" : {
+    "bool" : {
+        "must" : {
             "match_all" : {}
         },
         "filter" : {
@@ -152,8 +152,8 @@ Format in `lat,lon`.
 [source,js]
 --------------------------------------------------
 {
-    "filtered" : {
-        "query" : {
+    "bool" : {
+        "must" : {
             "match_all" : {}
         },
         "filter" : {
@@ -181,8 +181,8 @@ values separately.
 [source,js]
 --------------------------------------------------
 {
-    "filtered" : {
-        "query" : {
+    "bool" : {
+        "must" : {
             "match_all" : {}
         },
         "filter" : {
@@ -227,8 +227,8 @@ are not supported. Here is an example:
 [source,js]
 --------------------------------------------------
 {
-    "filtered" : {
-        "query" : {
+    "bool" : {
+        "must" : {
             "match_all" : {}
         },
         "filter" : {
diff --git a/docs/reference/query-dsl/geo-distance-query.asciidoc b/docs/reference/query-dsl/geo-distance-query.asciidoc
index 130319d..c5b6029 100644
--- a/docs/reference/query-dsl/geo-distance-query.asciidoc
+++ b/docs/reference/query-dsl/geo-distance-query.asciidoc
@@ -22,8 +22,8 @@ filter:
 [source,js]
 --------------------------------------------------
 {
-    "filtered" : {
-        "query" : {
+    "bool" : {
+        "must" : {
             "match_all" : {}
         },
         "filter" : {
@@ -51,8 +51,8 @@ representation of the geo point, the filter can accept it as well:
 [source,js]
 --------------------------------------------------
 {
-    "filtered" : {
-        "query" : {
+    "bool" : {
+        "must" : {
             "match_all" : {}
         },
         "filter" : {
@@ -77,8 +77,8 @@ conform with http://geojson.org/[GeoJSON].
 [source,js]
 --------------------------------------------------
 {
-    "filtered" : {
-        "query" : {
+    "bool" : {
+        "must" : {
             "match_all" : {}
         },
         "filter" : {
@@ -99,8 +99,8 @@ Format in `lat,lon`.
 [source,js]
 --------------------------------------------------
 {
-    "filtered" : {
-        "query" : {
+    "bool" : {
+        "must" : {
             "match_all" : {}
         },
         "filter" : {
@@ -119,8 +119,8 @@ Format in `lat,lon`.
 [source,js]
 --------------------------------------------------
 {
-    "filtered" : {
-        "query" : {
+    "bool" : {
+        "must" : {
             "match_all" : {}
         },
         "filter" : {
diff --git a/docs/reference/query-dsl/geo-distance-range-query.asciidoc b/docs/reference/query-dsl/geo-distance-range-query.asciidoc
index cacf0a7..901cca0 100644
--- a/docs/reference/query-dsl/geo-distance-range-query.asciidoc
+++ b/docs/reference/query-dsl/geo-distance-range-query.asciidoc
@@ -6,8 +6,8 @@ Filters documents that exists within a range from a specific point:
 [source,js]
 --------------------------------------------------
 {
-    "filtered" : {
-        "query" : {
+    "boost" : {
+        "must" : {
             "match_all" : {}
         },
         "filter" : {
diff --git a/docs/reference/query-dsl/geo-polygon-query.asciidoc b/docs/reference/query-dsl/geo-polygon-query.asciidoc
index ff53a35..306b2dd 100644
--- a/docs/reference/query-dsl/geo-polygon-query.asciidoc
+++ b/docs/reference/query-dsl/geo-polygon-query.asciidoc
@@ -7,7 +7,7 @@ points. Here is an example:
 [source,js]
 --------------------------------------------------
 {
-    "filtered" : {
+    "bool" : {
         "query" : {
             "match_all" : {}
         },
@@ -53,8 +53,8 @@ conform with http://geojson.org/[GeoJSON].
 [source,js]
 --------------------------------------------------
 {
-    "filtered" : {
-        "query" : {
+    "bool" : {
+        "must" : {
             "match_all" : {}
         },
         "filter" : {
@@ -80,8 +80,8 @@ Format in `lat,lon`.
 [source,js]
 --------------------------------------------------
 {
-    "filtered" : {
-        "query" : {
+    "bool" : {
+        "must" : {
             "match_all" : {}
         },
         "filter" : {
@@ -105,8 +105,8 @@ Format in `lat,lon`.
 [source,js]
 --------------------------------------------------
 {
-    "filtered" : {
-        "query" : {
+    "bool" : {
+        "must" : {
             "match_all" : {}
         },
         "filter" : {
diff --git a/docs/reference/query-dsl/geo-shape-query.asciidoc b/docs/reference/query-dsl/geo-shape-query.asciidoc
index 8ab2f13..77deabc 100644
--- a/docs/reference/query-dsl/geo-shape-query.asciidoc
+++ b/docs/reference/query-dsl/geo-shape-query.asciidoc
@@ -40,8 +40,8 @@ The following query will find the point using the Elasticsearch's
 --------------------------------------------------
 {
     "query":{
-        "filtered": {
-            "query": {
+        "bool": {
+            "must": {
                 "match_all": {}
             },
             "filter": {
@@ -81,8 +81,8 @@ shape:
 [source,js]
 --------------------------------------------------
 {
-    "filtered": {
-        "query": {
+    "bool": {
+        "must": {
             "match_all": {}
         },
         "filter": {
diff --git a/docs/reference/query-dsl/geohash-cell-query.asciidoc b/docs/reference/query-dsl/geohash-cell-query.asciidoc
index c3c83de..807e867 100644
--- a/docs/reference/query-dsl/geohash-cell-query.asciidoc
+++ b/docs/reference/query-dsl/geohash-cell-query.asciidoc
@@ -43,8 +43,8 @@ next to the given cell.
 [source,js]
 --------------------------------------------------
 {
-    "filtered" : {
-        "query" : {
+    "bool" : {
+        "must" : {
             "match_all" : {}
         },
         "filter" : {
diff --git a/docs/reference/query-dsl/has-child-query.asciidoc b/docs/reference/query-dsl/has-child-query.asciidoc
index 6f42e6f..24951bb 100644
--- a/docs/reference/query-dsl/has-child-query.asciidoc
+++ b/docs/reference/query-dsl/has-child-query.asciidoc
@@ -23,9 +23,9 @@ an example:
 ==== Scoring capabilities
 
 The `has_child` also has scoring support. The
-supported score types are `min`, `max`, `sum`, `avg` or `none`. The default is
+supported score modes are `min`, `max`, `total`, `avg` or `none`. The default is
 `none` and yields the same behaviour as in previous versions. If the
-score type is set to another value than `none`, the scores of all the
+score mode is set to another value than `none`, the scores of all the
 matching child documents are aggregated into the associated parent
 documents. The score type can be specified with the `score_mode` field
 inside the `has_child` query:
diff --git a/docs/reference/query-dsl/has-parent-query.asciidoc b/docs/reference/query-dsl/has-parent-query.asciidoc
index 2b84811..5f12e44 100644
--- a/docs/reference/query-dsl/has-parent-query.asciidoc
+++ b/docs/reference/query-dsl/has-parent-query.asciidoc
@@ -24,20 +24,21 @@ in the same manner as the `has_child` query.
 [float]
 ==== Scoring capabilities
 
-The `has_parent` also has scoring support. The default is `false` which
-ignores the score from the parent document. The score is in this
+The `has_parent` also has scoring support. The
+supported score types are `score` or `none`. The default is `none` and
+this ignores the score from the parent document. The score is in this
 case equal to the boost on the `has_parent` query (Defaults to 1). If
-the score is set to `true`, then the score of the matching parent
+the score type is set to `score`, then the score of the matching parent
 document is aggregated into the child documents belonging to the
-matching parent document. The score type can be specified with the
-`score` field inside the `has_parent` query:
+matching parent document. The score mode can be specified with the
+`score_mode` field inside the `has_parent` query:
 
 [source,js]
 --------------------------------------------------
 {
     "has_parent" : {
         "parent_type" : "blog",
-        "score" : true,
+        "score_mode" : "score",
         "query" : {
             "term" : {
                 "tag" : "something"
diff --git a/docs/reference/query-dsl/limit-query.asciidoc b/docs/reference/query-dsl/limit-query.asciidoc
deleted file mode 100644
index 198ad78..0000000
--- a/docs/reference/query-dsl/limit-query.asciidoc
+++ /dev/null
@@ -1,19 +0,0 @@
-[[query-dsl-limit-query]]
-=== Limit Query
-
-A limit query limits the number of documents (per shard) to execute on.
-For example:
-
-[source,js]
---------------------------------------------------
-{
-    "filtered" : {
-        "filter" : {
-             "limit" : {"value" : 100}
-         },
-         "query" : {
-            "term" : { "name.first" : "shay" }
-        }
-    }
-}
---------------------------------------------------
diff --git a/docs/reference/query-dsl/not-query.asciidoc b/docs/reference/query-dsl/not-query.asciidoc
index a74a0f1..7854ee9 100644
--- a/docs/reference/query-dsl/not-query.asciidoc
+++ b/docs/reference/query-dsl/not-query.asciidoc
@@ -6,8 +6,8 @@ A query that filters out matched documents using a query. For example:
 [source,js]
 --------------------------------------------------
 {
-    "filtered" : {
-        "query" : {
+    "bool" : {
+        "must" : {
             "term" : { "name.first" : "shay" }
         },
         "filter" : {
@@ -29,8 +29,8 @@ Or, in a longer form with a `filter` element:
 [source,js]
 --------------------------------------------------
 {
-    "filtered" : {
-        "query" : {
+    "bool" : {
+        "must" : {
             "term" : { "name.first" : "shay" }
         },
         "filter" : {
diff --git a/docs/reference/query-dsl/or-query.asciidoc b/docs/reference/query-dsl/or-query.asciidoc
deleted file mode 100644
index 46005dc..0000000
--- a/docs/reference/query-dsl/or-query.asciidoc
+++ /dev/null
@@ -1,29 +0,0 @@
-[[query-dsl-or-query]]
-=== Or Query
-
-deprecated[2.0.0-beta1, Use the `bool` query instead]
-
-A query that matches documents using the `OR` boolean operator on other
-queries.
-
-[source,js]
---------------------------------------------------
-{
-    "filtered" : {
-        "query" : {
-            "term" : { "name.first" : "shay" }
-        },
-        "filter" : {
-            "or" : [
-                {
-                    "term" : { "name.second" : "banon" }
-                },
-                {
-                    "term" : { "name.nick" : "kimchy" }
-                }
-            ]
-        }
-    }
-}
---------------------------------------------------
-
diff --git a/docs/reference/query-dsl/script-query.asciidoc b/docs/reference/query-dsl/script-query.asciidoc
index c14e814..223460f 100644
--- a/docs/reference/query-dsl/script-query.asciidoc
+++ b/docs/reference/query-dsl/script-query.asciidoc
@@ -2,13 +2,13 @@
 === Script Query
 
 A query allowing to define
-<<modules-scripting,scripts>> as filters. For
-example:
+<<modules-scripting,scripts>> as queries. They are typically used in a filter
+context, for example:
 
 [source,js]
 ----------------------------------------------
-"filtered" : {
-    "query" : {
+"bool" : {
+    "must" : {
         ...
     }, 
     "filter" : {
@@ -28,8 +28,8 @@ to use the ability to pass parameters to the script itself, for example:
 
 [source,js]
 ----------------------------------------------
-"filtered" : {
-    "query" : {
+"bool" : {
+    "must" : {
         ...
     }, 
     "filter" : {
diff --git a/docs/reference/query-dsl/terms-query.asciidoc b/docs/reference/query-dsl/terms-query.asciidoc
index 58b0ba5..16cfd8c 100644
--- a/docs/reference/query-dsl/terms-query.asciidoc
+++ b/docs/reference/query-dsl/terms-query.asciidoc
@@ -79,16 +79,12 @@ curl -XPUT localhost:9200/tweets/tweet/1 -d '{
 # search on all the tweets that match the followers of user 2
 curl -XGET localhost:9200/tweets/_search -d '{
   "query" : {
-    "filtered" : {
-      "filter" : {
-        "terms" : {
-          "user" : {
-            "index" : "users",
-            "type" : "user",
-            "id" : "2",
-            "path" : "followers"
-          }
-        }
+    "terms" : {
+      "user" : {
+        "index" : "users",
+        "type" : "user",
+        "id" : "2",
+        "path" : "followers"
       }
     }
   }
diff --git a/docs/reference/redirects.asciidoc b/docs/reference/redirects.asciidoc
index 9c6a9b4..922216a 100644
--- a/docs/reference/redirects.asciidoc
+++ b/docs/reference/redirects.asciidoc
@@ -77,20 +77,6 @@ in ``query context'' and as a filter in ``filter context'' (see <<query-dsl>>).
 Queries and filters have been merged.  Any query clause can now be used as a query
 in ``query context'' and as a filter in ``filter context'' (see <<query-dsl>>).
 
-[role="exclude",id="query-dsl-and-filter"]
-=== And Filter
-
-The `and` filter has been replaced by the <<query-dsl-and-query>>.  It behaves
-as a query in ``query context'' and as a filter in ``filter context'' (see
-<<query-dsl>>).
-
-[role="exclude",id="query-dsl-or-filter"]
-=== Or Filter
-
-The `or` filter has been replaced by the <<query-dsl-or-query>>.  It behaves
-as a query in ``query context'' and as a filter in ``filter context'' (see
-<<query-dsl>>).
-
 [role="exclude",id="query-dsl-not-filter"]
 === Not Filter
 
@@ -195,13 +181,6 @@ The `indices` filter has been replaced by the <<query-dsl-indices-query>>.  It b
 as a query in ``query context'' and as a filter in ``filter context'' (see
 <<query-dsl>>).
 
-[role="exclude",id="query-dsl-limit-filter"]
-=== Limit Filter
-
-The `limit` filter has been replaced by the <<query-dsl-limit-query>>.
-It behaves as a query in ``query context'' and as a filter in ``filter
-context'' (see <<query-dsl>>).
-
 [role="exclude",id="query-dsl-match-all-filter"]
 === Match All Filter
 
@@ -381,3 +360,86 @@ The shard query cache has been renamed <<shard-request-cache>>.
 === Query cache
 
 The filter cache has been renamed <<query-cache>>.
+
+[role="exclude",id="query-dsl-filtered-query"]
+=== Filtered query
+
+The `filtered` query is replaced in favour of the <<query-dsl-bool-query,bool>> query. Instead of
+the following:
+
+[source,js]
+-------------------------
+GET _search
+{
+  "query": {
+    "filtered": {
+      "query": {
+        "match": {
+          "text": "quick brown fox"
+        }
+      },
+      "filter": {
+        "term": {
+          "status": "published"
+        }
+      }
+    }
+  }
+}
+-------------------------
+
+move the query and filter to the `must` and `filter` parameters in the `bool`
+query:
+
+[source,js]
+-------------------------
+GET _search
+{
+  "query": {
+    "bool": {
+      "must": {
+        "match": {
+          "text": "quick brown fox"
+        }
+      },
+      "filter": {
+        "term": {
+          "status": "published"
+        }
+      }
+    }
+  }
+}
+-------------------------
+
+[role="exclude",id="query-dsl-or-query"]
+=== Or query
+
+The `or` query is replaced in favour of the <<query-dsl-bool-query,bool>> query.
+
+[role="exclude",id="query-dsl-or-filter"]
+=== Or filter
+
+The `or` filter is replaced in favour of the <<query-dsl-bool-query,bool>> query.
+
+[role="exclude",id="query-dsl-and-query"]
+=== And query
+
+The `and` query is replaced in favour of the <<query-dsl-bool-query,bool>> query.
+
+[role="exclude",id="query-dsl-and-filter"]
+=== And filter
+
+The `and` filter is replaced in favour of the <<query-dsl-bool-query,bool>> query.
+
+[role="exclude",id="query-dsl-limit-query"]
+=== Limit query
+
+The `limit` query is replaced in favour of the <<search-request-body,terminate_after>>
+parameter of search requests.
+
+[role="exclude",id="query-dsl-limit-filter"]
+=== Limit filter
+
+The `limit` filter is replaced in favour of the <<search-request-body,terminate_after>>
+parameter of search requests.
diff --git a/docs/reference/search.asciidoc b/docs/reference/search.asciidoc
index 9a0de10..f59444d 100644
--- a/docs/reference/search.asciidoc
+++ b/docs/reference/search.asciidoc
@@ -34,8 +34,8 @@ only the relevant shard:
 --------------------------------------------------
 $ curl -XGET 'http://localhost:9200/twitter/tweet/_search?routing=kimchy' -d '{
     "query": {
-        "filtered" : {
-            "query" : {
+        "bool" : {
+            "must" : {
                 "query_string" : {
                     "query" : "some query string here"
                 }
diff --git a/docs/reference/search/request/from-size.asciidoc b/docs/reference/search/request/from-size.asciidoc
index d8d8095..d19b850 100644
--- a/docs/reference/search/request/from-size.asciidoc
+++ b/docs/reference/search/request/from-size.asciidoc
@@ -19,3 +19,8 @@ defaults to `10`.
     }
 }
 --------------------------------------------------
+
+Note that `from` + `size` can not be more than the `index.max_result_window`
+index setting which defaults to 10,000. See the
+{ref}/search-request-scroll.html[Scroll] api for more efficient ways to do deep
+scrolling.
diff --git a/docs/reference/search/request/named-queries-and-filters.asciidoc b/docs/reference/search/request/named-queries-and-filters.asciidoc
index 183f0e7..96d7c13 100644
--- a/docs/reference/search/request/named-queries-and-filters.asciidoc
+++ b/docs/reference/search/request/named-queries-and-filters.asciidoc
@@ -1,20 +1,16 @@
 [[search-request-named-queries-and-filters]]
-=== Named Queries and Filters
+=== Named Queries
 
 Each filter and query can accept a `_name` in its top level definition.
 
 [source,js]
 --------------------------------------------------
 {
-    "filtered" : {
-        "query" : {
-            "bool" : {
-                "should" : [
-                    {"match" : { "name.first" : {"query" : "shay", "_name" : "first"} }},
-                    {"match" : { "name.last" : {"query" : "banon", "_name" : "last"} }}
-                ]
-            }
-        },
+    "bool" : {
+        "should" : [
+            {"match" : { "name.first" : {"query" : "shay", "_name" : "first"} }},
+            {"match" : { "name.last" : {"query" : "banon", "_name" : "last"} }}
+        ],
         "filter" : {
             "terms" : {
                 "name.last" : ["banon", "kimchy"],
@@ -26,32 +22,5 @@ Each filter and query can accept a `_name` in its top level definition.
 --------------------------------------------------
 
 The search response will include for each hit the `matched_queries` it matched on. The tagging of queries and filters
-only make sense for compound queries and filters (such as `bool` query and filter, `or` and `and` filter, `filtered` query etc.).
-
-Note, the query filter had to be enhanced in order to support this. In
-order to set a name, the `fquery` filter should be used, which wraps a
-query (just so there will be a place to set a name for it), for example:
-
-[source,js]
---------------------------------------------------
-{
-    "filtered" : {
-        "query" : {
-            "term" : { "name.first" : "shay" }
-        },
-        "filter" : {
-            "fquery" : {
-                "query" : {
-                    "term" : { "name.last" : "banon" }
-                },
-                "_name" : "test"
-            }
-        }
-    }
-}
---------------------------------------------------
-
-==== Named queries
+only make sense for the `bool` query.
 
-The support for the `_name` option on queries is available from version `0.90.4` and the support on filters is available
-also in versions before `0.90.4`.
diff --git a/docs/reference/search/request/post-filter.asciidoc b/docs/reference/search/request/post-filter.asciidoc
index 274d14b..7c352e9 100644
--- a/docs/reference/search/request/post-filter.asciidoc
+++ b/docs/reference/search/request/post-filter.asciidoc
@@ -2,28 +2,24 @@
 === Post filter
 
 The `post_filter` is applied to the search `hits` at the very end of a search
-request,  after aggregations have already been calculated. It's purpose is
+request,  after aggregations have already been calculated. Its purpose is
 best explained by example:
 
 Imagine that you are selling shirts, and the user has specified two filters:
 `color:red` and `brand:gucci`.  You only want to show them red shirts made by
 Gucci in the search results.  Normally you would do this with a 
-<<query-dsl-filtered-query,`filtered` query>>:
+<<query-dsl-bool-query,`bool` query>>:
 
 [source,js]
 --------------------------------------------------
 curl -XGET localhost:9200/shirts/_search -d '
 {
   "query": {
-    "filtered": {
-      "filter": {
-        "bool": {
-          "must": [
-            { "term": { "color": "red"   }},
-            { "term": { "brand": "gucci" }}
-          ]
-        }
-      }
+    "bool": {
+      "filter": [
+        { "term": { "color": "red"   }},
+        { "term": { "brand": "gucci" }}
+      ]
     }
   }
 }
@@ -43,15 +39,11 @@ This can be done with a
 curl -XGET localhost:9200/shirts/_search -d '
 {
   "query": {
-    "filtered": {
-      "filter": {
-        "bool": {
-          "must": [
-            { "term": { "color": "red"   }},
-            { "term": { "brand": "gucci" }}
-          ]
-        }
-      }
+    "bool": {
+      "filter": [
+        { "term": { "color": "red"   }},
+        { "term": { "brand": "gucci" }}
+      ]
     }
   },
   "aggs": {
@@ -78,7 +70,7 @@ the `post_filter`:
 curl -XGET localhost:9200/shirts/_search -d '
 {
   "query": {
-    "filtered": {
+    "bool": {
       "filter": {
         { "term": { "brand": "gucci" }} <1>
       }
diff --git a/docs/reference/search/search-template.asciidoc b/docs/reference/search/search-template.asciidoc
index bce9528..77670ac 100644
--- a/docs/reference/search/search-template.asciidoc
+++ b/docs/reference/search/search-template.asciidoc
@@ -169,8 +169,8 @@ We could write the query as:
 ------------------------------------------
 {
   "query": {
-    "filtered": {
-      "query": {
+    "bool": {
+      "must": {
         "match": {
           "line": "{{text}}" <1>
         }
@@ -212,7 +212,7 @@ via the REST API, should be written as a string:
 
 [source,js]
 --------------------
-"inline": "{\"query\":{\"filtered\":{\"query\":{\"match\":{\"line\":\"{{text}}\"}},\"filter\":{{{#line_no}}\"range\":{\"line_no\":{{{#start}}\"gte\":\"{{start}}\"{{#end}},{{/end}}{{/start}}{{#end}}\"lte\":\"{{end}}\"{{/end}}}}{{/line_no}}}}}}"
+"inline": "{\"query\":{\"bool\":{\"must\":{\"match\":{\"line\":\"{{text}}\"}},\"filter\":{{{#line_no}}\"range\":{\"line_no\":{{{#start}}\"gte\":\"{{start}}\"{{#end}},{{/end}}{{/start}}{{#end}}\"lte\":\"{{end}}\"{{/end}}}}{{/line_no}}}}}}"
 --------------------
 
 ==================================
diff --git a/docs/reference/search/suggesters/completion-suggest.asciidoc b/docs/reference/search/suggesters/completion-suggest.asciidoc
index ee8969b..af93ea1 100644
--- a/docs/reference/search/suggesters/completion-suggest.asciidoc
+++ b/docs/reference/search/suggesters/completion-suggest.asciidoc
@@ -15,11 +15,12 @@ suggestion is, why you should use it at all, if you have prefix queries
 already. The answer is simple: Prefix suggestions are fast.
 
 The data structures are internally backed by Lucenes
-`AnalyzingSuggester`, which uses FSTs to execute suggestions. Usually
-these data structures are costly to create, stored in-memory and need to
-be rebuilt every now and then to reflect changes in your indexed
-documents. The `completion` suggester circumvents this by storing the
-FST as part of your index during index time. This allows for really fast
+`AnalyzingSuggester`, which uses FSTs (finite state transducers) to
+execute suggestions. Usually these data structures are costly to
+create, stored in-memory and need to be rebuilt every now and then to
+reflect changes in your indexed documents. The `completion` suggester
+circumvents this by storing the FST (finite state transducer) as part
+of your index during index time. This allows for really fast
 loads and executions.
 
 [[completion-suggester-mapping]]
diff --git a/docs/reference/search/validate.asciidoc b/docs/reference/search/validate.asciidoc
index b47f63e..a08e183 100644
--- a/docs/reference/search/validate.asciidoc
+++ b/docs/reference/search/validate.asciidoc
@@ -55,8 +55,8 @@ Or, with a request body:
 --------------------------------------------------
 curl -XGET 'http://localhost:9200/twitter/tweet/_validate/query' -d '{
   "query" : {
-    "filtered" : {
-      "query" : {
+    "bool" : {
+      "must" : {
         "query_string" : {
           "query" : "*:*"
         }
@@ -99,7 +99,7 @@ curl -XGET 'http://localhost:9200/twitter/tweet/_validate/query?q=post_date:foo&
   "explanations" : [ {
     "index" : "twitter",
     "valid" : false,
-    "error" : "org.elasticsearch.index.query.QueryParsingException: [twitter] Failed to parse; org.elasticsearch.ElasticsearchParseException: failed to parse date field [foo], tried both date format [dateOptionalTime], and timestamp number; java.lang.IllegalArgumentException: Invalid format: \"foo\""
+    "error" : "[twitter] QueryParsingException[Failed to parse]; nested: IllegalArgumentException[Invalid format: \"foo\"];; java.lang.IllegalArgumentException: Invalid format: \"foo\""
   } ]
 }
 --------------------------------------------------
@@ -112,14 +112,14 @@ For Fuzzy Queries:
 
 [source,js]
 --------------------------------------------------
-curl -XGET 'http://localhost:9200/imdb/movies/_validate/query?rewrite=true'
+curl -XGET 'http://localhost:9200/imdb/movies/_validate/query?rewrite=true' -d '
 {
   "query": {
     "fuzzy": {
       "actors": "kyle"
     }
   }
-}
+}'
 --------------------------------------------------
 
 Response:
@@ -137,7 +137,7 @@ Response:
       {
          "index": "imdb",
          "valid": true,
-         "explanation": "filtered(plot:kyle plot:kylie^0.75 plot:kyne^0.75 plot:lyle^0.75 plot:pyle^0.75)->cache(_type:movies)"
+         "explanation": "plot:kyle plot:kylie^0.75 plot:kyne^0.75 plot:lyle^0.75 plot:pyle^0.75 #_type:movies"
       }
    ]
 }
@@ -175,7 +175,7 @@ Response:
       {
          "index": "imdb",
          "valid": true,
-         "explanation": "filtered(((title:terminator^3.71334 plot:future^2.763601 plot:human^2.8415773 plot:sarah^3.4193945 plot:kyle^3.8244398 plot:cyborg^3.9177752 plot:connor^4.040236 plot:reese^4.7133346 ... )~6) -ConstantScore(_uid:movies#88247))->cache(_type:movies)"
+         "explanation": "((title:terminator^3.71334 plot:future^2.763601 plot:human^2.8415773 plot:sarah^3.4193945 plot:kyle^3.8244398 plot:cyborg^3.9177752 plot:connor^4.040236 plot:reese^4.7133346 ... )~6) -ConstantScore(_uid:movies#88247) #_type:movies"
       }
    ]
 }
diff --git a/docs/reference/testing/testing-framework.asciidoc b/docs/reference/testing/testing-framework.asciidoc
index ecfd168..a2d3f39 100644
--- a/docs/reference/testing/testing-framework.asciidoc
+++ b/docs/reference/testing/testing-framework.asciidoc
@@ -18,18 +18,12 @@ All of the tests are run using a custom junit runner, the `RandomizedRunner` pro
 [[using-elasticsearch-test-classes]]
 === Using the elasticsearch test classes
 
-First, you need to include the testing dependency in your project. If you use maven and its `pom.xml` file, it looks like this
+First, you need to include the testing dependency in your project, along with the elasticsearch dependency you have already added. If you use maven and its `pom.xml` file, it looks like this
 
 [[source,xml]]
 --------------------------------------------------
 <dependencies>
   <dependency>
-    <groupId>com.carrotsearch.randomizedtesting</groupId>
-    <artifactId>randomizedtesting-runner</artifactId>
-    <version>${randomizedtesting-runner.version}</version>
-    <scope>test</scope>
-  </dependency>
-  <dependency>
     <groupId>org.apache.lucene</groupId>
     <artifactId>lucene-test-framework</artifactId>
     <version>${lucene.version}</version>
@@ -42,25 +36,22 @@ First, you need to include the testing dependency in your project. If you use ma
     <scope>test</scope>
     <type>test-jar</type>
   </dependency>
-  <dependency>
-    <groupId>org.elasticsearch</groupId>
-    <artifactId>elasticsearch</artifactId>
-    <version>${elasticsearch.version}</version>
-    <scope>test</scope>
-  </dependency>
 </dependencies>
 --------------------------------------------------
 
-Replace the elasticsearch version and the lucene versions with the current elasticsearch version and its accompanying lucene release.
-And replace the "randomizedtesting version" with the version that the current elasticsearch uses.
+Replace the elasticsearch version and the lucene version with the corresponding elasticsearch version and its accompanying lucene release.
+
+We provide a few classes that you can inherit from in your own test classes which provide:
 
-There are already have a couple of classes, you can inherit from in your own test classes. The advantages of doing so is having already defined loggers, the whole randomized infrastructure is set up already.
+* pre-defined loggers
+* randomized testing infrastructure
+* a number of helper methods
 
 
 [[unit-tests]]
 === unit tests
 
-In case you only need to execute a unit test, because your implementation can be isolated that well and does not require an up and running elasticsearch cluster, you can use the `ElasticsearchTestCase`. If you are testing lucene features, use `ElasticsearchLuceneTestCase` and if you are testing concrete token streams, use the `ElasticsearchTokenStreamTestCase` class. Those specific classes execute additional checks, which ensure that no resources leaks are happening, after the test has run.
+If your test is a well isolated unit test which doesn't need a running elasticsearch cluster, you can use the `ESTestCase`. If you are testing lucene features, use `ESTestCase` and if you are testing concrete token streams, use the `ESTokenStreamTestCase` class. Those specific classes execute additional checks which ensure that no resources leaks are happening, after the test has run.
 
 
 [[integration-tests]]
@@ -68,18 +59,20 @@ In case you only need to execute a unit test, because your implementation can be
 
 These kind of tests require firing up a whole cluster of nodes, before the tests can actually be run. Compared to unit tests they are obviously way more time consuming, but the test infrastructure tries to minimize the time cost by only restarting the whole cluster, if this is configured explicitly.
 
-The class your tests have to inherit from is `ElasticsearchIntegrationTest`. As soon as you inherit, there is no need for you to start any elasticsearch nodes manually in your test anymore, though you might need to ensure that at least a certain number of nodes is up.
+The class your tests have to inherit from is `ESIntegTestCase`. By inheriting from this class, you will no longer need to start elasticsearch nodes manually in your test, although you might need to ensure that at least a certain number of nodes are up. The integration test behaviour can be configured heavily by specifying different system properties on test runs. See the `TESTING.asciidoc` documentation in the https://github.com/elastic/elasticsearch/blob/master/TESTING.asciidoc[source repository] for more information.
+
 
 [[number-of-shards]]
 ==== number of shards
 
 The number of shards used for indices created during integration tests is randomized between `1` and `10` unless overwritten upon index creation via index settings.
-Rule of thumb is not to specify the number of shards unless needed, so that each test will use a different one all the time.
+The rule of thumb is not to specify the number of shards unless needed, so that each test will use a different one all the time. Alternatively you can override the `numberOfShards()` method. The same applies to the `numberOfReplicas()` method.
+
 
 [[helper-methods]]
 ==== generic helper methods
 
-There are a couple of helper methods in `ElasticsearchIntegrationTest`, which will make your tests shorter and more concise.
+There are a couple of helper methods in `ESIntegTestCase`, which will make your tests shorter and more concise.
 
 [horizontal]
 `refresh()`::           Refreshes all indices in a cluster
@@ -98,7 +91,7 @@ There are a couple of helper methods in `ElasticsearchIntegrationTest`, which wi
 [[test-cluster-methods]]
 ==== test cluster methods
 
-The `TestCluster` class is the heart of the cluster functionality in a randomized test and allows you to configure a specific setting or replay certain types of outages to check, how your custom code reacts.
+The `InternalTestCluster` class is the heart of the cluster functionality in a randomized test and allows you to configure a specific setting or replay certain types of outages to check, how your custom code reacts.
 
 [horizontal]
 `ensureAtLeastNumNodes(n)`::        Ensure at least the specified number of nodes is running in the cluster
@@ -112,10 +105,30 @@ The `TestCluster` class is the heart of the cluster functionality in a randomize
 `startNode(settings)`::             Create and start a new elasticsearch node
 
 
+[[changing-node-settings]]
+==== Changing node settings
+
+If you want to ensure a certain configuration for the nodes, which are started as part of the `EsIntegTestCase`, you can override the `nodeSettings()` method
+
+[source,java]
+-----------------------------------------
+public class Mytests extends ESIntegTestCase {
+
+  @Override
+  protected Settings nodeSettings(int nodeOrdinal) {
+      return settingsBuilder().put(super.nodeSettings(nodeOrdinal))
+             .put("node.mode", "network")
+             .build();
+  }
+
+}
+-----------------------------------------
+
+
 [[accessing-clients]]
 ==== Accessing clients
 
-In order to execute any actions, you have to use a client. You can use the `ElasticsearchIntegrationTest.client()` method to get back a random client. This client can be a `TransportClient` or a `NodeClient` - and usually you do not need to care as long as the action gets executed. There are several more methods for client selection inside of the `TestCluster` class, which can be accessed using the `ElasticsearchIntegrationTest.cluster()` method.
+In order to execute any actions, you have to use a client. You can use the `ESIntegTestCase.client()` method to get back a random client. This client can be a `TransportClient` or a `NodeClient` - and usually you do not need to care as long as the action gets executed. There are several more methods for client selection inside of the `InternalTestCluster` class, which can be accessed using the `ESIntegTestCase.internalCluster()` method.
 
 [horizontal]
 `iterator()`::                  An iterator over all available clients
@@ -136,7 +149,7 @@ You can use the `@ClusterScope` annotation at class level to configure this beha
 [source,java]
 -----------------------------------------
 @ClusterScope(scope=TEST, numNodes=1)
-public class CustomSuggesterSearchTests extends ElasticsearchIntegrationTest {
+public class CustomSuggesterSearchTests extends ESIntegTestCase {
   // ... tests go here
 }
 -----------------------------------------
@@ -145,7 +158,7 @@ The above sample configures the test to use a new cluster for each test method.
 
 
 [[changing-node-configuration]]
-==== Changing node configuration
+==== Changing plugins via configuration
 
 As elasticsearch is using JUnit 4, using the `@Before` and `@After` annotations is not a problem. However you should keep in mind, that this does not have any effect in your cluster setup, as the cluster is already up and running when those methods are run. So in case you want to configure settings - like loading a plugin on node startup - before the node is actually running, you should overwrite the `nodePlugins()` method from the `ESIntegTestCase` class and return the plugin classes each node should load.
 
@@ -157,13 +170,6 @@ protected Collection<Class<? extends Plugin>> nodePlugins() {
 }
 -----------------------------------------
 
-[[parametrized-tests]]
-=== parameterized tests
-
-It is possible to write parameterized tests, that get run multiple times with different parameters. `RandomizedRunner` needs to be used rather than the `Parameterized` runner provided with junit (all the base test classes already use `RandomizedRunner` though). The method that provides the parameters
-needs to be annotated with the `@ParametersFactory` annotation and must be `static`, `public`, without arguments and must have a return type assignable to `Iterable<Object[]>`. The iterable must return arrays conforming to the suite class's constructor with respect to the number and types of parameters.
-The constructor's parameters can be annotated with the `@Name` annotation to provide more descriptive parameter names for test descriptions. Have a look at `ElasticsearchRestTests` for an example.
-
 [[randomized-testing]]
 === Randomized testing
 
@@ -200,6 +206,8 @@ So, how can you create random data. The most important thing to know is, that yo
 `randomLocale()`::      Returns a random locale
 `randomTimeZone()`::    Returns a random timezone
 
+`randomFrom()`::        Returns a random element from a list/array
+
 In addition, there are a couple of helper methods, allowing you to create random ASCII and Unicode strings, see methods beginning with `randomAscii`, `randomUnicode`, and `randomRealisticUnicode` in the random test class. The latter one tries to create more realistic unicode string by not being arbitrary random.
 
 If you want to debug a specific problem with a specific random seed, you can use the `@Seed` annotation to configure a specific seed for a test. If you want to run a test more than once, instead of starting the whole test suite over and over again, you can use the `@Repeat` annotation with an arbitrary value. Each iteration than gets run with a different seed.
@@ -208,7 +216,7 @@ If you want to debug a specific problem with a specific random seed, you can use
 [[assertions]]
 === Assertions
 
-As many elasticsearch tests are checking for a similar output, like the amount of hits or the first hit or special highlighting, a couple of predefined assertions have been created. Those have been put into the `ElasticsearchAssertions` class.
+As many elasticsearch tests are checking for a similar output, like the amount of hits or the first hit or special highlighting, a couple of predefined assertions have been created. Those have been put into the `ElasticsearchAssertions` class. There is also a specific geo assertions in `ElasticsearchGeoAssertions`.
 
 [horizontal]
 `assertHitCount()`::        Checks hit count of a search or count request
@@ -232,6 +240,8 @@ Common matchers
 `hasId()`::     Matcher to check for a search hit id
 `hasType()`::   Matcher to check for a search hit type
 `hasIndex()`::  Matcher to check for a search hit index
+`hasScore()`::  Matcher to check for a certain score of a hit
+`hasStatus()`:: Matcher to check for a certain `RestStatus` of a response
 
 Usually, you would combine assertions and matchers in your test like this
 
diff --git a/plugins/analysis-icu/licenses/lucene-analyzers-icu-5.4.0-snapshot-1701068.jar.sha1 b/plugins/analysis-icu/licenses/lucene-analyzers-icu-5.4.0-snapshot-1701068.jar.sha1
deleted file mode 100644
index c1a1ec2..0000000
--- a/plugins/analysis-icu/licenses/lucene-analyzers-icu-5.4.0-snapshot-1701068.jar.sha1
+++ /dev/null
@@ -1 +0,0 @@
-b7f57ef60f302b30e88196d4f0d11f789c5cfabd
diff --git a/plugins/analysis-icu/licenses/lucene-analyzers-icu-5.4.0-snapshot-1702265.jar.sha1 b/plugins/analysis-icu/licenses/lucene-analyzers-icu-5.4.0-snapshot-1702265.jar.sha1
new file mode 100644
index 0000000..54c8e96
--- /dev/null
+++ b/plugins/analysis-icu/licenses/lucene-analyzers-icu-5.4.0-snapshot-1702265.jar.sha1
@@ -0,0 +1 @@
+1f92d0376ca9219b0bf96fe5bd9a913089608d6a
diff --git a/plugins/analysis-kuromoji/licenses/lucene-analyzers-kuromoji-5.4.0-snapshot-1701068.jar.sha1 b/plugins/analysis-kuromoji/licenses/lucene-analyzers-kuromoji-5.4.0-snapshot-1701068.jar.sha1
deleted file mode 100644
index 60ea23d..0000000
--- a/plugins/analysis-kuromoji/licenses/lucene-analyzers-kuromoji-5.4.0-snapshot-1701068.jar.sha1
+++ /dev/null
@@ -1 +0,0 @@
-5d1023fc3f28a42357d44d3a330ac0df1df4bf42
diff --git a/plugins/analysis-kuromoji/licenses/lucene-analyzers-kuromoji-5.4.0-snapshot-1702265.jar.sha1 b/plugins/analysis-kuromoji/licenses/lucene-analyzers-kuromoji-5.4.0-snapshot-1702265.jar.sha1
new file mode 100644
index 0000000..a3885bf
--- /dev/null
+++ b/plugins/analysis-kuromoji/licenses/lucene-analyzers-kuromoji-5.4.0-snapshot-1702265.jar.sha1
@@ -0,0 +1 @@
+60ee5bc1ac8ec102434e7064141a1f40281918b5
diff --git a/plugins/analysis-phonetic/licenses/lucene-analyzers-phonetic-5.4.0-snapshot-1701068.jar.sha1 b/plugins/analysis-phonetic/licenses/lucene-analyzers-phonetic-5.4.0-snapshot-1701068.jar.sha1
deleted file mode 100644
index 92243ae..0000000
--- a/plugins/analysis-phonetic/licenses/lucene-analyzers-phonetic-5.4.0-snapshot-1701068.jar.sha1
+++ /dev/null
@@ -1 +0,0 @@
-654c3e345ffdd74605582d1320c51c1c550a5cca
diff --git a/plugins/analysis-phonetic/licenses/lucene-analyzers-phonetic-5.4.0-snapshot-1702265.jar.sha1 b/plugins/analysis-phonetic/licenses/lucene-analyzers-phonetic-5.4.0-snapshot-1702265.jar.sha1
new file mode 100644
index 0000000..44ac92c
--- /dev/null
+++ b/plugins/analysis-phonetic/licenses/lucene-analyzers-phonetic-5.4.0-snapshot-1702265.jar.sha1
@@ -0,0 +1 @@
+977aa506485d358b40602347c11238b0f912fe2c
diff --git a/plugins/analysis-smartcn/licenses/lucene-analyzers-smartcn-5.4.0-snapshot-1701068.jar.sha1 b/plugins/analysis-smartcn/licenses/lucene-analyzers-smartcn-5.4.0-snapshot-1701068.jar.sha1
deleted file mode 100644
index a9159eb..0000000
--- a/plugins/analysis-smartcn/licenses/lucene-analyzers-smartcn-5.4.0-snapshot-1701068.jar.sha1
+++ /dev/null
@@ -1 +0,0 @@
-80c09e367abf2ad936c86cf74a16ae2b4e805b81
diff --git a/plugins/analysis-smartcn/licenses/lucene-analyzers-smartcn-5.4.0-snapshot-1702265.jar.sha1 b/plugins/analysis-smartcn/licenses/lucene-analyzers-smartcn-5.4.0-snapshot-1702265.jar.sha1
new file mode 100644
index 0000000..6f7d174
--- /dev/null
+++ b/plugins/analysis-smartcn/licenses/lucene-analyzers-smartcn-5.4.0-snapshot-1702265.jar.sha1
@@ -0,0 +1 @@
+61911b8400160bd206ea6ea46ba08fd9ba09e72b
diff --git a/plugins/analysis-stempel/licenses/lucene-analyzers-stempel-5.4.0-snapshot-1701068.jar.sha1 b/plugins/analysis-stempel/licenses/lucene-analyzers-stempel-5.4.0-snapshot-1701068.jar.sha1
deleted file mode 100644
index 390511f..0000000
--- a/plugins/analysis-stempel/licenses/lucene-analyzers-stempel-5.4.0-snapshot-1701068.jar.sha1
+++ /dev/null
@@ -1 +0,0 @@
-7c6ae4fc7e8e1d39c155068fea67b7fabb12c444
diff --git a/plugins/analysis-stempel/licenses/lucene-analyzers-stempel-5.4.0-snapshot-1702265.jar.sha1 b/plugins/analysis-stempel/licenses/lucene-analyzers-stempel-5.4.0-snapshot-1702265.jar.sha1
new file mode 100644
index 0000000..cf50fb6
--- /dev/null
+++ b/plugins/analysis-stempel/licenses/lucene-analyzers-stempel-5.4.0-snapshot-1702265.jar.sha1
@@ -0,0 +1 @@
+5a9bdf48b63562bf1ac8a73c1c6bdb4cc450439e
diff --git a/plugins/cloud-gce/src/main/java/org/elasticsearch/plugin/cloud/gce/CloudGcePlugin.java b/plugins/cloud-gce/src/main/java/org/elasticsearch/plugin/cloud/gce/CloudGcePlugin.java
index 8b2a3d2..5384f2c 100644
--- a/plugins/cloud-gce/src/main/java/org/elasticsearch/plugin/cloud/gce/CloudGcePlugin.java
+++ b/plugins/cloud-gce/src/main/java/org/elasticsearch/plugin/cloud/gce/CloudGcePlugin.java
@@ -25,6 +25,7 @@ import org.elasticsearch.common.inject.Module;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.discovery.DiscoveryModule;
 import org.elasticsearch.discovery.gce.GceDiscovery;
+import org.elasticsearch.discovery.gce.GceUnicastHostsProvider;
 import org.elasticsearch.plugins.Plugin;
 
 import java.util.ArrayList;
@@ -72,6 +73,7 @@ public class CloudGcePlugin extends Plugin {
 
     public void onModule(DiscoveryModule discoveryModule) {
         discoveryModule.addDiscoveryType("gce", GceDiscovery.class);
+        discoveryModule.addUnicastHostProvider(GceUnicastHostsProvider.class);
     }
 
 }
diff --git a/plugins/delete-by-query/src/main/java/org/elasticsearch/action/deletebyquery/DeleteByQueryRequestBuilder.java b/plugins/delete-by-query/src/main/java/org/elasticsearch/action/deletebyquery/DeleteByQueryRequestBuilder.java
index 803060c..9cf9103 100644
--- a/plugins/delete-by-query/src/main/java/org/elasticsearch/action/deletebyquery/DeleteByQueryRequestBuilder.java
+++ b/plugins/delete-by-query/src/main/java/org/elasticsearch/action/deletebyquery/DeleteByQueryRequestBuilder.java
@@ -63,7 +63,7 @@ public class DeleteByQueryRequestBuilder extends ActionRequestBuilder<DeleteByQu
      *
      * @see org.elasticsearch.index.query.QueryBuilders
      */
-    public DeleteByQueryRequestBuilder setQuery(QueryBuilder<?> queryBuilder) {
+    public DeleteByQueryRequestBuilder setQuery(QueryBuilder queryBuilder) {
         sourceBuilder().setQuery(queryBuilder);
         return this;
     }
diff --git a/plugins/discovery-ec2/src/main/java/org/elasticsearch/plugin/discovery/ec2/Ec2DiscoveryPlugin.java b/plugins/discovery-ec2/src/main/java/org/elasticsearch/plugin/discovery/ec2/Ec2DiscoveryPlugin.java
index 180581b..38c7042 100644
--- a/plugins/discovery-ec2/src/main/java/org/elasticsearch/plugin/discovery/ec2/Ec2DiscoveryPlugin.java
+++ b/plugins/discovery-ec2/src/main/java/org/elasticsearch/plugin/discovery/ec2/Ec2DiscoveryPlugin.java
@@ -24,6 +24,7 @@ import org.elasticsearch.cloud.aws.Ec2Module;
 import org.elasticsearch.common.component.LifecycleComponent;
 import org.elasticsearch.common.inject.Module;
 import org.elasticsearch.discovery.DiscoveryModule;
+import org.elasticsearch.discovery.ec2.AwsEc2UnicastHostsProvider;
 import org.elasticsearch.discovery.ec2.Ec2Discovery;
 import org.elasticsearch.plugins.Plugin;
 
@@ -61,5 +62,6 @@ public class Ec2DiscoveryPlugin extends Plugin {
 
     public void onModule(DiscoveryModule discoveryModule) {
         discoveryModule.addDiscoveryType("ec2", Ec2Discovery.class);
+        discoveryModule.addUnicastHostProvider(AwsEc2UnicastHostsProvider.class);
     }
 }
diff --git a/plugins/repository-s3/rest-api-spec/test/repository_s3/20_repository.yaml b/plugins/repository-s3/rest-api-spec/test/repository_s3/20_repository.yaml
index 69b50b6..9891c3e 100644
--- a/plugins/repository-s3/rest-api-spec/test/repository_s3/20_repository.yaml
+++ b/plugins/repository-s3/rest-api-spec/test/repository_s3/20_repository.yaml
@@ -1,6 +1,9 @@
 # Integration tests for Repository S3 component
 #
 "S3 repository can be registereed":
+    - skip:
+        version: "all"
+        reason:  does not work on java9, see https://github.com/aws/aws-sdk-java/pull/432
     - do:
         snapshot.create_repository:
           repository: test_repo_s3_1
diff --git a/pom.xml b/pom.xml
index cb4de2a..ceef389 100644
--- a/pom.xml
+++ b/pom.xml
@@ -45,7 +45,7 @@
 
         <!-- libraries -->
         <lucene.version>5.4.0</lucene.version>
-        <lucene.snapshot.revision>1701068</lucene.snapshot.revision>
+        <lucene.snapshot.revision>1702265</lucene.snapshot.revision>
         <lucene.maven.version>5.4.0-snapshot-${lucene.snapshot.revision}</lucene.maven.version>
         <testframework.version>2.1.16</testframework.version>
         <jackson.version>2.5.3</jackson.version>
@@ -115,8 +115,8 @@
         <tests.ifNoTests>fail</tests.ifNoTests>
         <skip.unit.tests>${skipTests}</skip.unit.tests>
         <skip.integ.tests>${skipTests}</skip.integ.tests>
-        <integ.scratch>${project.build.directory}/integ-tests</integ.scratch>
-        <integ.deps>${project.build.directory}/integ-deps</integ.deps>
+        <integ.scratch>${project.build.directory}/integ tests</integ.scratch>
+        <integ.deps>${project.build.directory}/integ deps</integ.deps>
         <integ.temp>${integ.scratch}/temp</integ.temp>
         <integ.http.port>9400</integ.http.port>
         <integ.transport.port>9500</integ.transport.port>
@@ -582,7 +582,7 @@
                             <arg>-XDignore.symbol.file</arg>
                             <arg>-Xlint:all</arg>
                             <arg>${xlint.options}</arg>
-                            <arg>-Werror</arg>
+                            <!-- DISABLED: incompatible with java 9 <arg>-Werror</arg> -->
                         </compilerArgs>
                     </configuration>
                 </plugin>
diff --git a/qa/smoke-test-client/src/test/java/org/elasticsearch/smoketest/ESSmokeClientTestCase.java b/qa/smoke-test-client/src/test/java/org/elasticsearch/smoketest/ESSmokeClientTestCase.java
index e18ca34..327bd2c 100644
--- a/qa/smoke-test-client/src/test/java/org/elasticsearch/smoketest/ESSmokeClientTestCase.java
+++ b/qa/smoke-test-client/src/test/java/org/elasticsearch/smoketest/ESSmokeClientTestCase.java
@@ -69,7 +69,7 @@ public abstract class ESSmokeClientTestCase extends LuceneTestCase {
      */
     public static final String TESTS_CLUSTER_DEFAULT = "localhost:9300";
 
-    protected static ESLogger logger = ESLoggerFactory.getLogger(ESSmokeClientTestCase.class.getName());
+    protected static final ESLogger logger = ESLoggerFactory.getLogger(ESSmokeClientTestCase.class.getName());
 
     private static final AtomicInteger counter = new AtomicInteger();
     private static Client client;
diff --git a/qa/vagrant/pom.xml b/qa/vagrant/pom.xml
index c2b6ca7..e31560d 100644
--- a/qa/vagrant/pom.xml
+++ b/qa/vagrant/pom.xml
@@ -167,6 +167,18 @@
                                 </artifactItem>
                                 <artifactItem>
                                     <groupId>org.elasticsearch.plugin</groupId>
+                                    <artifactId>discovery-ec2</artifactId>
+                                    <version>${elasticsearch.version}</version>
+                                    <type>zip</type>
+                                </artifactItem>
+                                <artifactItem>
+                                    <groupId>org.elasticsearch.plugin</groupId>
+                                    <artifactId>discovery-multicast</artifactId>
+                                    <version>${elasticsearch.version}</version>
+                                    <type>zip</type>
+                                </artifactItem>
+                                <artifactItem>
+                                    <groupId>org.elasticsearch.plugin</groupId>
                                     <artifactId>lang-javascript</artifactId>
                                     <version>${elasticsearch.version}</version>
                                     <type>zip</type>
@@ -179,13 +191,19 @@
                                 </artifactItem>
                                 <artifactItem>
                                     <groupId>org.elasticsearch.plugin</groupId>
+                                    <artifactId>mapper-murmur3</artifactId>
+                                    <version>${elasticsearch.version}</version>
+                                    <type>zip</type>
+                                </artifactItem>
+                                <artifactItem>
+                                    <groupId>org.elasticsearch.plugin</groupId>
                                     <artifactId>mapper-size</artifactId>
                                     <version>${elasticsearch.version}</version>
                                     <type>zip</type>
                                 </artifactItem>
                                 <artifactItem>
                                     <groupId>org.elasticsearch.plugin</groupId>
-                                    <artifactId>mapper-murmur3</artifactId>
+                                    <artifactId>repository-s3</artifactId>
                                     <version>${elasticsearch.version}</version>
                                     <type>zip</type>
                                 </artifactItem>
diff --git a/qa/vagrant/src/test/resources/packaging/scripts/30_deb_package.bats b/qa/vagrant/src/test/resources/packaging/scripts/30_deb_package.bats
index 8f60521..2579e6a 100644
--- a/qa/vagrant/src/test/resources/packaging/scripts/30_deb_package.bats
+++ b/qa/vagrant/src/test/resources/packaging/scripts/30_deb_package.bats
@@ -67,6 +67,17 @@ setup() {
     verify_package_installation
 }
 
+@test "[DEB] elasticsearch isn't started by package install" {
+    # Wait a second to give Elasticsearch a change to start if it is going to.
+    # This isn't perfect by any means but its something.
+    sleep 1
+    ! ps aux | grep elasticsearch | grep java
+    # You might be tempted to use jps instead of the above but that'd have to
+    # look like:
+    # ! sudo -u elasticsearch jps | grep -i elasticsearch
+    # which isn't really easier to read than the above.
+}
+
 @test "[DEB] test elasticsearch" {
     start_elasticsearch_service
 
diff --git a/qa/vagrant/src/test/resources/packaging/scripts/40_rpm_package.bats b/qa/vagrant/src/test/resources/packaging/scripts/40_rpm_package.bats
index 588fe38..09bb5b0 100644
--- a/qa/vagrant/src/test/resources/packaging/scripts/40_rpm_package.bats
+++ b/qa/vagrant/src/test/resources/packaging/scripts/40_rpm_package.bats
@@ -66,6 +66,13 @@ setup() {
     verify_package_installation
 }
 
+@test "[RPM] elasticsearch isn't started by package install" {
+    # Wait a second to give Elasticsearch a change to start if it is going to.
+    # This isn't perfect by any means but its something.
+    sleep 1
+    ! ps aux | grep elasticsearch | grep java
+}
+
 @test "[RPM] test elasticsearch" {
     start_elasticsearch_service
 
diff --git a/qa/vagrant/src/test/resources/packaging/scripts/60_systemd.bats b/qa/vagrant/src/test/resources/packaging/scripts/60_systemd.bats
index 8df4f4a..77e8d80 100644
--- a/qa/vagrant/src/test/resources/packaging/scripts/60_systemd.bats
+++ b/qa/vagrant/src/test/resources/packaging/scripts/60_systemd.bats
@@ -46,6 +46,14 @@ setup() {
     systemctl daemon-reload
 }
 
+@test "[SYSTEMD] daemon isn't enabled on restart" {
+    # Rather than restart the VM we just ask systemd if it plans on starting
+    # elasticsearch on restart. Not as strong as a restart but much much
+    # faster.
+    run systemctl is-enabled elasticsearch.service
+    [ "$output" = "disabled" ]
+}
+
 @test "[SYSTEMD] enable" {
     systemctl enable elasticsearch.service
 
diff --git a/qa/vagrant/src/test/resources/packaging/scripts/70_sysv_initd.bats b/qa/vagrant/src/test/resources/packaging/scripts/70_sysv_initd.bats
index 5bf4316..4f134ba 100644
--- a/qa/vagrant/src/test/resources/packaging/scripts/70_sysv_initd.bats
+++ b/qa/vagrant/src/test/resources/packaging/scripts/70_sysv_initd.bats
@@ -37,11 +37,31 @@ setup() {
     skip_not_dpkg_or_rpm
 }
 
+@test "[INIT.D] remove any leftover configuration to start elasticsearch on restart" {
+    # This configuration can be added with a command like:
+    # $ sudo update-rc.d elasticsearch defaults 95 10
+    # but we want to test that the RPM _doesn't_ add it on its own.
+    # Note that it'd be incorrect to use:
+    # $ sudo update-rc.d elasticsearch disable
+    # here because that'd prevent elasticsearch from installing the symlinks
+    # that cause it to be started on restart.
+    sudo update-rc.d -f elasticsearch remove
+}
+
 @test "[INIT.D] install elasticsearch" {
     clean_before_test
     install_package
 }
 
+@test "[INIT.D] daemon isn't enabled on restart" {
+    # Rather than restart the VM which would be slow we check for the symlinks
+    # that init.d uses to restart the application on startup.
+    ! find /etc/rc[0123456].d | grep elasticsearch
+    # Note that we don't use -iname above because that'd have to look like:
+    # [ $(find /etc/rc[0123456].d -iname "elasticsearch*" | wc -l) -eq 0 ]
+    # Which isn't really clearer than what we do use.
+}
+
 @test "[INIT.D] start" {
     service elasticsearch start
 
diff --git a/qa/vagrant/src/test/resources/packaging/scripts/plugin_test_cases.bash b/qa/vagrant/src/test/resources/packaging/scripts/plugin_test_cases.bash
index ebd23ee..24900aa 100644
--- a/qa/vagrant/src/test/resources/packaging/scripts/plugin_test_cases.bash
+++ b/qa/vagrant/src/test/resources/packaging/scripts/plugin_test_cases.bash
@@ -83,11 +83,6 @@ else
     }
 fi
 
-@test "[$GROUP] install jvm-example plugin" {
-    install_jvm_example
-    remove_jvm_example
-}
-
 @test "[$GROUP] install jvm-example plugin with a custom path.plugins" {
     # Clean up after the last time this test was run
     rm -rf /tmp/plugins.*
@@ -132,54 +127,181 @@ fi
     remove_jvm_example
 }
 
+# Note that all of the tests from here to the end of the file expect to be run
+# in sequence and don't take well to being run one at a time.
+@test "[$GROUP] install jvm-example plugin" {
+    install_jvm_example
+}
+
 @test "[$GROUP] install icu plugin" {
-    install_and_remove_special_plugin analysis icu icu4j-*.jar
+    install_and_check_plugin analysis icu icu4j-*.jar
 }
 
 @test "[$GROUP] install kuromoji plugin" {
-    install_and_remove_special_plugin analysis kuromoji
+    install_and_check_plugin analysis kuromoji
 }
 
 @test "[$GROUP] install phonetic plugin" {
-    install_and_remove_special_plugin analysis phonetic commons-codec-*.jar
+    install_and_check_plugin analysis phonetic commons-codec-*.jar
 }
 
 @test "[$GROUP] install smartcn plugin" {
-    install_and_remove_special_plugin analysis smartcn
+    install_and_check_plugin analysis smartcn
 }
 
 @test "[$GROUP] install stempel plugin" {
-    install_and_remove_special_plugin analysis stempel
-}
-
-@test "[$GROUP] install aws plugin" {
-    install_and_remove_special_plugin cloud aws aws-java-sdk-core-*.jar
+    install_and_check_plugin analysis stempel
 }
 
 @test "[$GROUP] install azure plugin" {
-    install_and_remove_special_plugin cloud azure azure-core-*.jar
+    install_and_check_plugin cloud azure azure-core-*.jar
 }
 
 @test "[$GROUP] install gce plugin" {
-    install_and_remove_special_plugin cloud gce google-api-client-*.jar
+    install_and_check_plugin cloud gce google-api-client-*.jar
 }
 
-@test "[$GROUP] install delete by query" {
-    install_and_remove_special_plugin - delete-by-query
+@test "[$GROUP] install delete by query plugin" {
+    install_and_check_plugin - delete-by-query
+}
+
+@test "[$GROUP] install ec2 discovery plugin" {
+    install_and_check_plugin discovery ec2 aws-java-sdk-core-*.jar
+}
+
+@test "[$GROUP] install multicast discovery plugin" {
+    install_and_check_plugin discovery multicast
 }
 
 @test "[$GROUP] install javascript plugin" {
-    install_and_remove_special_plugin lang javascript rhino-*.jar
+    install_and_check_plugin lang javascript rhino-*.jar
 }
 
 @test "[$GROUP] install python plugin" {
-    install_and_remove_special_plugin lang python jython-standalone-*.jar
+    install_and_check_plugin lang python jython-standalone-*.jar
+}
+
+@test "[$GROUP] install murmur3 mapper plugin" {
+    install_and_check_plugin mapper murmur3
 }
 
-@test "[$GROUP] install murmur3 mapper" {
-    install_and_remove_special_plugin mapper murmur3
+@test "[$GROUP] install size mapper plugin" {
+    install_and_check_plugin mapper size
+}
+
+@test "[$GROUP] install s3 repository plugin" {
+    install_and_check_plugin repository s3 aws-java-sdk-core-*.jar
+}
+
+@test "[$GROUP] install site example" {
+    # Doesn't use install_and_check_plugin because this is a site plugin
+    install_plugin site-example $(readlink -m site-example-*.zip)
+    assert_file_exist "$ESHOME/plugins/site-example/_site/index.html"
+}
+
+@test "[$GROUP] start elasticsearch with all plugins installed" {
+    start_elasticsearch_service
+}
+
+@test "[$GROUP] check the installed plugins matches the list of build plugins" {
+    curl -s localhost:9200/_cat/plugins?h=c | sed 's/ *$//' |
+        sort > /tmp/installed
+    ls /elasticsearch/plugins/*/pom.xml | cut -d '/' -f 4 |
+        sort > /tmp/expected
+    echo "Checking installed plugins (<) against the plugins directory (>):"
+    diff /tmp/installed /tmp/expected
+}
+
+@test "[$GROUP] stop elasticsearch" {
+    stop_elasticsearch_service
+}
+
+@test "[$GROUP] remove jvm-example plugin" {
+    remove_jvm_example
+}
+
+@test "[$GROUP] remove icu plugin" {
+    remove_plugin analysis-icu
+}
+
+@test "[$GROUP] remove kuromoji plugin" {
+    remove_plugin analysis-kuromoji
+}
+
+@test "[$GROUP] remove phonetic plugin" {
+    remove_plugin analysis-phonetic
+}
+
+@test "[$GROUP] remove smartcn plugin" {
+    remove_plugin analysis-smartcn
+}
+
+@test "[$GROUP] remove stempel plugin" {
+    remove_plugin analysis-stempel
+}
+
+@test "[$GROUP] remove aws plugin" {
+    remove_plugin cloud-aws
+}
+
+@test "[$GROUP] remove azure plugin" {
+    remove_plugin cloud-azure
+}
+
+@test "[$GROUP] remove gce plugin" {
+    remove_plugin cloud-gce
+}
+
+@test "[$GROUP] remove delete by query plugin" {
+    remove_plugin delete-by-query
+}
+
+@test "[$GROUP] remove ec2 discovery plugin" {
+    remove_plugin discovery-ec2
+}
+
+@test "[$GROUP] remove multicast discovery plugin" {
+    remove_plugin discovery-multicast
+}
+
+@test "[$GROUP] remove javascript plugin" {
+    remove_plugin lang-javascript
+}
+
+@test "[$GROUP] remove python plugin" {
+    remove_plugin lang-python
+}
+
+@test "[$GROUP] remove murmur3 mapper plugin" {
+    remove_plugin mapper-murmur3
+}
+
+@test "[$GROUP] remove size mapper plugin" {
+    remove_plugin mapper-size
+}
+
+@test "[$GROUP] remove s3 repository plugin" {
+    remove_plugin repository-s3
+}
+
+@test "[$GROUP] remove site example plugin" {
+    remove_plugin site-example
+}
+
+@test "[$GROUP] start elasticsearch with all plugins removed" {
+    start_elasticsearch_service
+}
+
+@test "[$GROUP] check that there are now no plugins installed" {
+    curl -s localhost:9200/_cat/plugins > /tmp/installed
+    local installedCount=$(cat /tmp/installed | wc -l)
+    [ "$installedCount" == "0" ] || {
+        echo "Expected all plugins to be removed but found $installedCount:"
+        cat /tmp/installed
+        false
+    }
 }
 
-@test "[$GROUP] install size mapper" {
-    install_and_remove_special_plugin mapper size
+@test "[$GROUP] stop elasticsearch" {
+    stop_elasticsearch_service
 }
diff --git a/qa/vagrant/src/test/resources/packaging/scripts/plugins.bash b/qa/vagrant/src/test/resources/packaging/scripts/plugins.bash
index 2ca6e75..787f774 100644
--- a/qa/vagrant/src/test/resources/packaging/scripts/plugins.bash
+++ b/qa/vagrant/src/test/resources/packaging/scripts/plugins.bash
@@ -36,6 +36,12 @@ install_plugin() {
 
     assert_file_exist "$ESPLUGINS/$name"
     assert_file_exist "$ESPLUGINS/$name/plugin-descriptor.properties"
+}
+
+install_jvm_plugin() {
+    local name=$1
+    local path="$2"
+    install_plugin $name "$path"
     assert_file_exist "$ESPLUGINS/$name/$name"*".jar"
 }
 
@@ -53,7 +59,7 @@ remove_plugin() {
 # placements for non-site plugins.
 install_jvm_example() {
     local relativePath=${1:-$(readlink -m jvm-example-*.zip)}
-    install_plugin jvm-example "$relativePath"
+    install_jvm_plugin jvm-example "$relativePath"
 
     assert_file_exist "$ESHOME/bin/jvm-example"
     assert_file_exist "$ESHOME/bin/jvm-example/test"
@@ -74,14 +80,14 @@ remove_jvm_example() {
     assert_file_exist "$ESCONFIG/jvm-example/example.yaml"
 }
 
-# Install and remove a plugin with a special prefix. For the most part prefixes
-# are just useful for grouping but the "analysis" prefix is special because all
+# Install a plugin with a special prefix. For the most part prefixes are just
+# useful for grouping but the "analysis" prefix is special because all
 # analysis plugins come with a corresponding lucene-analyzers jar.
 # $1 - the prefix
 # $2 - the plugin name
 # $@ - all remaining arguments are jars that must exist in the plugin's
 #      installation directory
-install_and_remove_special_plugin() {
+install_and_check_plugin() {
     local prefix=$1
     shift
     local name=$1
@@ -93,12 +99,11 @@ install_and_remove_special_plugin() {
         local fullName="$prefix-$name"
     fi
 
-    install_plugin $fullName "$(readlink -m $fullName-*.zip)"
+    install_jvm_plugin $fullName "$(readlink -m $fullName-*.zip)"
     if [ $prefix == 'analysis' ]; then
         assert_file_exist "$(readlink -m $ESPLUGINS/$fullName/lucene-analyzers-$name-*.jar)"
     fi
     for file in "$@"; do
         assert_file_exist "$(readlink -m $ESPLUGINS/$fullName/$file)"
     done
-    remove_plugin $fullName
 }
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/test/cat.nodeattrs/10_basic.yaml b/rest-api-spec/src/main/resources/rest-api-spec/test/cat.nodeattrs/10_basic.yaml
index f076a3b..5f6e3e9 100755
--- a/rest-api-spec/src/main/resources/rest-api-spec/test/cat.nodeattrs/10_basic.yaml
+++ b/rest-api-spec/src/main/resources/rest-api-spec/test/cat.nodeattrs/10_basic.yaml
@@ -1,30 +1,64 @@
 ---
-"Test cat nodes attrs output":
+"Help":
+  - do:
+      cat.nodeattrs:
+        help: true
 
-  - skip:
-      version:  "all"
-      reason:   "Waiting for #12558"
+  - match:
+      $body: |
+               /^  node   .+ \n
+                   id     .+ \n
+                   pid    .+ \n
+                   host   .+ \n
+                   ip     .+ \n
+                   port   .+ \n
+                   attr   .+ \n
+                   value  .+ \n
+               $/
 
+---
+"Test cat nodes attrs output":
   - do:
       cat.nodeattrs: {}
-
-  - match:
+  - match: # All attributes look good
+      $body: |
+               /^#  node\s+         host\s+ ip\s+                   attr\s+     value\s* \n
+                    (((\S+\s?){1,10})\s+(\S+)\s+(\d{1,3}\.){3}\d{1,3}\s+(\S+)\s+    (\S+)\s* \n)+
+               $/
+  - match: # A specific planted attribute is present and looks good
       $body: |
-               /((\S+)\s+(\S+)\s+(\d{1,3}\.){3}\d{1,3}\s+(\S+)\s+(\S+)\s*)+/
+               /#   node\s+         host\s+ ip\s+                   attr\s+     value\s* \n
+                    ((\S+\s?){1,10})\s+ (\S+)\s+(\d{1,3}\.){3}\d{1,3}\s+testattr\s+ test \s* \n
+               /
+  # Note for future editors: its quite possible to construct a regex with an
+  # intense amount of backtracking if you use something like (\S\s?)+ to match
+  # node name.
 
   - do:
       cat.nodeattrs:
         v: true
-
-  - match:
+  - match: # All attributes look good including the heading
       $body: |
-               /((\S+)\s+(\S+)\s+(\d{1,3}\.){3}\d{1,3}\s+(\S+)\s+(\S+)\s*)+/
+               /^   node\s+        host\s+ ip\s+                   attr\s+     value\s* \n
+                    (((\S+\s?){1,10})\s+(\S+)\s+(\d{1,3}\.){3}\d{1,3}\s+(\S+)\s+    (\S+)\s* \n)+
+               $/
+  - match: # A specific planted attribute is present and looks good
+      $body: |
+               /#   node\s+        host\s+ ip\s+                   attr\s+     value\s* \n
+                    ((\S+\s?){1,10})\s+ (\S+)\s+(\d{1,3}\.){3}\d{1,3}\s+testattr\s+ test \s* \n
+               /
 
   - do:
       cat.nodeattrs:
           h: attr,value
           v: true
-
-  - match:
+  - match: # All attributes look good
+      $body: |
+               /^   attr\s+     value\s*\n
+                    ((\S+)\s+   (\S+)\s*)+
+               $/
+  - match: # A specific planted attribute is present and looks good
       $body: |
-               /((\S+)\s+(\S+)\s*)+/
+               /#   attr\s+     value\s*\n
+                    testattr\s+ test\s*\n
+               /
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/test/cat.recovery/10_basic.yaml b/rest-api-spec/src/main/resources/rest-api-spec/test/cat.recovery/10_basic.yaml
index 4bc3e99..c34437c 100755
--- a/rest-api-spec/src/main/resources/rest-api-spec/test/cat.recovery/10_basic.yaml
+++ b/rest-api-spec/src/main/resources/rest-api-spec/test/cat.recovery/10_basic.yaml
@@ -28,8 +28,8 @@
                 index1      \s+
                 \d          \s+                                 # shard
                 \d+         \s+                                 # time
-                (store|replica|snapshot|relocating)     \s+   # type
-                (init|index|start|translog|finalize|done) \s+   # stage
+                (store|replica|snapshot|relocating)     \s+     # type
+                (init|index|verify_index|translog|finalize|done) \s+ # stage
                 [-\w./]+    \s+                                 # source_host
                 [-\w./]+    \s+                                 # target_host
                 [-\w./]+    \s+                                 # repository
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/test/cat.shards/10_basic.yaml b/rest-api-spec/src/main/resources/rest-api-spec/test/cat.shards/10_basic.yaml
index 40f8740..766d178 100755
--- a/rest-api-spec/src/main/resources/rest-api-spec/test/cat.shards/10_basic.yaml
+++ b/rest-api-spec/src/main/resources/rest-api-spec/test/cat.shards/10_basic.yaml
@@ -39,6 +39,7 @@
                     indexing.index_current           .+   \n
                     indexing.index_time              .+   \n
                     indexing.index_total             .+   \n
+                    indexing.index_failed            .+   \n
                     merges.current                   .+   \n
                     merges.current_docs              .+   \n
                     merges.current_size              .+   \n
